"{\"title\":\"\",\"courses\":[{\"course_title\":\"Python for Data Science and Machine Learning Essential Training Part 1\",\"course_admin_id\":3006708,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3006708,\"Project ID\":null,\"Course Name\":\"Python for Data Science and Machine Learning Essential Training Part 1\",\"Course Name EN\":\"Python for Data Science and Machine Learning Essential Training Part 1\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;&lt;i&gt;Python for Data Science and Machine Learning Essential Training&lt;/i&gt; is one of the most popular data science courses at LinkedIn Learning. It has now been updated and expanded to two parts-giving you even more hands-on, real-world Python experience. In part one, instructor Lillian Pierson takes you step by step through a data science and machine learning project: a web scraper that downloads and analyzes data from the web. Along the way, she introduces techniques to clean, reformat, transform, and describe raw data; generate visualizations; remove outliers; perform simple data analysis; and generate web-based graphs using Streamlit. By the end of this course, you'll have acquired basic coding experience that you can take to your organization and quickly apply to your own custom data science and machine learning projects.&lt;/p&gt;&lt;p&gt;This course is integrated with GitHub Codespaces, an instant cloud developer environment that offers all the functionality of your favorite IDE without the need for any local machine setup. With GitHub Codespaces, you can get hands-on practice from any machine, at any time-all while using a tool that you'll likely encounter in the workplace. Check out the Using GitHub Codespaces with this course video to learn how to get started.&lt;/p&gt;\",\"Course Short Description\":\"Learn Python programming skills for data science and machine learning. Discover how to clean, transform, analyze, and visualize data, as you build a practical, real-world project.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":8464985,\"Instructor Name\":\"Lillian Pierson\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Engineer, CEO, and Head of Product at Data-Mania\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-03-12T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/python-for-data-science-and-machine-learning-essential-training-part-1,https://www.linkedin.com/learning/python-for-data-science-and-machine-learning-essential-training-part-1-2024-revision,https://www.linkedin.com/learning/python-for-data-science-essential-training-part-1-2022-revision\",\"Series\":\"Essential Training\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":27863.0,\"Visible Video Count\":49.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":285,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2715030\",\"duration\":41,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Data science life hacks\",\"fileName\":\"3006708_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":46,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2176232,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Lillian] Have you ever wanted to be able to copy\\nand paste a bunch of data off a website\\nor just get the gist\\nof all the content without actually having to read\\nthrough line by line?\\nIf so, then great,\\nbecause I'm going to show you how\\nto build a web scraper in Python so that you can have\\nthat data written off of the web for you automatically.\\nAnd I'm also going to be introducing you to a Python library\\nthat you can use to visualize that data in a standalone,\\nshareable web application using just a few lines of code.\\n\\nHi, I'm Lillian Pearson.\\nI'm a data and AI strategist with nearly three decades\\nof experience working with data.\\nLet's get going on Python for Data Science.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4589016\",\"duration\":59,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you should know\",\"fileName\":\"3006708_en_US_00_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":103,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1295829,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] As far as what\\nyou should know for this course,\\nwe'll be programming in Python,\\nbut you don't need to have\\nany prior Python experience to take this course.\\nWe are going to be using Jupyter Notebooks\\nas our interactive programming environment.\\nIn case you've never worked with Jupyter Notebooks before,\\nthen, you can go check out\\nthe work with Jupyter Notebooks video,\\nin the course Python programming efficiently\\nin the LinkedIn Learning Library.\\n\\nDon't worry too much about the notebooks\\npart of this course, though,\\nbecause you'll be getting the course notebooks\\nwith the Codespaces environment.\\nMore on Codespaces in the next video, by the way.\\nLastly, as for the math and statistics requirements\\nfor this course, there are no\\nreal math or stats prerequisites.\\nI'm going to be taking you through everything\\nyou need to know during the course.\\nSo, let's get started.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4589017\",\"duration\":185,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"How to use Codespaces with this course\",\"fileName\":\"3006708_en_US_00_03_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":332,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6859569,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's look at how to configure code spaces.\\nTo begin head over to the courses repository\\nand then select this green code button.\\nSelect the Code Spaces tab,\\nand then click this plus icon\\nto create a code space on main.\\nThis action launches a new tab to prepare your code space,\\nwhich might take some time to complete,\\nso we'll revisit once it's ready.\\n\\nOkay, so as you can see, the Code Spaces is now launched,\\nand you'll find yourself in a web-based working environment\\nthat looks like this.\\nHow Code Spaces works is\\nthat essentially it initiates a virtual machine providing\\nyou a web interface with which to interact.\\nWithin the terminal here\\nyou're free to execute common Linux commands\\nand Python scripts.\\nWe'll be using the terminal\\nto build Streamlit applications in\\nchapter eight of this course.\\n\\nFor our course,\\nsimply open this folder here called Notebooks.\\nThis is the primary folder for the course,\\nbut just so you know, chapter eight scripts are housed in\\nthis folder here called Streamlit.\\nNow let me show you how to open a Jupyter Notebook.\\nLet's click on the 0403 iPython notebook file.\\n\\nDo a double click, and it opens up a Jupyter Notebook.\\nOnce you're inside the notebook, well,\\nfirst thing I like to do is just close this terminal\\nbecause we don't need it when we're working\\ninside of a notebook.\\nSo let's look at how\\nto run a cell within a Jupyter Notebook.\\nSo just click on this first code cell here\\nand press control, enter to execute it.\\nAnd it's connecting here to, you could see it was connecting\\nto a Python kernel,\\nand it's already run, so that's great.\\n\\nWhen you see this check mark here,\\nyou know that the code is finished running,\\nand this timestamp indicates how long it took\\nfor the program to run.\\nAnd this demo has now guided you\\nthrough opening a project on GitHub, creating a code space,\\nopening a Jupyter Notebook,\\nand executing it via code spaces.\\nI find Code Spaces to be a handy GitHub product.\\nIt simplifies project initiation, removing a lot\\nof the hassle involved in environment configuration.\\n\\nIt's particularly useful for those people\\nwho might be a little less familiar\\nwith Python's virtual environments.\\n\"}],\"name\":\"Introduction\",\"size\":10331630,\"urn\":\"urn:li:learningContentChapter:2714164\"},{\"duration\":1598,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4583158\",\"duration\":823,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to the data professions\",\"fileName\":\"3006708_en_US_01_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":1050,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to orient yourself in the data world. This video covers the definition of data science, data engineering, and data analytics.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":21506363,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Narrator] Welcome to Introduction\\nto the Data Professions.\\nThe conversation we're about to have is really important\\nto people who are aspiring to become data scientists\\nbecause it's vital that you understand\\nwhere you will fit in within the data profession spectrum,\\nwhen you actually do level up\\nand become a trained data scientist.\\nThe thing about the data space in general\\nis that there are many, many different types of roles,\\nand although there may be similarities\\nbetween the objectives that these roles fill,\\nthe roles are actually quite different.\\n\\nSo when you're taking a training course in data science\\nand you aspire to become a data scientist,\\nyou really do need to have a fundamental idea\\nabout where you fit in and what your responsibilities\\nand requirements should be\\nwith respect to other data professionals.\\nSo you want to have that in mind\\nwhen you get placed in the field\\nin order that in case your employer\\nis asking you to do something\\nthat is outside the scope of data science per se,\\nyou want to know that actually you transitioning your career\\ninto a similar, yet competing field.\\n\\nSo first, let's just talk about the functions\\nwithin the data space.\\nI've broken these down into data science,\\ndata engineering, data analytics, and business intelligence.\\nThese four functions work together\\nto generate business value from data.\\nWhat I really encourage you to do\\nif you're just getting started on your path\\ntowards becoming a data professional,\\nis to focus on mastering one area\\nand then leaning in on your peers\\nthat are data professionals in the other areas.\\nSo don't try and master all of these areas all at one time\\nbecause it will really impede your progress.\\n\\nIt will make it slow\\nfor you to progress down one career path,\\nand it's also going to make it confusing for you.\\nSo this section of the course\\nis really to help you compartmentalize\\nwhere you fit in\\nand what this course is actually preparing you to do,\\nwhich is data science.\\nIf you really want to learn how to become a professional\\nthat serves more than one of these functions,\\nthen I at least suggest\\nthat you master each function one at a time\\nand not try and master them all at the same time\\nbecause that's just going to make it harder for you\\nand result in you making slower progress\\nin your skill development.\\n\\nNow, let's talk about why we need clarity\\non this subject in and of itself.\\nSee, you're really the one who gets to decide\\nwhere you fit in best within a data profession.\\nSo I want to make sure that you are prepared\\nand that you can be deliberate in choosing\\nwhat you actually want to do\\nand not just what you happen to fall into\\nor what you happen to pick up\\nby basically being forced\\nto be the jack of all trades, right?\\nSo I'm trying to give a choice here\\nand a vision whereabouts\\nyou can be deliberate in the advancement of your career\\nas a data professional.\\n\\nI want you to be fully aware\\nof what you're actually signing up for\\nbefore you decide to move further\\ninto the data science space\\nor become a data scientist.\\nAnd there's lots of good news here.\\nThere's plenty of demands for skills in all of these areas,\\nand there are emerging roles\\nwithin the data space all of the time.\\nSo you're going to have opportunity as a data professional,\\nbut we do want to have clarity here\\nbecause basically less confusion in your mind\\nequals more results.\\n\\nAnd I want to make it easier for you to make this transition\\nto the data professions.\\nThat's why I'm clarifying this topic for you\\nso you can get results faster.\\nThis is a course on data science.\\nSo naturally we'll start with the data science rule.\\nAnd what data science really is\\nit's a systematic study of the structure\\nand behavior of data\\nin order to quantifiably understand past\\nand current occurrences\\nas well as to predict the future behavior of data.\\n\\nLet's look at some of the traits\\nof a typical data scientist.\\nData scientists generally should have a degree\\nin a quantitative field.\\nSo if you are already having a STEM degree,\\nit's going to be a lot easier for you\\nto transition into a data science role\\ncompared to if you are of a liberal arts background\\nor something like that.\\nAnother thing is that data scientists are programmers,\\nso they should really know how to program in R and Python,\\nand also how to write SQL queries, things like that.\\n\\nData scientists, by personality, well they're curious\\nand they're tenacious individuals,\\nso they're willing to really stick it out\\nuntil they get the findings and results that they need.\\nIf you have a background\\nin business intelligence reporting, data analysis,\\nor data-driven decision making,\\nthen you're a good candidate\\nfor looking into maybe stepping up\\ninto a data scientist role.\\nGenerally, data scientists are interested in why over how.\\n\\nSo they're looking for the patterns and correlations\\nand the trends and that basically indicate\\nwhy something is happening, not how it's happening.\\nThe reason for that\\nis that they're looking to make predictions.\\nSo once you understand why something is happening\\nthe way it's happening,\\nyou can then make predictions based on that why.\\nData scientists are known to spend hours and hours,\\nif not days, analyzing complex questions.\\nSo if you're a people person\\nand like to spend most of your time consulting\\nand working with people,\\nthen becoming a data scientist\\nmight not be the most fulfilling thing for you.\\n\\nNow, let's look at some of the typical tasks\\nthat data scientists are required to do.\\nData scientists in general derive insights from data,\\nincluding big data sets.\\nSo if you've been around in the field for a while,\\nthen you probably know what big data is.\\nIt's actually a term that's decreasing in popularity.\\nBut big data just means data of many different structures,\\nmany different velocities and many different varieties.\\nAnd a data scientist's job is to derive insights from data.\\n\\nThat data is probably going\\nto be sitting in a data engineered system.\\nAnd when I say data engineered system,\\nI mean if you're working on data\\nthat's being derived from big data,\\nthen it's probably going to be in a more innovative system\\nthan just the traditional\\nrelational database management system.\\nAlthough you may also be pulling data\\nfrom relational databases,\\njust like statisticians and business intelligence people\\nhave been doing for many, many decades.\\n\\nThe next type of task that data scientists do\\nis that they uncover correlations\\nand causations in business data\\nto support business decision making.\\nSo what this is actually called is decision support,\\nand the name makes sense in light of the task\\nassociated with that requirement.\\nAnother typical task that data scientists do\\nis they generate predictions from data\\nand communicate those predictions\\nthrough data visualization.\\nIn terms of competencies\\nthat are generally required of data scientists,\\nyou should have a STEM degree\\nwith some advanced mathematics.\\n\\nSo if you finish your calculus\\nand have gone into differential equations,\\nthat would be a good setup.\\nYou will also need to take fundamental statistics,\\nbut if you've gone into linear algebra\\nand these types of topics during your college education,\\nthen you're going to be in a good place\\nto try and move into the data science role.\\nData scientists also need to know how to code,\\nso they should know how to code\\nin languages like Python, R, and SQL.\\nThey should know how to use coding\\nto implement machine learning algorithms.\\n\\nSo these are basic typical competencies\\nthat are required of data scientists.\\nAnd just to put things into perspective,\\nthis course is Python for data science.\\nSo we'll be discussing some basic math,\\nand we'll be doing a high level overview\\nof machine learning algorithms\\nand the math that goes into them.\\nYou're going to be learning to use Python\\nto implement these.\\nThis is a coding course that's going to be teaching you\\nhow to implement data science methodologies.\\n\\nNow that you know what a data scientist is,\\nlet's compare that to a data engineer.\\nData engineering is the design,\\nconstruction and maintenance of data systems.\\nAs far as typical traits, data engineers are programmers,\\nthey're good at math, but honestly,\\nthey don't use advanced statistics\\nand really advanced mathematics very often.\\nTheir previous experience is likely to be something\\nlike working as a database architect\\nor an ETL developer,\\nwhich is extract, transform, and load.\\n\\nIt's just a process which is used to move data\\nfrom one storage system to another.\\nOther rules they may have had in the past\\nwould be database developer or security architect.\\nSo people that work as data engineers,\\nthey prefer to design\\nand build IT systems rather than to analyze data.\\nSo it's really a shift in scope.\\nData engineers are generally interested more\\nin how over why,\\nbecause they're actually building the systems\\nthat hold the data,\\nthat data scientists analyze,\\nand so they really need to build reliable systems.\\n\\nThey need to focus on how to actually get that done,\\nand they're not as much interested in uncovering the whys\\nthat are contained within that data.\\nObviously, you can see there's a bit of a scope shift there.\\nIn terms of typical tasks,\\ndata engineers design systems that collect, handle,\\nand store big data sets.\\nThey work to build modular,\\nscalable platforms for data processing,\\nand they also design,\\nbuild and maintain systems that store\\nand move big data and regular types of data as well.\\n\\nIn terms of typical competencies, people that work\\nas data engineers generally should have\\ngood computer science background,\\na background in software engineering.\\nAnd then in terms of coding requirements,\\nthey should generally know languages\\nlike Java, C++, and Python.\\nAnd moving into the data analytics professionals.\\nFirst, let's start off by what is data analytics?\\nData analytics are data products\\nthat describe data and how it behaves.\\n\\nSo these data products are generated\\nfrom data analysis and visualization processes,\\nand the people that are generally functioning\\nwithin a data analytics role would be titled something\\nlike analytics specialist or analytics expert.\\nThe role of analytics professionals\\nhas evolved significantly over the past few years.\\nIn 2023, analytics professionals are expected\\nto have a strong understanding of data science,\\nmachine learning, and artificial intelligence.\\n\\nThey're also expected to be proficient\\nin coding languages like Python and R\\nand be able to use advanced tools and platforms.\\nThey need to have a solid background in math and statistics,\\nand they also need to understand\\nthe business context in which they're working.\\nThey're often responsible\\nfor translating complex data insights\\ninto actionable business tactics and strategies.\\nIn terms of typical tasks,\\nanalytics specialists generate predictive,\\nprescriptive, and descriptive data insights.\\n\\nAnd of course, right now you are probably not exactly clear\\non what those terms actually mean,\\nbut don't worry because we're going to cover that later\\nin this course.\\nJust know that analytics specialists\\nuncover correlations and causations in business data\\nto support business decision making.\\nSo yes, they operate in a decision support function.\\nHowever, they're oftentimes achieving this outcome\\nby using applications.\\n\\nThey're often called to deploy analytics technologies\\nand software applications to generate their findings\\nand then return those insights\\nto business decision makers\\nin order to help them lead their organization\\nand become more data driven.\\nThe challenge for you in this section\\nis that I want you to sit back\\nand really think about yourself\\nand your background and your true passions,\\nand then decide which of these fields\\nreally sounds like the best fit\\nfor what you actually love doing.\\n\\nBecause you're going to thrive\\nif you are operating in a capacity\\nthat is the best fit for your personality,\\nfor your passion, and for your interests, right?\\nSo I want to encourage you to place yourself\\nin one of these three roles that we outlined here,\\nand then go ahead and just pursue that.\\nLet that be your focus for this journey in your career.\\nHopefully you will find\\nthat you are interested in pursuing the data science path\\nbecause this course is Python for data science,\\nand you're going to learn a lot about Python\\nand using it to implement data science\\nover the next several hours.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4588022\",\"duration\":297,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Data science careers: Identifying where and how you'll thrive\",\"fileName\":\"3006708_en_US_01_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":502,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn about three main types of data science careers, as well as info on how data science is creating remarkable changes in all industries, especially the software industry.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13100151,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Narrator] For someone taking\\nan entry-level data science course,\\nit would be easy to assume\\nthat once you've developed data science skills,\\nyou will then become a data analyst or a data scientist.\\nAnd for some people that might be true,\\nbut oftentimes, people with data science skills\\ndon't actually work as data analysts or data scientists.\\nIn fact, by 2023, over 50 types of roles\\nhad begun to require applicants to have data science skills.\\n\\nThe fact of the matter is\\nthere are really three different types\\nof data science professional,\\nand where you fit in with these really depends a lot\\non your passion and unique talents.\\nAs I see it, all data science professionals\\ncan be classified as either a data implementer,\\na data leader or a data entrepreneur.\\nBut the long and the short of it is\\ndespite the surging demand,\\nnot everyone should seek to become a data scientist.\\n\\nIn fact, pursuing that goal\\nwhen the data scientist role is not aligned\\nwith your personality is\\nsetting yourself up for disappointment.\\nSpeaking of data scientists though,\\nlet's see where they fit in\\nwithin the three-tiered ecosystem\\nof data science professionals.\\nAs you can see here, the data scientist position\\nis classified with other implementation focused roles\\nlike machine learning engineer and enterprise architect.\\n\\nData implementers are the people we can thank\\nfor coding up all of these amazing applications\\nthat make our lives today so much easier\\nand so much more interesting.\\nImplementers love to code and focus on details.\\nThey're generally happy to code on their own all day long,\\nso long as that means that they don't have to talk to\\nor interact with other people all that much.\\nA recent market research shows that data implementers\\ngenerally earn anywhere between $60,000 to $120,000 per year\\nin salary in the United States.\\n\\nBut what if you love working with people\\nand you really need to see that big picture impact\\nof your work in order to be satisfied\\nin your professional life?\\nNot to worry.\\nPeople like this are just as needed and wanted\\nin the data science space as the data implementers.\\nThey're called data leaders.\\nData leaders are the people who have data science skills\\nand are responsible for leading teams\\nand project stakeholders through the process\\nof building successful data solutions.\\n\\nData science leaders often hold titles like\\nanalytics program manager, data product manager\\nand continuous improvements manager,\\nand their salaries average from $45,000 to $110,000 per year\\nacross the US in general.\\nAnd if neither of these sounds like you,\\nthen you may be a good, old-fashioned data entrepreneur.\\n\\nOf course, as an entrepreneur,\\nyou can be either a data implementer\\nor a data leader in your own business.\\nAnd how you function within the business depends on\\nwhat you want to do since it's your business.\\nData entrepreneurs are distinguished\\nfrom their counterparts\\nby their desire for creative autonomy,\\nfinancial autonomy and their higher risk tolerance.\\nOf course, entrepreneurs who run their own business\\ngenerally hold the title of founder or CEO,\\nbut for people who are just starting off as entrepreneurs,\\nthey generally need to do services work for a while\\nuntil they can build out a more scalable business model.\\n\\nNew data science freelancers would fall into this category\\nand are often offering machine learning services,\\ndata strategy services, or even just data analysis services.\\nFor new entrepreneurs who are just starting off\\nas data science freelancers,\\nthey're often earning between $45 and $115 per hour\\nin the United States.\\nBut one of the nice things about having a business\\nis that the growth potential is pretty open-ended.\\nI mean, look at Facebook and how much money and impact\\nthat Mark Zuckerberg had with that platform.\\n\\nAt its core, Facebook is a data company.\\nNow that you know about the different types of options\\navailable to you with data analysis\\nand data science skills,\\nlet's look at why Python is such a great\\nprogramming language for analyzing data.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2714159\",\"duration\":384,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Why to use Python for analytics\",\"fileName\":\"3006708_en_US_01_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":554,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to justify your choice in using Python for data science. This video covers an intro to Python, Python for analytics, and Python in big data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10046349,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's talk about why it's a good idea\\nto use Python for working with data\\ninstead of any of the other competing coding languages\\nor methodologies you could use to implement data science.\\nFirst of all, let's look at\\nwhat are your alternatives to Python?\\nFor data science, of course, you can use Python,\\nwhich is the focus of this course,\\nbut you could also use R, Julia,\\nand a program called Go, short for Golang.\\n\\nLooking into the definition of Python,\\nwhat is the Python programming language?\\nWell, Python is a high-level interpreted coding language\\nthat's useful for a wide variety of applications,\\nand it's the official programming language of Google.\\nThe benefits to using Python are\\nthat it's extremely easy to learn and it's human readable.\\nIt's got an extensive array\\nof well-supported data science libraries,\\nand it's got the biggest user base\\nof all data science languages.\\n\\nAlso, it's useful in data engineering\\nas well as data science.\\nYou can use it\\nfor building predictive web applications as well.\\nIt's basically quite extensible, and you can use it\\nfor a lot of different applications areas,\\nnot just data science.\\nAlso, another thing that's preferable about Python is\\nthat it's an extremely popular coding language.\\nAs of 2023, Python is the most popular programming language\\nof all programming languages around.\\n\\nIn the TIOBE Index, a measure\\nof the programming language's popularity,\\nPython ranks first,\\nwhereas the ubiquitous querying language SQL\\nis ranked at position nine in popularity.\\nR is another widely used language, especially in the fields\\nof data science and research and statistics.\\nBut as of October 2023, R actually ranks\\nas 17th in the TIOBE Index.\\n\\nAnd Go is ranked at the 11th place.\\nJulia, which is a relatively new language\\nthat came out in 2018, has really been growing\\nin popularity, and as of October, 2023,\\nJulia ranks 28th in the TIOBE Index.\\nSo if you're using Python for data science,\\nyou're just going to be a lot better off,\\nbecause when you get stuck, there's going to be a lot\\nof people out there that are getting stuck\\nin the exact same way as you are, and it'll be easy for you\\nto find solutions on Stack Overflow.\\n\\nAlso, the libraries in Python are super well supported\\nbecause it's a popular language.\\nIt's the most popular language\\nof all coding languages out there.\\nAnd so these are just some of the advantages\\nof learning Python for data science\\nrather than R or its alternatives.\\nHere's a Google Trends screenshot\\nthat shows you the difference between Python\\nfor data science in blue and R for data science in red.\\nAs you can see, R for data science has never been able\\nto keep up in popularity with Python for data science.\\n\\nThe nice thing about Python that makes it so desirable,\\nand this is probably why most people are pursuing Python\\nfor data science, is that it's also popular\\nfor data engineering.\\nAs you can see here in blue, that is the search trends\\nfor Python for data engineering.\\nHonestly, more people are searching Python data engineering\\nthan they are Java data engineering.\\nPython's very, very popular for data science,\\nbut people are also interested in working\\nto build out its functionality\\nwith respect to data engineering as well.\\n\\nSo if you know Python, it's good for you\\nbecause you can do data science\\nand then you can expand into data engineering,\\nand then you could get into machine learning engineering,\\nanother role we'll talk about later in this course,\\nbut basically learning Python first is\\njust a really well-rounded decision\\nand will be better for you and your long-term future.\\nNow, let's talk about why use Python for working with data.\\nPython is useful for data science, data analytics,\\nand data engineering, like we just discussed,\\nbut it's also useful in a professional academic environment.\\n\\nPython is an open-source programming language,\\nand so you can use it for web development,\\napplication development, and heck,\\nyou can even use it to build out your own games.\\nSo it's very open-ended.\\nIf you know how to use Python, then you can function\\nin a lot of different types of tech roles.\\nYou don't necessarily need to stay in the data professions\\nfor the rest of your life and you could branch off\\ninto many, many different types of roles.\\n\\nThe same is not true of other programming languages\\nlike R, Julia and Go.\\nThose languages are more likely to keep you locked down\\nand limited to working in a data science capacity,\\nnot extending much beyond that.\\nAnd that's just another reason\\nthat I love Python for data science.\\nNow, in terms of the main libraries that are used\\nwith Python for data science, for advanced data analysis,\\nyou'd use NumPy, SciPy, and pandas,\\nand then for data visualization,\\nthe most widely used libraries are Matplotlib and Seaborn.\\n\\nFor machine learning, in this course,\\nwe'll be using scikit-learn, but if you venture\\ninto deep learning later on\\nin your data science learning adventures,\\nthen you would probably be using TensorFlow,\\nKeras, or PyTorch.\\nIn this course, you're going to be learning how\\nto use NumPy, SciPy, pandas, Matplotlib,\\nSeaborn, and scikit-learn.\\nWe're not covering TensorFlow, Keras or PyTorch\\nbecause those are deep learning libraries\\nand we're only covering data analysis,\\ndata visualization, and machine learning in this course.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4583159\",\"duration\":94,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"High-level course road map\",\"fileName\":\"3006708_en_US_01_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":116,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Get oriented with this course. This video covers a roadmap for data preparation, data visualization, and the math requirements for analytics.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2545971,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now that you know where data science fits in\\nwithin the spectrum of data roles\\nand you understand the basics of the data professions,\\nlet me just give you a quick roadmap\\nfor what we're about to cover\\nin the remainder of this course.\\nSo we are here now.\\nWe've just finished up Introduction to Data Professions,\\nand then in the next section,\\nwe're going to talk about data preparation basics.\\nThen we're going to go into the fundamentals\\nof data visualization\\nin a section that's called Data Visualization 101.\\n\\nAfter that, we'll be moving\\ninto practical data visualization\\nwhere you'll be learning\\nto create data visualizations for yourself.\\nNext, we'll be covering exploratory data analysis,\\nalso called EDA.\\nAnd after you've grasped the EDA basics,\\nwe'll move into Getting Started with Machine Learning.\\nAnd then after that,\\nwe'll be moving into data sourcing via web scraping.\\nSo I'll be teaching you how to generate data sets\\nby basically going out onto the internet and scraping data\\nand generating data sets you can use for making predictions.\\n\\nAnd then lastly in this course,\\nwe'll be talking about\\nbuilding collaborative analytics with Streamlit.\\nSo I'm going to be teaching you\\nhow to create interactive data visualizations\\non the internet that you can share across your organization\\nand also use for business decision support.\\nNow that you understand where we're headed,\\nlet's get started with data preparation basics.\\n\"}],\"name\":\"1. Introduction to the Data Professions\",\"size\":47198834,\"urn\":\"urn:li:learningContentChapter:4590008\"},{\"duration\":3953,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4588023\",\"duration\":200,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Intro to data preparation\",\"fileName\":\"3006708_en_US_02_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":291,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn about what role data preparation plays in the data science project lifecycle and its significance.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5190004,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Preparing your data for analysis is\\none of the most resource intensive requirements\\nin data science.\\nIn fact, the general consensus is that data scientists\\nspend 80% of their time on data preparation.\\nThat means the better and more efficient\\nyou become in data preparation,\\nthe more likely it is\\nyou'll be effective as a data scientist.\\nLet's look at where data preparation falls\\nwithin the typical data analytics project life cycle.\\n\\nThe data analytics project life cycle is pretty simple.\\nIt starts off with evaluation,\\nthen you move into data preparation,\\nthen analysis and model building.\\nNext implementation and then communication.\\nThere are six main steps involved in data preparation.\\nThose are importing data, cleaning data,\\ntransforming data, processing data, logging data,\\nand then backing up data.\\nThe first step is always\\nto import the data you want to work with\\ninto your programming environment or application.\\n\\nAnd step two is cleaning data,\\nwhich involves removing duplicates\\nand removing out of range records,\\nremoving stray characters, and standardizing casing.\\nThe third step is transforming data.\\nAnd that involves treating missing values\\nand scaling and normalizing variables.\\nIt's really important to scale your data\\nbecause you need to make sure that\\ndiffering magnitudes among the variables in your data sets\\ndo not produce erroneous or misleading statistics.\\n\\nAnd this is a basic step\\nin preparing your data for machine learning.\\nThere are two ways to scale your data.\\nOne is normalization and the other is standardization.\\nNormalization is where you put each observation\\non a relative scale between values of zero and one.\\nAnd this is where you would divide\\nthe value of the observation\\nby the sum of all observations in a variable.\\nThe other alternative is standardization,\\nwhich involves rescaling data\\nso that it has a zero mean and unit variance.\\n\\nStep four is processing data.\\nAnd that generally involves parsing data,\\nrecoding data, and formatting data.\\nAnd step five is logging your data.\\nAnd this is where you would generate descriptive statistics,\\nlog your variable information,\\nand store your variable information.\\nIn terms of what type of information you need\\nto log about your variables,\\nI would consider detailing your variable name\\nand statistical description,\\nthe format of the data,\\nthe method used to collect the data,\\nthe date of the data collection, the source of the data,\\nthe location, where the data is stored,\\nand any other notes that you feel are relevant\\nto your dataset.\\n\\nLastly, you'd be backing up your data,\\nwhich just involves creating a backup copy of your data\\nand then taking it over to begin data analysis.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4589018\",\"duration\":243,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Numpy and pandas basics\",\"fileName\":\"3006708_en_US_02_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":380,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Get introduced to the two most fundamental Python libraries for data science: numpy and pandas. Learn the numpy basics of arrays, vectorized operations, indexing, types and efficient ufuncs. Learn the pandas basics on series, dataframe, data reading, and saving.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6584805,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] For embarking on any sort of\\ndata analysis journey in Python,\\nyou need to be very clear on NumPy and Pandas basics.\\nThe NumPy library is a third party Python library\\nthat is used ubiquitously across data science\\nand data analysis.\\nNumPy is a numerical library that you can use\\nto create shape and reshape data structures.\\nEach of these data structures are what's called\\nan N-dimensional array or ndarray.\\n\\nNdarrays are faster than and more computationally efficient\\nthan Python's built-in containers,\\nand because of that, almost all data analytics\\nand data science Python libraries require NumPy\\nor are what we call built on top of NumPy.\\nAn ndarray is simply a container for data.\\nEach ndarray has a distinct number of dimensions\\nas well as a size and data type.\\n\\nConsider the two ndarrays you see on the screen here,\\nthey both contain identical data,\\nmeaning technically they are the same data set,\\nbut they're stored in completely different structures.\\nNumPy makes it very easy to shape\\nand reshape your data into the exact structure\\nyou need for analysis.\\nWith just one function call,\\nyou can easily use the NumPy library\\nto arrange and rearrange your data set\\nin order to store it in various structures.\\n\\nThe flat container you see on the screen here\\nis an array structure.\\nMore specifically, a one dimensional array.\\nThe table is an ndarray.\\nIt's a two dimensional array.\\nBoth are matrix structures.\\nTechnically, they're both ndarrays,\\nbut the flat array has only one dimension,\\nso it's more clear to call it an array.\\nThe Pandas library is also a third party Python library.\\nIt's built on top of NumPy\\nand it offers an easy way to work with arrays in matrices.\\n\\nPandas is useful for its fast data cleaning preparation.,\\nits powerful analysis capabilities,\\nIts ease of use for data visualization and machine learning,\\nand also for its deep compatibility with NumPy arrays\\nand matrices because of course, it's built on top of NumPy.\\nArrays and matrices are called series\\nand data frames in Pandas.\\nA series is an array similar\\nto a one dimensional array in NumPy.\\n\\nA data frame is a two dimensional table\\nthat can hold different types of data.\\nIt's similar to a matrix in NumPy.\\nWithin pandas, a series object is either a single row\\nor column, and it's always indexed.\\nA data frame object is pretty much like a spreadsheet\\nof rows and columns.\\nThe rows and columns individually are actually series\\nof objects in pandas library,\\nand data frames are always indexable.\\n\\nIn case you're curious about all this index talk,\\nAn index is a list of integers or labels\\nyou can use to uniquely identify rows or columns.\\nIn this course, we're going to be indexing\\nusing mostly square brackets.\\nIn the following coding demonstration\\nwe're going to be using comparison operators,\\nso I wanted to give you this table.\\nYou can review it on your own j\\njust to re-familiarize yourself\\nwith using comparison operators in Python.\\n\\nThe two I wanted to point out are simply\\nthe greater than symbol and the less than symbol,\\nbecause we'll be using those\\nin the following coding demonstration.\\nThroughout this course, we're going to be consistently\\nusing the NumPy and Pandas library.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2714160\",\"duration\":813,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Filtering and selecting\",\"fileName\":\"3006708_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"3 pickups recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1599,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to filter and select data by using indexes of series objects and DataFrame objects.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":31754399,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's talk about filtering\\nand selecting data with pandas.\\nNext up, I'm about to show you how to filter\\nand select data using plain indexing, data slicing,\\nand arithmetic comparisons using Python and Pandas.\\nIn this demonstration, we're going to work with two libraries,\\nNumPy and Pandas.\\nAnd the first thing you need to do is just to make sure\\nthat you have your library installed in your environment.\\nSo let's really quickly run pip install pandas.\\n\\nAnd in order to execute any code\\ninside of a Jupyter Notebook,\\nyou want to just hit Shift + Enter in order to run code.\\nSo that's what I did there.\\nAnd okay, so we have installed Pandas.\\nNow we want to import both NumPy and Pandas.\\nSo to do that we say import numpy as np,\\nimport pandas as pd,\\nand then from pandas\\nwe want to make sure to import DataFrame.\\n\\nAnd then we have all of that.\\nSo we will run this, Shift + Enter.\\nSo what you actually do is importing these libraries\\ninto the IPython environment.\\nThen the next step involves the creation\\nof a DataFrame object, and we'll fill it with some numbers\\nand then I'll show you how we can apply different functions\\non that DataFrame object.\\nSo let's call that object numbers_df\\nand we'll set it equal to,\\nand then we'll call the DataFrame constructor\\nand we'll pass in the np.arrange function.\\n\\nAnd then we'll say we want to generate a series of numbers\\nbetween zero and 90,\\nbut we want only every third number.\\nSo to do that, we say zero is the first number,\\n90 as the end.\\nAnd then define that we want only every third number here.\\nThe next thing we need to do\\nis to define a shape for this object.\\n\\nAnd so to do that, we will call the reshape method\\nand we'll pass in\\nthe values of 10 and three.\\n10 is going to be the number of rows,\\nand then three will be the number of columns.\\nThe next thing we need to do\\nis to set an index for this DataFrame.\\nSo to do that\\nwe'll just say index\\nand then we'll set it equal to a list.\\n\\nAnd then for each index, we just want to create a label.\\nSo we'll start with row one,\\nthen we'll go through\\nand just create a label for each index value.\\nAnd since we have 10 rows,\\nwe need 10 index values.\\nSo I'll go ahead and just copy in all of these labels.\\nAnd then also, let's name the columns here.\\n\\nSo we'll say columns equal to, and then create another list.\\nAnd then we'll just call the columns,\\ncolumns one through three.\\nSo column one, and then just finish this out.\\nI'll copy it in.\\nThis is red here.\\nSo it looks like we probably have a syntax error.\\nSo you can see here I have one too many parentheses.\\nSo let me just delete that\\nand then rerun it.\\n\\nOkay, that cleared out that error.\\nSo now let's print the numbers DataFrame object.\\nIn order to do that, we just need to say numbers_df\\nand then run this.\\nOkay, so great, now you can see\\nwe have a numbers DataFrame object,\\nand each of the index values are labeled\\naccording to the labels we passed\\ninto the DataFrame constructor.\\nSo now let's take a look at indexing and slicing.\\n\\nIndexing means accessing items from a data structure\\nlike arrays, series or DataFrames.\\nAnd there are three types of indexing.\\nSimple indexing, Boolean indexing, and fancy indexing.\\nLet's start first with simple indexing on a DataFrame.\\nTo do that, we can use the iloc indexer\\nto access items within a DataFrame.\\nOne thing you need to know\\nis that indexing starts from zero,\\nwhich means that the first element\\nis placed at the zero index.\\n\\nIn a DataFrame, we have multiple rows and columns.\\nSo in order to access an item in a DataFrame,\\nwe need to pass its row and column number\\nin square brackets separated by a comma.\\nThe value before the comma is the row number\\nand the value after the comma is the column number.\\nAnd if we want to access the second item\\nin the first row of the DataFrame,\\nthen we would just call the numbers_df object.\\n\\nAnd then we would use the iloc method,\\nand we will pass row number zero\\nin column number one into this iloc indexer.\\nAnd then when we run this,\\nwe get back the value of three.\\nSo if we look back up here,\\nwe can see that the value of three\\nis sitting in the row that is of index value zero\\nin the column which has an index value of one,\\n'cause again, indices start from zero,\\nwhich means that the first element\\nis placed at the zero index value.\\n\\nWe can use the equal notation\\nto replace a value in a DataFrame.\\nTo illustrate this better,\\nlet's replace the value at row one and column one\\nwith the number 20, and then run the code block.\\nSo we'll call the numbers,\\nnumbers underscore DataFrame object,\\nthe iloc method, and then we'll define the position here\\nas zero and one.\\nSo the value at row zero in column one,\\nand we'll set that equal to 20.\\n\\nAnd then we will, oops,\\nI missed an S here.\\nAnd then let's print out the object.\\nSo we'll say numbers underscore DataFrame\\nand then run this.\\nAnd you can see here now\\nthat what used to be value of three here\\nhas now been replaced with a value of 20.\\nNow let's look at how fancy indexing works.\\nFancy indexing is like the simple indexing\\nthat we just used, but there's a difference.\\n\\nInstead of passing single scalers,\\nwe're going to pass arrays of indices.\\nIn the DataFrame we can retrieve common items\\nbetween specific rows and columns using fancy indexing.\\nSo as an example, let's access the common items\\nbetween the second, third and fifth row\\nin the second and third column.\\nSo to do that, we call the numbers_df object\\nand we call the iloc method.\\n\\nAnd then let's define the rows\\nthat we want to return,\\nwhich would be one, two, and four,\\nand also the columns,\\nwhich is going to be columns at index position one\\nand index position two.\\nAnd then we run this.\\nAnd now as you can see, we have returned the common items\\nbetween the second, third and fifth row\\nand the second and third column.\\n\\nNow let's dig into Boolean indexing in a DataFrame.\\nBoolean indexing is done through comparison operators,\\nand in case you are not quite sure\\nwhat I mean by comparison operators,\\ncomparison operators are just like\\ngreater than, less than, equal than,\\nbasic arithmetic comparison operators.\\nSo we're going to look at comparison operators and masking.\\nComparison operators compare a single scaler value\\nwith all the values in the DataFrame,\\nand they always return a DataFrame with Boolean values.\\n\\nBoolean values are also called a Boolean mask.\\nLet's implement Boolean indexing on the DataFrame.\\nSo to do that, if we wanted to find values\\ngreater than 30 in the DataFrame,\\nwe could say mask equal to,\\nand then call the numbers_df object\\nand just say we want everything\\nthat's greater than the number 30.\\nAnd then print out the mask\\nand run that.\\n\\nThat was marked down so we need to make sure\\nthat it is actually the correct code formatting here.\\nSo I'll turn that to Python code and then run that.\\nAnd now you can see we have a DataFrame\\nfull of Boolean values\\nwhere if the value is greater than 30,\\nthen the result is returned as true.\\nAnd then if the value is less than 30,\\nthe result is returned as false.\\n\\nWe can use this Boolean mask to retrieve\\na subset of data from the DataFrame.\\nIf we pass the Boolean mask in the DataFrame,\\nit will return to us those values\\nwhich were greater than 30.\\nSo we'll say numbers_df\\nand then we just want to return the mask.\\nAnd if we run this code block,\\nwe can see that only the values\\nwhich are greater than 30 are returned.\\n\\nIf the value is less than 30,\\nthen we get NAN, not a number.\\nSo if the values are less than 30,\\nthen we just get this NaN.\\nSo as you can see,\\nthis just returns all the values from the DataFrame\\nthat are greater than 30 as defined by our mask object.\\nBoolean mask is also used to replace values in a DataFrame.\\nSo let's try that out really quickly.\\n\\nHere let's set all of the values in the DataFrame\\nthat are greater than 30\\nsuch that they are set equal to zero.\\nTo do that, we'll just call the numbers_df object,\\nand then we want to return\\nall of the numbers within the numbers DataFrame\\nthat are greater than 30,\\nand we want to set those values equal to zero.\\n\\nAnd then we'll call the numbers_df object again.\\nRun that, and you can see\\nthat all of the numbers from the DataFrame\\nthat were greater than 30 have now been set to zero.\\nThe last thing I wanted to show you here\\nis how to slice values from the DataFrame.\\nSlicing means pulling a section from the DataFrame.\\nSo we can slice values using the colon notation.\\nAny value that we put before the colon\\nis the starting index of the slice.\\n\\nAnd the value after the colon\\nis the ending index of the slice.\\nLet's slice the values from the third to the sixth row\\nand the second to third column.\\nTo do that, we'll say numbers_df\\nand then we'll call the iloc method.\\nAnd then we'll say we want the rows\\nin index position two through six\\nand column index position\\none through three,\\nand we can run this.\\n\\nAnd then as you can see, it has returned to us the values\\nthat are common between the third, fourth,\\nfifth, and sixth row and the second and third column.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4586141\",\"duration\":1084,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Treating missing values\",\"fileName\":\"3006708_en_US_02_04_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1945,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to treat missing values. This video covers dropping values, approximation, and filtering.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":35498780,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now we're going to talk\\nabout comparison operators and scalar values.\\nJust in case you don't know what a scalar value is,\\nit's basically just a single numerical value.\\nYou can use comparison operators like greater than\\nor less than to return true or false values for all records\\nto indicate how each element compares to a scalar value.\\nIn Python, by default,\\nmissing values are represented with a symbol, NaN,\\nwhich stands for not a number.\\n\\nBe warned, if your data set has zeros, 99s, or 999s,\\nbe sure to either drop or approximate them\\nas you would with missing values.\\nLet me give you an example\\nof where treating missing values is useful.\\nImagine you work in a marketing department\\nof a local car dealership.\\nYou've been tasked with summarizing recent results\\nfrom a customer satisfaction survey.\\nYou get this data set and you can see\\nthat most of the records have been completed,\\nbut Sally and Jim didn't respond with information\\nabout their opinion of quality of work.\\n\\nYou can see that here with the missing values.\\nNonetheless, Sally and Jim have responded\\nto 75% of their request for information,\\nso we wouldn't want to drop them from the survey altogether.\\nThat said, the other respondents,\\nRod, Sam, and Jane, did give information\\nabout what they thought of the quality of work.\\nSo we wouldn't want to drop this variable altogether either.\\nWhat could we do?\\nWell, we could take the average value\\nof the responses we do have, which would be an average\\nof eight, nine, and 10,\\nand then just fill in these missing values,\\nin order to generate an approximation\\nthat gives your boss a pretty good idea\\nof the customer's actual responses.\\n\\nYou'll see later in the coding demonstration,\\nwhy it's important to try and use approximation,\\nrather than just dropping missing values altogether.\\nIn the coding demonstration that's coming up,\\nI'm going to show you how to work\\nwith missing values in Python.\\nYou're going to learn how to discover what's missing,\\nfill in for those missing values, count up missing values,\\nand also filter them out.\\nLet's go ahead and look\\nat how to work with missing data and Pandas.\\nSo as you can see, this notebook is coming preloaded\\nwith our NumPy and Pandas libraries.\\n\\nWe just need to run that.\\nAnd when working in data science,\\nthere are going to be situations that arise all the time\\nwhere you encounter missing values.\\nSometimes it's caused by data entry errors,\\nother times by machine function,\\nbut really, we have a variety of ways\\nto handle missing values and data.\\nAnd I wanted to show you those.\\nBut before I do that, I need to create a dataset\\nthat we can work with.\\n\\nSo let's just call that dataset data,\\nand we'll create a dataset about a group of people\\nthat go by the names,\\nSteve, John, Richard,\\nSarah, Randy, Michael,\\nand lastly, Julie.\\n\\nAnd within this dataset,\\nwe're going to describe their age, gender, and rank.\\nSo we'll set the age equal to 20 for the first person,\\n22, 20, 21, 24, 23, and 22.\\nAs far as the gender,\\nI'm just going to copy and paste these over.\\n\\nOkay, and then let's assign them a rank\\nfor each of these people.\\nSo we'll just say two, one, four, five,\\nthree, seven and six.\\nOkay, so now we have a dataset\\nand everything seems to work fine here,\\nso what I want to do is I want\\nto use the data frame constructor\\nto create a ranking data frame object.\\n\\nSo I'll call it ranking_df.\\nAnd then we'll call the data frame constructor,\\nand we'll pass in our dataset here.\\nAnd then off of that, let's call the iloc method.\\nSo we'll say ranking_df.iloc,\\nand then let's pick the rows\\nin index position two through five.\\n\\nAnd then let's also select the column in index position one.\\nAnd we'll set all of these values equal to a missing value.\\nSo to do that, we will just call np.nan,\\nand that will set the values equal to missing value.\\nAnd then let's do the same thing for rows\\nat index position three through six\\nand column at index position three.\\n\\nAnd then lastly, let's do that\\nfor row at index position three and then all of the columns.\\nSo we can just use a colon operator here,\\nand then we can leave the start and end value undefined,\\nand that will set all\\nof the columns equal to missing values.\\nAnd then let's just print this out and see what we get.\\n\\nAnd as you can see,\\nnow, we have a data frame and it's got missing values\\nfor Richard, for all of row at index position three.\\nAnd at the other locations\\nthat we defined in our iloc indexer above.\\nThe Pandas has several different functions\\nthat are available to us for handling missing values.\\n\\nThe first step for handling missing values is\\nto detect if there are any missing values present\\nin the dataset.\\nIn order to do that, in the data frame,\\nPandas provides us two functions, isnull and notnull.\\nThe isnull function returns true for those values\\nwhich are missing values in a data frame,\\nand the notnull function returns true for the values\\nwhich are not missing.\\n\\nSo let's try both of those out.\\nLet's call our ranking data frame object,\\nand then we will call the isnull function.\\nAnd when we print it out,\\nwe see that we get returned a Boolean data frame\\nwhere true represents missing values\\nand false represent the values which are not missing.\\nNow, let's also try the notnull function.\\n\\nSo we'll say ranking_data frame,\\nand then call the notnull function.\\nAnd then when we print this,\\nyou see that it's absolutely the opposite\\nof the isnull method.\\nSo we are getting back true values\\nwhere the value is not missing,\\nand then where there are missing values,\\nwe should be getting back false,\\nwhich as you can see, we do here.\\n\\nNext, I want to show you how to apply Boolean masking\\nto show only the rows where there is a missing value\\nin a specific column.\\nTo do that, first, we need to find the Boolean mask\\nof the column age with the isnull function,\\nand then we'll pass this Boolean mask into the data frame.\\nSo let's call this whole thing bool_series,\\nand then we'll set it equal to pd.isnull,\\nand within this function,\\nwe will pass our ranking data frame,\\nand we are going to select the age column here.\\n\\nNext, let's pass the Boolean mask into the data frame.\\nSo to do that, we will just call our data frame object,\\nand then we'll pass in the Boolean series object,\\nand then print this out.\\nNow, you can see that we have only returned the rows\\nwhere the age is missing.\\nSo if the age value was not missing\\nin the original dataset,\\nthen those rows did not get returned.\\n\\nWe should also look at\\nhow to fill in missing values using the fill NA function,\\nthe replace function in the interpolate function.\\nHow these data frame functions work is\\nthat they replace missing values\\nwith some value of their own.\\nSo all of these functions help in filling missing values\\nwithin a dataset.\\nThe interpolate function is used to fill missing values\\nin the data frame,\\nbut it uses various interpolation techniques\\nto find the missing values,\\nrather than hard coding the value.\\n\\nLet's start out first by filling a missing value\\nwith a single value.\\nLet's call our ranking_df object,\\nand then we'll call the fillna function,\\nand we will pass zero.\\nAs you can see,\\nall of the missing values\\nin the data frame have been replaced with a zero.\\n\\nLooking at another example, let's fill missing values\\nwith the values that comes prior to the missing value\\nwithin the data frame.\\nIt's a little tricky for me to explain,\\nso I just need to show you.\\nWe'll use the fillna function with the data frame.\\nSo we'll say ranking_df.fillna,\\nand if we pass the method pad here,\\nand print this out.\\n\\nWhat you can see is that all the missing values\\nin the data frame have been replaced with the value\\nthat came prior to the missing value.\\nSo as you recall, all of the values in the row\\nat index position three were previously missing values.\\nAnd now, all of these values have been replaced\\nby the values that were in row at index position two.\\n\\nCan see what I mean here.\\nSo that's how the fillna function works.\\nAnother example is to fill missing values\\nwith the next value, which is not missing in the data frame.\\nSo it would be the opposite approach\\nto filling the missing value.\\nTo make this change, we can still use the fillna function,\\nbut we just need to change the method\\nto be fill for backfill.\\n\\nWe'll print this out.\\nAnd then as you can see here,\\nnow, the row at index position three has been filled\\nwith the values that came after it\\nin the original data frame, it came back up here.\\nYou can see that we had Randy, NaN, male.\\nNow interestingly, we had NaN here.\\nSo all of these NaN missing values were backfilled\\nwith the one prior, which would be six.\\n\\nSo that's why all of these values are now six.\\nThey have been backfilled from the value\\nthat was not missing that came after them.\\nLet's also look at filling missing values\\nin a data frame using the interpolate function\\nwith a linear method.\\nThe linear method ignores the index\\nand treats the values as equally spaced.\\nSo let's just call our ranking data frame object,\\ncalled the interpolate function.\\n\\nAnd here, we'll say that the method is equal to linear,\\nand run that.\\nSo now you can see that for each of the missing values\\nthat was numerical here,\\nit has been filled with a linear interpolation.\\nSo as you recall,\\nif we go back up to the original data frame,\\nwe had here in our rank column,\\nwe had numbers which were not a number,\\nand they ranged between four and six,\\nand there were three of them, right?\\nSo if we were to make a linear interpolation,\\nbetween the values of four and six,\\nthen we would come up with these values.\\n\\nAnd so that's exactly what this method did,\\nis it interpolated between the value\\nthat came before the missing numbers and the value\\nthat came after the missing numbers, column-wise.\\nWe can also drop all of the rows and columns\\nthat contain missing value use using the dropna function.\\nSo if we call the dropna function off\\nof the ranking data frame object,\\nand run this, see that all the rows and columns containing\\nat least one missing were all dropped from the data frame,\\nand all we're getting back are the rows and columns\\nwhich have no missing values whatsoever.\\n\\nNow, let's try to drop all the rows and columns,\\nwhich only contain missing and values,\\nusing the dropna function with the keyword,\\nhow equal to all,\\nand see how that changes things.\\nSo we'll say how, we'll set that equal to all,\\nand we'll run this.\\nAnd now you can see that all the rows and columns\\nthat contain only missing values have been dropped.\\nSo for example,\\nthe row at index position three was all missing values,\\nand now you can see it's been dropped.\\n\\nLet's also drop all the columns,\\nwhich contain at least one missing value.\\nWe can use the dropna function to do that as well.\\nAnd then what we would need to do here though is\\nthat instead of using how equals all,\\nwe would say access equal to one.\\nAnd you can see that each column had a missing value.\\nSo what we're doing here with the access equal to one is\\nwe are telling the dropna function\\nthat we wanted to look in all of the columns.\\n\\nAnd for all of the columns that contain a missing value,\\nthen that column needs to be dropped from the data frame.\\nAnd when we run this,\\nyou can see that we get returned no columns.\\nThat is because all of the columns had a missing value\\nin them in the original data frame.\\nSo we can go back here to the original data frame and look,\\nand there is not a column without a missing value,\\nspecifically because of this row at index position three.\\n\\nSo all of the columns have been dropped.\\nNow, if we wanted to drop all of the rows\\nthat contain a missing value,\\nwe can use the same function,\\nand then we would just change the access here to zero,\\nand run this.\\nAnd now you can see, okay, we back only the rows\\nthat have no missing values.\\nFor real, had a missing value,\\nthen it got dropped.\\n\\nAnd that is how to work with missing values using Pandas.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4586142\",\"duration\":470,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Removing duplicates\",\"fileName\":\"3006708_en_US_02_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":779,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to remove duplicates. This video covers dropping records with pandas.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16426350,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] It's really important\\nto remove duplicates from your dataset\\nin order to preserve the dataset's accuracy\\nand avoid producing incorrect and misleading statistics.\\nFor example, imagine you're analyzing a retail sales table\\nand shopaholic Sally came in three times\\nand used three different credit cards\\nto make purchases but provided the cashier\\nthe same zip code, 3-2-8-0-3, for each sale.\\nJust based on the card number, Sally looks\\nlike three different customers all\\nfrom the 3-2-8-0-3 zip code.\\n\\nIf you fail to examine other attributes of the customer\\nso that you can identify and remove duplicates,\\nshopaholic Sally's results would skew the results\\nof any customer demographic analysis\\nbecause Sally would be counted\\nas three people rather than one.\\nTo market to the 3-2-8-0-3 customers effectively\\nyou need to understand their characteristics.\\nDon't let duplicate records skew your analysis.\\nOkay, now let's look at removing duplicates.\\n\\nThis notebook is coming preloaded with Numpy and Pandas.\\nAnd as you can see here, we're also going to be importing\\nthe series as well as data frame from Pandas library.\\nSo you can just run that.\\nAnd then we need to have data\\nfrom which to remove duplicates.\\nSo let's create a data frame.\\nWe'll call it DF_object.\\nAnd we'll set it equal to,\\ncall the data frame constructor here.\\n\\nAnd then we will create three columns.\\nSo column 1.\\nAnd in column 1 let's pass in a list of values.\\nWe'll say 1, 1, 2, 2, 3, 3, and 3.\\nGreat, so let's look at column 2.\\nFor column 2, we'll just create a list of letters.\\n\\nSay A, and I'm just going to copy these over.\\nSo we'll have it be a, a, b, b, c, c.\\nOkay, and then for column 3,\\njust name this column name\\nand then we will define the values\\nas same thing, A, A, B, B, C, C,\\nbut we'll just make those uppercase instead of lowercase.\\n\\nLet's just print this out.\\nOkay, so now we have a data frame to work from.\\nClearly has duplicate values in here\\nso I wanted to show you the .duplicated method.\\nThis method searches each row in the data frame\\nand returns a true or false value\\nto indicate whether it's a duplicate of another value found\\nin a different row earlier in the data frame.\\n\\nSo let me show you how that works.\\nWe'll say DF_obj and then we'll call the .duplicated method\\nand then we'll run this.\\nAnd looking at the original data frame, you can see\\nthat if there was a duplicate value within a row\\nso, looking at row at index position 0,\\nthere were no duplicate values here.\\n\\nSo we got returned a false.\\nBut then when you look at row at index position 1,\\nwe get returned a value of true and that is because\\nof values at row index position 1 are duplicates\\nof the row prior.\\nAnd then you'll see row index position 2 returns a false\\nbecause they are not duplicates.\\n\\nBut then row at index position 3 returns a true\\nbecause, again, we have another set of duplicates.\\nNow that we have found duplicate records, let's look\\nat how we can drop them.\\nTo do that, we'll use the drop duplicates method.\\nAnd if we wanted to just drop all the duplicate rows\\nwe would simply call the drop duplicates method\\noff of the data frame object.\\n\\nAnd we won't specify anything here\\nand you'll see that for row 2\\nor the row with the series index value at 1 was dropped.\\nAnd that makes sense here because it was a duplicate\\nof the row at index position 0.\\nSo it got dropped and then using similar logic\\nthe row at index position 3 also should have been dropped.\\n\\nAnd as you can see, it was.\\nSo, yes, it looks like absolutely all\\nof our duplicate rows have been dropped from our data frame.\\nBut I also want to show you how to drop records based\\non the column values.\\nIn order to do that, I need to make a small change\\nto our data frame.\\nSo let's just go back and copy this code we used originally\\nhere to create the data frame.\\nAnd what I'm going to do is I'm going to change\\nthis letter here at the end.\\n\\nThis C here, I'm going to change it to a D,\\nwhich is a pretty minor change.\\nBut let's just see how we can use this\\nto drop records based on the column values.\\nSo I'll print this out.\\nHere we see okay, we've got changed this C out to a D.\\nSo to drop the rows that have duplicates\\nin only one column series, you just call\\nthe drop duplicates method off of the data frame\\nand then pass in the label index\\nof the column you want to de-duplicate.\\n\\nSo let's say DF_obj and then say drop duplicates.\\nAnd I'll set column 3 here and then run this.\\nAnd just as we predicted, what this function has done is\\nit has dropped the series\\nthat have index values 1, 3, and 6.\\n\\nBecause we do not have a duplicate\\nin column 3 here, that row did not get dropped.\\nI want to highlight really quick\\nthat it's important, in fact it's really important\\nthat you check your data for duplicates\\nand remove them if you find them.\\nNow it's time to move on\\nto data concatenation and transformation.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4584140\",\"duration\":795,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Concatenating and transforming\",\"fileName\":\"3006708_en_US_02_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1375,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to concatenate and transform. This video covers combining data, converting data, and reformatting data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":26344657,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Voiceover] Knowing how to concatenate and transform data\\nis really important in data analysis.\\nConcatenation and data transformation are useful\\nfor getting your data into the structure\\nand order you need for analysis.\\nFor example, imagine you're mailing out a piece\\nof direct mail advertisement.\\nYou have one table with customer ID and name,\\nand you have another table with customer ID,\\nmailing address, and age.\\nYour mailing address application requires you\\nto supply it only one table that contained\\nonly customer name and address.\\n\\nYou generate this table by concatenating your two tables\\nby customer ID, row wise.\\nConcatenating is simply combining data\\nfrom separate sources.\\nTransformation, on the other hand,\\nis converting and reformatting data\\nto the format necessary for your purposes.\\nWhen you transform your data, you convert it\\ninto the format that's required to facilitate analysis.\\nThis could include dropping data, which is essentially just\\ndropping variables or observations,\\ncan include adding data, which is adding variables\\nand observations,\\nand it also includes sorting data.\\n\\nSo, going back to our example,\\ntransformation would be when you drop the age column\\nin order to get your data into the exact format\\nthat the application would need.\\nOkay, so in this demonstration we're going to look at\\nconcatenating and transforming data.\\nAnd as you can see, the notebook is coming loaded\\nwith both pandas and numpy.\\nSo, you've got everything set up here,\\nall you need to do is just make sure you run that.\\n\\nAnd then we'll start first with concatenating data.\\nBefore we do anything else, we'd need to create\\na data frame object, which I'll call \\\"DF_obj\\\"\\nand then call the data frame constructor.\\nAnd we'll pass the np,arange function,\\nand we will say\\nthat we want to create a series of values.\\n\\nRephrase, and we will say we want to create\\na series of 36 values,\\nand then we want them to come in the shape of a 6x6.\\nSo, we'll say reshape,\\nand then say six rows\\nand six columns.\\nAnd then if we print this out,\\nyou can see, great, we have a series of numbers\\nstarting at zero, going to 35, so it's 36 numbers\\nand it's in a 6x6 shape.\\n\\nNow let's create a second data frame.\\nAnd we'll call it \\\"DF_obj_2\\\"\\nand we'll do the same process here, except for let's just\\ncreate a series of 15 numbers\\nand then with five rows and three columns,\\nand print that out.\\n\\nGreat, perfect.\\nSo, now we have something to work with.\\nLet's look at how to concatenate data.\\nTo do that, we will use the concat method,\\nwhich joins data from separate sources\\nand combines them into one combined data table.\\nIf you want to join objects based on their row index value\\nyou just call the \\\"pd.concat\\\" method\\non the objects you want joined and then pass in\\nthe \\\"axis=1\\\" argument\\nand \\\"axis=1\\\" tells Python to concatenate the data frames\\nby adding columns.\\n\\nIn other words, joining on the row index values.\\nSo, let's just test that out here.\\nSay \\\"pd.concat\\\"\\nand we'll select our data frame object\\nand our data frame object two,\\nand we'll pass in \\\"axis=1\\\".\\nNow, as you can see, we have gone from having\\na data frame with... here has six columns,\\nthis one has three columns,\\nnow we have a data frame with nine columns\\nwhere data frame object two has been appended\\nor concatenated onto the original data frame object.\\n\\nAnd in the case where the shapes didn't match up,\\nlike at row index position five here,\\nwe don't have that row in the second data frame object,\\nand so as you can see, we got missing values returned\\nin that part of the results that were returned to us.\\nNow, if we wanted to do the opposite,\\nand we wanted to join on the column index values,\\nwhat we could do is we can just\\neither say \\\"axis=0\\\" or we can just completely omit\\nthis axis parameter and by default it will\\njoin on the column index values.\\n\\nSo, I run this, and now you see that\\nthe two objects have been concatenated column-wise.\\nLet's look at transforming data really quickly.\\nSo first, let's look at dropping data.\\nYou can easily drop rows from a data frame\\nby calling the drop method and passing in the index values\\nfor the rows you want dropped.\\nSo, say \\\"DF_obj\\\"\\nand then \\\".drop\\\",\\nlet's say we want to drop the rows\\nat index position zero and two.\\n\\nWe can execute the code here.\\nThere was a syntax error where I missed brackets.\\nThere we go.\\nNow you see that the rows at index position zero and two\\nhave been dropped from my results.\\nNow, if we wanted to go ahead and instead drop\\nthe columns at index position zero and two,\\nall you would need to do is pass a parameter\\nthat says \\\"axis=1\\\" and run that,\\nand you can see now it's dropped those columns.\\n\\nLet's look now at adding data.\\nSo, let's create a series object called \\\"series_obj\\\"\\nand then we'll call the series constructor,\\nwe'll pass in the \\\"np.arange\\\" function\\nand we will say we want a series of values\\nfrom zero to five, we'll want six values.\\nAnd then let's give this series the name \\\"added_variable\\\".\\n\\nSo, to do that we'll say \\\"series_obj.name\\\"\\nand we'll set that equal to \\\"added_variable\\\"\\nand then just print this out to see what it looks like.\\nOkay, great, so it's a series of six numbers\\nthat range between zero and five\\nand the series is named \\\"added_variable\\\".\\nNow, you can use the join method\\nto join two data sources into one.\\n\\nBy default, the join method works by joining the two sources\\non their row index values.\\nLet me show you real quick how this works.\\nWe will say \\\"variable_added\\\"\\nis equal to...\\nand we'll call \\\"DataFrame.join\\\" function\\nand we will pass in our data frame object\\nand our series object,\\nand then print it out.\\n\\nAh, look, and then as you can see, our series\\nthat we created here called \\\"added_variable\\\"\\nhas now been added to the data frame.\\nNow let's try adding data using the concat function.\\nWe will create a object called \\\"added_datatable\\\"\\nand we'll set that equal to \\\"pd.concat\\\".\\n\\nWithin the concat function, let's pass\\nthe \\\"variable_added\\\" object twice.\\nSo, we're asking it to concat the \\\"variable_added\\\"\\ndata frame to itself, essentially here.\\nAnd then, let's set the parameter \\\"ignore_index=False\\\"\\nand I'll print this out, and then I'll explain\\nhow this will work.\\n\\n\\\"Added_datatable\\\", okay, good.\\nSo, what you can see here is\\nit's taken our \\\"variable_added\\\" object that we had,\\nand it's concatenated it to itself.\\nBut, because we said this \\\"ignore_index=False\\\" here,\\nwhat it's done is the index now has duplicates\\nbecause the original index values from the original object\\nhave just been concatenated into the results\\nthat were returned.\\n\\nSo, if we wanted to reset the index so that it\\nworks properly, we would want to then just say\\n\\\"ignore_index=True\\\".\\nAnd basically what we have done here\\nis we have told pandas to ignore the index\\nof the input data frame and create a new integer index\\nfor this resulting data frame.\\n\\nAnd so, the new index starts at zero,\\nand it increments by one for each row,\\nregardless of what the original index was\\nin the input data frame.\\nThe last thing I want to look at here with you\\nis sorting data.\\nTo sort rows in the data frame, either in ascending\\nor descending order, you'd need to call\\nthe \\\".sort_values\\\" method off of the data frame\\nand then pass in the by argument to specify the column index\\nupon which the data frame should be sorted.\\n\\nSo, let's create a data frame called \\\"DF_sorted\\\"\\nand we'll set it equal to our data frame object,\\nand off of that object we'll call the sort values method,\\nand then we will say we want to sort by our column\\nthat is in index position five.\\nSo, in order to do that, we would just say \\\"by=[5]\\\"\\nand then if we want it to be in descending order\\nthen we just say \\\"ascending=False\\\".\\n\\nAnd then when we print this out,\\nyou can see that our column...\\nour data from our column index position five\\nhas been sorted in descending order.\\nSo, if we look back at our original data frame,\\nyou can see that it was in ascending order\\nand so now the order has been clipped\\nand with that, all of the other values\\nin all of the other columns have also been sorted\\nin that exact same way.\\n\\nAnd that's about all you need to know about\\nconcatenating and transforming data using pandas.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4586143\",\"duration\":348,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Grouping and aggregation\",\"fileName\":\"3006708_en_US_02_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":449,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to group and aggregate. This video covers subgrouping, describing subgroups, and data aggregation.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12311338,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now, we're going to talk about data grouping\\nand aggregation.\\nGrouping and aggregation are useful for exploring\\nand describing your dataset in its subgroups.\\nImagine you are a merchant that sells fruit\\nand you have a dataset that describes\\nthe different types of fruit you have\\nand where you purchase them from.\\nTo understand what a subgroup is,\\nlook at this example of the data set\\nthat has apple and orange records.\\nIf you were to reduce this data set down\\nto its fundamental subgroups by fruit category,\\nyou would get two records, apple and orange.\\n\\nGrouping is an excellent method to use\\nwhen you want to explore and understand your data\\nand its inherent subgroups.\\nIt's useful for many, many reasons.\\nYou can group data in order to compare subsets\\nand deduce reasons why subgroups differ the way they do.\\nOr you may only be interested\\nin specific subgroups for your analysis.\\nGrouping can help you identify\\nand subset out those subgroups.\\nOkay, let's go ahead\\nand look at how to group data by column index.\\n\\nThis Jupyter notebook is coming preloaded\\nwith numpy and pandas, so just make sure to run that.\\nAnd then for this demonstration,\\nwe're going to use a dataset called mtcars.\\nThe first thing we need to do\\nis define a location for that dataset.\\nSo it's going to be address, I say address is equal to,\\nand what you need to do is actually go\\ninto the data folder here and find mtcars dataset,\\nand then right click.\\nAnd you want to copy the full path here.\\nSo Copy path, and then back to the Jupyter notebook\\nand paste the path in here.\\n\\nAnd now you have defined the address\\nwhere the CSV file sits.\\nTo read it in, you want to use the read CSV function,\\nso we'll call this dataframe cars\\nand we'll say cars is equal to pd.read_csv,\\nand we'll pass in the address.\\nAnd then let's assign names\\nto each of the columns in this dataset.\\nSo to do that, we need to access the cars columns.\\nWe'll say cars.columns and let's have that equal to a list.\\n\\nWithin that list,\\nwe'll pass in the name of each of the columns.\\nSo the first column name is car_names.\\nAnd then I'm going to go ahead\\nand just paste in the rest of these.\\nIn a different coding demonstration,\\nwe will dig into further details\\nabout what these variables mean as needed.\\nBut for now, I'm just trying to show you\\nhow to group data by column index.\\nSo let's just take a look\\nat the first five records in this data set.\\nWe'll say cars.head, call the head method off of that,\\nand then print it out.\\n\\nAnd here we go, we have the first five records\\nfor the mtcars data set.\\nSo we're good to go there.\\nNow, what I want to do is show you how to group this dataframe\\nby a particular column.\\nAnd to do that we'll use the group by method.\\nSo let's create a new dataframe called cars_groups.\\nAnd we'll form that by calling the groupby method\\noff of the cars dataframe.\\nAnd then passing in, we'll be selecting the cylinder column.\\n\\nSo we want to say cars.groupby.\\nAnd then we pass in the cars dataframe,\\nand then we'll select the cylinder column here.\\nAnd so say we want to generate a mean of the values,\\nthe numeric values in the dataframe\\nas grouped by the cylinders column.\\nSo to do that, we would say cars_groups,\\nand then call the mean method off of that.\\n\\nWe need to pass in a parameter\\nthat says numeric only equal to true,\\nbecause we only want to be looking at the numeric values\\nsince we're calculating a mean.\\nAnd then here, we can see there's a little typo.\\nSo I'll fix that and then run this.\\nOkay, I need to add an S here.\\nOkay, great.\\nSo now, just to show you what this is doing,\\nthe groupby method has grouped the entire dataframe\\nby the different categories that were in the cylinder field,\\nwhich the cylinder field only had the values\\nof four, six, and eight.\\n\\nSo the dataframe is now grouped according to those values.\\nAnd then for each numeric field within this dataframe,\\nmean value was generated for each grouping.\\nSo to make this a little more relatable,\\nlet me just explain how.\\nHere, you can see, okay, for our four-cylinder group,\\nthe average, the mean miles per gallon is 26.6.\\nAnd then for our six-cylinder cars, our miles per gallon,\\nthe average miles per gallon for six cylinders cars is 19.7.\\n\\nAnd then for eight-cylinder cars,\\nthe average mile per gallon is 15.1.\\nAs you can see, as the cylinders increase\\nthe average mile per gallon that the cars gets decreases.\\nAnd that is how you group data by column index.\\n\"}],\"name\":\"2. Data Preparation Basics\",\"size\":134110333,\"urn\":\"urn:li:learningContentChapter:4583163\"},{\"duration\":1570,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4583160\",\"duration\":223,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Importance of visualization in data science\",\"fileName\":\"3006708_en_US_03_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":392,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn why visualization is a key aspect of data science. Learn how data scientists effectively communicate data, insights, and predictions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5117666,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Presenter] And let's talk about the importance\\nof visualization in data science.\\nData visualization is important\\nbecause data insights cannot very easily be converted\\nto business value if they're not communicated effectively.\\nData visualization is the process of transforming data\\nin the form of graphs, charts,\\nor any other form of visual scheme.\\nThe purpose of data visualization is to explore data\\nand to extract useful information from it.\\n\\nVisualization helps in finding patterns,\\nleaning valuable insights,\\nand observing trends in the dataset.\\nDifferent types of graphs are used for data visualization.\\nLet's take a look at some examples of graphs\\nand their utilization for various problems.\\nA line graph graphically displays data\\nthat changes continuously over time,\\nor whatever variable you have mapped out over the X axis.\\nLine graphs have a horizontal axis and a vertical axis.\\n\\nWe use line graphs\\nwhen we want to demonstrate trends in data.\\nSimilarly, we can also use line graphs\\nwhen we want to compare different variables\\nin specific time periods.\\nBar graphs are one of the most popular types of graphs.\\nThey are popular for an obvious reason.\\nThey're easy to understand.\\nGenerally, how bar graphs are set up\\nis that on the horizontal axis,\\nwe represent the name of the categorical data,\\nand on the vertical axis,\\nwe demonstrate the measurable value.\\n\\nBar graphs can be used\\nto visualize the distribution of data,\\nand similarly, we can also use bar graphs\\nwhen we want to compare data of different categories.\\nThere are several other scenarios\\nwhere we would use bar graphs.\\nPie charts use pie slices\\nto display relative sizes of data categories.\\nYou can use pie charts\\nto show the relative sizes of many things.\\nFor example, what type of transport most people use,\\nor how many customers a shop has\\non different days of the week.\\n\\nWith technological advancements\\nand generative AI in the picture,\\nhuge volumes of data are generated on the internet\\non a daily basis.\\nWith machine learning,\\nyou make decisions based on actionable insights\\nthat you predict from datasets.\\nHuge datasets can be very tricky to interpret\\nand extracting information from them is a tedious job.\\nData visualization makes this task much easier.\\nData visualization makes decision-making\\nand problem-solving easier for data scientists.\\n\\nIt can help you understand the next steps\\nthat must be taken to complete a project.\\nSimilarly, it makes it easier for you\\nto document your findings\\nand communicate them visually with stakeholders.\\nLet's take a real-life example\\nwhere data visualization can help\\nin business decision-making.\\nHere's a graph showing the number of sales produced\\nfrom a sports store.\\nThe data is collected each hour\\nfrom the time when the store is open\\nto when the store is closed.\\n\\nThe store manager needs to decide\\nwhich time slot is the busiest at the store.\\nIn other words, which period requires\\nthat maximum staff be present at the store?\\nIf we take a look at the graph,\\nwe can see the spike in sales at the store after 4:00 PM,\\nand this goes on till 1:00 AM.\\nWith this, we can conclude\\nthat 4:00 PM to 1:00 AM is the busiest period at the store\\nand the maximum number of staff are needed\\nat this specific time interval.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4584141\",\"duration\":522,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The three types of data visualization\",\"fileName\":\"3006708_en_US_03_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":767,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to identify three types of data visualization. This video covers data storytelling, data showcasing, and data art.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14070959,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this segment,\\nwe're going to be talking about the three\\ntypes of data visualization.\\nThose data visualization types are data storytelling,\\ndata showcasing, and data art.\\nData storytelling is the type\\nof data visualization you would create\\nfor generating presentations that you would use to present\\nto organizational decision makers.\\nData showcasing is the type\\nof data visualization you would be making\\nfor generating presentations for analysts, scientists,\\nmathematicians, and engineers.\\n\\nLastly, data art is the type\\nof data visualization you would create\\nfor presentations when you're presenting to activists\\nor the general public at large.\\nData art is pretty effective in these cases.\\nIn this section of the course, we're just going to go\\nthrough each of the different areas\\nand get them really well-defined for you so\\nthat you can use them effectively across your career.\\nDiving into data storytelling first, the purpose\\nof data storytelling is to make it easy for your audience\\nto really understand the point you're trying to make\\nwith the data visualization.\\n\\nYou need them to understand the point you're making\\nwith your data visualization,\\nand you want them to be able to understand that within 10\\nto 15 seconds of looking at the graphic.\\nIf they have to study it for longer than that, you're going\\nto lose their attention.\\nThat and your data visualization needs to be clutter-free\\nand highly focused.\\nAgain, you have to think about your intended audience when\\nyou're creating a data visualization.\\nIn these cases, when you are generating data\\nstorytelling pieces, your audience is going\\nto be comprised mostly of non analysts\\nand non-technical business managers,\\ndecision makers and leaders.\\n\\nThey do not want to wade through a bunch of clutter\\nand a bunch of details that they don't need\\nto make a conclusion.\\nThey want you to tell them your findings within the data\\nand basically show that in a visual manner.\\nWhen you're creating a data storytelling product\\nthat would be in the form of something like a static image\\nor a very simple interactive dashboard, maybe something\\nthat you would create in an application like\\nXcelsius by SAP.\\nIn this course, you're going to be learning how\\nto use a library called Streamlink\\nto create interactive data visualizations.\\n\\nThis slide demonstrates a great example\\nof data storytelling.\\nIf you look at this example here, you should be able\\nto understand what the graphic is telling you within about\\nfive seconds.\\nThe headline says, \\\"What's really warming the air?\\\"\\nObviously, they're talking about global warming,\\nand there is a simple line chart with a trend\\nthat's increasing.\\nBasically, without even thinking,\\nyou can tell that whoever produced this data storytelling\\npiece is trying to tell you\\nthat there's an increase in global warming.\\n\\nDo you see how simple that is to analyze and understand?\\nYou want to make sure that your data storytelling products\\nare also simple and easy to understand in this way.\\nNow, let's look at data showcasing.\\nData Showcasing is where you showcase a lot of data so\\nthat your audience members can think for themselves.\\nThis is an opposition to what you do with data storytelling.\\nData storytelling is\\nwhere you present your findings in a very, very clear\\nand easy to understand way.\\n\\nWhen you do data showcasing,\\nthe audience is actually looking\\nto draw conclusions for themselves.\\nTo that end, you need to make sure\\nthat your data visualization is highly contextual,\\nthat you've included all sorts of background information\\nto help people in your audience draw their own conclusions.\\nThe data visualization should be open-ended.\\nIn other words, you are not telling them your findings,\\nbut allowing them to think for themselves.\\nThe intended audience\\nfor data showcasing products would be analysts, quants,\\nengineers, mathematicians, scientists, basically people\\nwith an analytical mindset, background in that,\\nbecause this is the kind of thing that's going to be\\nof value to them.\\n\\nIn terms of product types,\\nwhen you are doing data showcasing,\\nyou'll be producing static images\\nand interactive dashboards,\\nand you're going to learn how to do both\\nof these things throughout the remainder of this course.\\nHere's an example of data showcasing.\\nI actually took this example from my book,\\n\\\"Data Science for Dummies.\\\"\\nYou can see that here,\\nthere's a lot of data that's being showcased on one screen.\\nYou could probably spend 15 minutes visually exploring this\\ndata visualization, looking for trends,\\npatterns, and correlations.\\n\\nYou could come away from this with many,\\nmany different types of hypotheses.\\nData showcasing is a good tool for exploratory data analysis\\nand for allowing other analysts\\nto do exploratory data analysis on a visual basis without\\nthem actually having to get in\\nand generate that data visualization for themselves.\\nIt's a great presentation tool.\\nLastly, let's look at data art.\\nYou can use data art to make a statement.\\nMost data art is used in something like data journalism,\\nor if you're trying to get your community\\nor a community of activists to be engaged in taking action,\\nthen you would benefit by generating a piece of art\\nthat's based on data.\\n\\nSomething that's really riveting\\nand inspiring or provoking to get them to have an opinion\\nand take action based on the data you're presenting them\\nthrough the artwork.\\nYour data visualization should be attention-getting\\nand creative, if not controversial,\\nbecause the more controversial it is,\\nthe more action you're likely to inspire.\\nIntended audiences\\nfor data art tend to be people like idealists, dreamers,\\nartists, and social activists.\\n\\nData art is a tool to educate, inform, and motivate\\nthe public in most cases.\\nIn terms of product types,\\ndata art is almost always produced as static images.\\nIn some cases, it's also produced\\nas an interactive data piece on the internet.\\nStatic data visualizations are generally\\nsufficient here though.\\nHere's an example of data art\\nthat I took from periscopic.com.\\nIf you're like most people, then you look at this example\\nfor about 10 to 15 seconds\\nand you understand exactly what it's trying to say.\\n\\nIt's saying that US gun laws need to change.\\nThis data art is attempting to get people\\nto rally up against the Second Amendment\\nand get gun laws tightened up in America.\\nIt's using data art to achieve that goal.\\nAs you can see here on the left, you've got an account\\nfor the number of people killed,\\nand that's 9,595 people\\nas highlighted in orange.\\nThen on the right side of this example, you see\\nthat they have actually counted up an approximation\\nof the number of years that were lost from those lives,\\nfrom those people that were killed.\\n\\nWhat they're really trying to do in this piece is\\nthat they're trying to numerically exaggerate the\\ndetrimental impact\\nthat US gun laws have upon the population as a whole.\\nIn order to do that, they're breaking down the number\\nof people killed to the number of years of life\\nthat's been lost.\\nIt's clear that they really want to rally up people in a\\npolitical way and get them\\nto take action against a Second Amendment.\\nBy exaggerating impact, they're looking for ways to amplify\\nthat impact as much as possible by using a metric\\nthat's got the highest number possible.\\n\\nIn this case, it's number of years of life lost\\nbecause of the gun laws.\\nThen if you look here under the title, it's not the number\\nof years of life lost.\\nThey call it stolen.\\nThey're really trying to impassion people\\nto take action against gun laws.\\nThey're saying, okay, people's lives are being stolen here.\\nIn fact, that may or may not be true\\nbecause a lot of times death from guns happen as a result\\nof deliberate criminal activity that a person chooses\\nto participate in despite its high risk nature.\\n\\nIf a person dies via a gunshot wound in this case,\\nis that truly a life stolen?\\nIt's up for you to decide.\\nWhat's presented in this visualization is a\\nmatter of perspective.\\nWhoever created this is really trying\\nto push people in their audience to get out\\nand change gun laws.\\nThey're infusing their opinions in order to get that done,\\nbut they're using data art as a way to drive impact.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4590003\",\"duration\":417,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Selecting optimal data graphics\",\"fileName\":\"3006708_en_US_03_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":575,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to select optimal data graphics. This video covers graphics for storytelling, graphics for showcasing, and graphics for data art.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15285627,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] It is time to talk about selecting\\noptimal data graphics.\\nYou're going to use different types of data graphics\\ndepending on the type of data visualization you're creating.\\nAgain, referring back to the last section,\\nyou learned that you can create data storytelling pieces,\\ndata showcasing visualizations, or data art.\\nIf you were to choose graphics for data storytelling,\\nappropriate graphics for this type of data piece\\nwould be things like pie charts, line charts,\\nbar charts, even area charts, point maps,\\nor chloropleth maps.\\n\\nA chloropleth map is a map that shows area boundaries.\\nIf you looked at a map of the United States,\\nyou would see 48 different areas outlined,\\nthat's a chloropleth map.\\nNow, if you were to take a look\\nat a map of the United States\\nto examine major cities within the United States,\\nyou would see points to indicate\\nwhere the major cities are located,\\nthat's a point map.\\nThe reason why these types of graphics are appropriate\\nfor data storytelling\\nis that people understand what they mean.\\n\\nAgain, going back to the purpose of data storytelling,\\nthat purpose is to share your findings\\nwith an audience of people\\nwho are generally not very quantitative\\nor analytical by nature.\\nBecause this type of audience tends not\\nto be very analytical,\\nthey generally want to be given the findings\\nin a way that is comfortable\\nand easier for them to understand.\\nThat's why these are the best type of graphics\\nwhen we are creating data storytelling pieces.\\nNow, in terms of creating data showcasing pieces,\\nyou have a little bit or a lot more options\\nwith respect to the type of graphics you can use here.\\n\\nOf course, you can use the same type of graphics\\nthat you would in data storytelling,\\nbut you also want to add more context\\nto data showcasing pieces.\\nIn addition to pie charts, line charts,\\nand bar charts, you would also want to include\\nor could include things like histograms,\\nscatter plots, scatter plot matrices, and even raster maps.\\nTo add a little bit of clarity here\\non what exactly a raster map is,\\nI brought in a picture of a Doppler weather radar\\non top of a geographic map.\\n\\nBasically, what a raster map is,\\nis it's a raster file that's actually made\\nof an X and Y grid, which is filled\\nwith a variety of numerical values.\\nThe grid is X and Y.\\nThe numerical values are colored according to count.\\nIn this case, the raster is showing you\\nthat where it's red, the value is higher,\\nand then as the value decreases,\\nit goes from yellow to green to blue,\\nand then turquoise.\\n\\nRaster coverage is just a coverage\\non top of a geographic map that provides\\na layer of information about one metric.\\nSince data showcasing is intended\\nfor analytical audiences, STEM grads,\\nanalysts, engineers, quants, these type of people,\\naudience members usually want\\nthat extra bit of information,\\nand these would be an appropriate graphic type\\nto use in the data showcasing piece.\\nOkay, now let's look at data art.\\n\\nIn terms of data art, like we saw in the last section,\\ndata art is intended for the general public\\nor for activists, dreamers, and doers.\\nThey're generally not super analytical people,\\nso we would want to keep it simple for them.\\nYou could use a line chart, a graph network,\\nor a chloropleth map to communicate\\nas the data graphic within data art.\\nBut honestly, most of the time when you see data art,\\nthe data is shown in some sort of weird\\nor artistic representation\\nthat actually isn't a data graphic at all.\\n\\nThe creator often finds some sort of artistic way\\nto represent their data\\nand what they're trying to present about that data.\\nTo try and make it just a little more clear\\nabout what I mean when I say weird\\nor creative data visualization,\\nI brought in this data visualization\\nthat was presented by Mona Challabi and TEDx at NYC.\\nShe was basically educating her audience\\non three ways to spot a bad statistic.\\n\\nBut as you can see here,\\nthe state of the visualization is definitely provocative\\nbecause it's kind of gross.\\nWell, it's really gross,\\nand it's also really, really creative\\nas data visualizations go.\\nIn this case, the graphic represents\\nthe peak month of flu virus and the times per month\\nthat this season's peak since 1982.\\nThe creator is trying to make a point\\nabout when flu viruses peak,\\nand they've created this provocative data visualization\\nto get the point across.\\n\\nThis is a fine example of data art.\\nLet's now move on to the four steps\\nto choosing the right type of data graphic\\nwhen you're creating a data visualization.\\nStep one is that you make a list of questions\\nthat your data visualization is meant to answer.\\nStep two is to consider\\nwhether your data visualization type\\nshould be data storytelling,\\ndata showcasing, or data art.\\nYou would make that determination\\nby thinking about your intended audience,\\nwho is meant to consume the data visualization.\\n\\nStep three is just to answer the question,\\n\\\"What data graphic types are preferable\\nfor this type of data visualization?\\\"\\nWe covered this topic in this lecture here.\\nOnce you've answered that third question,\\nmoving into step four,\\nyou go ahead and you test out\\nthe different types of data graphics with your data\\nand decide which graphic type displays\\nthe most clear and obvious answer to your question.\\nLet me illustrate what I mean\\nbecause it could sound kind of vague\\nif you haven't seen an example.\\n\\nIn step four, we're actually testing out\\nyour data graphic to see\\nwhich is the most effective visual communication tool.\\nJust look at this example.\\nYou see that you have two data graphics.\\nThey both represent the same statistic,\\nbut you notice that the data graphic on the right\\ndoes a much better job of visually emphasizing\\nthe differences in values.\\nOn the left, you basically can't see\\nany difference whatsoever,\\nso it makes it very hard to communicate the data.\\n\\nYou should always test your different data graphics\\nto make sure that you use the one\\nthat is most clear and effective\\nin displaying your data\\nand the trends and patterns within the data.\\nThe graphic on the left below\\nis definitely not the most effective choice.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4588024\",\"duration\":408,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Communicating with color and context\",\"fileName\":\"3006708_en_US_03_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":590,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to communicate with color and context. This video covers color schemes, annotation, and visual context.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11462929,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now let's talk about communicating\\nwith color and context.\\nThe correct choice of color and context can really,\\nreally add a lot of value to your data visualization,\\nso it's an important topic for us to cover here.\\nStarting first with creating context with color.\\nColor should be used strategically,\\nsparingly, and consistently.\\nWe want to use color to draw attention\\nto the most important parts of your data visualization\\nand away from the parts that are not that important.\\n\\nThe first and foremost rule you need\\nto follow when you're choosing a color scheme\\nfor your data visualization is that you need to make sure\\nthat the color stage you choose\\nto use in your data visualization are all from the\\nsame color formula.\\nThere are many different options out there\\nfor color formulas.\\nPopular ones include monochromatic, analogous,\\nand complementary,\\nbut then there's also split complimentary, triadic\\nand tetradic and many other options out there as well.\\n\\nColor formulas are based on extensive color theory\\nthat's been adapted over hundreds of years,\\nand so you want to use them in order to ensure\\nthat you're using a color scheme\\nor a color formula that's going to be harmonious to the eye\\nof the end consumer.\\nYou also want to make sure that you have some shades\\nthat are useful for drawing the attention of the eye\\nand other shades that are more muted so\\nthat you can use your color strategically\\nto attract attention where it's needed.\\n\\nIn case you're looking for a good tool\\nto find good color schemes\\nto use in your data visualizations,\\nthere is an AI driven color matching tool\\ncalled Colormind IO.\\nI'll put a link for you here.\\nI took this color scheme\\nthat you're seeing on this side from Colormind,\\nand it's actually a very good example of something\\nthat could be used in a data visualization quite well.\\nAs you can see, there are two shades that really pop,\\npurple and red, and the other three shades are muted\\nor they don't draw a lot of attention,\\nso you can use the muted shades to basically plot out data\\nthat is of lesser interest.\\n\\nAnd then the purple\\nand red shades would be good\\nfor really showcasing whatever trend\\nor finding that you're demonstrating.\\nIn other words, the part of the data visualization\\nthat you want to stand out the most to the consumer.\\nAll of the color schemes that are generated\\nwith a Colormind tool include shades\\nthat are within the same color formula.\\nThis tool takes care of that for you, which is very nice.\\nNow, moving into annotation,\\nyou can see here an example I got from USA ID\\nwhere they're basically using annotation to add context\\nand tell the story around how the data is performing.\\n\\nUsing annotations as context is useful\\nfor providing your audience some information about why the\\ndata behaves as it does.\\nAnnotation is especially useful in data storytelling\\nand data showcasing because they add a layer of context\\nand meaning to the data visualization\\nthat helps consumers understand\\nwhat it is that you're showing them.\\nAnother way that you can add context\\nto a data visualization is to introduce graphic elements.\\n\\nIn this case, we're looking at a trend line,\\nbut also single value alerts\\nand benchmarks are very useful in helping your audience\\nunderstand the relative significance\\nof the data that you're showing them.\\nLet's talk a bit about the mechanics\\nbehind creating context in a data visualization.\\nYou can create context in your data visualization just\\nby adding data on additional and relevant metrics.\\nFor example, if you were\\nto be featuring some statistics on dropout rates in a\\nparticular region of a city, some data\\nthat might be a good contextual layer\\nto add would possibly be data on the household\\nand the parents' level of education,\\nand if the parents were also dropped out of high school,\\nbecause it would seem that if a child comes from a household\\nwhere both of the parents\\nor one of the parents dropped out of high school\\nand did relatively okay with their life,\\nthat the child would also feel like dropping out of\\nhigh school would be a viable alternative for them.\\n\\nSo that would be an example of adding relevant data sets\\nand additional metrics around\\nwhat you're featuring in your data visualization.\\nAbout why you'd want to create context.\\nBy adding context,\\nyou're giving your audience a deeper perspective\\nand insight into what's happening with the situation\\nthat's represented by your data visualization.\\nOther ways that you can add context are, again,\\nlike I stated, just adding trendlines, single value alerts,\\na strategic use of color and annotations.\\n\\nAdded context is especially useful in data showcasing\\nbecause again, data showcasing pieces are meant\\nfor analytical audiences that really want to put a lot\\nof thought into drawing conclusions from the data\\nthat they're looking at.\\nBut that said, context is also useful in data showcasing,\\nbecause usually in data showcasing,\\nyou would just add a little bit of textual context\\nor maybe a trend line to clarify exactly what you're trying\\nto tell your audience.\\n\\nYou wouldn't expect them to go in\\nand read multiple layers of annotation\\nor to go deep into evaluating the visualization,\\nbut you may want to give them some text\\nor markers in order to make it abundantly clear\\nwhat you're trying to tell them\\nwith your data visualization.\\nHere's an example of a good solid data visualization.\\nWhat I really love about this data visualization is its\\nstrategic use of color.\\nThe color is done right.\\nThis data visualization is taken from Data Lab's agency,\\nand they have really done a great job in using color\\nto draw attention to what matters most in this piece.\\n\\nThey are using more muted shades in order\\nto underlie and support their data visualization\\nfor completeness, but they use the red\\nand orange to really draw attention\\nto the points they're trying\\nto make within the data visualization.\\nNow that you know the basics of data visualization,\\nthe types of data visualizations you can create,\\nhow to select optimal graphics\\nand how to communicate well with color\\nand context, it's time to move into the next section\\nof the course where we'll talk about practical data\\nvisualization and how\\nto build data visualizations using Python.\\n\\n\"}],\"name\":\"3. Data Visualization 101\",\"size\":45937181,\"urn\":\"urn:li:learningContentChapter:4586146\"},{\"duration\":5866,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4590004\",\"duration\":1069,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to the matplotlib and Seaborn libraries\",\"fileName\":\"3006708_en_US_04_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1651,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Get a practical introduction to Python's matplotlib and Seaborn libraries. Learn how to set up an environment for creating data visualizations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":36335610,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this lecture, we'll explore two\\nof Python's most powerful visualization libraries,\\nMatplotlib and Seaborn.\\nWhile both are highly capable,\\nthey have distinct features and use cases.\\nSeaborn stands out for its simplicity and its elegance.\\nIt requires less complex syntax\\nand offers beautifully designed default themes,\\nmaking it ideal for creating sophisticated visualizations\\nwith very little effort.\\n\\nOn the other hand, Matplotlib excels at customizability.\\nIt allows for extensive visual modifications\\nthrough direct axis to its classes.\\nIt suffers greater control if you need\\nto fine tune every aspect of your charts and plots.\\nIn this module, I'm going to give you an overview\\nof how to effectively utilize both libraries\\nfor your data visualization needs.\\nMatplotlib and Seaborn are versatile libraries\\nfor creating a wide range of standard chart graphics.\\n\\nThey're useful for visualizing all types and kinds of data.\\nThis, of course, includes but isn't limited\\nto financial data, operational data,\\nemployee data, engagement and behavioral data.\\nOne thing to note, however, is\\nthat you can display network data\\nusing standard chart graphics,\\nbut you cannot create network graphs when you're working\\nwith only the Matplotlib or Seaborn library.\\n\\nMatplotlib is typically employed for generating basic plots.\\nIts visualization capabilities commonly include\\ncreating bar charts, line charts, scatter plots,\\nand similar straightforward graphical representations.\\nConversely, Seaborn offers an extensive array\\nof visualization options.\\nIt's known for its beautiful themes,\\nand Seaborn allows for the plotting of complex graphics\\nwith relatively minimal coding effort.\\n\\nIt specializes in statistical visualizations,\\nmaking it ideal for summarizing\\nand displaying distributions within datasets.\\nNow let's look at how we can utilize both Matplotlib\\nand Seaborn to create various types of graphics.\\nOkay, in this coding demonstration,\\nI just want to show you how to get started really quickly\\nwith Matplotlib and the Seaborn library.\\nSo we're first going to start\\nby installing the required libraries.\\n\\nSo for that, we'll need to do a pip install.\\nAnd we will pip install Matplotlib,\\nand run this.\\nAnd we'll also need to do a pip install\\nof the Seaborn library.\\nOkay, so we've got all of those installed.\\nNow we need to import them into our IPython environment.\\nSo we'll do that now\\nby just saying import matplotlib.pyplot as plt,\\nand import seaborn as sns.\\n\\nAnd then for this demonstration,\\nwe also need to work with DataFrames.\\nSo we'll say from pandas import DataFrame.\\nOkay, so then we'll run this.\\nOkay, now we have imported both,\\nall of the libraries that we need here.\\nSo let's get started looking\\nat how we can use them to generate plots.\\nI will go ahead\\nand just create a dataset that we can use\\nfor practicing our data visualization.\\n\\nSo we'll just call it data.\\nAnd then let's create a dataset\\nwith the names of individuals\\nalong with their age, gender, and rank.\\nThis is a dataset that we actually\\ndefined in an earlier lecture,\\nso I won't spend too much time typing everything out.\\nThe names here should be steve, john, richard,\\nsarah, and julie.\\n\\nSo we'll pass these strings\\ninto the list.\\nAnd then,\\nwe will define the age of each of these people.\\nSo create a column named age,\\nand we'll set the ages equal to,\\n20, 22, 20, 21, 24, 23, and 22.\\n\\nAnd it looks like we forgot a bracket.\\nSo let's close that.\\nAnd then create the next column, which is going to be gender.\\nWe'll say gender,\\nand set that equal to Male, Male, Male,\\nFemale, Male, Male, and Female.\\nAnd then the next column we need is rank.\\nWe'll create a rank column\\nand then we will assign a rank to each of these people.\\n\\nAnd that is 2, 1, 4, 5, 3, 7, 6.\\nSo now we have a dataset that we can work with.\\nLet's create a DataFrame from this dataset.\\nTo do that, we just use the DataFrame constructor\\nand pass in data,\\nand we'll set this equal to df,\\nand then let's just print it out.\\n\\nOkay, it looks like we have a syntax error,\\nwhich should be pretty easy to fix.\\nThe string just was not closed here for gender.\\nRun this again. Okay, so here is now our DataFrame.\\nAnd let's use this to create a Matplotlib bar chart.\\nAnd we'll just start by creating a simple bar chart.\\nTo do that, we will use the bar function.\\n\\nAnd in the function, we'll pass the DataFrame's names column\\nas the first parameter,\\nand then we'll pass in the DataFrame's age column\\nas a second parameter.\\nSo let's get started with that.\\nWe'll say plt.bar,\\nand then of the df DataFrame,\\nwe want to select names.\\nAnd then we also want\\nto select the age column from the DataFrame.\\n\\nSo we'll say df, and then we'll select here, age.\\nThe values of the first parameter will be shown\\nacross the X-axis, and then the values\\nof the second parameter will be shown across the Y-axis.\\nSo let's go ahead\\nand set some labels for both of these axes.\\nIn order to do that, you would use the xlabel function,\\nand so that looks like plt.xlabel.\\nAnd yeah, so along the X-axis we're going to have Names.\\n\\nAnd so we'll just create a label here for that axis.\\nAnd then for the Y-axis ylabel,\\nwe're going to have Age.\\nSo this is going to be shown along the Y-axis.\\nAnd let's also create a title for this plot.\\nTo do that, we would say plt.title,\\ncalled the title function,\\nand then pass in a string for the title of the plot.\\n\\nLet's call it Comparing Ages.\\nAnd then let's print the plot out.\\nTo do that, you use the show function.\\nSo plt.show,\\nand run this.\\nAnd okay, great.\\nSo now we actually have a bar chart\\nthat shows the ages of each\\nof the people in our DataFrame.\\n\\nNow let's create a similar bar graph using Seaborn.\\nAnd to do that, we'll call Seaborn's bar plot function.\\nIn the bar plot function,\\nwe'll just pass the DataFrame\\nand specify the columns we want to show on the X and Y-axis.\\nSo let's test that out real quick.\\nWe'll say plot, we'll say plot is equal to sns.barplot.\\n\\nAnd then we will say\\nthat our data is equal to the DataFrame function here.\\nOur x value is equal\\nto the names column.\\nSo we're selecting the names column for the X-axis.\\nAnd the Y-axis, we will select the age column.\\nAnd then let's create a title for this plot.\\nTo do that, we use the set_title function.\\n\\nSo this is plot.set_title.\\nAnd again, we'll just call it Comparing Ages.\\nNow to plot out this graph,\\nwe would just say plt.show,\\nand run that.\\nAnd here you can see we have similar object,\\nbut now it's a Seaborn bar graph.\\n\\nAnd as you can see, there are small differences\\nbetween the Matplotlib one and the Seaborn one,\\nbecause this name's variable\\nand this age variable have different casing than above,\\nbut in general, they look pretty darn similar.\\nThe key difference here though, is you can see\\nwith the method we're creating the bar chart\\nusing Matplotlib, it just requires more code\\nto generate the same graph.\\nSo it's pretty much always the case\\nthat Seaborn is more efficient\\nat data visualization than Matplotlib.\\n\\nAnd in general, it's more beautiful.\\nIt comes up with graphs that are more beautiful,\\nalthough in this example we aren't seeing a huge difference.\\nLater on in the course, you will start\\nto see the differences between Seaborn and Matplotlib\\nin terms of aesthetic.\\nDrawing all sorts of other types of graphs\\nwith Matplotlib and Seaborn are also pretty straightforward.\\nSo let's go ahead and create a line plot with Matplotlib.\\n\\nTo create a line plot with Matplotlib,\\nyou just use the plot function, so that's plt.plot.\\nAnd then let's pass in the DataFrame,\\nand let's put out again the names and age\\nof the people in this DataFrame.\\nSo put name.\\nAnd then for our Y-axis,\\nlet's select the age column here.\\n\\nAnd we can name the label names the same\\nas the bar chart here.\\nSo we can actually just copy these labels,\\npaste them down here.\\nAnd then to take a look at it,\\nwe would just say, plt.show,\\nand run this.\\nAnd okay, so here we have the ages\\nof our people plotted out in line chart format.\\n\\nLet's also look\\nat how we can create a line plot using Seaborn.\\nSo again, this is going to be a lot more simple.\\nWe'll create an object called plot,\\nand we'll say that it's equal to the DataFrame.\\nWe need to call the line plot function.\\nSo that's sns.lineplot,\\nand we'll pass in our df DataFrame\\nas our data here.\\n\\nAnd then again, we will just take X and Y-axis.\\nWe can just copy and paste these from above.\\nSo that's all the same as the bar chart.\\nAnd then to plot this out, we'll say plt.show.\\nOkay. And we'll run this.\\nAnd as you can see, it looks pretty much exactly\\nlike the line plot we created with Matplotlib,\\nwhich makes sense since it's exactly the same dataset,\\nbut it's just again, a lot more efficient\\nto use this method to create a line chart\\nthan it is to create a line chart in Matplotlib.\\n\\nLet's really quickly look at how\\nto create a pie chart in Matplotlib and in Seaborn.\\nSo for Matplotlib, we need to use the pie function.\\nIt will say plt.pie.\\nAnd then let's plot out the age column.\\nSo we'll select that from our DataFrame here,\\nand we'll add some labels.\\n\\nTo do that, we create a labels parameter\\nand we set it equal to the names column.\\nSo we'll select df, names column here.\\nAnd then let's create a title for the chart.\\nSo to do that, we use the title function,\\nwe pass in a title that says Age Comparison,\\nand then we can print this out.\\n\\nI have a typo here\\nwhere it should be title, so I'll fix that.\\nAnd then, okay,\\nso here's our Matplotlib pie chart.\\nNow, Seaborn doesn't have a default function\\nto create pie charts,\\nbut we can use the syntax in Matplotlib\\nto create a pie chart\\nand then add the Seaborn color palette.\\nLet me show you how to do that real quick.\\nSo we'll create a variable say, colors,\\nand then we we'll call the color_palette function.\\n\\nSo that's sns.color_palette.\\nLet's take a look and get the pastel color palette.\\nAnd then say if we only want five colors,\\nwe can just slice the color palette from zero to five.\\nAnd then what that will do is\\nit will just extract the color palette list,\\nand the colors that are associated\\nwith position 0, 1, 2, 3, and 4.\\n\\nAnd then now we have a color palette set up.\\nSo let's call the pie function, which is plt.pie,\\nand we'll pass in our DataFrame and select the age column.\\nAnd then let's set our labels equal to the names column.\\nSo to do that, we say labels is equal to df,\\nand select names here.\\n\\nAnd then lastly, we'll define the colors\\nequal to the colors palette\\nthat we just created in the line of code above.\\nAnd then we can run that.\\nSo I just ran this without using the show function.\\nAnd then that's actually what you get,\\nis you get all of this extra information about the plot\\nthat you don't necessarily want or need to see.\\nSo just to clean this up, I'm going to say plt.show\\nand run it again.\\nAnd here now we have a Seaborn chart.\\n\\nSo we have a pie chart that we actually used Matplotlib\\nto help build.\\nAnd we've then applied the color palette\\nfrom Seaborn to this pie chart.\\nAnd those are the basics of just how to get started\\nusing Matplotlib and Seaborn libraries.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4584142\",\"duration\":625,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating standard data graphics\",\"fileName\":\"3006708_en_US_04_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1141,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to create standard data graphics. This video covers line charts, pie charts, and bar charts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":20015180,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Standard chart graphics are excellent tools\\nfor conveying simple data insights in a way\\nthat anyone can understand.\\nFor example, imagine you are an E-commerce business analyst\\nfor a company that just made some major changes\\nto its website layout.\\nYou are visualizing the site usability insights\\nthat you've discovered to convey findings to your manager.\\nTo do this, you use a line chart,\\na bar chart, and a pie chart.\\nYou use a line chart to show how the total number\\nof items purchased per day has increased since the change.\\n\\nYou'll use the bar chart to show how the number\\nof purchases increased for customers\\nin the 18 to 25-year-old category,\\nbut that it decreased\\nfor customers in the greater than 44-year-old category.\\nLastly, you use a pie chart to show what categories\\nof products generate the greatest proportion of sales\\nand how the site changes affected that proportion,\\nboth before and after.\\nTo summarize, you'd use a line chart\\nto show the changes over time,\\nyou'd use a bar chart to show changes in categorical data,\\nand you'd use a pie chart to visualize categorical data\\nas a proportion of a whole.\\n\\nNow, we have two methods for plot building,\\na functional method and an object-oriented method.\\nIn the demonstration we're about to do,\\nI'm going to show you\\nhow to build plots using the functional method.\\nWith the functional method, you build plots\\nby calling the plotting function on a variable\\nor set of variables.\\nWith object-oriented plotting,\\nyou build a plot by first generating a blank figure object\\nand then populating that object with plot and plot elements.\\nWe'll be doing that in later demonstrations.\\n\\nIn the coding demonstration to come, I'm going\\nto show you the most popular data visualization libraries\\nin Python, which are, of course, Matplotlib and Seaborn.\\nIn this demonstration,\\nI'm going to show you how to use Matplotlib.\\nLet's get started.\\nSo here we have our Jupyter Notebook,\\nand I'm giving you the mtcars dataset preloaded here\\nwith the column names and everything prepared for you,\\njust so we don't have to type that out again.\\n\\nBut first things first, let's go ahead\\nand import our libraries, and in this demonstration,\\nwe're going to use NumPy.\\nSo we'll import numpy as np.\\nWe're also going to be generating random numbers\\nin this demonstration, so within NumPy,\\nwe need to import randn.\\nSo let's say from numpy.random,\\nimport randn,\\nand then we always of course need to import pandas,\\nand we'll import that as pd.\\n\\nAnd then let's bring in our series and data frame.\\nSo we'll import Series and DataFrame,\\nand we're going to be using Matplotlib in this demonstration\\nso we'll import matplotlib.pyplot\\nas plt,\\nand from matplotlib,\\nlet's also import the rcParams.\\n\\nGreat, and so now let's just run this\\nand we'll have our libraries ready for us.\\nNow, the first thing we're going\\nto work on here is that we're going\\nto create some line charts, so the first line chart,\\nlet's just generate two variables, an x and a y variable,\\nand x will be equal to a range\\nof values between one and nine.\\nSo we'll say x equal to range one through 10,\\nand y is equal to a list,\\nand it's just going to be a list of numbers,\\none, two, three, four,\\nzero, four, three, two, one.\\n\\nTo generate the line plot,\\nwhat we need to do is call the plot function,\\nso that's plt.plot,\\nand then let's just pass in the x and y,\\nand run this.\\nOkay, so we have our line chart,\\nand that's pretty straightforward.\\nNow let's work on creating a line chart\\nfrom a Pandas object.\\nWe've already got your data loaded\\nand ready to go inside of the Jupyter environment,\\nbut we need to go ahead and isolate a variable.\\n\\nSo let's isolate the mpg variable,\\nwhich we're doing here, mpg,\\nand we're setting it equal to the cars data frame,\\nand we've selected the mpg column out of that data frame.\\nSo the first thing I want to do is just run this,\\nand then we have our mtcars dataset available to us in here.\\nAnd now, let's just plot out the mpg variable,\\nso to do that, we'll do mpg.plot, and we'll run this.\\n\\nHere we go, we have a line chart\\nthat shows the values within the mpg variable.\\nNow, I want to show you\\nhow to actually plot out three variables in a chart.\\nSo to do that, let's create a data frame called df,\\nsay df is equal to cars,\\nand then let's select the variables we want to plot\\nand let's make those, let's make those cyl,\\nweight, and mpg.\\n\\nAnd then to plot it out,\\nwe just call the plot method off of the DataFrame object\\nand run this.\\nOh, it looks like I need to actually add another set\\nof brackets here.\\nAnd I'll run it again.\\nOkay, cool, so now we have a line chart\\nwith three variables plotted out instead of just one\\nand we've got a nice little legend here\\nso that we can make sense of which variable is which.\\n\\nNow, let's look at how to create bar charts.\\nTo create a bar chart, you would just call the bar function,\\nso that's plt.bar.\\nAnd then let's pass in our x and y variable\\nand run this, and it's easy as that.\\nWe've got a bar chart.\\nLet me show you how to create a bar chart\\nwith a Pandas object.\\nTo do that, you would just call the plot function,\\nso let's plot out our mpg variable as a bar chart.\\n\\nTo do that, we will say mpg.plot,\\nand then we'll pass a parameter\\nthat says kind is equal to bar,\\nand run this.\\nAnd now we have our mpg variable plotted out as a bar chart.\\nIf you wanted to plot this horizontally instead\\nof vertically, all you would need\\nto do is use the same command,\\nbut the parameter would instead be kind equal to barh,\\nand then you would get a horizontal bar chart,\\nso let me show you that real quick.\\n\\nI'll just copy this code,\\nand add a H here for this.\\nNow we have a horizontal bar chart, and that is easy-peasy.\\nThe last thing I want to show you\\nin this demonstration is how to create pie charts\\nand actually print them out.\\nSo for this example, let's create a new variable x,\\nand let's say that x is just a list\\nwith the values one, two, three, four, and 0.5.\\n\\n'Kay.\\nAnd then if we wanted to create a pie chart from this,\\nwe would just call the py function, plt.py,\\nand pass in our variable x,\\nand then to print it out, we would call the show function,\\nwhich is plt.show,\\nrun this.\\nAnd okay, now we have a very, very simple pie chart.\\nBut what I really wanted to do\\nin this demonstration was actually to show you\\nhow to save this pie chart as an image file.\\n\\nSo to do that, first, let's generate the pie chart again.\\nSo we'll say plt.py, and then we'll pass in our x variable.\\nAnd then to save this as an image file, we actually need\\nto use the savefig function,\\nso that's plt.savefig,\\nand we'll pass in a string with the file name,\\nand we'll call that pie_chart.png,\\nand then we can just plot this out\\nusing the show function here,\\nand great, okay, so that's still the same pie chart,\\nbut what this has actually done\\nwith the savefig function is it's saved this pie chart\\nas an image.\\n\\nSo you can see that here in our Notebooks folder,\\ndown at the bottom, you'll see pie_chart.png,\\nand here we go, we have the same image\\nthat is from our notebook\\nthat has been now printed within a separate image file.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2715031\",\"duration\":748,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining elements of a plot\",\"fileName\":\"3006708_en_US_04_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1306,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to define elements of a plot. This video covers object-oriented plotting, sub-plots, and axis labels.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":23712323,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now you're going to learn\\nabout defining plot elements using Matplotlib.\\nPlot elements add context to your plot\\nso that the plot effectively conveys meaning to its viewers.\\nYou set axes limits to make sure\\nthat your chart is well fit to your data graphic,\\nyou set axes tick marks and plot grids\\nto make it easier and faster for viewers\\nto interpret your chart at a glance.\\nYou can use subplots to visually compare changes\\nin data values under different conditions,\\nlike in different seasons,\\ndifferent locations, or in different years.\\n\\nThere are two methods for building plots.\\nYou can use the Functional method\\nor the Object-oriented method.\\nAdding plot elements is an essential part\\nof Object-oriented plotting.\\nWe discussed the functional plotting\\nin the last demonstration.\\nSo now it's time to go over Object-oriented plotting.\\nAgain with Object-oriented plotting,\\nyou build a plot by first generating a blank figure object\\nand then populating that object\\nwith plots and plot elements.\\nThere are four steps in Object-oriented plotting.\\n\\nFirst one is to create a blank figure object.\\nThen second, you will add axes to the figure.\\nThird, you'll generate a plot\\nor plots within the figure object.\\nAnd then fourth, you will specify plotting\\nand layout parameters for the plots within your figure.\\nOne last thing I want to touch on here\\nbefore we go into the demonstration is subplots.\\nA Subplot is a plotting figure\\nthat contains more than one plot or subplots.\\n\\nIt's easy to generate a subplot in Matplotlib\\nwith the subplots function.\\nLet's look at how to define elements\\nof a plot using Matplotlib.\\nSo this Jupyter notebook is coming preloaded\\nwith the libraries you'll need,\\nwhich is NumPy, Pandas and Matplotlib.\\nAnd I wanted just to start off this demonstration\\nby showing you how to set the figure size\\nand inline settings for your Matplotlib plots.\\n\\nSo to make sure that your plots print out properly\\nwithin Jupyter notebooks,\\nyou want to use the command matplotlib inline.\\nWhat this does is it tells Python\\nto print your Matplotlib plot in line\\nwith your Jupyter notebook.\\nAnd then you'll also probably want to go ahead\\nand do define a figure size.\\nSo to do that, you're going to use the rcParams function.\\n\\nThen create a list,\\nand you want to define the figure and figure size.\\nSo you'll say fig.figsize.\\nIn manual, just set this equal to the dimensions\\nyou want for your plots.\\nSo in this demonstration,\\nlet's just print plots\\nthat are 5 inches wide and 4 inches tall.\\nSo we'll put 5, 4 here.\\nAnd then we basically have set the parameters\\nfor generating plots within our Jupyter notebook.\\n\\nSo we run this.\\nNow let's go ahead and define axes, ticks and grids.\\nTo do that, we first need to generate some variables.\\nSo let's create an x variable here,\\nand then we'll say that the x variable\\nis a series of numbers between 1 and 9.\\nSo we'll use the range function\\nand we'll pass in the starting value of 1,\\nand then the end value is 10,\\nwhere 10 is actually excluded\\nfrom the numbers that are generated.\\n\\nAnd then another variable will be y\\nand we'll set y equal to a list.\\nThe values in this list will be\\n1, 2, 3, 4, 0, 4, 3, 2, 1.\\nNow let's generate a figure.\\nSo to do that, we will say fig is equal to plt.figure,\\nwe'll call the figure function here.\\n\\nAnd this is basically going to create a blank figure.\\nThe next thing we're going to do\\nis that we're going to add axes to this figure.\\nTo do that, you call the add axes method\\noff of this fig object.\\nSo we say fig.add_axes, axis.\\nAnd this will be our ax object.\\nSo I'll set this whole thing equal to ax.\\n\\nAnd for our axes parameters,\\nlet's just pass a list\\nthat will contain the numbers we want.\\nSo that'll be 0.1, 0.1, 1, 1.\\nAnd now let's plot this out.\\nTo plot it out, all we need to do is call the plot method\\noff of the ax object\\nand pass in our x and y variables.\\n\\nThere is a extra equal sign.\\nSo then we'll run this.\\nAnd there we have it.\\nWe have a simple line chart,\\nbut now we have created tick marks along the axes,\\nand we've created a figure\\nin which the line chart can be displayed.\\nThese are the basics of Object-oriented plotting.\\nNow let's go into some more details.\\n\\nWe're going to add limits\\nand tick marks on the x and y axes.\\nSo we'll start again with our figure and our axes.\\nAnd I'll just go ahead and copy this code\\nso we don't have to type it all out again.\\nNow let's add some limits to our x and y axes.\\nTo do that, you're going to call the xlim function\\nand set the 8 ylim function.\\nAnd basically what we want to do\\nis we want to set the limits of our axes,\\nand then we need to pass a list\\nthat tells Python what we want those limits to be.\\n\\nSo in this case, that will be 1 and 9.\\nSo we'll say ax.set_xlim\\nand then the limit is going to be 1 and 9.\\nAnd then moving into the ylim,\\nwe say set_ylim,\\nand we define those limits.\\n\\nSo those are going to be 0 and 5.\\nAnd then we also want to just practice\\nwith setting some tick marks.\\nSo to do that, we're going to use the xticks function\\nand set yticks function.\\nSo to do that, we're going to use the set xticks function\\nand the set yticks function.\\nSo let me just write those out here\\nand we'll say set_xticks.\\n\\nLet's also just set it up for our y tick marks.\\nI'll copy this over.\\nOkay, great. So now let's pass in a list here\\nand say what we want our tick marks to be.\\nAnd so for the x axes, let's just make that,\\nmake those 0, 1, 2, 3, 4, 5, 6, 8, 9 and 10.\\n\\nAnd then for our y ticks,\\nlet's make those 0, 1, 2, 3, 4, and 5.\\nAll right. And then we'll plot this out\\nusing the plot function.\\nSo now we have another line chart,\\nbut you can see now that we've added tick marks\\nand we've also added limits to our axes.\\nSo if we look back and forth between the prior graph\\nand this one, you can see the changes.\\nSpecifically, you can see that\\nthe 7 tick mark is missing here on the x axis,\\nand the maximum limit of the y axis is now 5 here\\ninstead of 4,\\njust above 4 in the prior graph.\\n\\nAnother thing you can do is that you can add a grid\\nto the background of your chart.\\nSo let me just show you how that works real quick.\\nWhat I'll do is I'll copy in this code from above,\\nand then we'll just add a grid to the plot.\\nAnd to do that, we just call the grid function.\\nSo we'll say here,\\nI'm going to take these tick marks out,\\nand then we'll say ax.grid\\nand then we'll plot it out, ax.plot\\nand then we'll pass in our x and y variables.\\n\\nAnd then we'll run this\\nand we'll get a nice little grid background\\non our line chart so that it makes it more easy to read.\\nYou can also generate multiple plots in one figure\\nwith a subplots function like I mentioned in the lecture.\\nSo let's go ahead and do that.\\nFirst things first, of course, we need to generate a figure.\\nSo in this case, it's going to be fig is equal to plt.figure.\\n\\nThis is the same as last time,\\nbut we're going to adjust the figure\\nto actually include two subplots.\\nSo to do that we need to say fig,\\nand then we need to create two axes here.\\nTo do that, we're going to create a tuple,\\nand we're going to say ax1 and ax2.\\nThen we're going to set these\\nequal to the subplots function.\\nThat's plt.subplots,\\nthen we want to define\\nwhat we want our subplots to look like.\\n\\nSo let's say we have\\n1 row and 2 columns.\\nSo we would just say 1 and 2 here.\\nOkay. And then to plot it out,\\nwhat you need to do\\nis you need to actually plot both axis,\\naxis 1 and axis 2.\\nSo we'll say ax1.plot.\\n\\nThen we'll pass in the x variable.\\nAnd ax2.plot\\nand we'll pass in the x and y variable here\\nso that we have a little bit\\nof a difference in our plots.\\nAnd then when I run this,\\noh before I do that, it's in markdown,\\nso I need to just make sure it's in Python.\\n\\nAnd then when I run this,\\nI'm missing a comma here.\\nSo I'll run this\\nand I need to add the figure subplots, okay.\\nHere we go.\\nSo now we have two subplots.\\nWhat we've actually done though\\nis we have created one figure with two axes,\\nand then we have generated plots within that one figure.\\nPretty cool, huh?\\n\"},{\"urn\":\"urn:li:learningContentVideo:4588025\",\"duration\":901,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Plot formatting\",\"fileName\":\"3006708_en_US_04_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"2 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1357,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to format plots. This video covers custom plot colors, line styles, and marker styles.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":31101182,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this section, I'm going to show you\\nhow to define custom plot colors,\\nline styles, and marker styles.\\nThe reason I think this is important to show you\\nis that enhancing chart colors and markers\\ncan help you convey a point\\nin a way that is visually easier to understand.\\nJust think, if all the slices of a pie chart\\nhad the same color, the chart would be meaningless.\\nAnd if all the lines in a line chart were the same color\\nand use the same markers,\\nyou wouldn't be able to decipher one from the other,\\nand the chart would have very little or no meaning.\\n\\nMatplotlib offers colors, line styles,\\nand marker style options\\nto help you build clarity into your data visualization.\\nMatplotlib has unlimited color options,\\nso you can set the color parameter\\nequal to the name of your color you want,\\nor you can set the color parameter equal to RGB\\nor RGBA color codes for even more customization.\\nMatplotlib also has a variety of line styles.\\n\\nIf you look at this chart here,\\nyou can see some of the codes\\nthat you would use to set those styles.\\nAlso, I'm going to show you how to do this\\nin the coding demonstration.\\nMatplotlib also has a lot of different options\\nin terms of marker styles.\\nI created this handy-dandy little chart\\nfor you to review\\nin case you want to get fancy with your charts,\\nyou can look it over,\\nbut I'm also going to show you\\nhow to use these markers in Python in just a second.\\nYou've already learned to generate your plots,\\nso let's go ahead and start working on customizing them.\\n\\nSo for this coding demonstration,\\nthe Jupyter Notebook is already coming preloaded\\nwith the libraries you need, which are NumPy,\\nPandas, and Matplotlib.\\nAnd also, I've gone ahead and set the parameters\\nin terms of the plot size.\\nWe discussed that in an earlier lecture.\\nSo all of this information is preloaded for you,\\nand we're going to start off by working to define plot color.\\nWe'll just run these.\\n\\nSo the first thing we need to do\\nis just to create some variables,\\nand we'll create an X variable and a Y variable.\\nWe'll set X equal to\\na series of numbers between one and nine.\\nTo do that, we'll call the range function\\nand we'll pass in, starting number one and number 10,\\nwhere the last number is excluded in the output.\\nSo that will generate a series of numbers from one to nine,\\nand then we'll define Y as\\nthe numbers one, two, three, four,\\nzero point five, four, three, two, one.\\n\\nOkay, so we have two variables,\\nand now let's just plot this out as a bar chart.\\nSo to do that, we'll say plt.bar,\\nand we'll pass in our two variables, X and Y,\\nand run this.\\nOkay, so now we have a nice little bar chart.\\nNow let's define some colors here.\\nLet's change things up a bit,\\nbecause the default colors are kind of boring,\\nand we could create something a lot more fun.\\n\\nSo we'll change the width of the bars\\nand we'll also change the color.\\nHow about that?\\nWe can also go ahead and change the alignment a bit.\\nSo first things first,\\nlet's create a list to define the width of our bars.\\nTo do that, we'll just create a variable name,\\nwe'll call it wide,\\nand we'll say wide is equal to a\\nkind of just a mix and match of some sizes here.\\nSo zero point five, zero point five, zero point five,\\nand then maybe we'll make\\na bar that's zero point nine wide,\\nanother one that's zero point nine wide,\\nanother one that's zero point nine wide,\\nand then we'll go back to bars of width zero point five.\\n\\nSo I'll just kind of paste these in here.\\nOkay, cool.\\nSo there we have some widths\\nthat Python is going to use to adjust our default bar chart.\\nSo we'll use the color label here\\nand we'll say, \\\"Color is equal to,\\\"\\nand then we'll create a list,\\nand we'll pass on a string that reads, \\\"Salmon.\\\"\\nNow, to plot this bar chart out,\\nwe again need to use our bar function,\\nso that's plt.bar.\\n\\nAnd then we want to pass in the X variable,\\nthe Y variable,\\nand then we wanted to find the width, color,\\nand alignment parameters.\\nSo to do that, we'll say width,\\nand we'll set width equal to wide,\\nwhich is the variable we just created.\\nWe'll set color equal to color,\\nand then we'll say that we want to align\\nthe bar in the center,\\nso we'll say align equal to center here.\\n\\nNow the color is going to be equal to color,\\nwhich we just defined a sum in,\\nand then we set the alignment to center.\\nAnd alignment refers to\\nwhere the bars actually plot out within the chart,\\nso we want them to be centered when they plot.\\nSo we have set the line parameter equal to center,\\nand so now all we need to do here is print this out.\\nOkay, so, cool.\\nYou can see we have made these outer bars,\\nand they're a lot more narrow than the ones in the center,\\nand the color has been changed to salmon,\\nand you can also see that the alignment of the bars\\nis centered between each of the intervals\\ninstead of kind of being pushed inwards.\\n\\nLooking at the difference between the two,\\nyou can see that, yeah, it's definitely made a difference.\\nSo we've got that there.\\nAnd now let's go ahead and start working with\\nsome data frame objects.\\nThe Jupyter Notebook is coming preloaded\\nwith the NumPy cars data set.\\nOf course, you are going to need to customize your address\\nand specify where that data set is stored on your computer,\\nbut I've named all the columns and everything,\\nso the next thing you'd want to do\\nis just to create a data frame.\\n\\nI'm going to run this.\\nAnd we will call the data frame DF,\\nand we'll set it equal to cars,\\nand then let's just go ahead and\\nselect the cylinder column,\\nthe MPG column,\\nand the weight column,\\nand then plot it out with the plot method,\\nso df.plot, and we'll run this.\\n\\nOkay, so now we have here a little line chart,\\nand that looks decent,\\nbut these are just the standard settings\\nthat you would get with Matplotlib.\\nAnd I want to play with these a little bit,\\nso we'll change the color scheme,\\nwe'll create a new variable called color theme.\\nSo let's do that now, color underscore theme,\\nlet's add an \\\"equal to,\\\"\\nand then we'll create a list of colors\\nwe want to use in the chart.\\nSo we'll say dark gray,\\nlight salmon,\\nneed to change this to a single quote,\\nand then the last color will be powder blue.\\n\\nOkay, and then we'll go ahead and call\\nthe plot method off of the data frame,\\nand we'll pass in the color theme.\\nTo do that, we say df.plot,\\nand then we set the color parameter equal to\\nour color underscore theme, and run this.\\nAnd now you can see we have shifted the colors\\ninto these sort of more fancy-looking colors.\\n\\nI also want to show you how to change colors\\nbased on our GP codes.\\nSo we will create a Z variable\\nand we'll set Z equal to a list,\\nand it'll have the numbers one, two, three, four,\\nand zero point five.\\nAnd now we want to call the pie function\\nand we'll pass in our Z object.\\nSo that's plt.pie.\\n\\nAnd then, we'll go ahead and say plt.show,\\nprint it out,\\nand there we have a pie chart,\\nbut it's coming with our default colors for Matplotlib.\\nSo let's go ahead and adjust these colors using our GP codes\\ninstead of the color labels we have been using.\\nSo we'll create a new color theme.\\nAnd we can just overwrite the previous one,\\nso we'll say \\\"color theme equal to,\\\"\\nand then we'll create a list.\\n\\nAnd this time, instead of passing in the color labels,\\nwe're going to pass in our RGB codes.\\nSo our first RGB code will be #A9A9A9.\\nAnd then I'm going to paste in the next four.\\nThese are just RGB codes to represent\\nwhat the color should look like\\nwhen it gets plotted into the pie chart.\\nNow we've got those.\\nAnd now all we need to do is call the pie function.\\n\\nSo that's plt.pie, and we'll pass in Z.\\nAnd then our color, we'll set our color parameter\\nequal to color theme,\\nand then plot it out for the plt.show.\\nThere is a typo here, so this should be colors.\\nAnd as you can see,\\nwe have now adjusted the colors out a little bit\\nso that there's just a bit more creativity\\nthan the standard Matplotlib printout.\\n\\nNow let's look at how to customize line styles.\\nSo the first thing we would do\\nis just to create two new variables.\\nWe'll call them X1 and Y1.\\nAnd let's say X1 is basically the same variable\\nthat we created here, series of numbers between\\none and nine.\\nSo I'm just going to copy this.\\nAnd then our Y1 variable will be a series of numbers\\nbetween one and 10 in descending order,\\nso I'll just create a list and write them in.\\n\\nOkay, so now let's just plot this thing out.\\nThe plt.plot.\\nWe'll pass in our X and Y.\\nLet's also create a second plot.\\nAnd we'll just plot the X1 and Y1 variables\\nin that second plot.\\nSo just copy this,\\nand add the numbers for the variable names\\nthat we just created, and run this.\\n\\nOkay, so it looks like we have a little bit of a typo\\nbecause X and Y must have the same first dimension,\\nso I messed up in my creating\\none of my variables here, and that would be this variable\\nbecause we need to have nine numbers in X1\\nand nine numbers in Y1,\\nso I wrote in one too many.\\nSo let's run this, and yeah, okay, great.\\nSo here we have now two lines in the plot,\\nand that's exactly what we wanted,\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4586144\",\"duration\":1129,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating labels and annotations\",\"fileName\":\"3006708_en_US_04_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1973,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to create labels and annotations. This video covers labeling pot features, legends, and annotating plot features.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":38717589,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Labels and annotation\\nadd a deeper layer of context to a plot,\\nenabling the plot to convey extra meaning to its viewers.\\nIn this section, I'm going to show you\\nhow to label plot features,\\nadd a legend to your plot,\\nand annotate features on your plot.\\nBut before that,\\nlet me give you an example of where this comes in handy.\\nData journalists often add a lot of context\\nand annotation to their visualizations\\nin order to add and augment the story they're telling.\\nFor example, imagine you're a data journalist\\ncovering a story of tourism in central Florida.\\n\\nYou'd use a simple line chart\\nto show the number of travelers over time.\\nBut if you're telling a story about the success\\nof a grand opening of a new theme park,\\nyou may want to add some text\\nabout how many visitors came to the grand opening.\\nYou then may also want to add a pointer\\nthat ties that text into the date\\nof the park's grand opening.\\nThere are two methods for labeling and annotating.\\nAgain, the functional and object-oriented method.\\n\\nI'm going to show you both of those\\nin the demonstration to come.\\nBut before that, let me give you some extra information\\nabout the methods we'll use.\\nIn order to add a legend,\\nyou'll need to call the legend method\\nand you'll pass in a label and a location.\\nThis will then place a legend on your plot axes.\\nOver here on the right of the page,\\nyou can see all of these different options\\nin terms of where you want to position your legend\\non your plot.\\n\\nAnd then with respect to annotating your plot,\\nyou would call the annotate method,\\nand then you would just pass in a parameter\\nfor the location that's being annotated,\\nas well as the location of the text\\nand any information that you want to add\\nabout how the arrow should be drawn.\\nSo let's get to work on doing this in Python.\\nThe Jupyter Notebook here is already coming preloaded\\nwith the libraries you'll need.\\nSo those are numpy, pandas, matplotlib, and seaborn.\\n\\nI've also added in the parameters\\nfor plotting by matplotlib, which you can see right here.\\nSo everything is all typed out for you.\\nLet's just start by labeling plot features.\\nAnd I'm going to start by showing you\\nhow to do that using the functional method.\\nSo the first thing we need to do\\nis to create some variables.\\nLet's create an x variable using the range function,\\nand we'll just create a series of numbers\\nbetween 1 and 9.\\nAnd then let's create a Y variable.\\n\\nWe'll set that equal to a list,\\nwhich will contain the values, 1,2,3,4,0.5,4,3,2,1.\\nAnd then say we want to generate a bar chart.\\nSo to do that, we'll use the bar function.\\nThat's plt.bar, and we'll pass in our variables x,y.\\nAnd then let's go ahead and create a label.\\nTo do that, we will call the xlabel function.\\n\\nSo that's plt.xlabel.\\nAnd then we'll pass in a string\\nwith the label that we want to be showed on the x-axis.\\nSo we'll say your x-axis label\\njust to make this super clear.\\nAnd then let's also create a label for the y-axis.\\nSo to do that, it's actually very simple\\nbecause the function for that is just ylabel.\\n\\nSo I'm going to copy this code\\nand then just change out the function name here for x for y,\\nand then update the string\\nand then run this.\\nOkay, cool.\\nSo now we have a bar chart\\nand it looks like we actually have two labels,\\none on the x-axis and one on the y-axis.\\nAnd we did that using the functional method.\\nSo now I want to show you how to do the same thing\\nwith something like a pie chart.\\nSo let's create a new variable here and we'll call it z.\\n\\nAnd we'll say z is equal to a list\\nthat contains the values, 1,2,3,4,0.5.\\nAnd then let's also create some labels\\nand we'll label it according to vehicle type.\\nSo we'll call this veh_type,\\nand we'll set it equal to a list\\nthat contains a series of strings\\nwhere the first string is 'bicycle',\\nthe second one is 'motorbike',\\nthird one is 'car',\\nthe fourth one is 'van',\\nand then the fifth one, let it be 'stroller'.\\n\\nNow we want to generate a pie chart.\\nSo we'll call the pie function,\\nit's plt.pie, and we'll pass in our variable Z.\\nAnd then we needed to find the labels parameter.\\nWe'll just say labels=veh_type.\\nAnd then plot it out using the show function, plt.show.\\nYou can see what this has done is it has gone along\\nand nicely created some labels\\non the outside of the pie chart.\\n\\nThis is still the functional method of creating labels.\\nNow I want to show you the object-oriented method.\\nSo for this part of the demonstration,\\nI want to use the mtcar dataset\\nthat we've been using in earlier demonstrations.\\nSo I'm going to set the address for that first.\\nI'm going to go up to the data folder\\nand right click to get the path\\nand then paste that into the string here, right?\\nSo we have the address for our CSV file.\\n\\nAnd then let's create a data frame called cars.\\nAnd then we'll read in the file using the read_csv function.\\nSo that's pd.read_csv,\\npass in address,\\nand then let's assign names to the columns.\\nTo do that, let's first select the columns\\nby saying cars.columns,\\nand then we'll assign values to these column names\\nby just setting this equal to a list of strings\\nwith names for each of the columns.\\n\\nSo the first column is 'car_names',\\nand then I'm just going to copy and paste\\nover the rest of the column names,\\nwhich are 'mpg','cyl','disp',\\n'hp','drat','wt','qsec',\\n'vs','am','gear','carb'.\\nAnd now let's isolate the mpg variable.\\nSo to do that, we're going to say mpg = cars.mpg.\\n\\nAnd since this is object oriented,\\nof course, we'll start first by creating a figure.\\nSo we're going to do that by calling the figure function,\\nwhich is plt.figure,\\nand we'll set this equal to fig.\\nThen we're going to add some axis to the figure.\\nTo do this, we need to call the add_axes method\\noff of the fig object.\\nSo we'll say fig.add_axes,\\nand then let's define what we want for our axes.\\n\\nSo create a list here.\\nI'll say .1,.1,1,1,\\nand we'll set this whole thing equal to ax.\\nNow let's call the plot method.\\nSo to do that we say mpg.plot.\\nBut before actually running the cell,\\nlet's go ahead and add some tick marks and labels\\nalong the axis.\\n\\nSo to do that, we will use the set_xticks method.\\nSo we'll say ax.set_xticks,\\nand then we'll pass in range function\\nand we'll pass in the value 32.\\nOkay, and then let's also set some xticks labels.\\nSo we'll say ax.set_ticklabels.\\n\\nAnd within that function,\\nwe're going to pass the car names,\\nthat's cars.car_names.\\nAnd let's add a little rotation to the label\\nso that they're easier to read.\\nTo do that, we'll pass a perimeter\\nthat says rotation=60.\\nLooks like I need to move this bracket.\\nAnd then we'll also set a fontsize='medium'.\\nSo it's fontsize=, and then create a string\\nthat reads 'medium'.\\n\\nOkay, so we need to make sure\\nthat this says set_xticklabels.\\nSo I need to add an x here.\\nAnd then let's also add a title.\\nTo do that, we'll call the set_title method\\noff of the ax object, set_title,\\nand then we'll pass in a string for the title of the graph.\\nAnd let's call it 'Miles Per Gallon of Cars in mtcars'.\\n\\nLastly, I would like to create some labels for our chart.\\nSo we'll call the set_xlabel method\\nand the set_ylabel method.\\nSo ax.set_xlabel,\\nand then pass in a string that reads 'car names'.\\nAnd then for the ylabel,\\nwe can actually just copy this.\\n\\nThe method is ylabel.\\nSo I changed this here,\\nand then I update this string to read 'miles/gallon'.\\nOkay, I am just looking it over real quick to make sure\\nthat I don't see any syntax errors.\\nAnd then let's run this.\\nAnd here we have our printout.\\nSo look how nice this is.\\nWe've got a little rotation\\nin terms of the labels on the x-axis,\\nand both the x-axis and the y-axis are labeled.\\n\\nThe only thing that's not so nice about this graph\\nis of course the text,\\nwhich is kind of piling on top of itself.\\nAnd that's actually because we set the parameters\\nwith the rcParams at the top.\\nAnd so it's eight inches wide.\\nIf we wanted to fix that,\\nwe could just change that to 12 here and then go back down\\nand run this code block and you'll see that.\\nOkay, now it's much more nicely spaced.\\n\\nAnd we also have a title to the chart.\\nI also wanted to show you how to add a legend to your plot.\\nSo we'll first do that with a functional method\\nand let's call the pie function\\nand we'll pass it in our z variable.\\nSo that's plt.pie, and then pass in our z variable.\\nAnd then let's also create a legend.\\nTo do that, you need the legend function.\\nSo we'll say plt.legend,\\nand then we need to pass in our vehicle type\\nbecause we want to use those as our labels in our legend.\\n\\nSo that's the veh_type.\\nAnd then we want this legend location\\nto be set at the best possible location, right?\\nSo to make that happen,\\nwe will set the loc parameter equal to 'best',\\nand then you just plot it out.\\nTo do that, you call the show function.\\n\\nAnd then, cool.\\nNow we actually have created a nice little legend\\nfor our pie chart,\\nand that's awesome.\\nLet's also look at how we can create a legend\\nwith the object-oriented method.\\nSo what I'm actually going to do\\nis I'm going to go back up here to the top\\nwhere we've already written all of this code\\nand I just want to reuse it and adjust it.\\n\\nSo I'm going to take this chunk here\\nand I'm going to paste it down here.\\nAnd we're still using the mpg variable.\\nThe xticks are the same.\\nAnd the only thing we're actually going to change here\\nis that we're going to add a legend.\\nTo add a legend,\\nwe'll call the legend method off of the ax object.\\nSo we'll say ax.legend.\\n\\nAnd then we also need to set the perimeter for the location.\\nAgain, let's just set that equal to best.\\nSo we'll say loc='best'.\\nRun this, and nice.\\nYou can see up here in the upper right corner,\\nwe now have a legend.\\nAnd the final thing we're going to cover in this demonstration\\nis how to annotate your plot.\\nSo first things first,\\nlet's just look and find out\\nwhat is the max value for our mpg variable.\\n\\nTo do that, we're going to call the max method\\noff of the mpg variable here,\\nso mpg.max.\\nAnd we can see that the max value\\nin the mpg variable is 33.9.\\nSo let's go ahead and label that point on our chart.\\nI'm going to go back up\\nand get the code for this chart\\nagain so we can reuse it.\\n\\nAnd what I want to do\\nis set a limit to this chart for the y-axis.\\nSo to do that, I'll use the set lim method.\\nSo we'll say ax.set_ylim,\\nand then we'll pass in\\na list that contains two values.\\nSo our minimum y limit will be 0,\\nand our maximum y limit will be 45.\\n\\nAnd let's also create some annotation.\\nTo do that, we'll call the annotate method\\noff of the ax object, so ax.annotate.\\nAnd the first thing we need to do is pass in a string,\\nwhich is going to be the text\\nthat should be added as annotation to the graph.\\nWe'll move this up\\nand then create the string that says 'Toyota Corolla'.\\n\\nAnd then we need to give some details\\nabout where this annotation should be placed.\\nSo we're going to say xy=,\\nand then we're going to create a two pull\\nthat describes the position.\\nSo we'll put 19 and 33.9.\\nOkay, and then we also need to go ahead\\nand pass a parameter for the xy text.\\nBasically, where the text needs to be placed.\\nSo we'll say xytext=,\\nand then it's created two pull.\\n\\nAnd we'll say we want the text\\nto be positioned at 21 on the x-axis\\nand 35 on the y-axis.\\nAnd let's also set an arrow, okay?\\nSo to do that, we're going to pass a perimeter\\nthat reads arrowprops,\\nand then we're going to set it equal to a dictionary.\\nAnd then we're going to set a color for our arrow,\\nand that color is going to be black.\\nSo we need to call the dictionary constructor.\\nAnd then we need to say that the facecolor parameter\\nis equal to a string called 'black'.\\n\\nAnd then let's just shrink it up a little bit.\\nSo we'll pass a perimeter that says shrink=0.05.\\nSo I'm going to print this out.\\nAnd look at that,\\nwe have a nice annotation with an arrow pointing\\nto the maximum value for mpg.\\nAnd because we created this nice label,\\nit's really obvious and easy to see\\nthat the Toyota Corolla is the vehicle\\nthat is getting the best mile per gallon\\nout of all of the cars in the mtcar dataset.\\n\\nNow that you know how to add labels and annotation,\\nlet's look at how to visualize time series in Python.\\nThat will be our next lecture.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4579301\",\"duration\":503,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Visualizing time series\",\"fileName\":\"3006708_en_US_04_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":810,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to visualize time series. This video covers handling time series and plotting time series.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17052908,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Time series plots convey\\nhow an attribute changes over time.\\nUsing statistical methods like\\nautoaggressive integrated moving average,\\nyou can reliably predict or forecast\\nthe demand of a particular retail product\\nbased on historical time series\\non previous sales of that product.\\nBefore forecasting your time series,\\nyou need to know how to handle and plot time series\\nin Python.\\nWorking with time series in Python can get really tricky,\\nbut Pandas makes it simple.\\n\\nBefore showing you how to use time series in Pandas,\\nlet me just show you what a time series looks like.\\nThese four plots all show time series,\\nthe first one is a constant time series.\\nBasically, you're not seeing any trends or changes\\nin the variable over time.\\nTrended time series is like this chart over here\\nin the upper right,\\nthat's where you see a net increase or decrease\\nin the time series variable over time.\\nIn the lower left you'll see an untrended time series.\\n\\nThis is an untrended seasonal time series,\\nso the variable is increasing and decreasing\\naccording to the seasons of the year,\\nbut you're not seeing a net change\\nin the average value of the time series.\\nSo we call that untrended.\\nIn contrast, over in the lower right corner,\\nyou'll see a trended seasonal time series.\\nThis is where the variable increases and decreases\\nwith the season,\\nbut there's a net gain in the variable over time.\\nSo like I said,\\nand your Jupyter Notebook is coming\\nall loaded with the libraries you need,\\nwhich are NumPy, Pandas, and Matplotlib.\\n\\nWe're also going to be using Seaborn here\\nto just set the style.\\nSo I actually prefer to use the alias, sns here,\\nlet me update this.\\nAnd we can just run this\\nand we'll be ready to start creating time series.\\nSo we'll get right to work with just reading in our data\\nand then printing it out as a time series.\\nThe first thing we need to do is set an address.\\nSo let's say address =,\\nand then for this demonstration,\\nI want to use the Superstore Sales data.\\n\\nSo the location of that is over here in the data folder.\\nJust Right Click, copy path,\\nand then paste it into this string here.\\nAnd then I'll close this.\\nThe next thing that we'll do\\nis we'll create a data frame from the CSV file.\\nAnd we need to read the CSV file in\\nusing the read CSV function.\\nSo let's just call this data frame df\\nand we'll set it =pd.read_csv,\\nand then we'll pass in the address.\\n\\nAnd then we also want to set our index.\\nThe index for the data frame\\nshould be set to the order date.\\nSo to do that we'll just say index_col,\\nwhich is the parameter which is used to set the index.\\nAnd let's set that = 'Order Date.'\\nAnd we have to be sure also to encode the data properly.\\nFor this particular demonstration,\\nwe need to set our encoding here = cp1252.\\n\\nAll we need to do is define the encoding parameter\\nequal to a string, which reads cp1252.\\nAnd let's also parse the dates.\\nSo we'll want to pass a parameter that says\\nparse_dates=True.\\nAnd then let's just look at the first five records\\nby calling the head method off of the DF data frame.\\n\\nSo we'll say df.head() and run this.\\nAnd here we've got now a little preview of the data\\nthat is sitting inside of this Superstore Sales data set.\\nAnd as you can see,\\nPerfect, so now let's go ahead\\nand create a time series plot from this.\\n\\nTo do that, we're going to call the plot method\\nand we'll just select the order quantity variable\\nfrom the data frame.\\nSo we'll say df and then select order quantity here,\\nand then call the plot method off of this and run it.\\nAnd it printed out very quickly,\\nbut it's way too much data.\\n\\nWe can't make any sense of this, right?\\nSo what I'm going to do is I'm just going to create\\na small sample of this data\\nso that we can plot something out\\nthat we're able to actually decipher.\\nSo let's create a second data frame\\nand we'll call it df2.\\nAnd then we'll call the sample method\\nin order to take a random sample of data points\\nfrom the dataset.\\nSo we'll say df.sample(),\\nand then let's take 100 data points.\\n\\nTo do that, we need to define the n perimeter = 100.\\nNow this function is going to be doing random sampling\\nand I want you to get the same results on your machine\\nthat I get in here in this demonstration.\\nSo what we need to do is actually set the seed for that.\\nSo to do that,\\nwe'll say random_state and just set it equal to 25.\\nAnd that will ensure that the points that are pulled\\nin this demonstration are the same ones that are pulled\\non your machine when you're doing this\\nat home or in the office.\\n\\nAnd then we also have to pass in a perimeter for the axis\\nand we'll say axis=0.\\nAnd let's also create some labels real quick.\\nSo plt.xlabel on the x-axis.\\nLet's label that order date.\\nAnd then let's create a y-label.\\n\\nChange out the string here, call that order quantity.\\nAnd let's also call the title function,\\nwhich is pt.title.\\nAnd we'll just pass in a string for the title of the chart.\\nSo that's going to be Superstore Sales.\\nAnd then let's just plot out this smaller data frame.\\nSo we're going to call the plot method.\\n\\nLet's select only the order quantity field.\\nSo we'll say df2.\\nAnd then from that data frame,\\nwe want to select only the order quantity.\\nAnd then off of this entire thing, we call the plot method.\\nAnd I'm going to run this.\\nLooks like there was a syntax error.\\nI need to add a letter T here, run this again.\\n\\nOkay, cool.\\nSo this is a lot easier to read than the graph prior.\\nAnd what we're seeing along the x-axis\\nis really the dates that the orders were made\\nand the quantity of orders that happened on those dates.\\nSo this was a really quick and easy way\\nto use Python to generate a time series.\\nIn the next section,\\nI'm going to show you how to create statistical data graphs.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2714161\",\"duration\":891,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating statistical data graphics in Seaborn\",\"fileName\":\"3006708_en_US_04_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1398,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to create statistical data graphics. This video covers histograms, box plots, and scatter plots.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":29803818,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Statistical plots allow viewers\\nto identify outliers, visualize distributions,\\ndeduce variable types, and discover relationships\\nand core relations between variables in a dataset.\\nIn this course, I'm going to show you\\nhow to use statistical plots to visually detect outliers,\\ndeduce variable distribution and type, and uncover\\nrelationships and core relations between variables.\\nNow, histograms are very simple plots\\nthat are used to show variable distribution.\\nScatter plots, on the other hand,\\nare used to show relationships between variables.\\n\\nScatter plot matrices show core relations between variables\\nand box plots show variable spread\\nand are useful for outlier detection.\\nLet me show you how to create these in Python.\\nSo your Jupyter Notebook is coming loaded with the libraries\\nthat you will need, or at least most of them.\\nSo we have our standard libraries, which are num, pi,\\npandas, matplotlib and seaborn.\\n\\nI've also gone ahead here\\nand set the plotting parameters for matplotlib.\\nIn this demonstration, we're actually going to be working\\nwith seaborn, and I showed you\\nhow to import that in earlier demonstrations.\\nA nice thing about seaborn is that it provides you options\\nfor style sets and there are a lot of different options.\\nSo what I did is I set a seaborn style equal to whitegrid.\\nThere are many different options,\\nbut I like the whitegrid option, so we'll use that.\\n\\nAnd yeah, I'm just going to run all of this\\nto have it imported into our IPython environment.\\nAnd then let's get started\\nwith creating statistical data graphics.\\nThe first thing we're going to do in this demonstration is just\\nto start eyeballing dataset distributions with histograms.\\nAnd this Jupyter Notebook is coming loaded with the data\\nthat you should need, although you'll want to change\\nthis file extension for the file extension at your setup.\\n\\nSo you would just go over here to the Explorer\\nand then go to the data folder and right-click.\\nIn this demonstration,\\nwe're going to be using the empty cars dataset.\\nSo then you will just right-click here,\\nget the empty car dataset,\\nand then change out the string for the address.\\nAnd for this demonstration, let's just set the index\\nfor the data frame equal to the car names column\\nin the cars data frame.\\n\\nAnd I've already preloaded this into your notebook\\nso you don't have to type all of this out again,\\nbecause this is very similar to prior demonstrations.\\nSo what I want to do here first\\nis just isolate the mpg variable.\\nSo we'll say mpg variable is equal to cars.\\nAnd then we'll use the indexer\\nto select the mpg column here.\\nAnd to plot it out, we'll call the plot method\\noff of the mpg variable,\\nso mpg.plot, and since we are creating a histogram,\\nwe need to set that perimeter inside of the plot method.\\n\\nTo do that, we're going to say kind=,\\nand then create a string that reads hist\\nand that will instruct Python to create a histogram.\\nAnd then we run this,\\nand as you can see, we have a nice little histogram\\nthat shows the distribution of data in our mpg variable.\\nAnother way to create a histogram\\nwould be to just call the hist function\\nand then pass in the mpg variable.\\n\\nLet me show you how to do that,\\nplt.hist and then pass in mpg\\nand then call the plot function,\\nplt.plot, and run this.\\nAnd now we have just a different way\\nof creating a histogram inside of Python.\\nNow let me show you how to create a histogram using seaborn.\\nTo do that, you would use the disc plot function,\\nso that's going to be snsdisplot.\\n\\nAnd then we need to pass in the mpg variable.\\nAnd this is one of the two ways\\nI want to show you how to do it.\\nThis is the simplest way\\nof creating a histogram using seaborn.\\nSo I'm going to run this.\\nAnd there you can see we have a nice,\\nkind of more beautiful, more styled plot\\nthat was actually created more simply\\nusing the seaborn method.\\nNow let me show you another way to use seaborn\\nto create scatter plots.\\n\\nBasically, I messed up with our script.\\nSo I said something about\\nhow I'm going to show two different ways to do this,\\nbut that wasn't proper.\\nThat wasn't correct.\\nSo let's just actually start over again from the part\\nwhere we're going to create this from scratch\\njust 'cause it's super simple.\\nSo now let me show you how to use seaborn\\nto create a histogram.\\nTo do that, you would use the displot rephrase.\\n\\nTo do that, you would use the displot function,\\nso that would be sns.dissplot,\\nand then pass in the mpg variable and run this.\\nAnd as you can see, you know,\\nwe've got a nice styled histogram here\\nthat was extremely simple to create,\\nand that's the basics of how\\nto create a histogram using seaborn.\\nI'm going to show you two different ways of doing this,\\nand the first one is just via the plot method.\\n\\nSo we'll call plot off of our cars data frame,\\nand then we'll pass in a parameter\\nto say what kind of plot we want.\\nSo we'll say kind is equal to scatter.\\nAnd then we want to set our variables.\\nSo X should be equal to hp\\nand then let's set our Y variable equal to mpg.\\n\\nAnd let's also go ahead and set a color for this plot.\\nTo do that, we can just say C is equal to,\\nand then we'll select the color dark gray\\nby writing a string that reads dark gray.\\nAnd lastly, let's set a size\\nfor each of our dots in our scatterplot.\\nSo to do that, we would say S is equal to 150.\\n\\nAnd I'm just checking this over\\nfor any obvious syntax errors.\\nOkay, and then run this.\\nAnd there we go, we have a nice scatter plot.\\nBut I also want to show you\\nhow to create a scatter plot using seaborn.\\nSo with seaborne, you just use the reg plot function,\\nwhich it's going to be sns.regplot,\\nand you pass in the variables that you want plotted out\\nfor the X and Y axis.\\n\\nSo for X, we will say x should be equal to the hp variable,\\nand then y should be equal to the mpg variable.\\nAnd then we also need to define\\nwhere we're actually pulling this data from.\\nSo for that, we would need to create a perimeter\\nthat says data and then set the equal to cars,\\nour cars data frame.\\nAnd then to make sure that this comes out as a scatterplot,\\nwe need to say scatter equal to true.\\n\\nAnd this just tells seaborne yes, create a scatterplot.\\nAnd then when we run this, we see seaborn's version\\nof the very same scatterplot.\\nAs you can see, it's a lot more detailed\\nand helpful than the generic version\\nwe created with the simple plot method above.\\nMoving on, I want to show you how to use seaborn\\nto generate a scatter plot matrix.\\nAnd this is actually really, really easy.\\nSo you would just call the pair plot function.\\n\\nSo this is going to be sns.pairplot\\nand we pass in our data frame cars and then run this.\\nAnd of course this is awesome,\\nbut it's also a lot of information to take in at a glance.\\nSo what I think we should do is let's just create a subset\\nand then we'll plot that out instead.\\nWe'll call it car subset.\\nSo we'll say cars_subset,\\nand we'll set that equal to cars.\\n\\nAnd then we'll use the indexer\\nto select the variables we want here.\\nLet's make those mpg,\\ndisp, hp and wt.\\nAnd then again, we will use our pairplot function.\\nSo sns.pairplot,\\nand we'll pass in this time our car subset.\\n\\nAnd then to generate the plot, we just need\\nto say plt.show, run this.\\nAh, okay, so this is a bit easier to read,\\nbut the nice thing about having a scatterplot is\\nat a glance, you can really get an idea about the type\\nof relationship that is occurring between the variables.\\nAnd also you can see things like possible outliers.\\nLike this point right here is possibly an outlier\\nor over here, this could be an outlier.\\n\\nAnd then you can also tell at a glance\\nwhat type of variables you have.\\nFor example, these variables plotted here are\\nall continuous variables, which you can tell by looking at\\nthe distribution of points that are plotted.\\nSo scatterplot matrices are just really nice to have\\nto get a fast understanding of your variables\\nand your variable pairs.\\nNow let's look at how to build a box plot.\\nWe're going to use the box plot method to do this.\\n\\nSo we're going to say cars.boxplot,\\nand then we'll pass in the perimeter to say\\nwhat we want plotted in our box plot.\\nSo our first box plot, let's just plot out a column mpg.\\nSo we'll say column equal to mpg.\\nAnd then we want to plot the mpg variable\\nagainst the automatic manual transmission variable.\\nSo to do that, we'll say by is equal to am\\nfor automatic and manual transmission variables.\\n\\nAnd then let's also just create a second block box plot.\\nAnd this time we'll plot weight against transmission type.\\nSo we'll say cars.boxplot,\\nand we'll say our first column should be weight.\\nAnd then we want to plot this\\nagainst or by the automatic manual transmission variable.\\n\\nSo am here and then we run this.\\nI would say it's a little cramped.\\nI'm going to go up and just change this variable\\nto make it a little taller.\\nI'm going to say six inches, six inches tall for our chart\\nhere, just so we don't have any labels scrunched up.\\nOkay, so this is better.\\nAnd this is showing us how our data is distributed\\nacross mpg and automatic and manual transmission.\\n\\nSo what it's saying here is that cars\\nthat get less miles per gallon\\ntend to not have an automatic transmission.\\nIf they do have an automatic transmission,\\nwhich is am equal to one, then they tend\\nto get more miles per gallon.\\n\\n\"}],\"name\":\"4. Practical Data Visualization\",\"size\":196738610,\"urn\":\"urn:li:learningContentChapter:4583164\"},{\"duration\":4779,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4583161\",\"duration\":494,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Simple arithmetic\",\"fileName\":\"3006708_en_US_05_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":749,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to perform simple arithmetic. This video covers standard arithmetic, arithmetic multiplication, and matrix multiplication.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15743431,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this section,\\nwe're going to be talking about how\\nto do simple arithmetic in Python.\\nThe benefit of the NumPy library\\nis that it makes it really easy to do math on data\\nthat's stored in either arrays or matrices.\\nNow, an array is just a one-dimensional container\\nfor elements that are all of the same data type.\\nAnd, matrix is just a two-dimensional container\\nfor elements that are stored in an array.\\nThe basic arithmetic operators in Python\\nare addition, subtraction,\\nmultiplication, and division.\\n\\nLet me give you an example of where NumPy can come in handy.\\nHave you ever tried to use a spreadsheet application\\nto perform mathematical operations on a data set\\nthat has more than 300,000 rows?\\nWhat happened?\\nIf the application didn't crash,\\nthen it took a lot of time\\nand effort to get the program to make the computation.\\nBut with NumPy, on the other hand,\\nyou can quickly and easily do mathematical\\nand statistical operations on data sets\\nwith even millions of records.\\n\\nSimply put, NumPy makes it easy\\nto do math on large data sets.\\nWith this slide here, I just wanted to familiarize you\\nwith the operators that you will use in Python\\nto achieve these arithmetic operations.\\nSo we're starting out the coding demonstration\\nwith having imported NumPy\\nand also imported the random number generator from NumPy.\\nJust run this.\\nAnd,\\nit never looks good to see more than two digits\\nafter a decimal point,\\nso let's go ahead and limit the number\\nof decimal places returned in this demonstration.\\n\\nSo to do that, you would just say,\\nnp.set_printoptions,\\nand then let's set a precision of 2.\\nSo precision equal to 2,\\nand run this.\\nNow the first thing we're going to do\\nis look at math with arrays.\\nSo we of course need to create some arrays to do that math.\\nAnd our first array will be array a,\\nand we'll set that equal to an array of six values.\\n\\nSo what we need to do is call the array function,\\nnp.array,\\nand then we'll pass in a list\\nof values from one to six.\\nAnd then print that out.\\nWe'll just say a and run this,\\nand there you go,\\nwe have an array of six values.\\nAnd then let's create a second object,\\nwhich will be a matrix and we'll call it b.\\n\\nAnd to create this matrix,\\nwe'll use the array function,\\nso we'll say np.array,\\nand this time we need to pass in two lists.\\nSo the first one is going to contain the values,\\n10, 20, and 30.\\nAnd then the second list will contain the values,\\n40, 50, and 60.\\n\\nAnd then we'll print this out\\nand very good, we have a matrix.\\nNow, before we're actually going in and doing math,\\nlet's create an array via assignment.\\nI want to show you how to do that.\\nSo let's this time use a random number generator\\nin NumPy, and what we're going to do\\nis we're going to create six random values.\\nSo to set the seed for a random generator,\\nwe need to say np.random.seed.\\n\\nAnd this just makes so\\nthat the results you get on your computer\\nwill be the same as we,\\nas I show you here in the demonstration.\\nAnd then we need to assign a value to the variable c.\\nSo we'll say c is equal to 36 times,\\nthe random numbers that are generated\\nby the random number generator in NumPy.\\nSo we'll say np.random.randn,\\nand let's pass in the value of six.\\n\\nThis is just saying that we want to have six values.\\nAnd we'll print this out.\\nAnd the one thing that I would like to point out here is\\nthat when we use the randn function,\\nwhich is the random number generator in Python,\\nwhat that is actually doing\\nis it's generating both positive\\nand negative random numbers.\\nNow let's create a fourth array,\\nwhich is going to be called d,\\nand we'll set d equal to a series of sequential numbers\\nbetween 1 and 34.\\n\\nSo we'll use the arange function,\\nnp.arange,\\nand then we will make the starting point 34\\nand the ending point 35,\\nwhere 35 is excluded from the series of numbers\\nthat's output from this function.\\nAnd we can just go ahead and print this out.\\nOkay, great.\\nSo we have our array.\\nNow let's just start performing some math.\\n\\nBefore doing so, I just want to point out one thing here\\nbecause I'm calling all of these objects arrays,\\nbut some of them are actually matrices,\\nand what I want you to keep in mind\\nis that a matrix is actually just a two-dimensional array.\\nThat's why you're hearing me say array\\nwhen I'm actually creating matrices\\nand kind of using them interchangeably in certain points.\\nFirst things first,\\nlet's just multiply the array a by the number 10.\\nSo we'll say a times 10, run this.\\n\\nAnd if we look back here at the a variable,\\nif we multiplied each of these numbers by 10,\\nwe would get this output here.\\nMakes sense, and that was very easy to do,\\nvery straightforward.\\nNow let's try an addition operation.\\nSo we'll do c plus a,\\nand run this.\\nSo this output array is a result of adding the c array\\nto the a array.\\n\\nJust to do a little back checking here,\\nlet's look at the value of c and a,\\nto make sure it matches up.\\nWe've got a 9.22 and up here, c,\\nc here is 8.22,\\ngo up a,\\nvalue here is 1,\\nso when you add those together, you get 9.22.\\nSo yeah, that makes sense.\\nAs you can see, it's really simple\\nto do straight-out arithmetic\\nwith arrays and matrices in Python.\\n\\nLet's do c minus a.\\nAnd again, makes sense.\\nThis time we're getting 7.22,\\nwhich is 8.22 minus 1.\\nSo yep.\\nNow let's try c times a,\\nwhich of course should be 8.22\\nas the first value in the output array.\\nSo we'll say c times a,\\nand run this.\\nAnd yeah, it's 8.22.\\n\\nMakes sense.\\nAnd if you wanted to do division here,\\nall you'd have to do is say c divided by a.\\nAnd of course, 8.22 divided by 1 is going to be 8.22.\\nSo we're good to go there.\\nAnd now you know how to do simple arithmetic using arrays\\nand matrices in Python.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4589019\",\"duration\":579,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Generating summary statistics\",\"fileName\":\"3006708_en_US_05_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":868,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to create standard data graphics. This video covers line charts, pie charts, and bar charts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":18762967,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Descriptive statistics describe a variable's\\nvalues and their spread.\\nFor example, imagine you work for a company\\nthat monitors patients' health in real time\\nand you need to build a script\\nthat detects dangerous anomalies.\\nYou could generate summary statistics\\nin micro batch and then calculate the mean, max,\\nand standard deviation of incoming health data\\nthat's generated from the monitoring device.\\nWith these descriptive statistics\\nyou could generate automatic alerts\\nwhen unusually high or low data points are generated\\nby the patient's monitoring dived\\nindicating potentially dangerous health status\\nof the monitored patient.\\n\\nDescriptive statistics provide a quantitative summary\\nof a variable and the data points that comprise it.\\nYou can use them to get an understanding of a variable\\nand the attributes that it represents.\\nThere are two categories of descriptive statistics.\\nOne is descriptive statistics that describe the values\\nof an observation in a variable.\\nAnd the second is the descriptive statistics\\nthat describe a variable's spread.\\nSo to get more specific,\\nif you wanted to generate descriptive statistics\\nthat describe the observations in a variable\\nthen what you would do is you'd go ahead\\nand calculate the sum, median, mean, and max\\nof those observations in the variable.\\n\\nBut again, the second way\\nto generate descriptive statistics is\\nto describe the variable's spread.\\nAnd if you wanted to do that\\nwhat you would to is calculate out standard deviation,\\nvariance, counts or quartiles.\\nIf this doesn't make a lot of sense to you now\\njust hold on, because I'm going to show you an example\\non the coding demonstration and then\\nyou'll really understand what I'm talking about.\\nBut first let's look at some of the uses\\nfor descriptive statistics.\\nYou can use descriptive statistics\\nto easily detect outliers.\\n\\nYou can use it for planning data preparation requirements\\nfor machine learning, and you could use it\\nfor selecting features for use in machine learning.\\nOkay, so now let me show you how\\nto generate summary statistics using pandas and scipy.\\nWe're going to start off, of course,\\nby bringing in our libraries.\\nSo we need to to import numpy, pandas, series and data frame\\nand then also scipy.\\nI want to point out that we are importing stats\\nfrom scipy.\\n\\nAnd I've got these already loaded for you\\nin the Jupiter notebook\\nand your notebook's also coming preloaded\\nwith the MT car's data set\\njust to save you time\\nso you can just go ahead and run these.\\nWe've already covered these in previous lectures.\\nAnd what I'd like to do first is just to print out\\nthe first five records of the cars data frame here.\\nSo we'll say cars.head.\\n\\nRun this.\\nAnd now we have a little preview of the data\\nwe've got inside of the cars data set.\\nNow I want to show you how to use the sum method.\\nSo we'll drop down here\\nand the sum method adds up the total of numbers\\nin a column, or in rows of a data frame.\\nBy default, sum will count up values and provide a total\\nfor each column.\\nBut if you pass an axis equal to one argument\\nthen it will add up the values\\nalong the data row-wise instead.\\n\\nSo let's practice with this one.\\nSo we'll just say cars.sum and run this.\\nSo how this works is, the sum method has gone along\\nand summed up the values in the columns\\nof the cars data frame.\\nBut if you wanted to sum the values along the rows instead\\nthat's easy enough to do.\\nYou would just take the same command\\nand then you would pass in a perimeter\\nthat says axis is equal to one.\\n\\nSo let's try that out here.\\nWe'll say cars.sum\\nand we'll say axis equal to one.\\nAnd of course, we only wanted to sum up numeric values\\nso we'll pass in an argument that says numeric_only\\nequal to true.\\nLooks like I need to change this m to an n.\\n\\nAnd run this.\\nAnd there we have it.\\nSo this is basically the output of the summation,\\nthe values of the dataset, row-wise.\\nThe median method finds and returns a median value\\nwith the middle value from the columns\\nor rows of the data frame.\\nSo let's calculate a median value by saying\\ncars.median and then again we need to pass a perimeter\\nthat says numeric only equal to true\\nand run this.\\n\\nAnd then what Python has done here is it's gone\\ninto each of the variables in the cars data set\\nand it's found the median value for each of those variables.\\nIt's returned those as an output here.\\nAnd to calculate the mean it's very, very simple.\\nYou can just say cars.mean.\\nAnd again pass in the numeric only equal to true.\\n\\nAnd run this.\\nAnd this is the average value for each variable\\nin the cars data frame.\\nIf you wanted to generate some statistics\\nabout the maximum value for each variable\\nwe would just say cars.max\\nand then what this is doing is\\nit's outputting the greatest value in each of the variables.\\nNow if you wanted to be able to identify the row\\nwhere the maximum value came from\\nyou'd just call the id maximum method.\\n\\nTo see the index value of the row\\nthat contains the maximum value.\\nSo let's try that out here.\\nWe'll look at the mpg variable.\\nTo isolate that, we'll say mpg is equal to cars.mpg,\\nselect that variable,\\nand then we'll call the id xmax method off of this\\nso that's mpg.idxmax\\nand then what we're seeing here is that\\n19 is the index number of the row\\nwhere the maximum value was found in the mpg variable.\\n\\nNow let's look at som summary statistics\\nthat describe variable distribution.\\nThe most fundamental summary statistic\\nthat describes distribution would be standard deviation.\\nAnd in order to generate that in Python\\nyou can just use the standard method.\\nSo for our example we would take cars.std and then\\npass in perimeter numeric only equal to true\\nand run this.\\n\\nAnd what this has done is it's gone along\\nfor each of the variables\\nand calculated the standard deviation\\nof the values in that variable.\\nTo calculate the variance you would say cars.var,\\nuse the var method here.\\nAnd set numeric only equal to true.\\nAnd now you're getting the variance\\nfor each of the variables.\\nThere's also the value counts method\\nand this method counts up the unique values\\nin and array or a series object.\\n\\nIt shows you how many unique values are present\\nin a data set.\\nSo let's look at the gears variable.\\nWe'll isolate that.\\nWe'll create and object called gear\\nso we'll say gear is equal to cars.gear\\nand then off of that object\\nwe will call the value underscore counts method\\nand run this.\\nAnd what you're seeing here is that\\nthe gear variable has three unique values.\\n\\nThose are three, four, and five.\\nOn the right side you can see the unique counts\\nfor each of these variables.\\nIf you wanted to take a broader perspective,\\nwhat this is really saying is\\nthat the cars data set has 15 cars with three gears,\\n12 cars with four gears\\nand five cars with five gears.\\nAnd I want to show you really quickly the easy peasy way\\nto get an entire statistical description of a data set.\\nThis is the describe method.\\nSo all you would need to do is say cars.describe\\nand with this you're basically getting\\nall of the descriptive statistics that can be generated\\nfrom each of the variables in the entire data set\\nall at one time.\\n\\nSo it's super efficient and helpful to have this on hand.\\nNow that you know how to summarize numerical variables\\nlet's move on to summarizing categorical ones.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2715032\",\"duration\":619,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Summarizing categorical data\",\"fileName\":\"3006708_en_US_05_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"2 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1018,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to define elements of a plot. This video covers object-oriented plotting, sub-plots, and axis labels.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":20130845,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's talk about how to summarize\\ncategorical data.\\nCategorical data is described by how observations\\nare distributed across a variable's categories.\\nA very simplistic approach to sentiment analysis\\ncould involve web scraping public product reviews,\\nthen classifying certain words found in the scraped data\\nas positive or others as negative.\\nYou could then do a categorical word count\\non the product review data\\nto score product reviews or feedback as either good or bad.\\n\\nCategorical variables only assume a fixed number of values.\\nSo, as you can see here, we have a very simple dataset\\nthat contains apples and oranges.\\nSo this variable here, the fruits variable,\\nis actually a categorical variable.\\nAnd then what you can do\\nis you can group your categorical variable into subgroups\\nbased on the fruit category.\\nSo in this case we could break down the dataset\\ninto apples and oranges\\nbased on this categorical fruits variable.\\n\\nThere are three main ways to describe categorical variables.\\nThose are counts, variable description, and grouping.\\nSo I'm going to show you\\nhow to create each of these three types of descriptions\\nover in the Jupyter Notebook.\\nRight, so we're bringing in numpy and pandas.\\nI've already got those imported for you\\ninto the IPython environment.\\nAnd I've also got the empty cars dataset\\nready for you to go here.\\nSo let's just take a look at the first 15 records.\\n\\nTo do that, we will use the head method.\\nSo we'll say cars.head() and then pass in the number 15.\\nNow, you get a basic idea\\nof the data that's inside this dataset.\\nAnd, of course, we've also now set an index.\\nThat index here is equal to the car_names variable.\\nSo you can see that here.\\nWe set it here.\\n\\nOkay, so the first thing that I want to show you\\nis the value_counts method.\\nAnd this method makes a count of all the unique values\\nin an array or a series object.\\nSo, first, let's just isolate our car variable.\\nThis is for carburetors.\\nIt's a number of count of carburetors that each car has.\\ncarb is equal to cars.carb.\\nAnd then we'll generate the value counts\\nby calling the value_counts method.\\n\\nWe'll say carb.value_counts() and run this.\\nAnd what you're seeing here is that there are 10 cars\\nthat have four carburetors.\\nThere are 10 cars that have two carburetors.\\nSeven cars have one carburetor.\\nThree cars have three carburetors.\\nAnd so that's basically how you need\\nto interpret this result.\\nNow, let's look at the groupby function.\\nAnd to group a dataframe by its values\\nin a particular column,\\nyou just call the groupby method off of a dataframe\\nand then pass in the index value of the column series\\nyou want the dataframe to be group by.\\n\\nSo let's just create a subset of our dataframe,\\nand we'll call that cars_cat.\\nAnd within this subset, we'll include five variables,\\nthe cyl variable,\\nthe vs variable,\\nthe am variable,\\nthe gear variable,\\nand, last one, carb.\\n\\nAdd the single quote here.\\nThen let's just print this out.\\nSo we'll say cars_cat.head().\\nRun this.\\nOkay, so here we have a small subset\\nof our original cars dataframe.\\nSo now let's group by the gear variable\\nand then describe the dataset by that unique grouping.\\nIn order to do this,\\nlet's just create a new variable called gears_group.\\n\\nAnd then we'll set it equal to our cars_cat dataframe.\\nAnd what we'll do for the grouping part of this\\nis that we will call the groupby method\\noff of that dataframe\\nand pass in the label index of the column\\nby which we want the dataframe to be grouped which is gear.\\nThen we want to generate a statistical description\\nof the dataset based on that grouping.\\nSo let's just use the describe method.\\n\\nWe'll say gears_group.describe()\\nand run this.\\nAs you can see, we have three rows by 32 columns.\\nThe reason we have three rows\\nis because there are only three different options\\nor your count for the cars dataset.\\nAnd then we have 32 columns\\nbecause for each of the variables in the small subset,\\nthe cars_cat subset,\\nwe have generated statistical descriptions for each of them.\\n\\nSo, as you can see, we're getting a long output table.\\nThe next thing we need to look at\\nis how to transform variables to categorical data type.\\nNow, to create a series of categorical data type,\\nyou would just call the pd.Series function\\non an array or a series that holds\\nthe data you want the new series object to contain.\\nNow, when you pass in the dtype\\nequal to category argument,\\nthis tells Python to assign\\na new series data type of category.\\n\\nHere, we'll create a new categorical series\\nfrom the gear variable.\\nAnd then we'll assign it to a new column\\nin the cars dataframe called group.\\nSo we'll say cars[],\\nand then we will create a new column here called group.\\nAnd then we're going to say that this is equal\\nto a new series object that we're going to create here\\nwith the series constructor.\\nSo we're going to say pd.Series().\\n\\nAnd we'll pass in cars.gear because we're interested\\nin converting the cars.gear variable to a series.\\nAnd then we want to, of course, assign the dtype\\nequal to category.\\nTake that and then print this out.\\nNow, let's just print out this new variable\\nand look at its data type.\\nSo to do that, we will just copy our variable here,\\ncars['group'],\\nand then we call the dtypes method off of that, .dtypes,\\nand run it.\\n\\nOkay, great, so now you see\\nthat we actually do have a categorical data type,\\nand it's part of our cars dataframe which is cool.\\nWe just created this new variable\\nand added it to our cars dataframe.\\nNow, let's look at the distribution of gear types\\nin this variable.\\nTo do that, what we would need to do\\nis say cars[] and then select our group variable here\\nand then call the value_counts method off of that,\\nvalue_counts().\\n\\nAnd so here we have got cars\\nwith three different counts of gears.\\nSo pretty much makes sense.\\nLast thing I wanted to show you in this demonstration\\nis basically how to create a crosstab\\nor cross-tabulation table.\\nThese are very important.\\nYou need to know how to use these\\nin order to make sense of categorical data in data science.\\nLet's just start by creating our crosstab.\\nTo create a crosstab,\\nyou would just call the pd.crosstab function\\non the variable you want included in the output table.\\n\\nSo let's do that here by saying pd.crosstab().\\nAnd we're going to select our first variable\\nwhich would be the am variable.\\nSo we'll say cars[]\\nand then select the am variable.\\nThen for our second variable,\\nthat's going to be the gears variable.\\nSo we'll say cars[], and we'll select gears.\\n\\nAnd we run this. Looks like there is a typo.\\nYeah, so I need to take this s out,\\nthen run it again.\\nAnd, as you can see, we have a really concise summary\\nof each of these two variables.\\nA crosstab is a cross tabulation of two or more features.\\nBy default, a crosstab shows frequency counts for features.\\nSo the example we just did in Python, we basically selected\\nthis am variable and the gear variable,\\nand Python went ahead and created\\na small cross tabulation of these two variables\\nand described to us basically about how gears are broken up\\nwith respect to automatic and manual transmission.\\n\\nSo the am stands for manual transmission.\\nAnd what this table is telling us\\nis that for cars with a manual transmission,\\nthey mostly have three gears,\\nbut cars that have an automatic transmission\\nare more likely to have five gears.\\nIt's basically showing a distribution of gear counts\\nbased on the type of car transmission.\\nThis is just a very simple example\\nof how you can use crosstabs to generate\\nsummary statistics and descriptions of categorical data.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2714162\",\"duration\":893,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Pearson correlation analysis\",\"fileName\":\"3006708_en_US_05_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"3 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1573,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to conduct parametic correlation analysis via Pearson correlation. This video covers linear correlation and causation.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":32785448,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's talk about\\nparametric correlation analysis.\\nParametric correlation analysis is\\na method you can use\\nto find correlation between\\nlinearly related continuous numeric variables.\\nDon't worry if you don't\\nexactly understand what that means\\nbecause I'm going to show you how\\nto figure this out in just a minute.\\nFirst, I want to explain one\\nimportant point about correlation.\\nCorrelation does not imply causation.\\nLet me explain.\\nImagine you're a doctor studying\\nregional obesity trends.\\n\\nYou have two data sets:\\nOne on store size reported\\nby zip code,\\nand two on national obesity prevalence broken down\\nby zip codes.\\nIn the course of your investigation,\\nyou apply the Pearson correlation method,\\nthat's the method I'm about to show you,\\nand you find that there's\\na very strong positive correlation\\nbetween grocery store size and obesity.\\nThe bigger the grocery stores,\\nthe more obesity there tends to be.\\nOf course, the size of the store doesn't cause obesity,\\nbut they're correlated,\\nand that correlation is quantifiable\\nthrough the Pearson Method.\\n\\nPearson correlation is measured\\nby the correlation coefficient, R.\\nIf you have a Pearson R\\nthat's close to one,\\nthen that's a strong positive relationship.\\nAnd if you had an R value\\nthat is close to negative one,\\nthen you've got a strong negative relationship.\\nIf you have an R value equal to zero,\\nor close to it,\\nthen you're basically seeing\\nthat your variables are not linearly correlated.\\nNow, the Pearson correlation assumes\\nthat your data is normally distributed,\\nthat you have continuous numeric variables,\\nand that your variables are linearly related.\\n\\nA really important note\\nthat I wanted to add here is\\nhow do you use the Pearson correlation?\\nSo it's safe to use Pearson correlation\\nto uncover linear relationships between variables,\\nbut you can not use it\\nto rule out the possibility\\nof non-linear relationships between variables.\\nFor this demonstration,\\nwe're going to be bringing\\nin our standard libraries,\\npandas and numpy,\\nbut also please note that\\nI've imported matplotlib and seaborn,\\nas well as the rcParams.\\n\\nWe're also going to be using scipy\\nin this demonstration.\\nSo all of these are already loaded\\nin our notebook,\\nand I've also preloaded\\nthe empty cars data set\\nthat we've been working with,\\nand set the plotting parameters for matplotlib.\\nWe covered all of these things in previous lectures,\\nbut the one thing I want to point out here is\\nthat we are importing Pearson R\\nfrom the scipy stats package.\\nSo you have to first start off\\njust by running these.\\n\\nAnd like I said,\\nempty cars is ready to go.\\nSo all we need to do is run this\\nto load it into our environment.\\nCool.\\nand let's just go ahead and start\\nby generating a pairplot using\\nthe seaborn library.\\nTo do that, we'll use the pairplot function,\\nso that's sns.pairplot,\\nand we'll pass in cars data frame\\nand run this.\\n\\nMove it up a bit.\\nIt's just thinking for a little while.\\nYou can tell what Python's doing\\njust by seeing this moving blue scroll\\nat the top,\\nand also this icon here saying\\nhow long it's taken for Python\\nto process the request.\\nOkay, wow.\\nSo we have a lot of data here\\nthat's been plotted out for us.\\nAnd as you can see,\\nif you were to count them up,\\nwe actually have 11 numeric variables\\nin the cars data set.\\nThis basically takes up a lot of space.\\n\\nI went ahead and selected\\nsome variables for our analysis,\\nand I'll go ahead and generate\\na scatter plot matrix of those\\nin order to show you\\nwhat about them is desirable\\nfor the Pearson correlation.\\nAnd I'm going to take you over\\ninto another screen\\nto explain really quickly.\\nBut before I do that,\\nlet's just make this second scatter plot.\\nSo we'll call it X,\\nand we'll set X equal to our cars data frame,\\nbut we only want to select four columns,\\nwhich are mpg, hp, qsec, and wt.\\n\\nAdd the single quotes here.\\nAnd then, again, we use the pairplot function,\\nso that's sns.pairplot,\\npass in X, and run this.\\nOkay, so that was a lot faster,\\nand here we have a smaller pairplot.\\nNow let me take you over to\\nthe other screen to explain\\nwhat all this means.\\nSo let's consider the model assumptions\\nfor the Pearson correlation analysis.\\n\\nPearson correlation assumes\\nthat your data is normally distributed,\\nthat variables are linearly related,\\nand that the variables are\\ncontinuous numeric variables.\\nLet's look here at\\nthe normally distributed requirement.\\nA normally distributed requirement is going\\nto give a shape like a bell curve\\nin a histogram.\\nI wouldn't say that all these variables are\\nexactly normally distributed,\\nbut they could possibly be close enough\\nin order to generate\\nsome sort of correlation using\\nthe Pearson correlation method,\\nso I'm going to go with these.\\n\\nNow, let's look at the requirement\\nfor a linear relationship.\\nDo these variables have\\na linear relationship between them?\\nIn other words, does one increase\\nwhile the other decreases?\\nBased on the shape of the distribution\\nof points between the variables,\\nit looks like most of these have\\na distribution that could be\\nat least close to linear,\\nso I'm going to test them out\\nwith the Pearson correlation method.\\nThe last requirement is that\\nthe variables be continuous numeric variables.\\nThe best way for me to show you\\nwhy I think that these are\\ncontinuous numeric variables is\\nto show you what a variable looks like\\nwhen it's not a continuous numeric variable.\\n\\nIf you look over at the scatterplot on the right,\\nthese variables over here are not\\ncontinuous numeric variables.\\nThese are categorical variables\\nbecause they can only assume\\na fixed number of positions,\\nlike we just discussed in the last section.\\nSo this variable can assume one of two values.\\nThat makes it a binomial variable.\\nIn the gear variable,\\nit can assume three values;\\nthree, four, or five.\\nThat makes it a multinomial variable.\\nThese are not continuous numerical variables.\\n\\nWhen you see continuous numerical variables,\\nthe scatterplot of the variables is much\\nmore randomly and evenly distributed.\\nThe end conclusion here is that\\nthe variables that are shown\\non the right would not qualify\\nfor the Pearson R correlation analysis.\\nOkay, great.\\nSo let's get back to our coding demonstration\\nand use scipy to calculate Pearson correlation coefficients.\\nNow, let's look at how to use scipy\\nto calculate the Pearson correlation coefficient.\\n\\nOkay, so let's start by creating\\nsome variables we can use here.\\nSo we'll create an mpg variable,\\nand we'll set that equal to cars.mpg.\\nAnd then let's create an hp variable\\nthat's equal to cars hp.\\nWe'll create a qsec variable\\nand we'll set that equal to cars qsec.\\n\\nAnd then, a wt variable,\\nwhich will be directly\\nfrom our cars data frame,\\nthe weight variable here.\\nOkay.\\nSo let's start first by taking\\nthe Pearson R coefficient\\nof the mpg and hp variable pair.\\nSo to do that,\\nwe're going to say pearsonr_coefficient\\nand P value.\\n\\nWe're going to set these equal to\\nthe Pearson R function,\\nand we'll pass in our mpg\\nand our hp.\\nAnd then, let's print out the label.\\nSo we'll say print,\\nand let our label be Pearson R correlation coefficient.\\n\\nOkay.\\nAnd then, say %0.3f.\\nAnd then, give another percentage sign,\\ncreate a tuple here,\\nand pass in our Pearson R coefficient object.\\nOkay, I'm going to look this over\\nreally quick for any typos.\\nOkay, yeah, so one issue is that\\nI needed to close out\\nthe string here after the F,\\nso I'm going to add a single quote\\nand remove the single quote from there,\\nand then we should be good to go.\\n\\nSo let's run this.\\nAnd then, what I'm going to do\\nto calculate the Pearson R\\nfor the other variable pairs is\\njust to copy this little chunk of code\\nand paste it down here,\\nand just change the variables out.\\nOnce we have the Pearson R coefficients,\\nthen we will discuss.\\nSo the second variable pair is going to be mpg and qsec.\\nAnd the third variable pair will be mpg and weight.\\n\\nSo let me run this.\\nAnd this.\\nOkay, great.\\nSo now we have our Pearson R values.\\nLet's just look at what this means.\\nBased on the Pearson correlation coefficient\\nof these three variable pairs,\\nthe mpg weight variable pair appears\\nto have the strongest linear correlation.\\nThe mpg qsec variable pair has\\na moderate degree of linear correlation.\\n\\nAnd you may be wondering,\\n\\\"Well, what do I do\\n\\\"with this information once I have it?\\\"\\nWhen you're doing machine learning,\\nor other forms of advanced statistical analysis,\\nthese models often have assumptions\\nthat either the features are independent\\nof one another\\nor that they exhibit\\na degree of correlation,\\nand you're going to see\\nthat later in this course.\\nSo you can use the Pearson R correlation coefficient\\nto establish whether or not\\nyour variable pairs meet the requirements\\nof more advanced models.\\n\\nNow, that you've seen the long form way\\nof calculating the Pearson R value,\\nlet me show you some shortcuts.\\nWe will start by using pandas\\nto calculate Pearson R correlation coefficient.\\nSo let me just notate that here.\\nYou can also generate\\nsome Pearson R statistics\\nby using this corr method,\\nso let's do it really quick.\\nUsing pandas, you can also generate Pearson R statistics\\nby using the corr method.\\n\\nSo let's do that real quick.\\nWe'll say that corr here is equal to x.corr,\\ncalled the corr method.\\nAnd then we'll print this out.\\nAnd as you can see,\\nit's really quickly generated\\nall of the Pearson R values\\nfor each of the variable pairs\\nin our smaller subset.\\nThe last way you can do this is using seaborn,\\nand that would be with its heat map function.\\n\\nSo we'll just say sns.heat map,\\nand then we'll pass in our corr variable,\\nand then we'll create some tick labels.\\nSo our xticklabels will be equal to\\nthe column values in our corr data frame.\\nSo we're going to say corr.column.values,\\nand then our ytick labels will be equal to\\nthe columns in the corr data frame.\\n\\nSo corr.columns.values,\\nand then we run this.\\nThat looks nice, but what does it mean?\\nWell, the darker shades of red indicate\\na strong degree of positive correlation,\\nas you can see from the legend.\\nBased on what we see,\\nthe hp weight variable pair has\\nthe highest degree\\nof positive linear correlation.\\nJudging by the darker hues in the grid,\\nthe mpg weight variable pair appears\\nto have the strongest degree\\nof negative linear correlation.\\n\\nYou'll of course see here\\nthat when mpg is plotted against itself,\\nthen it has an absolute value of one.\\nIt correlates 100% with itself,\\nthat's why these are solid cream colors here.\\nAnd then the sort of fuchsia color here,\\nthe weight qsec variable pair is not linearly correlated.\\nKeep in mind, that doesn't mean\\nthere's no correlation between\\nthese variables whatsoever.\\nIn the next video, I'm going to show you\\nsome methods you can use\\nto establish correlation\\nbetween non-linearly related variables.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4588026\",\"duration\":888,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Spearman rank correlation and Chi-square\",\"fileName\":\"3006708_en_US_05_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1465,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to conduct non-parametric correlation analysis. This video covers categorical variables, Spearman rank correlation, and Chi-square tables.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":29738610,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's talk about nonparametric\\ncorrelation analysis.\\nYou can use nonparametric correlation analysis\\nto find correlation between categorical nonlinearly,\\nnon-normally distributed variables.\\nFor an example of where nonparametric correlation analysis\\ncould be useful, imagine that you're a social scientist\\nthat studies smoking habits.\\nYou'll use a non-parametric correlation analysis\\nlike Spearman's rank to test the population\\nfor a correlation between income as a bracket\\nand cigarette consumption of smokers.\\n\\nYou find that higher income individuals are much more likely\\nto smoke cigarettes than lower income people.\\nI'm about to show you how to use Spearman's rank correlation\\nand chi-square tables to establish correlation\\nbetween categorical variables.\\nThe Spearman's rank correlation method\\nworks on ordinal variables.\\nIn case you don't know what that is, an ordinal variable\\nis a numeric variable that is able to be categorized.\\nThe Spearman's rank method converts ordinal variables\\ninto variable pairs and then calculates\\nan R correlation coefficient\\nby which to rank their variable pairs\\naccording to the extent of their correlation.\\n\\nIf that doesn't make much sense for you now,\\ndon't worry at all because I'm going to show you\\nwhat this means in the coding demonstration to come.\\nBut first, let's talk about the R values\\nfor Spearman's rank test.\\nSimilar to Pearson correlation,\\nif you get an R value that is close to one,\\nthen you are seeing a strong positive relationship.\\nWhereas if you get an R value that's close to negative one,\\nthen you're seeing a strong negative relationship.\\nIf your R value is close to zero,\\nyou are seeing that there is either a weak relationship\\nor no relationship whatsoever.\\n\\nIn terms of assumptions, the Spearman's correlation\\nassumes that your variables are ordinal.\\nIn other words, they are numeric\\nbut able to be ranked like categorical variable.\\nIt also assumes that your variables\\nare related nonlinearly.\\nLastly, it assumes that your data\\nis non-normally distributed.\\nDon't worry about these too much right now though,\\nbecause in the coding demonstration,\\nI'm going to show you how to examine your variables\\nand find out whether they meet these assumptions.\\n\\nYou can also use the chi-square test to see\\nif non-linear variables are independent of one another.\\nThe null hypothesis of this test\\nis that the variables are independent of one another.\\nSo if you have a p value of less than 0.05,\\nyou would reject the null hypothesis\\nand conclude that the variables are correlated.\\nIf you had a p value greater than 0.05,\\nyou'd accept the null hypothesis and conclude\\nthat the variables are independent of one another.\\n\\nIn terms of the assumptions of the chi-square test,\\nyou just want to make sure\\nyour variables are categoric or numeric.\\nIf you have numeric variables, then you're going to need\\nto make sure that you have binned them.\\nAnd in case you don't know what binning is,\\nnow is a great time to get familiar with that term.\\nAs an example, imagine you had a variable\\nthat had values between zero and 100.\\nThat's a numeric variable.\\nAs an example of binning, you could break up that variable\\ninto 10 separate groups, 10 groups of 10.\\n\\nAnd then within these 10 groups of 10,\\nyou would just put your data into different categories\\naccording to its numeric values, like this.\\nNow that you know what binning is, let's move on\\nto the coding demonstration portion of this section.\\nOkay, so for this demonstration, we're bringing in\\nour standard libraries, pandas and numpy,\\nbut please note that I also imported matplotlib\\nand seaborn as well as rcParams.\\nAnd we're going to be using scipy in this demonstration.\\n\\nSo all of these are already loaded into our notebook.\\nI've also preloaded the mtcars data set\\nthat we've been working with\\nand set the plotting parameters for matplotlib.\\nWe covered all of these in previous lectures.\\nThe one thing I wanted to point out specifically here\\nis that we are importing spearmanr from scipy.stats package.\\nYou can see that here.\\nSo you just start by running this.\\n(keyboard taps)\\nAnd as I said, the data sets are already loaded for you,\\nbut what you need to do is just run this\\nso we can take a look at the head of the dataframe,\\nthe cars dataframe.\\n\\nOkay, great.\\nSo we have a little preview\\nof what's inside the cars data set.\\nNow, let's just generate a quick pairplot from seaborn.\\nTo do that, we'll say sns.pairplot,\\nand we'll pass in cars, and run this.\\nLet it think for a little while.\\nOkay, great.\\nSo we've got our scatter plot matrix, but as you can see,\\nsince there's so many variables in the dataset,\\nit's pretty hard to visually see what's going on.\\n\\nSo I went ahead and selected some variables\\nfor our demonstration here.\\nSo let's just make a scatter plot matrix of these\\nso I can show you why I chose them.\\nWe'll call the subset x\\nand then we'll just select some variables\\nfrom our cars dataframe.\\nWe'll take the cyl variable, the vs variable,\\nthe am variable and the gear variable.\\n\\nAnd then we will call the pairplot function.\\nSet sns.pairplot, and then we'll pass in our x object,\\nand run this.\\nAll right, so there you have it.\\nNow let me explain why I chose these variables.\\nThe first thing I looked at is are these ordinal variables?\\nWell, if they're numeric\\nbut able to be ranked into categories,\\nthen yes, all of these variables are numeric.\\n\\nAnd they each assume only a set number of possible values.\\nSo yes, these variables are ordinal.\\nAre these variables related nonlinearly?\\nWell, based on this quick glimpse,\\nI don't see any linear relationships between the variables.\\nSo hopefully, yes.\\nLastly, is the data distribution\\nof each variable non-normal.\\nJudging from the histogram here, I'd say yes.\\nBased on this reasoning,\\nI decided to test the variables cylinder, vs, am and gear.\\n\\nSo next steps.\\nLet's just go ahead and isolate each of these variables.\\nSo we'll have cyl, and that's going to be equal\\nto the cyl column of our car dataframe.\\nAnd vs is equal to our vs column.\\nAm is equal to our am column.\\n\\nAnd gear is equal to our gear column.\\nOkay, so we isolated our variables here.\\nSo now, let's go ahead and let's just create some outputs\\nfor our Spearman rank correlation.\\nLet's do that by saying spearmanr_coefficient,\\n(keyboard taps)\\nunderscore coefficient.\\nP_value, and most of these equal to the spearmanr function,\\nand we'll pass in our cyl and vs variable pair here.\\n\\nNeed to change this order here to YL.\\nAnd then we'll also print out a label\\nso that we can really understand\\nwhat our test is telling us.\\nTo do that, we'll just write print,\\nand then we'll create a string which reads,\\nSpearman Rank Correlation Coefficient %0.3f.\\nSpearman Rank Correlation Coefficient %0.3f.\\n\\nAnd then close out the string.\\nAnd then we will write out our results,\\nwhich is going to be this placeholder here,\\nwhich is spearmanr_coefficient.\\nAnd check the syntax real quick.\\nLooks okay.\\nI'm going to run this.\\nOkay, so now what I'm going to do is I'm going to copy\\nthis code here so that we can use it\\nto calculate spearmanr for the other variable pairs.\\n\\n(mouse clicks)\\nSo the second variable pair here should be cyl versus am.\\nAnd then the third variable pair will be cyl versus gear.\\nOkay, so we have these, let's just run them real quick.\\nSo based on the Spearman's rank correlation\\ncoefficient of these three variable pairs,\\nthe cylinder vs variable pair\\nappears to have the strongest correlation.\\n\\nThe other variable pairs do show some correlation,\\nbut only a moderate amount.\\nThat was pretty easy.\\nNow let's look at the chi-square test for independence.\\nTo implement the chi-square test,\\nwe first need to start off by creating a cross tab.\\nWe'll call it table,\\nand we'll say cross tab equal to pd.crosstab.\\nWe'll pass the cylinder and am variables into this function.\\n\\nAnd then what we need to do\\nis we need to import our chi-square function.\\nSo that comes from the scipy library stats module.\\nSo we'll do an import by saying,\\nfrom scipy.stats import chi2_contingency.\\nOkay, now we have what we need\\nto actually implement a chi-square test.\\n\\nLet's write some placeholders for our output.\\nWe'll put chi2 as the first placeholder,\\nand then p and then dof, and lastly, expected.\\nAnd we'll set these equal to the output\\nof our chi contingency function.\\nSo chi2_contingency.\\n\\nAnd then we need to pass in our table.\\nThis is the table we just created,\\nbut we want to pass in only the values.\\nSo we'll say table.values.\\nAnd then let's print this out.\\nWe need a label so that it all makes more sense.\\nSo let that label be Chi-square Statistic %0.3f,\\nclose the string.\\n\\nAnd then we want to print out the p value, p_value label.\\nOkay, so we should actually close the string here.\\nThis is all one label.\\nAnd add a percentage sign.\\nAnd then our actual values that are generated by the task.\\nSo that's going to be chi2 and p placeholders here.\\n\\nOkay, and then we'll run this.\\nOkay, so it looks like there's a typo here.\\nLet's go ahead and take out this comma\\nand then also just fix the spelling here, table.\\nAnd then run this.\\nSo what we're getting here is a chi-square statistic\\nfor cylinder am variable pair.\\nLet's just generate a few more chi-square statistics\\non other variable pairs.\\nTo do that, I'm just going to copy this code over.\\n\\n(keyboard taps)\\nAnd then I'll change out the variable pairs.\\nSo let's change this for vs.\\nAnd then we'll switch out the am\\non the third variable pair for gear.\\nRun this.\\n\\nSo I'll move this up so we can see the results.\\nRemember, with the chi-square test,\\nwe need a p value greater than 0.05\\nin order to conclude that the variables\\nare independent of one another.\\nBased on what I see here, none of the p values\\nare greater than 0.05, so we must reject the null hypothesis\\nand conclude that the variable pairs are correlated.\\nThat's exactly how you would use the chi-square test.\\n\\nNow, let's look at how to do extreme value analysis\\nfor outliers.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4588027\",\"duration\":839,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Extreme value analysis for outliers\",\"fileName\":\"3006708_en_US_05_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"5 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1581,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to conduct extreme value analysis for outliers. This video covers point outliers, contextual outliers, and collective outliers.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":27084894,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now, let's look at extreme value analysis\\nfor outliers.\\nMost machine learning methods assume your data\\nhas been treated for outliers.\\nDetecting outliers can be a data preprocessing task\\nor an analytical method of its own merit.\\nBasically, use outlier detection\\nto uncover anomalies in data.\\nIn this section, we're going\\nto talk about univariate methods.\\nSome use cases for outlier analysis include detecting fraud,\\ndetecting equipment failure,\\nand also cybersecurity event detection.\\n\\nTukey methods are useful\\nfor identifying a variable's outliers.\\nYou can detect unusually high\\nor low data points in a variable\\nby applying the Tukey method for outlier detection.\\nData points identified using the Tukey method\\nshould be treated as potential outliers\\nto be investigated further.\\nThis is a Tukey Boxplot\\nand I wanted to point it out to you to show you\\nhow you can use a Boxplot to detect outliers.\\nBoxplot whiskers are set\\nat 1.5 times the interquartile range.\\n\\nThe interquartile range is really just a distance\\nbetween the lower quartile and the upper quartile.\\nThe upper quartile is where 25%\\nof data points are greater than the value.\\nAnd the lower quartile is where 25%\\nof data points are less than the particular value.\\nAny points beyond 1.5 times the interquartile range\\nare considered outliers.\\nThey'll show up in a boxplot visually as the dots\\nthat extend past the whiskers of the boxplot.\\n\\nThe other way to use Tukey methods to find outliers\\nis to use the Tukey outlier labeling method.\\nAnd this is essentially calculating the Tukey outlier\\nmathematically instead of using the boxplot.\\nSo let's look at how to do all of this in Python.\\nFor this demonstration,\\nwe're bringing in the standard libraries,\\npandas and numpy.\\nPlease note that I also imported matplotlib\\nand cbon as well as rcParams.\\nWe're going to be using scipy in this demonstration.\\n\\nSo all of these are already loaded into your notebook.\\nAnd I've also set the plotting parameters for matplotlib.\\nWe covered all of these in previous lectures.\\nWe're going to be using the iris data set\\nin this demonstration.\\nSo let's go ahead and get that imported.\\nWe'll start by setting the address variable\\nand we'll say that address is equal to\\nand then create a string.\\nAnd I'm going to go over to the notebook.\\n\\nYou'll need to do this for your setup.\\nSo we want iris.data.csv.\\nRight click \\\"Copy Path\\\"\\nand then copy that into the string.\\nOkay, great.\\nSo next, let's create a data frame called \\\"df\\\"\\nand we'll use the read CSV file.\\nSo we'll say, \\\"pd.read_csv\\\"\\nand then say \\\"filepath_or_buffer\\\" here.\\n\\nAnd we'll set that perimeter equal to \\\"address\\\".\\nAnd for header, we will say \\\"none\\\".\\n(keys typing)\\nAnd then it separated with comma.\\nSo for sep, we set that equal to comma\\nsince it's a column delineated file.\\nOkay, so now let's assign names to the columns.\\nSay \\\"df.columns\\\".\\n\\nAnd then we'll set that equal to a dictionary,\\nwhich contains column names.\\nSo the first column name is going to be \\\"Sepal Length\\\".\\nThe second column name is going to be \\\"Sepal Width\\\".\\nNext, \\\"Petal Length\\\".\\nAnd then, the last column...\\nThen, there's two more columns,\\nwhich are \\\"Pedal Width\\\" and \\\"Species\\\".\\n\\nShould be \\\"Species\\\".\\nOkay, now let's just create an X and Y variable.\\nFor X, we want that to be a data frame\\nthat contains the predictor variables.\\nSo in this case, we're going to use the iloc method.\\nSo we're going to call that off of the data frame\\nby saying \\\"df.iloc\\\".\\n\\nAnd then we're going to select only the first four columns.\\nSo we're going to say \\\":,0:4\\\".\\nOkay. And then we actually only want the values.\\nSo we'll just type \\\".values\\\" here.\\nAnd for our target, our Y variable,\\n\\\"y = df.iloc\\\"\\nand we're going to select the column\\nat the column index position four.\\n\\nSo we'll just put \\\":,4\\\".\\nAnd again, we only want the values.\\nSo then we're going to write \\\".values\\\".\\nAnd then let's go ahead\\nand just print out the first five records.\\nSo to do that, we'll say \\\"df\\\"\\nand then we'll select the first five records here.\\nRun this.\\nAh. \\\"PD is not defined.\\\"\\nThat makes sense because I didn't run this at the top here\\nwhen I opened the notebook.\\n\\nSo you always have to remember that even if your notebooks\\ncome preloaded, you, of course,\\nhave to run the cells in order\\nto import your libraries and modules that you need.\\nSo, okay, I ran everything here.\\nAnd then, now,\\nwe have the first five records in our dataset.\\nSo we've already gone ahead\\nand split that data frame into a set of X variables\\nas well as a Y variable.\\nSo now, let's begin looking at the Tukey boxplot.\\nWe can call the boxplot function off\\nof the data frame in order\\nto generate a boxplot automatically.\\n\\nSo to do that, we'll just say \\\"df.boxplot\\\".\\nAnd then we'll pass a parameter\\nthat says, \\\"return_type=dict\\\" for dictionary\\n'cause we want to return a dictionary.\\nAnd then plot this out with a plot function here.\\n\\\"plt.plot\\\". Run this.\\nOkay, so here we have a Tukey boxplot\\nfor our four numeric variables from our data frame.\\n\\nSo I'll go ahead and show you how\\nto actually use this boxplot to detect outliers.\\nSo you see here, we have a boxplot\\nand do you see those points that lay beyond the whiskers?\\nNow, those are our potential outliers.\\nWhat I did was I took a quick note of\\nwhere those outliers were found.\\nThat's the Sepal width column\\nand it's the values that are greater than four\\nor less than 2.5, approximately.\\n\\nLet's look a little closer at these values.\\nI'm going to use filtering in comparison operators\\nto isolate these values from the rest of the data frame.\\nSo let's go back over to our coding demonstration\\nand let's isolate Sepal Width.\\nSo let's get back over into our coding demonstration\\nand then we'll isolate Sepal Width.\\nTo do that, we'll just say \\\"Sepal_width = \\\"\\nand we'll set it equal to our X variable\\nthat we just created.\\n\\nAnd what we want to do is we want\\nto select our Sepal Width variable.\\nSo we're going to say \\\":,1\\\".\\nAnd then in terms of our outliers,\\nlet's create a second variable here called \\\"Iris Outliers\\\".\\nSo this would be \\\"iris_outliers\\\".\\nAnd we're going to say,\\n\\\"iris_outliers = Sepal Width greater than four\\\"\\nSo we'll just set this equal to a tuple,\\nwhere sepal_width is greater than four.\\n\\nAnd what we're actually trying\\nto do here is isolate the records\\nwhere this Sepal width is greater than four,\\nso that we can understand what's really happening\\nwith these data points.\\nNow, let's go ahead and print these out.\\nSo we'll say \\\"df\\\"\\nand then we want to print out the iris outliers.\\n(keys typing)\\nRun this.\\nOkay, it looks like I have a typo.\\nThis should be equals, not minus thing,\\nand I fixed that, rerun it, and great.\\n\\nSo we see that we have three records\\nthat have a Sepal width greater than four,\\nwhich makes sense\\nbecause, as you can see here,\\nthere are actually three small circles, right?\\n1, 2, 3, where they're outside the whiskers\\nthat are located at position of four here\\nand the Sepal Width variable.\\nLet's also isolate this value here that is below 2.05.\\n\\nSo what I'm going to do is I'm actually just going to copy\\nand reuse the code we just created here.\\n(keys typing)\\nOkay. And so all I need to do here is just change this\\nso that it is Sepal width less than 2.05 and then run this.\\nAnd as you can see,\\nwe have this one record here that is lower\\nthan the interquartile range\\nand it corresponds to this point here in the boxplot.\\n\\nLet me try to explain\\nwhat these records are actually telling us.\\nMoving the results over here,\\nI just wanted to point out\\nthat we now have the row index values for each\\nof the records that are coming back in looking suspicious\\nas outliers.\\nNow, I'm going to show you how\\nto do Tukey outlier labeling.\\nLet's go back over to the coding demonstration.\\nSo in this case, what we need to do is we need\\nto get some display settings.\\nSo we're going to say \\\"pd.options.display.float_format\\\"\\nand we're going to set that equal to a string value,\\nwhich contains a dictionary\\nand it's going to include a blank value.\\n\\nSo we'll create a string and then a dictionary.\\nSo \\\":1f\\\"\\nand then we're going to say \\\".format\\\".\\nOkay?\\nSo this is basically just setting up the display settings.\\nAnd let's create a X data frame.\\nWe'll call it \\\"X_df\\\"\\nand we'll set it equal to pd.\\n\\nAnd we're going to call the data frame constructor here\\nand pass in our X variable that we created earlier.\\nAnd then let's just print out a description\\nof these variables\\nthat are in the X data set that we created.\\nSo to do that, we're going to say \\\"print\\\",\\ncall the print function,\\nand then we're going to pass in X_df.\\nAnd off of that, we need to call the describe method.\\n\\nAnd then print this out.\\nNow, we have some descriptive statistics on each\\nof the variables in our data frame.\\nLet me explain to you what these actually mean.\\nLet's see how we can use them to find potential outliers.\\nThe interquartile range is the distance\\nbetween the third quartile and the first quartile.\\n75% is our third quartile, so we'll say\\nthat 3.3 minus 2.8, that's our first quartile.\\nThe difference between them is 0.5.\\nSo we multiply the interquartile range times 1.5\\nand we get a value of 0.75.\\n\\nTo find outliers from our first quartile,\\nwe'll just look at the value from the first quartile,\\nwhich here, it is 2.8,\\nand we will subtract out 0.75.\\nThis gives us a value of 2.05.\\nWe see that our minimum value is even less than that,\\nwhich means that it is suspicious for being an outlier.\\nFinding an outlier from the third quartile\\nuses the same approach.\\nIn this case, you would take the value\\nat the third quartile, which is 3.3,\\nand you'd add 0.75.\\n\\nThat gives us 4.05.\\nSince the max value in the Sepal Width column is greater\\nthan 4.05, we know that the Sepal Width is suspect\\nfor having outliers.\\nThat's it for univariate methods to finding outliers.\\nNext, I'm going to show you some multivariate methods.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4583162\",\"duration\":467,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Multivariate analysis for outliers\",\"fileName\":\"3006708_en_US_05_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"3 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":812,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to conduct multivariate analysis for outliers. This video covers box plots and scatter plot matrices.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15790874,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now let's talk about\\nmultivariate analysis for outliers.\\nUse multivariate methods to find outliers\\nthat only show up within combinations of observations\\nfrom two or more different variables.\\nThere are many different multivariate methods\\nto detect outliers.\\nWe are going to pick up where we left off\\nin the last section with the box plot,\\nand then I'm going to introduce you\\nhow to use scatterplot matrices to find outliers.\\nFor this demonstration,\\nwe're bringing in our standard libraries,\\npandas, matplotlib, and seaborn.\\n\\nSo all of these are already loaded in the notebook,\\nand I've also set the plotting parameters for matplotlib,\\nand I preloaded the iris dataset,\\nwhich we worked with in the previous demonstration.\\nSo all you need to do is run these code blocks.\\nAnd then let's just print out the first five records\\nin this data frame so we can get a look at the data.\\nAnd next, let's generate a box plot.\\nTo do that, we'll use seaborn's box plot function.\\nSo what you need to say is sns.boxplot.\\n\\nAnd for X, that's going to be equal to our species column.\\nSo you'll say X is equal to a string that reads species.\\nFor our Y variable, we're going to set that\\nequal to the sepal length label.\\nSepal length.\\nIn terms of the data we want plotted,\\nthat's going to be our data frame.\\n\\nSo we'll say data is equal to df.\\nAnd then with seaborne it gives us\\na lot of different color options.\\nSo in this case, we want our hue to be set equal to species.\\nAnd we'll set our color palette equal to HLS.\\nSo we'll say palette equal to,\\ncreate a string and write HLS.\\n\\nAnd lastly, we'll just say legend is equal to false.\\nOkay, so checking to see if I made any typos.\\nThe only thing I can see is that\\nthis should be boxplot instead of barplot.\\nSo let me change that.\\nI'm going to run this.\\nAnd great.\\nSo now we have a box plot.\\nAnd there are two things I want to point out\\nabout this box plot here.\\nOne is that we are plotting sepal length against species.\\nSo we're actually plotting two variables in one box plot.\\n\\nWhen we do that, the outlier falls out, as you can see here.\\nIt's passed the whiskers in the virginica species.\\nAnd this would be considered as\\nsuspicious for being an outlier.\\nNow let's look at the scatterplot matrix.\\nIt's really easy to generate\\na scatterplot matrix using seaborn.\\nSo we'll just say sns.pairplot.\\nAnd we're going to plot out our data frame.\\nSo we'll pass in df as the first variable.\\n\\nWe'll set our hue equal to species.\\nAnd again, we'll set our pallet equal to HLS.\\nWe run this.\\nAnd look how beautiful that is.\\nSo now we have a great scatterplot matrix.\\nLet me take you over to the other side\\nto explain what all of this actually means.\\n\\nSo we already know that our sepal width\\nvariable is suspect for outliers.\\nIf you look at each of the scatterplot matrices,\\nthere's an odd red point\\nthat doesn't fit any of the other clusters.\\nAnd so I've added a circle to that\\nand pulled it up from the data table.\\nThat's actually record 41.\\nSo I just jotted that down.\\nAnd I keep that in mind,\\nto investigate whether that's an outlier\\nand whether it needs to be removed.\\nAnd that's it for using\\nmultivariate outlier detection methods.\\n\\nNow let's look at applying Tukey outlier labeling.\\nThis is basically just a manual process for finding outliers\\nif we don't use the box plot.\\nSo in this case, what we need to do\\nis we need to get some display settings.\\nSo we're going to say pd.options.display.float format.\\nAnd we're going to set that equal to\\na string value, which contains a dictionary,\\nand it's going to include a blank value.\\n\\nSo we'll create a string and then a dictionary.\\nSo colon 0.1 F.\\nand then we're going to say dot format.\\nOkay.\\nSo this is basically just setting up the display settings.\\nAnd let's create a X data frame.\\nSo we'll call it X_df,\\nand we'll set it equal to pd.\\n\\nAnd we're going to call the data frame constructor here\\nand pass in our X variable that we created earlier.\\nAnd then let's just print out\\na description of these variables\\nthat are in the X data set that we created.\\nSo to do that we're going to say print,\\ncall the print function, and then we're going to pass in X_df.\\nAnd off of that we need to call the describe method.\\n\\nAnd then print this out.\\nNow we have some descriptive statistics\\non each of the variables in our data frame.\\nLet me explain to you what these actually mean.\\nLet's see how we can use them to find potential outliers.\\nThe interquartile range is the distance between\\nthe third quartile and the first quartile.\\n75% is our third quartile.\\nSo let's say 3.3 here.\\nMinus 2.8.\\n\\nThat's our first quartile.\\nThe difference between them is 0.5.\\nSo we multiply the interquartile range times 1.5,\\nand we get a value of 0.75.\\nTo find outliers from our first quartile,\\nwe would just look at the value from the first quartile,\\nwhich is 2.8, and we would subtract out 0.75,\\nwhich gives a value of 2.05.\\nWe see that our minimum value is even less than that,\\nwhich means that it's suspicious for being an outlier.\\n\\nFinding an outlier from the third quartile\\nuses the same approach.\\nIn this case, you would take\\nthe value from the third quartile, which is 3.3,\\nand you'd add 0.75.\\nThat gives us 4.05.\\nAnd since the max value of the sepal width column\\nis greater than 4.05, we know that the supple width\\nis suspect for having outliers.\\nThat's it for univariate methods to find outliers.\\n\\nAnd next, I'm going to show you\\nmultivariate analysis for outlier detection.\\n\"}],\"name\":\"5. Exploratory Data Analysis\",\"size\":160035610,\"urn\":\"urn:li:learningContentChapter:4579303\"},{\"duration\":1595,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4589020\",\"duration\":648,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Cleaning and treating categorical variables\",\"fileName\":\"3006708_en_US_06_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1236,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn about categorical encoding including one-hot, binary, and vectorizations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":23468515,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's take another look\\nat categorical variables and why we might need\\nto treat categorical variables as well\\nas the options we have for treating them.\\nAs you recall, a categorical variable is a type\\nof variable that can take on only a limited\\nor fixed number of possible values.\\nFor example, fruit types is a categorical variable\\nas there are only a limited number of types of fruits.\\nSay for example, apples, oranges, lemons,\\nthere's not an infinite number\\nof fruit types, so it's categorical.\\n\\nIn the field of machine learning,\\nit's common to come across categorical variables\\nwhen addressing data science challenges.\\nTypically, machine learning algorithms are not equipped\\nto directly process categorical data.\\nTherefore, we have to transform this type of data\\ninto numerical formats that are compatible\\nwith machine learning algorithms.\\nThis transformation can be done through various methods,\\nincluding label encoding, one-hot encoding, among others.\\nThe conversion of categorical variables\\ninto numerical forms is known as encoding.\\n\\nIn this coding demonstration,\\nI will demonstrate two common encoding techniques,\\nlabel encoding and one-hot encoding.\\nWe'll be using the scikit-learn library\\nto implement these encodings.\\nDuring the coding demonstration,\\nwe will explore how to transform categorical variables\\ninto formats that are interpretable\\nby machine learning models.\\nLet's get started importing the required libraries\\nfor cleaning and treating categorical variables,\\nI've already imported numpy in Pandas,\\nand now we'll also import the other required libraries.\\n\\nOne thing I wanted to point out here is\\nthat from sklearn, the preprocessing module,\\nwe're importing LabelEncoder and OneHotEncoder.\\nWe will need both of these functions for this demonstration.\\nHere you can see I've already created\\nthe dataset that we will work with.\\nHere are the columns,\\nand as you can see in the gender column,\\nit has some missing values.\\nSo let's convert this dataset\\nto a data frame and then print it out\\nto get started working with it.\\n\\nWe'll call the data frame df\\nand we'll say df is equal to data frame constructor,\\nand then we'll pass in the dataset,\\nwhich is called data, and then print this out.\\nThere are different ways to handle missing data\\nand categorical variables.\\nIf there are just a few missing values,\\nthen we can drop the rows that contain the missing values.\\nOr if there are a lot of missing values in a column,\\nthen we can drop that column altogether.\\nWe can also replace the missing values\\nwith the most frequent value of that column or row.\\n\\nOf course, let's start by adopting the most logical way\\nof handling missing categorical data points.\\nIf you think about it here with this dataset,\\nyou cannot fill the missing values\\nin the gender column with the most frequent values\\nbecause there's a chance of assigning\\nthe wrong gender to a person.\\nSo in this case, we'll have to just drop the gender column.\\nTo do that, we'll say df is equal\\nto df.drop, call the drop method,\\nand then here we'll pass the column name gender\\nthat we want to drop as the first perimeter.\\n\\nAnd in the second perimeter,\\nwe will pass Axis equal to 1,\\nwhich refers to the columns of the data frame.\\nAnd we'll print this out, and as you can see,\\nthe gender column is dropped from the data frame.\\nNext, let's try to represent the information\\nthat's contained within the names field\\nsuch that it's represented by categorical numerical data.\\nThis will require a two-step approach.\\nFirst, we'll use label encoding\\nto create a numerical representation\\nof each value in the names field.\\n\\nAnd then after that, we'll use OneHotEncoder\\nto convert each value of these numerical values\\ninto its own unique categorical column.\\nFor labeling coding, we'll use\\nsklearn's label encoding function\\nto transform the names into categorical numerical values.\\nHow label encoding function works is\\nthat it encodes the target labels,\\nin this case, names, with values between zero\\nand N minus one, where N is the total number\\nof unique values in the variable.\\n\\nTo do this, first, we'll create an object\\nof the label encoder.\\nSo we'll say label_encoder\\nand we'll set this equal to label encoder.\\nThen we'll call the label encoders a fit function\\nand pass column with a categorical data in it.\\nSo we'll say label_encoder.fit\\nand we will pass in df['names']\\nbecause this is the variable\\nthat we want to have transformed.\\n\\nWhat this does is that it's going to create a numerical mapping\\nthat maps the names labels to categorical numerical values.\\nSo I'll run this.\\nNow we will generate the encodings\\nof the categorical variable by calling the transform method\\noff of the label encoding class.\\nSo let's call this label encoded names,\\nlabel_encoded_names\\nand we'll set this equal to our label_encoder\\nand we'll call the transform method off of that,\\nand we'll pass in again, we'll pass in our names column.\\n\\nSo df['names']\\nand print this out.\\nWhat this is going to do is it's\\ngoing to generate their encodings.\\nSo here, you see the output,\\nthe numerical encodings have been\\ngenerated for the names column.\\nNow we need to transform the categorical data\\nusing one-hot encoding.\\nIn one-hot encoding, each categorical value is converted\\ninto a new categorical column\\nand it is assigned a binary value 0 or 1\\nfor whether the data point is true or false for that value.\\n\\nLet's just try it out so you can see how it works.\\nFirst, we'll create the object of class onehot_encoder.\\nSo we'll say OneHotEncoder\\nand we want to pass a parameter\\nthat says sparse_output is equal to false.\\nAnd what we'll do is we'll call this the onehot_encoder\\nand then run this, then we'll just call the fit method\\noff of the class onehot_encoder.\\n\\nSo to do that, we'll say onehot_encoder.fit\\nand we'll pass in our data frame names column.\\nIt looks like I have a typo.\\nI'm missing a set of brackets here,\\nso I'm going to go ahead and add those,\\nand run this again.\\nWhat this has done is that it's performed\\none-hot encoded mapping of the categorical values.\\n\\nNow let's transform the data\\nby calling the transform function\\nand passing the categorical values.\\nWe'll call this onehot_encoded_names.\\nSo onehot_encoded_names\\nand we'll set it equal to our onehot_encoder.\\nWe'll call the transform method\\nand we'll pass in our data frame,\\nnames column, and run this.\\n\\nLastly, let's just save this as a data frame.\\nSo we'll say one-hot encoded data frame,\\nonehot_encoded_df.\\nWe'll call the data frame constructor.\\nFirst, we'll pass the output encodings,\\nso we'll say onehot_encoded_names here.\\n\\nThen we'll pass the mappings\\nof all the columns as column names.\\nSo we'll say columns is equal to\\nonehot_encoder.categories.\\nNext, we'll assign the original column\\nand the data frame as names.\\nSo we'll say onehot_encoded_df\\nand we'll select the names\\nand we'll set this equal to df[['names']] column.\\n\\nAnd we'll print this out\\nby saying onehot_encoded_df,\\nI'm just looking at the syntax real quick\\nbefore running this.\\nAnd okay, so now we have transformed our names\\ninto a set of categorical numerical variables\\nthat are represented in binary format here, as you can see.\\nSo each of the names has been represented\\nas its own categorical variable in the dataset.\\n\\nAnd then for where the value is\\nactually true for that data point,\\nwhich is actually Steve in the original dataset,\\nthat value gets a 1.0.\\nEvery other value in that column gets a 0.0.\\nAnd that's the basics of label encoding\\nand one-hot encoding.\\nNext, let's look at transforming dataset distributions.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4590005\",\"duration\":415,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Transforming data set distributions\",\"fileName\":\"3006708_en_US_06_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":584,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to transform data set distributions. This video covers preparing data for machine learning, normalization, and standardization.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13592207,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] The term data transformation\\nrefers to the practice of changing data\\nfrom its original state into a different format.\\nThis often includes turning raw data\\ninto a format that is clean and ready for use.\\nIn this coding demonstration, we're going to explore\\na variety of beneficial data transformations\\nand look into those scenarios in which they're necessary.\\nWe'll focus on two specific data transformation techniques,\\nnormalization and standardization.\\n\\nNormalization, also known as min-max scaling is a method\\nwhere data values are adjusted and scaled\\nto fall within a range of zero to one.\\nThis technique maintains the original distribution of values\\nwithout altering their ranges.\\nOn the other hand, standardization is a technique\\nthat re-scales data so that it has a mean value of zero\\nand a standard deviation of one.\\nThis effectively normalizes the distribution of the data.\\nKeep in mind that in machine learning,\\nnot every data set necessitates normalization.\\n\\nIt's only required when the features\\nwithin the data set have varying ranges.\\nThe decision to use either normalization or standardization\\ndepends on the specific problem at hand\\nand the machine learning algorithm you're using.\\nThere is no strict rule that dictates the use\\nof normalization or standardization.\\nA practical approach is to initially feed\\nthe machine learning model with raw data,\\nas well as both normalized\\nand standardized versions of the data.\\n\\nBy evaluating the performance of the model\\nunder these different conditions,\\none can determine the most suitable type\\nof data transformation for the given scenario.\\nLet's take a look inside of Jupyter.\\nIn this demo, I'm going to show you\\nhow to transform dataset distributions.\\nAs you can see, I've already imported the required libraries\\nthat we're going to be using in this demonstration\\nwhich are numpy, pandas, matplotlib and sklearn.\\nFor pre-processing data,\\nwe're going to need the MinMaxScaler and the scale\\nfrom sklearn's preprocessing module.\\n\\nSo just pointing out that I have set those\\nand imported them here.\\nSo I'm going to run this.\\nAnd we're going to be using the mtcars data set\\nin this lecture.\\nSo I have imported that data set\\nand gotten that ready for us.\\nLet's look at the first five records\\nby calling the head method.\\nSo yeah, we've covered all of these things\\nin previous lectures and it just saves time\\nfor me to include these in the notebooks.\\nSo let's work with the miles per gallon column\\nwhich is represented by mpg.\\n\\nLet's see how we can transform its values\\nusing normalization and standardization.\\nThe first thing I want to do\\nis just plot the values of the mpg columns.\\nSo we'll just call the plot function, plt.plot,\\nand we'll pass in our data set, mpg column here.\\nAnd run this.\\nOkay, and then we have a visualization\\nof the distribution of the data points in the mpg variable.\\n\\nThat's what I wanted to create as a baseline\\nto compare this to as we work to transform\\nand normalize the data.\\nSo let's start first with normalization.\\nWe're going to normalize the values of the mpg column\\nusing sklearn's MinMaxScaler function.\\nSo we'll first create the object MinMaxScaler class.\\nWe'll say minmax_scalar,\\nand we'll set it equal to MinMaxScaler.\\n\\nAnd then what we want to do\\nis call the MinMaxScaler fit function.\\nSo we'll say minmax_scalar.fit,\\nand then we'll pass in the column, mpg.\\nAnd run this.\\nNow, if we call the MinMaxScaler's transform function\\nand then pass in the mpg variable,\\nthis will transform the values of the mpg column\\nso that they are distributed\\nas a series of numbers between zero and one.\\n\\nWe'll call it scaled_data, scaled_data.\\nWe'll set it equal to minmax_scalar.\\nWe'll call the transform method,\\nand we'll pass in our mpg column here.\\n(keyboard taps)\\nAnd then we'll just go ahead and plot this out\\nso you can see how the data has changed.\\nSo to plot it out, we'll use the plot function plt.plot,\\nand we'll pass in our scaled_data.\\n\\n(keyboard taps)\\nAnd run this.\\nNow, on its face, it looks just like the original plot,\\nbut if you look at the y-axis, the values have been rescaled\\nsuch that they fall between the values of zero and one.\\nWhereas in the original plot,\\nthe data points fell between 10 and 35.\\nBut there wasn't any distortion\\nin the range of the data points.\\nIt looks like the same distribution,\\nbut the values of the y-axis have just been scaled.\\n\\nNow, let's standardize the values of the mpg column\\nusing scikit-learn's scale function.\\nTo do that, we'll say standard_scalar is equal to scale,\\nstandard_scalar equal to scale.\\nAnd then let's pass in our mpg column.\\nSo we'll say, dataset mpg.\\nLet's just go ahead and plot this out, plt.plot,\\nand we'll pass in our standard_scalar, and run this.\\n\\nAnd again, the distribution of the data points\\nlooks identical to the previous two charts.\\nBut in this plot, we can see that the data points\\nhave been rescaled such that they have a mean equal to zero\\nand a standard deviation of one.\\nAs with normalization, the data points\\nhave not been skewed or distorted in any way.\\nNow that you know how to transform your data sets,\\nyou should be ready to get started\\nwith basic machine learning algorithms.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4579302\",\"duration\":532,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Applied machine learning: Starter problem\",\"fileName\":\"3006708_en_US_06_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":798,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to use the data in a ML problem by formatting predictors and labels, and then passing them to a simple ML algorithm.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16862354,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's dig into the process\\nof preparing a dataset\\nfor training a machine learning model.\\nOnce we have our dataset ready,\\nwe'll proceed to train\\na fundamental machine learning model\\nusing this data we've prepared.\\nThe preparation of a dataset\\nfor a machine learning models encompasses several steps.\\nMany of which, we've already covered.\\nThese include collecting the data,\\nfiltering out irrelevant features,\\nand managing existing values.\\nBuilding on this foundation, the next crucial step is\\nto format the data in a way that makes it suitable\\nfor input into a machine learning model.\\n\\nThis involves separating the dataset into features,\\nthe inputs and labels, the outputs we want to predict.\\nAdditionally, the dataset needs to be split\\ninto training and validation sets.\\nThis partitioning allows for the training\\nof the machine learning model on one subset of the data\\nwhile the other subset is used for validation.\\nThis is helpful for assessing\\nthe model's performance and effectiveness.\\nIn the coding demonstration I'm about to walk you through,\\nwe'll be utilizing various modules from scikit-learn.\\n\\nInitially we'll apply scikit-learn's\\ntrain test split function to divide our dataset\\ninto a training set and a validation set.\\nFollowing that, we will train a decision tree classifier\\nusing our dataset.\\nLastly, we'll employ scikit-learn's metrics module\\nto assess the performance of our model.\\nLet's get started\\nand see how these steps unfold in practice.\\nI've already imported the required libraries\\nthat we will use in this demo.\\nThose are pandas and sklearn.\\n\\nAlso, please note that\\nI'm importing metrics from sklearn here,\\nas you can see right here,\\nand that I've preloaded the iris dataset for you\\nthat we've been working with earlier demonstrations.\\nIris is a species of flowering plants.\\nIts dataset contains five columns,\\nwhich include petal length, petal width,\\nsepal length, sepal width, and species type.\\nWe'll try to predict the species type\\nusing the other features within the dataset.\\n\\nSo let's just start off here\\nby calling the head method off of this dataset.\\nLet me make sure I run this code block here\\nto import our libraries\\nand then we'll call the head method.\\nGive that a chance to run.\\nOkay, great.\\nSo this is the basic setup of the data\\ninside of the dataset.\\nThese are the first five records.\\nSo let's start off by just taking a look\\nat the unique species of iris flowers\\nthat are represented within this dataset.\\n\\nTo do that, we're going to call the unique method.\\nSo we'll say dataset.Species.unique\\nand run this.\\nAnd what we see here is that there are three types\\nof iris species in this dataset,\\nsetosa, versicolor, and virginica.\\nNext, we'll separate features and labels from the dataset.\\nThe second, third, fourth, and fifth columns\\ncontain features that describe the flower.\\n\\nAnd the sixth column contains the species labels.\\nFirst, let's separate the features\\nand save them as an X variable.\\nSo we'll say X is equal to dataset.iloc,\\nand then we'll tell it to return all of the rows\\nand only the second through fifth columns.\\nSo we'll pass in one through five here and print this out.\\n\\nAnd what we can see is that\\nthe dataset X now contains all\\nof the features from the dataset,\\nbut it no longer contains the label, the species label.\\nNow what we need to do is we need to separate the label\\nand save it as a Y variable.\\nSo we'll say Y is equal to dataset.iloc.\\nAnd in this case we want to select all of the rows,\\nbut only the sixth column.\\n\\nSo we'll pass a five here and then print this out.\\nAnd as you can see now we have all of the labels,\\nall of the species labels,\\nbut then none of the other variables in the dataset.\\nNext, we'll split the features and labels\\ninto training and test sets.\\nFor this, we'll use sklearn's train test split function.\\nAnd the training set will be used\\nto train the machine learning model.\\nThe test set will be used\\nto test the accuracy of our trained model.\\n\\nLet's write the code.\\nWe'll say x_train, x_test,\\ny_train and y_test.\\nThese are our placeholders.\\nAnd then we'll set them equal\\nto the train test split function.\\nSo it's train_test_split.\\nAnd then what we need to do is pass in our variables.\\n\\nSo first we're going to pass in our X dataset.\\nThen we'll pass in our target variable, which is Y.\\nIn the third parameter, we'll pass in the ratio\\nof the test data from the whole dataset.\\nSo here we'll need to say test_size equal to 0.3.\\nAnd what this means is that 30% of the data\\nwill become the test set\\nand 70% of the data will be the training set.\\n\\nAnd then let's set a seed for a random state.\\nWe'll just set random_state equal to zero,\\nand that's so that you get the same results on your screen\\nas we get in the demonstration here, we'll run this.\\nAnd now it's time to train a decision tree classifier\\non the training dataset.\\nFirst we'll create an object\\nof decision tree classifier class.\\n\\nSo to do that, we'll say clf is equal to.\\nAnd then we'll call DecisionTreeClassifier.\\nAnd then second, we're going to call the fit function.\\nSo we'll say clf.fit,\\nand then we'll pass in our x_train and y_train.\\nRun this.\\nOkay, because the Decision tree classifier is now trained,\\nwe can use it to predict labels for our test set.\\n\\nTo do that,\\nwe'll say y_predict,\\nand then we'll set it equal to clf.predict.\\nAnd we will pass in our x_test here\\nand then print this out.\\nAnd what you see as a result is that\\nyou see all of the predicted labels on the test dataset.\\n\\nThe last thing I want to show you how to do is\\nto evaluate our classifiers performance\\nby comparing the predicted labels\\nwith the original labels of the test set.\\nWe'll use the accuracy metric to evaluate the results.\\nAnd the function that we'll use is\\nsklearn's accuracy score.\\nSo we'll say accuracy is equal to metrics.accuracy_score\\nand we'll pass it in our y_test\\nand our y_predict variable.\\n\\nAnd then let's just print this out.\\nAnd when doing so, we'll create a little label here\\ncalled accuracy,\\nand we're just printing out our accuracy.\\nSo just pass that variable in and run.\\nAnd as you can see, the train model\\npredicted the labels of the test set\\nwith more than 90% accuracy.\\n\"}],\"name\":\"6. Getting Started with Machine Learning\",\"size\":53923076,\"urn\":\"urn:li:learningContentChapter:4583165\"},{\"duration\":5391,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4588028\",\"duration\":145,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction of web scraping\",\"fileName\":\"3006708_en_US_07_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":223,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn about data scraping from web sources to obtain data from multiple online sources. Learn why web scraping is needed in data science.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3689857,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Web scraping is a cornerstone technique\\nin data science.\\nWeb scraping automates the extraction of data from websites,\\nthus allowing us to gather large amounts\\nof information really quickly.\\nThe tool we use for this purpose is known as a web scraper.\\nToday, we'll dig into how web scrapers transform\\nthe raw data from websites into a format\\nthat's readily available for analysis.\\nYou might wonder why web scraping is so important.\\nThe internet is a treasure trove of data, stock prices,\\nsports statistics, product details, and more.\\n\\nManually collecting this data is a daunting task, though.\\nThat said, it's essential for many business activities\\nincluding market research and analytics.\\nWeb scrapers streamline this process\\nby efficiently gathering data that's crucial\\nfor organizational decision making.\\nWeb scraping offers several advantages.\\nIt enables the automatic extraction of fast data sets\\nwhile also significantly reducing manual efforts\\nand associated costs.\\nThis method is not only time-efficient,\\nbut also cost-effective.\\n\\nDeploying multiple web scrapers simultaneously\\naccelerates data collection while minimizing\\nthe human error, which is common in manual data gathering.\\nSo how does web scraping work?\\nThe process begins with identifying the target website.\\nWeb scrapers send requests to retrieve\\nthe site's HTML content,\\nwhich includes all of its data and code.\\nThe next step involves pinpointing\\nand extracting the necessary data\\nfrom the specific HTML text.\\n\\nThis extracted data is then cleaned, structured,\\nand stored in a database for further use.\\nWeb scraping has a diverse range of applications.\\nIt's a critical part of generative AI, machine learning,\\nand data analytics.\\nIt offers insights for market research\\nand competitive analysis.\\nWeb scraping is also instrumental in website migrations\\nwhere data is transferred from one site to another.\\nAll this said, it's important to recognize legal\\nand ethical boundaries.\\n\\nNot all data is permissible to script,\\nespecially when it involves confidential\\nor personal information.\\nEthical scraping respects privacy\\nand complies with legal standards.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4589021\",\"duration\":577,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Python requests for automating data collection\",\"fileName\":\"3006708_en_US_07_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":834,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn about the basics of the requests library, how connections are established, response headers, body, content-types, and metadata extraction.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17782415,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now it's time to talk\\nabout the requests library.\\nRequests is a Python library which is used\\nto make all sorts of HTTP requests.\\nIt's a human friendly HTTP library.\\nRequests Library provides a lot of customizable features\\nthat can be used for all sorts of different types of tasks.\\nAnd in this coding demonstration we're going to work on next,\\nI will teach you how to make requests using HTTP methods\\nand how connections are established.\\n\\nWe'll also look at to use requests to get response headers,\\ncontent types, and response content.\\nSo let's get started.\\nLet's start this demonstration\\nby importing the required libraries.\\nSo in this case, it's going to be the requests library.\\nWe'll say import_requests.\\nRun this.\\nAnd one of the most common HTTP methods is get.\\nthe get method gets or retrieves data\\nfrom a specific resource.\\n\\nLet's make a get request using the requests library\\nand check its response.\\nSo we'll say response\\nis equal to requests.get\\nand then we'll pass in the URL\\nhttps://www.python.org\\nto retrieve data from the original Python website's URL.\\n\\nLooks like I missed a Y here, so I'll add that.\\nAnd then print this.\\nThis needs to be a string.\\nSo let me add single quote\\naround each side of the string here.\\nAnd then we run it.\\nAnd when we run this code,\\nwe see that it returned a Response (200).\\nThis 200 response means that the connection\\nwith the website was successful.\\n\\nNow let's dive a little deeper\\ninto the response of that request.\\nWhen we make a request to a server like this,\\nit returns extra information with a response called headers.\\nHeaders contain all of the metadata of the URL\\nfor which we made the request of the server.\\nLet's print the response header.\\nSo we'll say response.headers\\nand run this.\\nAnd what you see is all of the headers information\\nthat is returned in the response.\\n\\nGoes on quite a ways here.\\nYeah, there's quite a bit of information.\\nOne type of information\\nthat's returned in headers is the content type.\\nContent type indicates the media type\\nof the returned content.\\nFor example, if the returned content is a simple HTML page,\\nthen its content type will be text/html.\\nSimilarly, if the returned content is a PDF file,\\nthen its content type will be application/pdf.\\n\\nLet's check the content type of the response object.\\nSo we'll say response.headers\\nand then we want to look here at the content type,\\nContent-Type\\nand run this.\\nAnd now we see that the content type\\nof the response object is text/html\\nwhich indicates that the returned content\\nis a simple HTML page.\\n\\nIn general, we use Python request\\nto fetch content from a server.\\nResponse content is the information\\nabout the server's response that's delivered back to us\\nwhen we send a request.\\nIf we want to return the content of the response in bytes,\\nwe'd say response.content like this.\\nresponse.content\\nAnd what you're seeing here is that we have returned\\nall of the content of the response in bytes.\\n\\nNow let's compare sequences in lines of text.\\nTo do that, we will need to import the diflib module.\\nSo we will say import_diflib\\nand run that.\\nNow let's create two sequences that we can compare.\\nThe first will be called flines\\nand we'll set that equal to a string that reads,\\nHello.\\n\\nHow are you?\\nI am fine.\\nAnd then the second sequence\\nwill be an object called glines,\\nand that will be equal to a string that reads,\\nHow are you, Lillian?\\nI am doing well.\\nOkay, so simple.\\n\\nI'll put a period here at the end\\njust for good grammar, at the end of the word fine.\\nAnd run this.\\nAnd next we need to create a differ object,\\nwhich we can use to compare the sequences of text\\nand find differences between them.\\nWe'll call this differ object d.\\nWe'll set it equal to diflib.Differ class,\\nand to compare the sequences,\\nwe need to call the compare method off of the d object.\\n\\nLet's call this whole thing diff\\nand we'll set diff equal to d.compare.\\nAnd then we want to compare our flines\\nagainst our glines.\\nSo we'll pass those names in.\\nThen we need to iterate over the sequence\\nand print out the differences.\\nOne problem here though,\\nbefore moving forward, I see a typo.\\nI have a stray dot here, so let me get rid of that.\\n\\nAnd then iterating over sequences\\nto print out the difference.\\nTo do that, we're going to use a for loop\\nthat iterates over the generator that's returned by compare.\\nSo we will say for line\\nin diff\\nprint(line)\\nWe'll call the print function\\nand we'll just have it print out the line.\\n\\nI need to add a colon here.\\nAnd then I'll run this.\\nOkay, it looks like I have a typo.\\nAh, okay, so I called it fline.\\nI forgot an S when I was creating these objects.\\nSo I'll just add an S here.\\nSo F line is equal to, \\\"Hello, how are you? I'm fine.\\\"\\nAnd then rerun this code block.\\nAnd there we go. We have our output.\\n\\nAnd let's take a look at what this actually means.\\nFirst off, what you're seeing here\\nis that each iteration has yielded a line\\nthat has been compared and printed to the console.\\nThe lines from the generator can include information\\nsuch as which elements are present in one sequence,\\nbut not the other, which are common to both,\\nand which are present in the second sequence,\\nbut not the first.\\nOn the bottom here you can see a notification\\nthat the output is truncated\\nand we can view it as a scrollable element\\nby clicking on this link here, which I'll do now.\\n\\nAnd then let's examine these results.\\nNow, if you look closely, we can see that the elements\\nthat are present in the first string,\\nbut not in the second string,\\nare marked with a negative sign.\\nSo for example, this word hello.\\nLet's look back.\\nHello is in the first line, but it's not in the second line.\\nHello is in flines, but it's not in glines.\\nAnd that difference is indicated\\nwith a negative symbol here.\\n\\nFor elements that are present in both strings,\\nthey're given no symbol or just a blank space.\\nSo for example, the word how.\\nHow exists in both flines and glines.\\nSo it's assigned the symbol\\nof a blank space in the output.\\nAnd for elements that are in the second string,\\nbut not the first, you could probably guess this,\\nbut those are indicated by a positive sign.\\n\\nSo for example, here the word Lillian has plus signs.\\nAnd as you can see,\\nthe word Lillian is in the glines variable,\\nbut it's not in the flines variable.\\nThat's why it's been assigned a plus sign as an indicator.\\nThat's the basics of what you need\\nto know about Python requests.\\nNow let's look at the beautiful soup object.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4588029\",\"duration\":1144,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"BeautifulSoup object\",\"fileName\":\"3006708_en_US_07_03_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1857,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to work with objects. This video covers the Beautiful Soup library and BeautifulSoup objects.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":42977993,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's look at web scraping with Python.\\nI'm about to show you how to scrape data from the internet.\\nBut before jumping in, let me give you a brief introduction\\nto web scraping by explaining how it's useful.\\nImagine you're a small business owner\\nand you've got a blog.\\nYou decide that you want to create a new resources page,\\nand on that page you want\\nto include every link from your blog.\\nWhat would you do?\\nGo through each page of the blog manually\\nand pull all of the links?\\nThat would take forever.\\n\\nWhat you could do instead is use Python\\nto automatically go through your blog for you\\nand extract every link from every page.\\nThat way you could just copy\\nand paste the links onto your new resource page\\nand it would be a lot more efficient.\\nI've seen environmental engineers\\nwho use Python to scrape web data from weather station pages\\nin order to gather sufficient data for hydrology analysis.\\nI've also seen Amazon vendors\\nwho scrape web data from competing Amazon vendor pages\\nso that they can use that data\\nto populate their product descriptions\\nusing a semi-automated approach.\\n\\nI've seen humanitarian volunteers scrape web data\\nfrom a foreign country's census site\\nso that the data could be used\\nto quickly form a resource allocation plan.\\nAnd last, but of course not least, without web scraping,\\nthere would be no generative AI.\\nScrape content in the form of copy and images\\nis a baseline necessity of training generative AI models.\\nWithout the source data that's scraped from the web\\nThere would be no chatGPT, Midjourney and what have you.\\n\\nIn other words, web scraping is useful\\nfor an almost unlimited number of applications.\\nIn the coding demo that's coming up,\\nI'm going to teach you about objects in Beautiful Soup\\nand how to work with them.\\nLater in the course, I'm going to teach you to work\\nwith parse data, scrape a webpage, and save your results.\\nThere are four main object types in Beautiful Soup.\\nThose are BeautifulSoup object, tag object,\\nNavigableString object and common object.\\n\\nThe BeautifulSoup object is a representation\\nof the document you're scraping as a whole.\\nIt's easily navigable and searchable.\\nTag elements correspond to XML\\nand HTML elements in an original document.\\nYou can navigate the reference data using tag attributes.\\nA NavigableString object is\\nto add a bit of text within tag.\\nBeautiful Soup uses NavigableString class\\nas a container for bits of text.\\n\\nAnd lastly, the comment object.\\nThe comment object is a type of NavigableString object\\nthat you can use for commenting your code.\\nIn the coding demonstration that's coming up,\\nI'm going to teach you about these objects in Beautiful Soup\\nand how to work with them.\\nIn this coding demonstration,\\nI'm going to teach you about objects in Beautiful Soup\\nand how to work with them.\\nLater in the course, I'm going to teach you how to work with\\nparse data, scrape a webpage, and save your results.\\n\\nBefore getting started here, I just want to check\\nto make sure that our version of Python is compatible\\nwith the demonstration we're about to do.\\nSo this notebook was written for Python 3.10\\nand let's just check the version we're running here.\\nSo we'll say import sys\\nand then let's print sys version.\\nSo we'll say sys.version and run this.\\n\\nAnd it looks like we have version 3.10,\\nso we're good to go.\\nNow let's go ahead\\nand import our Beautiful Soup into the Jupyter Notebook.\\nSo we'll say from bs4 import BeautifulSoup\\nand run this.\\nGreat, so now we have Beautiful Soup to work with\\ninside of our Jupyter Notebook.\\n\\nNow what I've done for this demonstration\\nis I'm providing you an HTML document\\nso you don't need to type all of this stuff out of course.\\nAnd so your Jupyter Notebook\\nis coming loaded with this HTML.\\nAnd we're going to use it to begin exploring\\nthe different types of objects within Beautiful Soup.\\nAll you have to do with this is run the block.\\nScroll to the end and then run it.\\n\\nLet's start by looking at the Beautiful Soup constructor.\\nBy default, the constructor will attempt to detect\\nwhat parser type you need based on the document\\nobject you pass.\\nLet's pick a parser for our constructor instead.\\nTo do that, we'll simply call the Beautiful Soup constructor\\nand we're going to pass in our_html_document.\\nThat's what we just created when we ran the block prior.\\n\\nAnd then for the second argument,\\nwe're going to tell Beautiful Soup exactly what type\\nof parser we want it to use to parse our data.\\nSince our data is html,\\nwe'll pass the html parser.\\nSo create a string that reads html.parser.\\nLet's set this whole thing equal to our_soup_object.\\nThis will be our soup object.\\nAnd then let's just print that out.\\n\\nSo we'll say print and then print(our_soup_object).\\nRun this.\\nOkay, so this is the output.\\nIt's all of our HTML.\\nBy default, the Beautiful Soup object\\nis a format of UTF eight,\\nwhich can be sort of difficult to read\\nbecause it doesn't have much formatting.\\nOne great way to make the output easier to read\\nis to prettify the soup object.\\nThe prettify method will turn a Beautiful Soup parse tree\\ninto a nicely formatted unicode string\\nwith each HTML or XML tag on its own line.\\n\\nLet's print out the first 300 characters of our soup object.\\nWe'll call the print function\\nand then we'll pass in our_soup_object\\nand then we'll call the prettify method off of that.\\nAnd we only want the first 300 characters,\\nso we'll just select [0:300]\\nand run this.\\n\\nGreat, so that's actually a lot easier to read\\nthan the output we got earlier.\\nIf you look back up here, it was kind of a big blob\\nand now at least we have some structure.\\nNow let's look at tag objects.\\nFirst, we'll create tag names.\\nSo let's create another Beautiful Soup object\\ncalled soup_object.\\nAnd to generate this object,\\nwe'll call the Beautiful Soup constructor.\\n\\nAnd let's just pass in a tag.\\nSo we'll create a string\\nand we'll say that this is h1 attribute_1\\nequal to heading level one.\\nSo this is actually heading level one tag\\nand we're saying that the attribute_1 = \\\"Heading Level 1\\\".\\n\\nAnd this heading should read\\n>Future Trends for IoT in 2018<.\\nAnd then we will close the </h1> tag.\\nAnd lastly, I want to pass in our html parser.\\nSo we'll say html.parser.\\nAnd let me check this index on this really quickly.\\n\\nShould be, okay.\\nSo now we have an h1 tag\\nand it's got an attribute of heading level one\\nand then it reads Future Trends for IoT in 2018.\\nNow what we need to do is go ahead\\nand create a tag variable.\\nWe'll call it say tag= soup_object.h1.\\nThis essentially tells Beautiful Soup\\nthat the tag's name is h1,\\na reference to the HTML we passed in.\\n\\nSo let's go ahead and print this whole thing out.\\nSo to do that, we'll call the type function\\nand we'll pass in our tag and hit run.\\nAnd so what you can see here is\\nthat our soup_object.h1 is actually a tag.\\nSo we named it tag,\\nbut when we call the type function,\\nit actually prints out here as a tag element.\\nAnd so we do indeed have a tag.\\nNow let's actually print out this tag\\nand see what it looks like.\\n\\nTo do that, we will call the print function\\nand we'll pass in our tag.\\nAnd as you can see, it returns a string that reads h1.\\nAnd that makes sense, right?\\nNow, let's see what happens when we call the tag name.\\nLet's say tag.name, print this out.\\nAnd of course it's also h1.\\nSo the name of our tag is actually h1.\\nAnd if you wanted to replace the tag name h1\\nwith heading one instead, you can do that.\\n\\nYou would just set the tag.name\\nand set that equal to heading one instead.\\nHere I'll show you.\\ntag.name = 'heading 1'.\\nPrint this out\\nand you can see that we've actually changed the tag name.\\nSo instead of it reading h1 as it does up here,\\nit actually reads heading 1.\\n\\nSo that's how you change the name of a tag.\\nLet's just also print this out really quick\\njust for clarity sake.\\nSo we'll say tag.name\\nand we get heading 1 and that's great,\\nwe changed the tag name.\\nNow let's look at tag attributes.\\nA tag can have any variety of attributes.\\nYou can access the tag's attributes\\nby treating the tag like a dictionary.\\nIn our example, the tag's attribute is attribute_1.\\n\\nSo let's just go ahead\\nand create a soup object, soup_object\\nand we'll set it equal to our BeautifulSoup constructor.\\nAnd then let's just take the tag that we created above,\\nI'm going to copy and paste it in.\\nWe need the quotes\\n'cause it should be a string.\\nAnd then we're going to use the same parameter of html.parser.\\n\\nAnd then let's create a tag variable.\\nSo we'll say tag is equal to soup_object.h1\\nand then we'll print this whole thing out.\\nSo we have our tag and it's been printed out here.\\nAnd imagine for example,\\nif you select attribute_1 from the tag object,\\nit returns to string that reads Heading Level 1.\\nThat is directly from the markup we passed into\\nBeautiful Soup constructor.\\nSo let's just try this out.\\n\\nWe'll say tag and then we'll select our attribute_1.\\nLet's see what we get back.\\nOkay, I missed a t here, attribute.\\nOkay, so fix that and then run this.\\nAnd cool, so that's called Heading Level 1.\\nThat's what prints out.\\nTo return a dictionary that contained\\nall of the tag attributes\\nyou'd simply call the attrs method.\\n\\nSo let's try that out here.\\nWe'll say tag.attrs.\\nAs you can see, this tag has only one attribute,\\nso you only get back one key value pair.\\nYou can easily add an attribute to a tag\\nby simply attaching an attribute labeled to a tag object.\\nLet's try that now.\\nSo we'll say tag\\nand then we'll select attribute_2\\nand we'll assign that a value of Heading Level 1,\\nwhich will be a string object, Heading Level 1\\nand I'll put an asterisk here.\\n\\nNow I have a little typo.\\nI got a dot that we don't need, so I'm going to remove that.\\nAnd then let's call the attrs method off of that tag.\\nRun this.\\nAnd then let's just print the tag.\\nSo those attributes both appear as part of the h1 tag.\\nPretty interesting.\\nWe can actually delete an attribute\\nfrom a tag object.\\nYou would just say del tag\\nand then select the attribute you want to delete.\\n\\nSo in this case, we'll delete attribute_2\\nand print this out again.\\nAnd now you can see attribute_2 is missing.\\nVery easy.\\nLet's also go ahead and just delete attribute_1.\\nI'm going to copy this and paste it.\\nAnd then just go ahead and change out the one for two.\\nRun both of these.\\nThen let's call attrs.\\nSo we'll say tag.attrs and run this.\\n\\nAnd now you can see we've deleted all of the attributes\\nand we get back an empty dictionary.\\nNow I want to show you how to navigate a parse tree\\nby using tags.\\nTo navigate a specific portion of the tree,\\nyou'd simply write the name of the tag you're interested in.\\nFirst things first though,\\nwe're going to start by importing our HTML document.\\nAnd this is the same document we used earlier\\nin your Jupyter Notebook.\\nIt's coming preloaded.\\nI'm just going to go back up to the top\\nand I'm going to copy this code block\\nand bring it down so we can reuse it.\\n\\nAnd let's create a soup object.\\nWe'll call it our_soup_object\\nand we'll set that equal to the BeautifulSoup constructor\\nand we'll pass in our_html_document\\nand an argument that reads html.parser.\\nGoing to run this.\\nNow to retrieve certain tags from within the parse tree,\\nall you need to do is write the name of the tag.\\n\\nSo if you want to pull up the title element\\nfrom the HTML document,\\nyou would just say our_soup_object.head,\\nso our_soup_object.head.\\nAnd this returns the head tag\\nthat contains the document title.\\nSo as you can see here, the document title is IoT Articles.\\nYou can also achieve the same outcome\\nby using the title tag.\\nSo let's just check that out.\\n\\nWe'll say our_soup_object.title,\\nrun that and get the same thing,\\nexcept that now we're missing the head tag, right?\\nBut we still get our article title.\\nIf you wanted to pull up this name of the article,\\nwell first let's look and see\\nwhat part of the tree that's actually located in.\\nSo let's go back up to the top here.\\nAnd it's held within the body tag,\\nbut there's a lot of other stuff in the body tag too.\\n\\nSo to narrow and further we can specify\\nthat it's within the body tag of the b tag.\\nSo here's the first b tag.\\nGo back down here and then just try\\nand access the title that way.\\nSo we'll say our_soup_object.body.b\\nand run this.\\nWell as you can see, the title of the article\\nis the same as what's been printed out.\\n\\nSo we were able to access it using tags.\\nJust to show you what we'd get if we were\\nto write in the b element,\\nI'll say our_soup_object.body.\\nAnd then what we're getting here\\nis the entire body of the HTML.\\nIt's a lot of text,\\nand so it's not really that useful\\nfor isolating portions of that text.\\nTo retrieve only the tags that are associated with lists,\\nyou could say our_soup_object.li.\\n\\nAnd then you get only the tags\\nthat are associated with lists.\\nAnd if you wanted to retrieve the first tag\\nthat contains a web link, you could say\\nour_soup_object.a and run this,\\nand then you would get our first link in the article,\\nwhich is a bit.ly link.\\nNow that we finished with tag objects,\\nlet's start looking at the NavigableStream object.\\nWe'll cover that in our next coding demonstration.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2715033\",\"duration\":660,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"NavigableString objects\",\"fileName\":\"3006708_en_US_07_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":928,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to work with objects. This video covers the NavigableString objects.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":26814035,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now that we've finished tag objects,\\nlet's start looking at the NavigatableString object.\\nBefore getting started here, I just want to check to make sure\\nthat our version of Python is comparable\\nwith the demonstration we're about to do.\\nSo this notebook was written for Python 3.10.\\nLet's just check the version we are running here.\\nSo we'll say import sys,\\nand then we'll print sys.version.\\n\\nAnd run this.\\nOops.\\nThis needs to be\\na new line here.\\nOkay, run this.\\nOkay, cool.\\nSo we have version 3.10, so we're good to go.\\nNext, let's just go ahead and import BeautifulSoup.\\nSo to do that, we'll say from BS4\\nimport\\nBeautifulSoup.\\n\\nRun this.\\nAnd now we have our BeautifulSoup library\\nimported into our IPython environment.\\nNow in this demonstration I'm going to show you how to work\\nwith NavigatableString objects.\\nNavigatableString objects are used as containers\\nfor chunks of text that are stored inside of tag objects.\\nSo let's just go back to our example from a previous lecture\\nwith our soup object,\\nand we'll create a variable here called soup object.\\nSoup_object.\\n\\nAnd we'll set it equal to\\nBeautifulSoup constructor.\\nAnd then within the constructor, we'll pass in an H1 tag.\\nAnd so to do that we'll create a string\\nand an open tag for an heading one element.\\nSo opening tag H1,\\nattribute_1 is equal to,\\nand then we'll set that equal to heading level one.\\n\\nLet's take that L out here,\\nand then close the string,\\nand then close this.\\nAnd we want this to read future trends for IoT\\nin 2018.\\nAnd then we'll close this H1 tag.\\nAnd then we need to be sure to pass our HTML parser\\njust to tell BeautifulSoup how to interpret\\nthe document we've passed in.\\n\\nIt does look like there's a typo,\\nso I'm missing a single quote here.\\nAnd then that should have cleaned that up.\\nSo, now let's create a tag,\\nand we'll set the tag equal to\\nour soup object\\nH1.\\nAnd then let's use the type function and pass in our tag.\\nAnd this is to verify that we actually indeed\\nhave created a tag object.\\n\\nSo I'll run this.\\nAs you can see,\\nwe have indeed created a tag object here.\\nSo let's verify the name of that tag.\\nIt should be H1,\\nbut let's double check by saying tag.name.\\nAnd yeah, indeed it is H1.\\nWe have an H1 tag,\\nbut if you just wanted to isolate the string object\\nfrom within this tag object,\\nthen what you could do is you could just say tag.string.\\n\\nSo tag.string and run this.\\nUh-oh, typo.\\nTag.string.\\nCool, so here we have it.\\nThat's our string within this tag.\\nIt's right here.\\nIt reads Future Trends for IoT in 2018.\\nI want to show you here how tag string is\\nactually a separate object of its own.\\nSo let's go ahead here and call the type function,\\nand then we'll pass in our tag.string.\\n\\nAnd run this.\\nAnd what you're seeing here is that the tag string\\nis actually a NavigatableString.\\nSo let's play with this a little bit.\\nI'll create a new variable,\\nand let's call that variable Our NavigatableString.\\nOur_Navigateable_String.\\nAnd we'll set it equal to our tag string.\\n\\nAnd then let's print it out.\\nSo basically what this is saying\\nis that our NavigatableString\\nis now this future trends in IoT in 2018.\\nIf you wanted to replace the string object\\nfrom within the NavigatableString,\\nyou can just call the replace\\nwith method off of the NavigatableString\\nand then pass in a replacement string.\\nSo let's try that out.\\nWe'll just replace this future trends for IoT in 2018\\nwith not a number.\\n\\nTo do that,\\nfirst, we'll pull up our NavigatableString object,\\nand then we'll call the replace with method.\\nAnd we'll pass in a string that reads NAN\\nfor not a number.\\nAnd then we'll print this out by saying tag string.\\nAnd as you can see, our string is\\nnow simply just not a number.\\nWe have replaced the future trends in IoT with not a number.\\n\\nOkay, so let's look at\\nhow we can utilize NavigatableStrings.\\nI'm giving you here this HTML document,\\nand we used this in a prior demonstration,\\nbut it's coming preloaded in your notebook,\\nso you don't have to try to type all of this out.\\nBut what we're going to do is we're going to convert this\\ninto a parse tree like we did in the previous section.\\nSo just to start things off, let's just run this cell.\\nWe'll go ahead and create our soup object,\\nand we'll set it equal to our BeautifulSoup constructor.\\n\\nAnd then we'll pass in our HTML document\\nand define our parser as the HTML.parser.\\nAnd then run this whole thing.\\nIf there's one or more string object within a parse tree,\\nyou can easily isolate them.\\nOne way to do this would be calling the\\nstripped string generator to return all of the strings\\nwithin the object where strings consisting entirely\\nof white spaces are ignored,\\nand white space at the beginning\\nand end of the string is removed.\\n\\nSo for this example,\\nfor each string object in the parse tree,\\nthis stripped strings generator passes through,\\nstrips white spaces,\\nand then prints out each string\\nthat contains a printable representation.\\nSo let's try this out here.\\nWe'll say for string\\nin our BeautifulSoup object,\\nour soup object.stripped_strings.\\n\\nWe want to print representation.\\nSo R-E-P-R.\\nAnd then of the string.\\nSo I'll pass in string.\\nThis is going to print a representation of the string,\\nand then we will run this.\\nOkay, so now you can see\\nthat our strings have been pretty much cleaned up.\\nWe just have a list of strings here without the tags\\nor any of the markup within the body\\nof the series of strings.\\n\\nThe last thing I want to show you in this demonstration\\nis how to access parent tag objects within a parse tree.\\nSo let's create a new object called First Link.\\nFirst_Link.\\nAnd then we'll set it equal to the A tag.\\nSo for our soup object,\\nwe'll reference the A tag.\\nOur soup object.A,\\nand then we'll call the print function\\nand pass in our first link.\\n\\nRun this.\\nUh-oh, this was changed to append\\nwith the autopopulater.\\nSo let's just fix that and run it again.\\nOkay, great.\\nSo this is actually the first link in our document\\nand the text that contains it.\\nSo in our document,\\nthis text here would actually be hyperlinked or clickable,\\nand it would redirect to a Bitly link.\\nIf we wanted to access the parent of that first link,\\nwe would just say, first link.parent.\\n\\nParent.\\nAnd we see that now we have the parent tag\\nof this first link.\\nNow, the NavigatableString object\\nof the first link is a string that reads\\nlast month Ericsson Digital invited me.\\nLet me show you.\\nWe'll say first link.string.\\nWe're going to take this string,\\nand we're basically going into this link\\nby pulling only the string from within it, right?\\nSo that is now printed out as the string object.\\n\\nAnd lastly, we can also retrieve the parent\\nof the NavigatableString object.\\nTo do that, we would say first link.parent.\\nSo in this case, the parent of the NavigatableString\\nis the A tag, which is sort of self-evident, right?\\nSo now you know how to work with objects in BeautifulSoup.\\nWe're going to get into using BeautifulSoup\\nfor data parsing.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4584143\",\"duration\":837,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Data parsing\",\"fileName\":\"3006708_en_US_07_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded, please mask the bottom deck from 00:00 - 10:13 in pickup\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1527,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to parse data. This video covers parsing data, getting data from a parse tree, and searching and retrieving data from a parse tree.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":34432705,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's look at working with parsed data\\nin beautiful soup.\\nI've broken the demonstration to come into three sections,\\nparsing data, getting data from a parse tree and searching\\nand retrieving data from a parse tree.\\nParsing data is where you'll pass an HTML\\nor XML document to a Beautiful Soup constructor.\\nThe constructor converts the document to Unicode\\nand then parses it with a built-in HTML parser.\\nWell, HTML parser, by default that is.\\n\\nLooking closer at searching and retrieving data.\\nI'm going to show you the find all method.\\nAnd this method searches a tag in its descendants\\nto retrieve tags or strings that match your filters.\\nThere are several methods for searching\\nand filtering a parse tree.\\nThe ones that I'm going to show you now are the name argument,\\nkeyword argument, string argument, lists, Boolean values,\\nstrings, and regular expressions.\\nYou can pass any of these arguments into the find all method\\nto use as filters and return either strings or tags.\\n\\nI'll show you in our demo.\\nData parsing is super simple with Beautiful Soup.\\nYou just pass in an HTML or XML document\\nto the Beautiful Soup constructor.\\nThe constructor converts the document to Unicode\\nand then parses it with a built-in HTML parser.\\nSo the first thing we need to do is just\\nto import our libraries.\\nAnd so your Jupyter notebook is coming preloaded\\nwith Beautiful Soup\\nand the urllib as well\\nas the regular expression library here.\\n\\nSo all you need to do is just run this code block\\nand you have your libraries available.\\nSo let's start by reading in some data.\\nWe're going to use the URL Lib library to do that.\\nSo we're going to say with\\nURL lib.request.URLopen,\\nand within this function, we're going to pass in a string\\nof a web address that has our HTML.\\n\\nSo that's https://Raw GitHub user content.com/bigdatagal/\\ndata-mania-demos/master/IOT2018.html.\\n\\nAnd then close the string.\\nSo again, that's https://raw GitHubusercontent.com/\\nbigdatagal/data-mania-demos/master/IOT- 2018html.\\nAnd we want this to be read as response\\nand we want HTML to be set equal\\nto the response read function.\\n\\nSo we'll say HTML equals response.read.\\nI need to HTML,\\ncheck the syntax really quick.\\nSo we need to have a colon here\\nand then I'm just going to bring this back up\\nand press enter so it's structured properly.\\nAnd then, okay, run this.\\n\\nSo now what we've done is we've loaded data into our\\nJupyter Notebook.\\nSo let's create a soup object, we'll call it soup,\\nand we'll say soup is equal to beautiful soup constructor.\\nAnd we'll pass in our HTML\\nand then we'll pass a perimeter that says it should be read\\nwith the HTML parser.\\nSo create a string that reads HTML.parser.\\n\\nThen let's just print the type out here.\\nSo we'll say type\\nand pass in our soup object and run this.\\nOkay, looks like I have a stray bracket here.\\nSo clean that up, run it again. And here we go.\\nAs you can see, we have created a Beautiful Soup object.\\nNow let's move into data parsing.\\nFirst thing's first, let's go ahead\\nand just prettify it so we can kind of get an idea\\nof what's in there and not have a bunch\\nof HTML that's totally unformatted.\\n\\nSo let's call the print function.\\nAnd we'll pass in soup.prettify and then let's just go\\nahead and print out only the first 100 characters.\\nSo we'll say zero:100\\nand run this.\\nAnd this is just a little preview of what we've got inside\\nof our soup object.\\nLet's practice getting data from a parse tree.\\nLet's start by getting the text out of our HTML\\nand isolating the text from within that HTML code.\\n\\nTo do that, let's just create an object called text_only\\nand we'll call the get text method off of our soup object.\\nSo we'll say soup.get_text.\\nAnd then print it out.\\nPrint our text only.\\nOkay, and then let me just check the syntax really quick.\\nWe've got a stray dot there,\\nso let's just get rid of that and then run this.\\n\\nAnd here's our output. That's nice and pretty easy to read.\\nNow I'm going to show you how to use this data\\nand basically search and retrieve data from a parse tree.\\nI've left some basic information\\nfor you within the notebook about searching\\nand retrieving data from a parse tree.\\nAnd we're going to be using the find all method.\\nThe find all method searches a tag in its descendants\\nto retrieve tags or strings that match your filters.\\nBasically, you can just pass any\\nof these arguments into the find all method to use\\nas filters and then return either strings or tags.\\n\\nSo the first thing I want to show you is how\\nto retrieve tags by filtering the name arguments\\nand name argument search for tags\\nby filtering based on the name tag.\\nSo let's practice really quickly.\\nWe'll just say soup\\nand we'll call the find all method off of that.\\nAnd then we want to pass in the tech LI.\\n\\nAnd run this.\\nHere's our output.\\nWhat this has done is it's gone through our parse tree\\nand it's basically filtered out all of the tags\\nthat have the name LI and printed only those.\\nSo you see we have a bunch of LI tags here.\\nYou can also retrieve tags by filtering\\nwith the keyword argument.\\nSo let's try that out real quick.\\nThis basically is going to search the parse tree for tags\\nby filtering based on tag attribute.\\n\\nSo what we need to do is call the find all method off\\nof our soup object,\\nand we'll go ahead and create a keyword filter.\\nWe'll call that ID equal to\\nlink seven.\\nSo we're basically saying we want all of the tags\\nthat have the identification link seven as a keyword.\\nSo when we run this,\\nwhat we're actually getting is only one tag, which happens\\nto be the one associated with the ID link seven.\\n\\nIt's a link to online courses for IOT.\\nYou can also retrieve tags by filtering\\nwith string arguments.\\nSo this is where you search for tags\\nby filtering based on exact stream.\\nSo again, let's call the find all method off\\nof our soup object.\\nAnd then this time, let's pass a string\\nthat reads OL and run this.\\nAnd so here what it's done is it's passed through our\\nparse tree and it's basically filtered out all of the code\\nthat fell within the OL tags.\\n\\nSo you can see here there's an opening tag here\\nand a closing tag here.\\nSo it's just passed through the entire document\\nand retrieved the tags within the OL tags.\\nNow let's retrieve tags by filtering with lists objects.\\nAgain, we will call the find all method\\noff of our soup object.\\n\\nAnd this time we'll pass in a list of tags.\\nThe first one will be the OL tag.\\nAnd then let's make the next one a B tag\\nand run this.\\nOkay.\\nYou can see now that we have filtered out from our\\nparse tree only the text from within the tags that fall\\nwithin the B tag and the OL tag.\\nYou can retrieve tags by filtering with regular expressions,\\nand what this function does is it searches for tags\\nand strings simply by filtering based on regular expression.\\n\\nSo let's go ahead and let's create a variable called T\\nand we'll say T is equal to\\nre, regular expression.compile,\\nAnd we'll pass in a string called T.\\nAnd then let's create a for loop.\\nWe'll say for tag in,\\nand then we'll call the find all method off\\nof the soup object.\\nSo we'll say soup.find all,\\nand we'll pass in again T.\\n\\nFor each of these tags, we want to print the tag name.\\nSo we'll call the print function\\nand pass in tag name.\\nTag.name,\\nrun this.\\nAnd so now we have retrieve tags by filtering\\nwith regular expression here, which was T.\\nYou can also retrieve tags by filtering\\nwith a Boolean value.\\nSo let's just practice that real quick.\\n\\nI'm going to copy this code that we just wrote here\\nso we can reuse it.\\nAnd then in this case, what we want to do is we want\\nto filter based on the Boolean value true here.\\nSo we're going to change that T to true.\\nAnd then just run this again.\\nAnd here's our output.\\nThat's basically how you filter with Boolean values.\\nYou can retrieve web links by filtering with string objects.\\n\\nLet me show you how to do that real quick.\\nSo for this, let's just create a new for loop\\nand we'll say for link in\\nand all the find all method, off of the soup object.\\nAnd then we'll pass in an A, a string that reads A.\\nBasically what we're doing here is we are retrieving all\\nof the links that are associated with an A tag.\\nFor each of those, we want to print them out.\\n\\nSo we'll call the print function\\nand then we'll say link.get,\\nand then let's just ask it to get the Href,\\nand run this.\\nOkay, here we have a list of links.\\nSo basically what this has done is it's gone\\nthrough our entire soup object and isolated only the links\\nand printed them out in a list.\\nYou can also retrieve strings by filtering\\nwith regular expression.\\n\\nSo let me show you how to do that really quick.\\nAgain, we're going to use the find all methods.\\nSo we'll say soup.find all,\\nand this time we wanted to find where string is equal to.\\nAnd then we want to call the compile function\\nfrom regular expression.\\nSo that's re.compile,\\nand then we'll pass in a string\\nthat reads data and run this.\\n\\nOkay, so that's a bit long as you can see here,\\nbut what it's actually done is it's filtered our parse three\\nby the regular expression data.\\nNow that you've made it this far,\\nyou've basically covered all of the mechanics\\nof scraping web data with Beautiful Soup.\\nSo next I'm going to show you how\\nto use this stuff in action.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4590006\",\"duration\":792,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Web scraping in practice\",\"fileName\":\"3006708_en_US_07_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1615,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to scrape web data. This video covers reading and writing data from the internet.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":32738581,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let me show you web scraping and action.\\nIn the following demonstration,\\nI'm going to show you how to scrape a webpage\\nand then save your results to an external file.\\nLet's get started.\\nSo your Jupyter Notebook is coming\\nwith the standard libraries for beautiful soup\\nalready loaded in it, and you've also got URL Lib,\\nand regular expression library preloaded.\\nSo all you need to do is run this\\nand what we're going to do is we're going to scrape\\na page from analytics.usa.gov.\\n\\nSo to start, we're going to create an R variable,\\nand we're going to say R is equal to urllib.request.urlopen,\\nand then we're going to pass in a string\\nthat is the URL we want to be having data read from.\\nSo that's going to be https://analytics.usa.gov.\\n\\nAnd then we're going to call the read method off\\nof this whole thing.\\nAnd next, we're going to create a soup variable,\\nand we're going to set it equal\\nto the beautiful soup constructor.\\nAnd then we want to pass,\\nour first perimeter is going to be our R variable.\\nAnd then our second parameter will be the HTML parser\\nto tell Beautiful Soup to use the HTML parser\\nto read the data.\\n\\nAnd we'll call the type function\\nand pass in our soup object just to double check\\nthe type of our soup object,\\nwhich of course, should be a beautiful soup.\\nSo I'll run this and yeah, there we have it.\\nIt's a beautiful soup object.\\nSo just remember here that you can use any web link you want\\nto basically scrap data from any webpage on the internet.\\nNow, I'm going to show you how to script a webpage\\nand save your results.\\n\\nFirst, let's start by printing out our soup object.\\nSo we're going to call the print function,\\npass in soup.prettify.\\nAnd then let's just take a look\\nat the first 100 characters.\\nI'll run this and okay,\\nso we're seeing the very tip top of the webpage\\nthat's located at the analytics.us.gov url.\\nNext, what we should do is just use the find\\nall function to find all of the A tags\\nand then retrieve from within them\\nthe A tag values from within those.\\n\\nTo do that, we're going to create a loop.\\nSo it'll be a for loop\\nand for each link in soup.find all,\\nwe're looking for the A tags.\\nAnd then we want to print, oh,\\nlooks like I forgot a colon here at the end of this.\\nOkay, so then for each of those,\\nwe want to print the link and then we need to get the A.\\n\\nSo that's going to be link.get.\\nAnd within this get method, we're going to pass a perimeter\\nthat reads href and run this.\\nOkay, cool. So now we have a list of links.\\nAnd what this has done is it's actually gone\\nthrough the analytics.usa.gov webpage,\\nand it's looped through all of the text on that page\\nand basically printed out only the web links.\\n\\nBut if you wanted to see what that entire body\\nof text actually looks like,\\nthen you can use the get text method.\\nSo let's just try that out really quickly.\\nWe're going to say print, and we'll pass in our soup object.\\nAnd off of that, we will call the get Text method\\nand run this.\\nOkay, so there is a lot of content.\\nSo what I'm going to do is just click this option\\nas view it as a scrollable element.\\n\\nAnd here is the body of text that's sitting on that webpage.\\nWe have scraped it directly from the webpage in real-time.\\nThe benefit of using this for loop\\nthat we created here is it basically went through all\\nof the text and got us exactly what we needed,\\nwhich was the links instead of us having to kind of pick\\nand choose through the body of text.\\nAnd in this case, I'm not even seeing the hyperlinks.\\n\\nSo if you just want to scrape links from a webpage,\\nthen you might as well use this method up here.\\nLet's go ahead and just prettify this,\\nso we can kind of take a look at it more easily.\\nTo do that, we'll call the print function,\\nwe'll pass in our soup object, soup.prettify\\nand then let's just look at the first 1,000 characters.\\n\\nSo we'll, 0:1000 and run this.\\nOkay, so here, we're seeing the links printed out,\\nand it's a lot more manageable to read,\\nand it's a lot easier to read than the output from above.\\nNow, what I want to do is create a for loop\\nto pass through our soup object and find all of the A tags\\nthat have an attribute of href.\\nSo we'll say for link in soup.find all.\\n\\nAnd the first parameter will be a string\\nthat reads A with attribute equal to href.\\nSo we're going to say attris equal to,\\nand then we're going to create a dictionary,\\nand we're going to pass a string that reads href.\\nAnd then for all of these tags that are returned,\\nwe want the loop to match against them irregular expression\\nthat reads HTTPS and print out only those.\\n\\nSo to make that happen,\\nwe're going to call the compile function\\nfrom the regular expression library, so that's re.compile.\\nAnd within that,\\nwe're going to pass a string that reads HTTP.\\nAnd then for any results that match this expression,\\nwe just print them out.\\nSo we're going to call the print function and pass in our link.\\nAll right, and I'm going to check the syntax here\\n'cause it looks like something is off.\\n\\nYeah, I am missing the closing parentheses here\\nto close out the tuple.\\nOkay, so I'm going to run this,\\nand that's a long list of tags\\nwith links within them.\\nLet's just take a look at what the data type is here.\\nSo to do that, we'll say,\\ntype and pass in our link object.\\nSo as you can see, this is actually a tag object,\\nand what we basically have is we have all of our A tags\\nthat have an attribute of href\\nand also have an HTTP batch within them.\\n\\nIt isn't useful for you\\nto have this result stuck within a Jupyter Notebook though,\\nso you'll want to know how to actually save this\\nas an external file.\\nTo do that, we're going to create a new text file\\ncalled parsed data.\\nAnd so, we're going to create a file variable,\\nand say, file is equal to,\\nand then we'll call the open function.\\nWe'll pass in a string\\nthat reads parsed_data.text,\\nand the second parameter\\nwill be a string that reads W.\\n\\nWhat that's doing is it's telling Python\\nthat we want to write into that text file,\\nso W stands for write.\\nAnd then what we want to do is for each of the links\\nthat was just printed out,\\nwe want to print those now into the parsed data text file.\\nSo now, what we actually need to do is\\nthat we can just go ahead\\nand copy this code from above of our for loop.\\nWe'll copy this and then we'll just reuse it\\nfor efficiency's sake.\\n\\nI'm going to paste it here,\\nand it's just performing\\nthe same operation now as it did before.\\nBut instead of printing out here into Jupyter,\\nit's going to go ahead,\\nand it's going to generate a soup link,\\nand that's going to be a string.\\nSo instead of printing the link,\\nit's going to create a new variable called soup link.\\nAnd that link is going to be equal to a string.\\nAnd this string is going to be derived\\nfrom each link within the soup object.\\nSo what I'm going to do here is\\nthat I'm going to move this down,\\nand I'm going to say soup_link is equal to str\\nand then I'm going to pass in a link there.\\n\\nAnd then for each soup link, we want to print that out.\\nSo we need to update this print function,\\nso that it's printing soup_link.\\nAnd then we're going to write into the file.\\nSo we're going to say file.write,\\nand we're going to pass in our soup link, soup_link.\\nAnd what this loop is going to do is that it's going\\nto pass it the entire beautiful soup object,\\nand it's going to find all of the links\\nand print them out until it finds no more links,\\nand then it's going to flush the file and close the file.\\n\\nSo to make that happen, we say file.flush,\\nfile.flush,\\nand file.close.\\nAnd let me just check really quick\\nfor any issues with the syntax.\\nOkay, we'll run this and great.\\nOkay, so we have a list of tags\\nwith the links inside of them.\\n\\nSo essentially, this is\\nwhat should be written into our text file, correct?\\nSo let's check that.\\nI could show you the shortcut of where\\nto find the file, but I also want to show you how\\nto use the present working directory command\\nto show you where to go to retrieve that text file.\\nSo you need to pull up your present working directory,\\nand if you just call the command, %pwd and run this,\\nit's going to tell you exactly where you can go\\nto find the text file that was just printed.\\n\\nSo it's in our folder\\nthat we're actually working within in code spaces.\\nThe extension is printed out here for us.\\nAnd then of course, the shortcut is you\\ncould just go up to this explorer,\\nand since we're working in the notebooks folder,\\nyou can actually just find the file written here.\\nSo let's look at that and then you can see,\\nokay, here are our links.\\nIt looks like they're not quite as nicely formatted,\\nbut it's the same information\\nthat has been printed out in the Jupyter Notebook,\\nexcept for now it's a text file,\\nwhich can, in times, be more convenient.\\n\\nThe only thing I would mention here is\\nthat you can still see a bunch of stray tags.\\nAnd a lot of times when you're doing web scraping,\\nno matter how much data formatting you do,\\nthere's always these stray characters.\\nBasically, a lot of times,\\nthere are data processing requirements\\nafter you scrape the data.\\nSo expect to spend some time data munging\\nafter you do web scraping.\\nBut if you ever find yourself again in a position\\nwhere you can't get data from a website\\nbecause it's been placed on different pages\\nor in weird formatting, remember how to use beautiful soup\\nto scrape the data for you.\\n\\nAnd in the next lecture,\\nyou're actually going to learn how\\nto build a whole web scraping application\\nthat will print out links for you in such a way\\nthat they're perfectly formatted.\\nAnd so, stay tuned because that's next.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4586145\",\"duration\":1236,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Asynchronous scraping\",\"fileName\":\"3006708_en_US_07_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":1985,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn about writing parallelized scrapers with asyncio.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":43183549,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's look at asynchronous web scraping\\nand how we can use this method to\\nspeed up the process of extracting data.\\nA normal web scraper can take a lot of time\\nto extract large amounts of data,\\nor in some cases, it might just fail altogether.\\nThis usually happens when a web scraper makes a request\\nand then waits for the response\\nbefore jumping to the next request.\\nDuring this time,\\nthe CPU remains idle,\\nwhich wastes a lot of CPU time.\\nCircumventing this process,\\nasynchronous web scraping allows us\\nto make multiple requests simultaneously\\nwithout waiting for the response of each request.\\n\\nIt also reduces CPU idle time.\\nIn the demonstration of asynchronous scraping\\nthat's coming up,\\nwe will use the aiohttp and the asyncio libraries.\\nAiohttp is a client and server side library\\nthat allows us to make asynchronous requests.\\nOn the other hand,\\nasyncio is a Python library,\\nwhich is used to write concurrent code.\\nLet's take a look at it inside of Python.\\n\\nFor this demonstration,\\nwe're going to be working with new libraries.\\nOne is aiohttp, and the other is asyncio.\\nSo just to be careful,\\nlet's go ahead and do a pip install of each of those\\nto make sure you've got them installed in your environment.\\nSo we'll start with pip install aiohttp,\\nand run this.\\n\\nAnd then let's do pip,\\npip install asyncio,\\nand run this.\\nOkay, great.\\nNow, your notebook is already coming preloaded\\nwith the libraries that you'll need.\\nAnd we'll mainly be working with aiohttp and asyncio,\\nbut also with BeautifulSoup, CSV,\\nand the regular expression library.\\n\\nAll you need to do to import those\\nis just to run that code block there.\\nAnd since we're working within a Jupyter Notebook,\\nthere's already an event loop that's running on the backend.\\nSo we cannot start a new event loop.\\nFor this reason,\\nwe need to run nest asyncio.\\nWhat this module does is that it patches asyncio\\nto allow a nested use of asyncio.\\nSo first we'll do a pip install.\\n\\nAnd we want to do a pip install of nest-asyncio.\\nand then let's import nest_asyncio,\\nand we'll call it Supply Function.\\nSo to do that,\\nwe'll say nest_asyncio.apply,\\nand we'll run this.\\n\\nNext, let's write an asynchronous python function\\nthat scrapes all of the links\\nfrom a given webpage's HTML content\\nand saves them into a CSV file.\\nThis can be especially useful\\nfor gathering data for web analysis, SEO monitoring,\\nor even just cataloging content.\\nSo we'll begin by defining our asynchronous function,\\nwhich we will call scrape and save links.\\nWe'll use the async keyword\\nto define an asynchronous function.\\n\\nSo we'll say async def scrape_and_save_links(text):.\\nAsynchronous functions are part\\nof asynchronous programming\\nand they allow us to handle long waiting operations\\nlike network requests more efficiently.\\nThey let other parts of your program run\\nwhile waiting for these operations to complete.\\n\\nInside the function,\\nthe first thing we'll do is parse the HTML content\\nwith BeautifulSoup.\\nSo we'll say soup equal to,\\ncall the BeautifulSoup constructor.\\nWe'll pass in our text object\\nand we'll define the parser as HTML.parser.\\nNow, we want to save these links to a file.\\nTo do this, we'll open a file in append mode.\\nIf the file doesn't exist, it will be created.\\n\\nIf it does exist, we'll add to the end of it.\\nWe don't want to add any unintended new lines.\\nSo we'll set new line equal to a blank string,\\nfile equal to open,\\nand then we will pass a string that reads CSV_file.\\nThe next parameter will be a string that reads A.\\nAnd then lastly,\\nour new line needs to be equal to an empty string.\\n\\nWith the file opened,\\nwe create a CSV writer object.\\nThis object is responsible for converting our links\\ninto a format that's suitable for a CSV file,\\nwhich by convention uses commas to separate items.\\nSo here we'll say, let me move this up a little.\\nOkay, writer equal to CSV.writer.\\n\\nAnd we pass in our file\\nand we just set our delimiter equal to a string\\nthat's got a comma in it.\\nNext we'll loop through all the A tags in our Soup object.\\nThe final method looks for these tags\\nand with the attrs parameter,\\nwe specify a regular expression to match the href attributes\\nthat start with HTTP.\\nThis way, we're only getting actual web links.\\nSo here we'll say for link in Soup.findall\\nwe'll pass in our A tag\\nand then we'll say attrs equal to dictionary\\nthat contains href.\\n\\nAnd then we'll pass our\\nregular expressions compile function.\\nSo re.compile,\\nand we'll ask it to look for HTTP.\\nThe colon at the end of this.\\nEach link we find is extracted using link.get('href').\\nEach link we find is extracted using link.get('href').\\nAnd we use our CSV writer to write this link into our file.\\n\\nSo we'll say link is equal to link.get('href')\\nand then writer.writerow\\nand we'll pass in our link.\\nAnd lastly, we need to close the file.\\nFailing to close the file could lead\\nto data not being written correctly\\nor the file being left open unnecessarily,\\nwhich is a resource link.\\n\\nSo to close the file, we will write file.close,\\nand then let's just run this whole thing.\\nOkay, so here we have our function.\\nNext we're going to define another piece\\nof our web scraping toolkit,\\nwhich will be the fetch function.\\nThis asynchronous functions responsible\\nfor making web request\\nand then passing the content it retrieves\\nto our scrape and save links function.\\nLet's start by defining our function with the async keyword.\\n\\nThis indicates that it's an asynchronous function\\nand it allows us to use the await inside the function,\\nwhich is essential for performing\\nasynchronous IO operations.\\nSo we'll call the fetch function\\nand we want to fetch our session\\nand the URL.\\nNow, we'll enter a try block.\\nThis is where we'll perform our web request.\\nThe reason we use a try block is\\nbecause network operations are unpredictable.\\n\\nThere might be connectivity issues,\\nthe server might not respond,\\nor there could be a myriad of other issues that could arise.\\nSo we'll say try...\\nInside the try block,\\nto send a get request to the URL\\nwe passed into the function.\\nThe session.get method is an asynchronous method,\\nso we'll use the async with statement.\\nWe'll say async with session.get(url) as response.\\n\\nOne thing I want to point out here is\\nthat the async with statement ensures\\nthat the session is properly closed\\nafter we're done with it even if an error does occur.\\nOnce we have the response from our get request,\\nwe want to retrieve the text of that page.\\nWe do this with await response.text.\\nThe await keyword is used to wait for the operation\\nto complete without blocking the entire program.\\nSo we will say text is equal to await response.text.\\n\\nWith the text of the response in hand,\\nwe now want to scrape the links from it.\\nHere we use the asyncio create task\\nto kick up our scrape and save links function.\\nThis function call creates a new task that runs concurrently\\nwith other tasks including the main program.\\nSo we'll say task is equal to asyncio.create_task,\\nand then scrape and save links(text).\\n\\nWe don't want to move on until\\nwe've actually scraped and saved the links,\\nso we await the task to ensure\\nit completes before proceeding.\\nThis is a key point,\\neven though we're doing things concurrently,\\nsometimes we need to wait for one task to finish\\nbefore starting another.\\nSo we'll say await task here.\\nAnd lastly, we have an except block.\\nThis is our safety net.\\n\\nIf anything goes wrong with a network request\\nor the scraping, instead of crashing our program,\\nwe catch the exception and print out the error message.\\nThis is just a general best practice for debugging\\nand ensuring the robustness of your program.\\nSo we'll say except exception as e:\\nprint(str) passing e,\\nand that's our fetch function.\\n\\nOh!\\nOkay. Looks like there's a syntax error.\\nSo let me take this async in and move it over.\\nMove this line over this line.\\nTab it over, tab await over.\\nOkay.\\nJust clean up the indentations a bit.\\n\\nOkay. Yeah.\\nSo it was just a matter of cleaning up the indentations\\nand that's our fetch function.\\nIt's designed to handle web request asynchronously,\\nscrape the content for links\\nand manage errors gracefully.\\nWith asyncio, this function will work efficiently\\nas part of an asynchronous python application,\\nfetching data and processing it\\nwithout blocking other operations.\\nNow we're ready to write a function\\nthat orchestrates the whole web scraping operation.\\n\\nWe'll name this function scrape,\\nand its job will be to manage multiple URLs\\nand ensure that we fetch and process them concurrently.\\nThis is where the true power\\nof asynchronous programming lies\\nhandling multiple IO bound tasks at once\\nwithout waiting unnecessarily for each one to complete\\nbefore starting the next.\\nHere's how we do it.\\nSo we say async def scrape,\\nwhich will accept a list of URLs to process.\\n\\nWithin this function,\\nwe'll initiate an empty list named tasks.\\nThis list will store the future tasks that we will create\\nand then execute concurrently.\\nEach task will be a web scraping operation for a single URL.\\nSo here we'll say tasks equal to,\\nand we'll just put an empty list.\\nNext we set up an asynchronous context manager using\\naiohttp client session.\\n\\nAiohttp is an asynchronous HTTP client for Python,\\nwhich allows us to make multiple HTTP requests concurrently\\nby using async with, we ensure that the session is closed\\nautomatically once all operations\\nwithin the block are completed.\\nSo we'll say async with aiohttp.ClientSession\\nas session\\nand colon.\\n\\nNow, we loop over each URL in the URL's list.\\nFor each URL we call the previously defined fetch function,\\nwhich fetches the URL's content and processes it.\\nWe append the resulting task, a coroutine object\\nto our tasks list.\\nSo we'll say for URL in URLs,\\ntasks.append(fetch(session,url)).\\n\\nAfter we have iterated through all the URLs\\nand created a task for each, we use asyncio.gather\\nto run all of these tasks concurrently.\\nAsyncio.gather takes a list of coroutines\\nand schedules them to run concurrently\\nby prefixing tasks with an asterisk.\\nWe're unpacking the list so\\nthat gather receives individual tasks as arguments.\\nSo we will say await asyncio.gather,\\nand then we'll pass in an asterisk and then tasks.\\n\\nNow let's make sure our indentation is correct here.\\nSo this should actually be moved up one.\\nOther than that, we need to also add a colon here.\\nAnd then it looks pretty good, so I'll run it.\\nOkay, no problems.\\nOne thing I want to point out here is\\nthat the await keyword is crucial.\\nIt means that the scrape function will wait\\nuntil all the fetch tasks have been completed.\\n\\nEach fetch task involves sending a request to a URL,\\ngetting the response and then passing that response\\nto scrape and save links,\\nwhich saves the links into a CSV file.\\nOnce await asyncio.gather tasks completes,\\nwe know that all the URLs have been processed\\nand the links have been saved.\\nSo here we are at the concluding portion\\nof our web scraping session.\\nUp to this point,\\nwe've built all of the individual components we need\\nfor our web scraping application.\\n\\nWe have the scrape and save links function\\nto extract links from the HTML content\\nand save them to a CSV file.\\nThe fetch function to get the HTML content from our URL\\nand the scrape function to manage all\\nof our fetch calls concurrently.\\nNow it's time to use them.\\nLet's create a object called URLs\\nand we're going to set it equal to a list of URLs.\\nLet's make the first URL,\\nhttps://analytics.usa.gov.\\n\\nAnd then our second URL will be\\npython.org.\\nSo we'll say https://www.python.org.\\nAnd lastly about we use LinkedIn,\\nso https://www.linkedin.com.\\n\\nI'm going to do a forward slash just to make sure\\nall of our ducks in a row here, clean up the formatting.\\nAnd the next line is where we actually start\\nour scraping operation.\\nSo we'll say asyncio.run(scrape),\\nwhere URLs is equal to URLs.\\n\\nThose are the URLs we wrote into the list above.\\nAnd run this.\\nOkay, it looks like I missed the N here.\\nIt should be asyncio.\\nOkay, run this.\\nSo it looks like it's found some objects\\nthat are not callable,\\nbut we should still have\\nall of the links saved in the CSV file.\\nSo let's go ahead and go into our explorer here\\nand look for a CSV file.\\n\\nOkay, so it looks like we have a problem\\nwith one of our functions.\\nSo what I'm going to do is I'm going to go back up\\nand just check this syntax really quickly.\\nAnd what I can see here is that\\nthis indentation needs to be moved out.\\nAnd then also this A needs to be changed to a capital A.\\nAnd then we will run this code block again,\\nand okay, fix the problem.\\n\\nAnd now all of these links from these webpages\\nhave been scraped asynchronously.\\nThey will be saved in the CSV file.\\nSo we can look over here in the explorer section\\nand you'll see we have a CSV file.\\nAnd here is the CSV file with\\nall of the links from each of the three pages\\nthat we referenced in our list.\\n\"}],\"name\":\"7. Data Sourcing via Web Scraping\",\"size\":201619135,\"urn\":\"urn:li:learningContentChapter:4579304\"},{\"duration\":2756,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4584144\",\"duration\":314,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to Streamlit\",\"fileName\":\"3006708_en_US_08_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":401,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Get introduced to the spectrum of dashboarding utilities for Python, including Streamlit, Voila, Panel, and Dash. Learn why Streamlit is preferable.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7107321,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Streamlit, Dash, Voila, and Panel\\nare the leading frameworks\\nwithin the Python dashboarding ecosystem.\\nLet's discuss the features of these frameworks.\\nI'll state a design assumption.\\nThen we'll decide which framework\\nis best for that assumption.\\nStreamlit is a Python library\\nthat's specifically built for machine learning engineers\\nand data scientists.\\nStreamlit makes it easy to create and share\\nbeautiful custom web apps\\nfor machine learning and data science projects\\neven if you don't have any prior knowledge\\nof web development.\\n\\nin the matter of a few minutes,\\nyou can use it to build and deploy powerful\\ndata applications.\\nSome of the primary features of this framework\\nare it only supports Python language.\\nIt supports all of the Python plotting libraries\\nlike Matplotlib, Seaborn, Plotly, what have you.\\nAnother nice thing about Streamlit\\nis it's an open source framework.\\nWe do not need any web development knowledge\\nto build a web application using Streamlit,\\nand it's also incredibly easy to use and manage,\\nrequiring very, very little bit of code.\\n\\nIt runs on its own server\\nand it doesn't support Jupyter Notebook,\\nbut it can be deployed on most of the deployment servers.\\nNext, there's Panel.\\nPanel is another Python library\\nthat lets you create custom,\\ninteractive web apps and dashboards\\nby connecting user-defined widgets\\nto plots, images, tables, or text.\\nThe best thing about Panel\\nis that you can build a simple dashboard application\\nfor a complicated system in Jupyter Notebook,\\nand you don't need to switch tools along the way.\\n\\nHere are some of the main features of Panel.\\nJust like Streamlit, Panel also supports Python language.\\nIt supports all of the main Python Ploting libraries\\nlike Matplotlib, Seaborn, and others.\\nIt's an open source framework\\nand it can be used to create multi-page web applications.\\nA nice thing about Panel\\nis we don't need any web development knowledge\\nto create web applications using it.\\nPanel offers amazing design flexibility,\\nand you can use it to create your templates as well.\\n\\nIt supports Jupyter Notebooks,\\nand with it you can create an end-to-end application\\nwithin a notebook environment.\\nLastly, Panel can easily be deployed\\nto most deployment platforms.\\nNext, there's Voila.\\nVoila is a tool that lets you turn any Jupyter Notebook\\ninto a standalone web application.\\nIt allows you to create interactive web pages,\\nand it has great support for widgets, such as IPyWidgets.\\n\\nHere are some of the more prominent features\\nof Voila.\\nIt supports multiple languages, such as Python, C++,\\nand Julia.\\nIt also supports most of the Python plotting libraries.\\nIt's an open source framework\\nand you don't need any web development knowledge\\nto create web applications using Voila.\\nVoila makes it really easy to create basic dashboards,\\nbut unfortunately it has limited design flexibility.\\nIt only offers a few templates,\\nbut it does give you an option to create your own templates.\\n\\nThe nice thing about Voila\\nis it has exceptional support for Jupyter Notebooks.\\nLastly, Voila can be easily deployed\\nto most of the deployment servers.\\nAnd last but not least, there's Dash.\\nDash is a web application development framework from Plotly.\\nIt's built specifically for developing data applications.\\nDash offers users a very easy way\\nof developing dynamic dashboards.\\nSome of its main features are that it supports\\nPython, R, and Julia languages.\\n\\nDash is primarily built for using\\nwith Python's Plotly Library.\\nIt explicitly supports multi-page web applications,\\nand it's an open source framework.\\nThat said, basic knowledge of HTML is needed\\nfor developing a web application.\\nIt's really easy to create a basic dashboard application\\nusing Dash and Dash offers incredible design flexibility.\\nUnfortunately, though it doesn't provide any support\\nfor Jupyter Notebooks.\\n\\nOne more thing about Dash\\nis that it's got plenty of deployment options\\nand can be deployed on most of the deployment servers.\\nNow, let's assume we need to develop a dashboard\\nfor a non-technical audience.\\nIn this case, Streamlit would be an ideal\\ndata dashboarding solution simply because\\nit's more simple and structured than other options.\\nIf you're looking for a more mature\\ndata dashboarding solution\\nand your primary goal is to develop dashboards\\nfor non-technical users,\\nthen Streamlit should be your choice.\\n\\nMoving forward, we'll get started working with Streamlit\\nand exploring its features.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4588030\",\"duration\":168,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Environment setup\",\"fileName\":\"3006708_en_US_08_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"1 pickup recorded\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":261,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Get a basic introduction to Streamlit and how to import the required packages.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5665410,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] You know, most Streamlit developers claim\\nthat it's really easy to set up Streamlit\\nand that you can use it\\nto build a web application in minutes using Python.\\nHow about let's test out that claim to see if it's true.\\nWe'll start by setting up Streamlit,\\nand once we have that up and running,\\nwe'll explore some of its more prominent features.\\nStarting first with the installation process,\\nStreamlit works fine with Anaconda,\\nso we'll install it in an Anaconda environment.\\n\\nTo install Streamlit, we'll need the following commands.\\nWe'll need pip install streamlit, streamlit hello,\\nand pip install upgrade protobuf.\\nLet's open the terminal.\\nIn this demonstration,\\nwe're going to be working inside the terminal here.\\nSo for building Streamlit applications,\\nyou always need to do a pip install\\nof any libraries you'll need when building them.\\nAnd so in this case, we're just working with Streamlit.\\nSo we would say, pip install streamlit.\\n\\nRun this.\\nAnd then once we have that installed,\\nwhat we need to do is we need to import it\\ninto our environment.\\nSo we're going to say import streamlit as st.\\nAnd what we're actually doing here is we're building\\na very, very simple Streamlit application\\nthat just writes the phrase Hello World onto a webpage.\\nSo in order to do that, we're going to call the right function\\nand pass in a string that reads Hello World.\\n\\nSo we'll say st dot write.\\nAnd then Hello World.\\nOkay, and so we should be good to go.\\nIt's a very simple routine.\\nAnd then to run this, what we need to do\\nis we need to say streamlit,\\nspace run, space,\\nand then we need to copy the file path\\nof the Python file we're working in.\\nSo in this case, it's 0802B.\\n\\nSo I open up Explorer, I right click on the file name,\\nI copy path, and then I can just paste it down here.\\nOkay, so Chrome is asking me\\nif that's okay with me to paste.\\nAnd so I say allow.\\nAnd then I hit Enter to run.\\nAnd then here you click this button\\nto open it up in a browser.\\nAnd here is your very first Streamlit application\\nthat reads, Hello World.\\n\\nCongratulations.\\nNext I'm going to show you how to use Streamlit\\nto start building charts and visualizations.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4590007\",\"duration\":546,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Create basic charts\",\"fileName\":\"3006708_en_US_08_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":966,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to create basic charts in Streamlit, including a simple line chart, bar chart, and pie chart.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":19553621,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay,\\nwe're going to be using pandas, NumPy, Streamlit,\\nand Matplotlib.\\nAnd as with any Streamlit coding demo inside of Codespaces,\\nwe need to do a pip install of the required libraries.\\nSo let me just do that real quick.\\nDo pip install pandas.\\nSo the next thing to do is pip install numpy.\\n\\nAnd then we need to pip install streamlit.\\nAnd lastly, pip install matplotlib.\\nOkay, so now, we should have all of our libraries\\navailable inside of our environment.\\nSo the next thing we need to do\\nis just to import them.\\nSo, we'll start off by saying\\n\\\"import pandas as pd,\\\"\\nand then, \\\"import numpy as np,\\\"\\n\\\"import streamlit as st,\\\"\\nand \\\"import matplotlib,\\\" and we need the pyplot module,\\nso we'll say \\\"matplotlib.pyplot as plt.\\\"\\nNext, we'll create a dataframe with random numbers,\\nand set the column names.\\n\\nOkay, so I'm going to take this terminal here,\\nand just minimize it,\\nso we have more working space.\\nOkay, so first we'll define the column names.\\nWe'll do call_names equal to a list.\\nThe first column name will be called \\\"column1,\\\"\\nand then the next will be column2,\\nand the third is, of course, column3.\\n\\nAnd now let's create a DataFrame called \\\"data.\\\"\\nAnd we'll set data equal to the DataFrame constructor.\\nAnd within it, let's pass the random number generator.\\nAnd we'll create a numpy array with size 30 rows\\nand three columns, containing random numbers.\\nAnd after that, we'll set the column names.\\nSo for the random number generator,\\nlet's use np.random.randint, pass in a 30,\\nwhich basically says that we want to have 30 datapoints.\\n\\nAnd then let's define the size of our DataFrame here,\\nso again, we want 30 rows and three columns,\\nso we'll just say \\\"size=,\\\"\\nand then pass in 30 and three.\\nAnd then lastly, we need to define the column names.\\nSo to do that, we'll just say \\\"columns=col_names.\\\"\\nOkay, so I have a typo there, where that needs to be names.\\n\\nThis is the part\\nwhere we're going to now create the line chart.\\nFor this, we'll use Streamlit's line chart function.\\nSo that's st.line_chart,\\nand we'll pass in our DataFrame data.\\nAnd above the chart, let's print chart name,\\nwhich will be \\\"line graph.\\\"\\nSo we just create a string here.\\nAbove the chart, we write a string called \\\"line graph:\\\"\\nwith a colon at the end.\\n\\nLet's run this code and visualize the line graph.\\nSo to do that, we need to go down to our terminal here.\\nI'm going to bring it back up so we can see a little better.\\nAnd we're going to say, \\\"streamlit run,\\\"\\nand again, we need to copy the file path for this file.\\nSo we're working in 080_3b.\\nGo to the explorer, and then copy the path here.\\n\\nPaste, and then hit enter.\\nAnd then open in browser, and click the button.\\nAnd we created this chart in Streamlit,\\nusing only one line of code,\\nwhich shows really how easy it is to use.\\nAnd in the next step I'd like to show you\\nhow to create a bar chart.\\nSo, for this,\\nwe're going to use Streamlit's bar chart function.\\nI think the easiest way to do this, actually,\\nwill be just to copy and paste the code up here.\\n\\nOkay, so let's change out the title.\\nIt's going to be \\\"bar graph.\\\"\\nAnd then the function is now, instead of st.line_chart,\\nit's st.bar_chart.\\nAnd then we can go back to the terminal,\\nand I'm just going to copy and paste the run code here,\\nenter it in, hit enter.\\nSo it's running.\\n\\nOkay, so after we update the code here,\\nand then what we can do is we can just go back over\\nto our application in the web browser.\\nAnd you see that our bar chart has been added,\\nwhich is a nice, dynamic bar chart.\\nAnd it's been added directly below the line graph.\\nNow, Streamlit doesn't have its own pie chart function,\\nbut we can use a pie chart in Matplotlib,\\nor other Python visualization libraries,\\nand pass it into Streamlit's chart function\\nfor Matplotlib to display in Streamlit.\\n\\nTo display the pie chart in Streamlit,\\nlet's first create a simple dataset\\ncontaining types of animals, and their heights.\\nSo, we'll create a variable named \\\"animals.\\\"\\nSet it equal to a list, with the name cat, cow, and dog.\\n\\nSo these are the types of animals\\nrepresented in our animal variable.\\nAnd then let's assign them some heights.\\nSo we'll create another variable named \\\"heights,\\\"\\nand we'll set that equal to another list,\\nwhich will be 30, 150, and 80.\\nOkay.\\nSo now, let's just take this dataset\\nand use it to create a pie chart.\\n\\nSo let's create a label for the pie chart first.\\nWe'll do that by creating a string,\\nand just writing \\\"pie chart:\\\" with a colon in it.\\nAnd then, now we'll need to use Matplotlib\\nto create the pie chart.\\nSo we'll say, \\\"fig and ax is equal to plt.subplots.\\\"\\nGoing to move this up a little just so you can see it better.\\n\\nAnd then we'll call the pie method.\\nSo we'll say \\\"ax.pie,\\\"\\nand the first variable we'll pass in here will be heights.\\nAnd then for our labels,\\nlets set that equal to the animals.\\nNow let's pass the pie chart\\nin Streamlit's pie plot function.\\nSo to do that, we'll say \\\"st.pyplot,\\\"\\nand we'll pass in the figure object.\\n\\nSo now we've written all of our code.\\nIn order to see this displayed in our web browser,\\nthat's also of course very simple.\\nWhat you need to do is just go over to the browser,\\nand then hit the refresh.\\nAnd then you can scroll down, and you can see the pie chart\\nnow shows up.\\nIn this demo,\\nwe displayed three different types of charts in Streamlit\\nusing less than 10 lines of code,\\nwhich is really impressive.\\nNext, we're going to do a deeper dive\\ninto line charts in Streamlit.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2714163\",\"duration\":522,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Line charts in Streamlit\",\"fileName\":\"3006708_en_US_08_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":811,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Explore various options for displaying line charts in Streamlit.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17244047,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's take a deeper dive\\ninto creating line charts in Streamlit.\\nSo as with the other Streamlit demonstrations\\nthat we're doing here inside of code spaces,\\nwe need to do a pip install of our libraries.\\nSo for this demonstration,\\nour libraries will be time NumPy Panda Streamlit,\\nand matplotlib.\\nWe don't need to do a pip install for time,\\nbut we do need to do a pip install NumPy\\npip install\\npandas.\\n\\nThis is just to be super sure that\\nyou have the libraries available inside your environment.\\nDo pip install Streamlit.\\nAnd then lastly, pip install matplotlib.\\nLet's see, there was a small typo here,\\nso I'm going to change that O to B and rerun this.\\n\\nOkay, good.\\nSo now we have our libraries available to us.\\nNow we need to import them into\\nour Python file here.\\nSo we'll start by importing time.\\nSo I say import time,\\nimport\\nnumpy as np,\\nimport pandas as pd,\\nimport streamlit as st,\\nand import matplotlib.pyplot\\nas plt.\\n\\nNext,\\nlet's create a line chart\\nwhich will grow over time\\nand we'll use the line chart add rows function\\nto grow the chart.\\nSo we'll start by first generating a numpy array\\nwith a single random value.\\nCall it rows.\\nSo we'll say rows is equal to np.random.randn.\\nIn here we will pass the shape of array one cross one.\\n\\nNow let's print the chart name.\\nWe'll call it Growing Line Chart.\\nSo to do that we just write a string\\nand pass in the title that we want for the chart.\\nTo create the line chart using Streamlit,\\nwe need to use the line chart function.\\nSo we'll say st.line_chart\\nand we'll parse in our rows.\\n\\nAnd then let's set this whole thing equal to chart.\\nAfter that, we'll create a loop\\nand we'll grow the line chart in the loop.\\nSo we'll say for i in range,\\n1 through 100, do this.\\nNext, let's generate a random number\\nand append it to the array.\\nThen we'll parse this array to add rows function.\\n\\nSo we'll say new_rows\\nequal to row zero\\nplus np.random.randn,\\nand parse the shape of the array, which is a one by one.\\nNow let's add this array to the chart.\\nTo do that, we'll call the add rows method off\\nof the chart object.\\nSo let's say chart.add_rows\\nand we'll parse in our new rows.\\n\\nAfter that, we'll set rows equal to new rows\\nand then we'll call time.sleep to stop the loop\\nfor five milliseconds.\\nSo here we'll say rows = new_rows.\\nAnd then we'll end this with time.sleep.\\nAnd we will parse in 0.05 for five milliseconds.\\n\\nOkay, so that needs to be a period instead of a comma.\\nSo I'm just going to kind of look through here\\nand make sure my syntax is okay.\\nThis is pretty simple code of course,\\nbut okay so now we go back to the terminal\\nand we need to say streamlit run\\nand we'll copy our file path here,\\npaste it in.\\n\\nOkay, so we have to allow pasting in the chrome browser\\nand then hit enter.\\nIt's going to run it\\nand then click the open in browser button.\\nAnd there is our growing line chart.\\nAnd streamlit really gives us a flexibility\\nof creating graphs\\nin any other Python visualization library\\nand then allowing you to show them inside of streamlit.\\nSo let's create a line chart using mapplotlib.\\n\\nFirst we'll create an array with random values.\\nSo let me go back over to our Python file.\\nAnd so we'll create an array called values\\nand we'll set it equal to np.random.rand,\\nwe'll pass in a 10.\\nThat's just saying that we want the length of the array\\nto be 10 data points.\\nNext, let's just create a little title for this chart.\\n\\nSo we'll call it matplotlib's line chart.\\nAnd\\nokay, it looks like\\nthis comma here isn't going to work\\n'cause it closes the string,\\nso I'll just take that out\\nand okay, that'll be our title.\\nNext, let's plot the values with mapplotlib.\\nSo we'll say fig and ax.\\n\\nWe'll set these objects equal to plt.subplot,\\nsubplots,\\nand then we'll call the plot method off of our ax object.\\nSo ax.plot\\nand we'll pass in our values here.\\nNow let's parse the line chart into streamlit\\nusing the pyplot function.\\nSo we'll say st.pyplot\\nand we'll parse in our figure object.\\n\\nSo then the next thing you need to do\\nis just let's go back over to our webpage\\nand we can hit refresh.\\nAnd now we have got our matplotlib line chart.\\nHere's our growing, here's our growing chart,\\nand then we've got our max matplotlib line chart.\\nAnd so it looks like\\nwe have far too many of these matplotlibs line charts\\nso let's go back to the code\\nand see if we can figure out what went wrong there.\\n\\nOkay, so after looking over the code here a little bit,\\nI couldn't find anything wrong with it\\nand so I went and just refreshed the screen\\nand the mapplotlib line chart\\nworking as expected.\\nSo you can see now here we only have one chart,\\nand after doing a little bit of research,\\nI discovered that this is actually\\na known issue with the context manager for mapplotlib.\\n\\nIn any case, it cleaned itself up here\\nwithin our streamlit, as you can see\\nand so we are good to go.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2715034\",\"duration\":691,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Bar charts and pie charts in Streamlit\",\"fileName\":\"3006708_en_US_08_05_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":1065,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Explore various options for displaying pie charts and bar charts in Streamlit.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":22156396,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] As usual, for using Streamlit in Codespaces,\\nwe need to do a pip install of our required libraries.\\nSo in this demonstration, we're going to be using Pandas,\\nNumPy, Streamlit, and Matplotlib.\\nSo I'll just do a quick pip install of each of these.\\nPip install numpy,\\npip install streamlit,\\nand pip install matplotlib.\\n\\nOkay, so great.\\nNow we have the libraries that we need.\\nI'm going to minimize the terminal here\\nand start working inside of the Python file.\\nWe'll need to first import our libraries, of course,\\nso we will import pandas as pd,\\nimport numpy as np,\\nimport streamlit as st,\\nand import matplotlib.pyplot\\nas plt.\\n\\nAnd in a previous Streamlit demonstration,\\nwe created a bar chart using Streamlit's bar chart function.\\nThis time, let's create a bar chart in Matplotlib\\nand display it in Streamlit.\\nThe bar chart we'll create\\nis a group bar chart comparing the heights\\nand weights of the animals.\\nFirst, let's define the data for the charts.\\nSo we're going to say animals.\\nSo our first variable,\\nand it's equal to\\na list of animal types.\\n\\nSo we'll have 'cat', 'cow',\\nI'm going to go through and just get the placeholders ready\\nfor 'dog' and 'goat'.\\nOkay, now let's create a second variable called heights.\\nWe'll set it equal to a list of numbers.\\nThat'll be 30, 150,\\n80, and 60.\\n\\nAnd then their weights in kilograms\\nwill be set equal to 5, 400,\\n40, and 50.\\nAnd we'll start first by defining the subplots.\\nSo fig, ax are equal to\\nplt.subplots.\\nNext we'll define the label locations\\nand the width of the bars.\\n\\nSo for that, we'll say x is equal to,\\nand then we'll call the arrange function.\\nSo that's np.arrange.\\nAnd we'll pass in length, so len.\\nAnd then we want the len to be heights.\\nSo we'll pass in our heights object,\\nand we'll set our width here equal to .40.\\n\\nWidth equal to 0.40.\\nNow let's draw the first set of the group of bars\\nfor the animal's heights.\\nTo do that, we will call the bar method\\noff of the ax object.\\nSo ax.bar.\\nAnd here, we'll first pass the position of the bars.\\nSo x minus 0.2.\\n\\nAnd then we'll pass the heights list next.\\nSo first let's just say x minus 0.2,\\nand the next parameter will say heights and width.\\nAnd then let's set the color of this bar\\nequal to red.\\nOkay, and then I'm going to copy and paste this code\\nto make a second group of bars\\nfor the animal's weights.\\n\\nSo let's change the position\\nto x plus 0.2 here.\\nAnd then we will replace the heights variable\\nwith the weights variable.\\nAnd then we can change the color here to orange.\\nNext, we'll set a legend for this chart.\\nSo to do that, we need to call the legend method\\noff of the ax object.\\nSo ax.legend.\\n\\nAnd then we'll pass in a list\\nwith the titles we want in the legend.\\nSo the first will be height,\\nand then the second will be weight.\\nThey should, of course, be in strings.\\nRephrase, and these labels should,\\nof course, be in strings.\\nNow we'll set the labels\\nand their positions on the x-axis.\\n\\nSo to do that we'll call the set_xticks method\\noff of the x object.\\nWe'll pass in our x variable.\\nAnd then let's also set some tick labels.\\nSo to do that we'll use the set\\nxtick labels method.\\nSo we'll say ax.set_xticklabels.\\n\\nAnd then we want our labels to be from our animals variable,\\nso we'll pass our animals variable.\\nAnd so here we'll pass the list of animal names.\\nAnd now let's call Streamlit's pyplot function\\nto display the Matplotlib chart in the Streamlit app.\\nSo to do that we'll say st.pyplot,\\nand we'll pass in our fig object.\\n\\nLet me just take a quick look at the syntax here.\\nDon't see any obvious problems,\\nso let's go ahead and then just run this.\\nSo what I'm going to do is in the terminal,\\nsay streamlit run.\\nWe need to copy the file path here,\\ncopy path, paste it in, hit Enter.\\nAnd then click the Open in browser button.\\n\\nOkay, amazing.\\nto plot out a Matplotlib function\\non an actual web browser.\\nNow let's look at how to do the same thing in a pie chart.\\nLet's go back over to our Python file.\\nAnd then what we're going to do\\nis we're going to create an advanced pie chart of some animals\\nand their heights and centimeters.\\nAnd we'll create the pie chart using Matplotlibs library,\\nand then display it using Streamlit again,\\nof course, like we did with the bar chart.\\n\\nIn the pie chart, the pie slices will be ordered\\nand plotted counterclockwise.\\nA wedge of a pie chart can be made to explode\\nfrom the rest of the wedges of the pie chart\\nusing the explode parameter of the pie function.\\nSo let's define that now.\\nWe'll say explode equal to, and then create a list,\\nand we'll say 0.2, 0.1,\\n0.1, 0.1.\\n\\nNow let's create the plot.\\nSo we'll say plot_pie, ax.\\nBoth of these objects are equal to\\nplt.subplots.\\nAnd then we'll call the pie method\\noff of the ax object,\\nso ax.pi.\\nAnd we'll pass in the height\\nof the animals, so heights.\\n\\nAnd then we'll set explode equal to\\nour explode object that we just created.\\nWe want our labels to be set equal to\\nthe list of names in our animals object.\\nSo we'll put labels equal to animals.\\nAnd next we'll pass in autopct as a parameter,\\nwhich enables you to display the percentage values\\nusing python string formatting.\\n\\nSo we'll say autopct\\nis equal to, and then we will write a string\\nthat says %1.1f%%.\\nSo %1.1f%%.\\nAnd that's it's string format.\\nThe next parameter is the shadow parameter.\\n\\nAnd so we're going to set shadow here equal to true.\\nIn the next line, we will call the axis method\\noff of the ax object.\\nSo we'll say ax.axis.\\nAnd then passing a string that reads equals.\\nIt should be equal, not equals.\\nSo I'll take that S out.\\nThe equal here acts as a keyword.\\nEqual aspect ratio ensures that pie is drawn as a circle.\\n\\nNext we'll call the pyplot function.\\nSo that's st.pyplot.\\nAnd we'll pass in our plot_pie object.\\nSo I'll go over to our browser and hit Refresh.\\nWow, that's amazing.\\nLook at that gorgeous pie chart.\\nIt looks so much better\\nthan what you can create in default,\\nin basic Matplotlib.\\n\\nAnd also another added advantage\\nis that this is showing now on a webpage\\nthat you can share with other users,\\ninstead of just having it stuck inside\\nof your Jupyter Notebook environment.\\nNow let's look at creating statistical charts in Streamlit.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2715035\",\"duration\":515,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Create statistical charts\",\"fileName\":\"3006708_en_US_08_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":740,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to create statistical charts in Streamlit. This video covers histograms, boxplots, and scatter plots.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":18753819,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] On this coding demo,\\nwe're going to create statistical charts using streamlit.\\nAnd so as usual, we need to do a pip install\\nof the libraries we need.\\nSo that'll be streamlit, seaborn, matplotlib,\\nand pandas, and sklearn in this case.\\nSo we'll start with a pip install of streamlit,\\nand then do a pip install seaborn,\\npip install matplotlib,\\npip install pandas,\\nand then we'll do pip install sklearn.\\n\\nOkay, so that should be pip install scikit-learn.\\nOkay there, now we have installed\\nall of the libraries we need for this demonstration.\\nSo let's import them in our Python file.\\nSo we'll say import streamlit as st,\\nimport seaborn as sns,\\nimport matplotlib.pyplot as plt,\\nimport pandas as pd.\\n\\nAnd then for the data for this demonstration,\\nwe're going to use the iris dataset.\\nSo we're going to import that from scikit-learn.\\nSo we'll say from sklearn.datasets\\nimport load_iris.\\nAfter that, let's load the iris data.\\nSo to do that, we'll create an object called iris_data\\nand we'll set it equal to load_iris function.\\n\\nNow we'll load iris dataset into a data frame.\\nWe'll call it data.\\nSo we'll say data =,\\nand then we will call the DataFrame constructor.\\nSo that's pd.DataFrame,\\nand we'll pass in our iris_data.data,\\nand then let's pass the column names.\\nSo we'll say columns = iris_data.feature_names.\\n\\nFirst, we'll create a histogram chart from the data frame\\nusing seaborn and streamlits pyplot function.\\nSo first let's just write fig = plt.figure,\\nand we'll also be using the histplot function from seaborn.\\nSo we'll say sns.histplot,\\nand we'll pass in our data frame.\\n\\nSo we'll say data=data,\\nand the number of bins\\nwe want to create in the histogram.\\nSo we'll say bins here=20.\\nNow let's show the histogram and the streamlit app.\\nTo do that, we would just call the pyplot function.\\nSo that's st.pyplot,\\nnow passing our fig object.\\nAnd just looking really quickly for any typos,\\nI see that I need to change this E to an O, load_iris.\\n\\nAnd aside from that, it looks pretty good.\\nSo the next thing I need to do\\nis just to say, streamlit run,\\ncopy the file path,\\npaste it in,\\nand hit Enter.\\nOkay, and then we'll open in browser.\\nSo our application is running.\\nLook how pretty that is.\\nSo with respect to colors,\\neach of the four features,\\nsepal length, sepal width, petal length, and petal width\\nare represented by a different color in the histogram.\\n\\nAnd this makes it easier to distinguish\\nbetween the distributions of each feature.\\nSo we have 150 data points\\nthat have been bend into 20 separate intervals.\\nAnd the value of this histogram\\nis that it provides a visual summary\\nof the numerical data in the dataset,\\nwhich allows us a quick understanding of the distribution\\nof measurements across the iris species.\\n\\nSo for example, these peaks here in the histogram\\nrepresent the most common measurement ranges\\nwhile the spread indicates variability within the data.\\nNext, let's create a boxplot on the iris dataset.\\nSo to do that,\\nwe'll say fig = plt.figure.\\nThen we'll call seaborn boxplot function.\\nSo that's sns.boxplot,\\nand we'll pass in our data.\\n\\nSo here we'll say data=data,\\nand then we will call streamlits pyplot function\\nto plot this out.\\nSo that's st.pyplot,\\nand we'll pass in our fig object.\\nAnd then go over to our browser and hit refresh.\\nOkay, so nice.\\nNow we have a nicely labeled boxplot.\\nAnd this is similar to the boxplot we explored\\nearlier in this course when we were discussing\\nhow to identify outliers in a dataset.\\n\\nSo you can see these points here past the whiskers\\nin the sepal width field.\\nThese points are highly suspect\\nfor being outliers in the dataset,\\nand you would want to examine and treat those data points\\nbefore moving into machine learning.\\nThe last plot we'll draw is a scatterplot.\\nSo we'll just create another fig object,\\nfig = plt.figure.\\n\\nAnd then we're going to use seaborn's scatterplot function.\\nSo that's sns.scatterplot,\\nwe'll say data=data,\\nand then plot this out using streamlits.\\nSo that's st.pyplot,\\nand passing our fig object.\\nAnd then I'm going to go back over to the browser\\nand hit refresh.\\n\\nAnd now we have a scatterplot\\nof all of the 150 data points\\nthat are contained within the iris dataset.\\nThey are color coded according to feature,\\nso this makes it easier for us\\nto get at glance view of the distribution of each feature\\nand basically what the values of the features are\\nwithout having to dig too much into the actual data itself.\\n\\nAnd that's it for Streamlit.\\n\"}],\"name\":\"8. Collaborative Analytics with Streamlit\",\"size\":90480614,\"urn\":\"urn:li:learningContentChapter:4583166\"},{\"duration\":70,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4588031\",\"duration\":70,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Next steps\",\"fileName\":\"3006708_en_US_09_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":93,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1694005,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In terms of next steps,\\nI definitely encourage you to go over to the Python\\nfor Data Science Essential Training,\\nIntroduction to Machine Learning Course.\\nThat course was built specifically\\nas the perfect follow up for this one.\\nAlso, I want to encourage you to go ahead\\nand start practicing your new data skills\\nby working to create efficiencies in your daily workflows\\nwith your employer or in your business.\\nLastly, I want to invite you to join our community,\\nThe Convergence.\\n\\nThe Convergence is an online community space\\nthat's dedicated to empowering operators\\nin the data industry by providing news and education\\nabout evergreen strategies, late-breaking data\\nand AI development, and free or low cost upscaling resources\\nthat you need to thrive as a data leader,\\nthat you need to thrive as a leader\\nin the data and AI space.\\nTo join us in The Convergence, simply visit this page,\\ndata-mania.com/newsletter, and drop your details\\nso that we can send you a kickoff email\\nthat's loaded to the brim with free goodies\\nto get you ahead in your data career.\\n\\n\"}],\"name\":\"Conclusion\",\"size\":1694005,\"urn\":\"urn:li:learningContentChapter:4589022\"}],\"size\":942069028,\"duration\":27863,\"zeroBased\":false},{\"course_title\":\"Python Data Analysis\",\"course_admin_id\":2825705,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2825705,\"Project ID\":null,\"Course Name\":\"Python Data Analysis\",\"Course Name EN\":\"Python Data Analysis\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Data science is transforming the way that government and industry leaders look at both specific problems and the world at large. Curious about how data analysis actually works in practice? In this course, instructor Michele Vallisneri shows you how, explaining what it takes to get started with data science using Python.&lt;br/&gt;&lt;br/&gt;Michele demonstrates how to set up your analysis environment and provides a refresher on the basics of working with data structures in Python. Then, he jumps into the big stuff: the power of arrays, indexing, and tables in NumPy and pandas\u00e2\u20ac\u201dtwo popular third-party packages designed specifically for data analysis. He also walks through two sample big-data projects: using NumPy to identify and visualize weather patterns and using pandas to analyze the popularity of baby names over the last century. Challenges issued along the way help you practice what you've learned.&lt;br/&gt;&lt;br/&gt;Note: This version of the course was updated to reflect recent changes in Python 3, NumPy, and pandas.\",\"Course Short Description\":\"Interested in using Python for data analysis? Learn how to use Python, NumPy, and pandas together to analyze data sets large and small.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":4666188,\"Instructor Name\":\"Michele Vallisneri\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Theoretical Astrophysicist at NASA Jet Propulsion Laboratory\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2020-03-11T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"Yes\",\"LIL URL\":\"https://www.linkedin.com/learning/python-data-analysis-2,https://www.linkedin.com/learning/python-data-analysis-2020-revision\",\"Series\":\"Deep Dive (X:Y)\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Data Science\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"Yes\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":9035.0,\"Visible Video Count\":41.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":185,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2293496\",\"duration\":120,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Get started in data analysis with Python\",\"fileName\":\"2825705_00_01_WL30_Welcome\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Using Python, you can analyze data rapidly, using powerful tools adopted by a large and helpful community.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":23028870,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Data science, it powers so much of modern life,  \\n the internet, social media, artificial intelligence.  \\n But also on a personal level, the statistics  \\n from your Fitbit or the next song recommended by Pandora.  \\n And, truly, data science is driving a personal  \\n and social evolution.  \\n We're constantly learning and getting better  \\n and accomplishing monumental goals.  \\n However, do you feel like you're missing the boat?  \\n Maybe you're watching all these advances,  \\n but you don't really know how to get in the game.  \\n And you wonder, \\\"What goes on under the hood?  \\n \\\"How does someone one do data science?\\\"  \\n You don't know where to start.  \\n Do not worry, this is where I can help.  \\n My name is Michele Vallisneri,  \\n and I'm a research scientist at NASA.  \\n I use data science concepts and tools every day  \\n to analyze astronomy datasets,  \\n and my tool of choice is Python.  \\n It's an expressive and pragmatic computer language  \\n that has its own spirit and style.  \\n And it's supported by a diverse and helpful user community.  \\n My goal with this course is to get you started  \\n with data science, and more specifically, data analysis  \\n with Python, in a friendly and approachable way.  \\n It's not all encompassing.  \\n I don't recommend applying for a PhD program  \\n right after this course, but it will get you started,  \\n and I really hope inspired.  \\n That's what matters, and that's what you need,  \\n a jumping off point.  \\n I will take you through the foundations  \\n of doing data analysis with Python.  \\n We will look at the most important programming constructs,  \\n data structures, and third party packages.  \\n With this, you will be able to complete  \\n simple data analysis tasks, and you will be ready  \\n to move on to more advanced topics.  \\n I like to teach by example rather than in the abstract,  \\n so throughout this course, we will write  \\n and execute practical code and analyze real-world data.  \\n So let's enter the friendly but exciting world  \\n of Python data analysis.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295355\",\"duration\":38,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you need to know\",\"fileName\":\"2825705_00_02_LA30_What\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"To learn the most from this course you need an elementary knowledge of the Python language, which you can obtain from other LinkedIn Learning courses. However, in this video, you can review Python's data structures, which are crucial to data analysis.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8474848,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Before getting started with this course,  \\n you want to have a basic working knowledge  \\n of programming in Python.  \\n Although we will review the aspects of the language  \\n that are essential to any data analysis task,  \\n I will not teach you about every feature of Python  \\n that we will meet.  \\n It will also be helpful to have an understanding  \\n of basic mathematical and statistical concepts,  \\n for example logical operations, functions,  \\n averages, minima and maxima.  \\n If you are familiar with these topics I recommend you start  \\n with beginner level Python and statistics courses  \\n in the library or with a textbook  \\n that suits your learning style.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294373\",\"duration\":27,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What's new in this update\",\"fileName\":\"2825705_00_03_LA30_New\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Like the original version, this course covers the foundations of data analysis with Python\u2014data structures, NumPy, pandas, matplotlib\u2014using practical real-world examples. The course is updated to reflect recent changes in the interfaces of those modules, to explore new features in recent versions of Python 3, to emphasize insightful visualization, and to introduce pandas with a modern pedagogical approach.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6090412,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - This is a new version of this course  \\n in which I have incorporated user feedback  \\n from many learners like you.  \\n Like the original version  \\n this course covers the foundations  \\n of data analysis with Python,  \\n data structures and the num pi, pandas,  \\n and map log packages  \\n using practical, real world examples.  \\n I have also updated the course  \\n to reflect changes in those modules  \\n and new useful features in recent versions of Python 3.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":37594130,\"urn\":\"urn:li:learningContentChapter:2294386\"},{\"duration\":840,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2295356\",\"duration\":155,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Install Anaconda Python on OS X\",\"fileName\":\"2825705_01_01_XR30_installosx\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Anaconda is a popular Python distribution that includes many useful packages. In this video, learn how to download and install Anaconda on your Mac.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5237373,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] For this course,  \\n we need an up to date installation of Python 3,  \\n and a few third party packages including Jupyter, NumPy,  \\n Pandas, and Matplotlib.  \\n In this video I show you how to install everything you need  \\n on MacOS 10.  \\n If you are a Windows user,  \\n feel free to jump to the next video.  \\n Later I will also show you how to use Python in the cloud  \\n using only your web browser.  \\n If you already use Python on your machine  \\n and you know how to install extra packages, please do so.  \\n Otherwise I suggest you follow me  \\n and install the free Anaconda Python Distribution,  \\n which includes everything that we will need.  \\n To install we go to anaconda.com.  \\n We find the download link at the top.  \\n Scroll down to our platform  \\n and select the Anaconda graphical installer  \\n which is currently at version 3.7.  \\n Any later version will also work fine.  \\n As of January 2020, Python 2 is no longer supported,  \\n so you should definitely be using version three  \\n which is mature, efficient,  \\n and introduces many exciting new features  \\n compared to version two.  \\n Once the download has completed,  \\n we click on the installer  \\n and proceed through a standard installation  \\n which will require several clicks.  \\n We are asked also  \\n whether we wish to install the PyCharm IDE,  \\n which is very complete and powerful.  \\n We will not be using it for this course,  \\n but you can give it a try.  \\n We can trash the installer,  \\n and we can now try out our new python installation,  \\n by opening up a terminal and typing Python.  \\n This gets us into the standard Python shell  \\n where we can write an execute code interactively.  \\n The prompt informs us  \\n that this is indeed the Anaconda version of Python 3.7.  \\n It's traditional to just say hello.  \\n We can also verify that all the packages we need  \\n are already installed by attempting to import them.  \\n NumPy, Pandas, and Matplotlib.  \\n No news is good news.  \\n All done.  \\n We are now ready to start experimenting with Python.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295357\",\"duration\":172,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Install Anaconda Python on Windows\",\"fileName\":\"2825705_01_02_XR30_installwindows\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Anaconda is a popular Python distribution that includes many useful packages. In this video, learn how to download and install Anaconda on your Windows PC.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4789286,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] For this course,  \\n we need an up to date installation of python three.  \\n And a few third party packages.  \\n Including jupyter notebook, numpy, pandas,  \\n and matplotlib.  \\n In this video, I show you how to install everything  \\n you need on Windows.  \\n However, you can also experiment with Python in the cloud  \\n from your web browser.  \\n I explain how to do so at the end of this chapter.  \\n If you are already using Python on your machine  \\n and you know how to install extra packages,  \\n you are free to do so.  \\n Otherwise, I suggest you follow me  \\n and install the free Anaconda Python distribution.  \\n Which includes everything that we need.  \\n To install, we go to the anaconda.com website,  \\n we find a download link on the top.  \\n Verify that we have the right platform.  \\n And then download the 64 bit graphical installer.  \\n This is currently at version 3.7,  \\n but any later version will also work fine.  \\n Once the download has completed,  \\n we click on installer and proceed through an installation.  \\n This requires a few clicks.  \\n (mouse clicks)  \\n As of January 2020, Python two is no longer supported.  \\n So you should definitely be using version three.  \\n Which is mature, efficient, and introduces  \\n many exciting new features compared to version two.  \\n The final phase of the installation takes a few minutes.  \\n It looks like the setup is finished,  \\n and we now can get started with Python.  \\n We can now try out our new Python  \\n by opening up the Anaconda prompt,  \\n and typing python.  \\n This gets us into the standard python shell,  \\n where we can write and execute code interactively.  \\n The prompt, informs us that this is indeed  \\n the Anaconda version of Python 3.7  \\n It's traditional to say hello.  \\n We can also verify that all the packages that we need  \\n are already installed by attempt to import them.  \\n Numpy, pandas, and matplotlib.  \\n No news is good news.  \\n All done.  \\n We are now ready to start experimenting with python.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295358\",\"duration\":251,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with Jupyter Notebooks\",\"fileName\":\"2825705_01_03_XR30_jupyter\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Jupyter Notebooks is a very powerful environment for exploratory data analysis. In this video, learn how to open, create, edit, and run Jupyter Notebooks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6607421,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Jupyter notebooks,  \\n offer a very convenient way to write code,  \\n run it, and collect the results including plots,  \\n in a single document.  \\n You can even write formatted text and equations.  \\n This is my favorite way of using Python,  \\n because it lets me experiment with data and code,  \\n document my work, and go back to it later.  \\n You start Jupiter notebook from the Anaconda navigator,  \\n by clicking on launch.  \\n If you don't have an Anaconda,  \\n you can go to a terminal, and type Jupyter notebook.  \\n A web browser opens, and I can choose  \\n if I wish to load an existing notebook from the file system,  \\n or to start a new one,  \\n which I do at the top right of the screen.  \\n New, Python three notebook.  \\n Here's the notebook. See the green box at the top?.  \\n It's a cell. It's ready for me to write some Python,  \\n for instance,  \\n (keyboard typing)  \\n The customary equating.  \\n I execute the code, by pressing Shift + Enter,  \\n or Shift + return depending on your keyboard.  \\n The output is printed immediately below it.  \\n I can click inside the cell,  \\n modify it,  \\n and execute it again, with shift enter.  \\n If a cell has a blue border,  \\n I need to press ENTER before I can edit it.  \\n Or I can click inside a different cell, to edit that one.  \\n In addition to a simple command,  \\n I can write a function over multiple lines.  \\n The editor, will color the Python source keywords,  \\n appropriately.  \\n Again, I execute with Shift + Enter  \\n cells, can also contain text rather than code.  \\n For that, I can use the drop down menu cell,  \\n to change the cell type to markdown.  \\n Then I click in the cell and start writing.  \\n Markdown is a simple but powerful text format  \\n that can do basic formatting, bold, italic,  \\n bullet points, hyperlinks, and even mathematical formulas.  \\n For instance, bold, (keyboard typing), with two asterisks.  \\n (keyboard typing)  \\n URLs, which are recognized,  \\n (keyboard typing)  \\n a bullet point,  \\n and a formula in the LaTeX language, between dollar signs.  \\n When I execute the cell, with shift Enter,  \\n everything is formatted in prettified.  \\n To copy a cell, I can click inside it,  \\n or use the arrow keys to select it, and then press  \\n escape C, to copy and then escape V, to paste.  \\n To cut a cell, I can do escape X  \\n To delete a cell ctrl M, and then D, and again D,  \\n Jupyter wants to be sure  \\n you really want to delete that cell.  \\n Or you can use the menus, of course,  \\n I gave you only the most useful keyboard shortcuts,  \\n but there are many more, look under the Help menu.  \\n The notebook is saved periodically for us,  \\n but I can also do that at any time with command S,  \\n ah, and I can give this notebook a name,  \\n such as learning Jupyter,  \\n by clicking at the top of the window.  \\n Go find the Jupyter notebook documentation,  \\n at Jupiter.org.  \\n You will also learn about Jupyter lab,  \\n and even more powerful,  \\n and complete interface than notebooks.  \\n For this course however, we will stay with Jupyter notebook.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295359\",\"duration\":92,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using the exercise files\",\"fileName\":\"2825705_01_04_XR30_exercisefiles\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2371318,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] For most of the videos in this course,  \\n we will be working through one of the Jupyter Notebooks  \\n that I prepare for you.  \\n For each notebook, we will go through the path  \\n and code that it contains.  \\n We will discuss what the code does  \\n and why I wrote it that way.  \\n We will execute it and examine the resulting output.  \\n At any time, you're welcome to pause the video,  \\n inspect the code, make changes  \\n and run your own experiments.  \\n All the notebooks are collected in your exercise files,  \\n organized by course chapter.  \\n They are the files with .ipynb file ending.  \\n You will also see some of the data files  \\n that we will be analyzing.  \\n In Chapter Five, I have included a subfolder  \\n named Downloaded.  \\n These are files that we will download  \\n from the web using Python,  \\n but I am including them here  \\n in case something goes wrong with the download.  \\n We open a notebook by finding it  \\n within the Jupyter Notebook file browser  \\n and clicking on it.  \\n The notebook cell that we're discussing and running  \\n will always be the one enclosed by a blue or green box.  \\n Once we're done with the notebook,  \\n you can close the browser tab  \\n and shut down the notebook in the Jupyter file browser  \\n by clicking on the box and then clicking Shutdown.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293497\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using Python in the cloud\",\"fileName\":\"2825705_01_05_XR30_cloudpython\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"You do not need to install Python on your computer to use it for data analysis. In this video, learn how to use the Microsoft notebook server to run Python code in the cloud.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5073696,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] An exciting, recent development  \\n in the Python ecosystem is that it has become possible  \\n to run notebooks in the cloud using services  \\n such as Google Colaboratory and Microsoft Azure Notebooks.  \\n With both, you get a rather functional environment for free.  \\n If you'd like to follow along with this course  \\n using Python in the cloud,  \\n I suggest you use Azure Notebooks.  \\n Let me show you how to.  \\n We start at notebooks.azure.com.  \\n We sign in, which you can do using  \\n an existing Microsoft account or creating one.  \\n You may also be asked to create a user name  \\n for your profile.  \\n In Azure Notebooks, notebooks are organized in projects,  \\n so we create a new one.  \\n I will call it Python data analysis.  \\n The easiest way to get the exercise files  \\n into Microsoft Azure is to upload the zip file  \\n that contains all of them.  \\n The Upload button is here on the top right.  \\n So I go find a file and upload it.  \\n To unzip the archive, I open the Azure terminal.  \\n I type cd library to move into the project directory  \\n and then unzip exercise\\\\ files.zip.  \\n This will take a moment.  \\n Once it's done, we can type exit,  \\n and close this tab.  \\n If I refresh the window,  \\n I see that the exercise files have appeared.  \\n We are now ready for our course.  \\n For instance, I can look inside the exercise files  \\n for chapter two and select the first notebook.  \\n Azure Notebooks can be somewhat slow when loading  \\n and writing files, but don't worry.  \\n You'll get there.  \\n Also, as we speak, the default Python on Azure is 3.5,  \\n which is too old for this course.  \\n Hopefully that will change soon.  \\n In the meantime, please remember to switch the kernel  \\n to Python 3.6 after you open each notebook.  \\n You do that from the Kernel menu, go into Change kernel,  \\n and select Python 3.6  \\n There are many options out there to use Python in the cloud.  \\n Please feel free to use the one that works out best for you.  \\n \\n\\n\"}],\"name\":\"1. Installation and Setup\",\"size\":24079094,\"urn\":\"urn:li:learningContentChapter:2294387\"},{\"duration\":1819,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2295360\",\"duration\":425,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Warmup with Python loops\",\"fileName\":\"2825705_02_01_XR30_loops\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are many use cases in data analysis where you need to operate on data in a sequential fashion. In Python, you do so with looping constructs. In this video, learn how to refresh the Python loop syntax by solving a simple problem\u2014finding all the ways in which you can break a dollar into a set of coins.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11735820,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We will begin every video  \\n by importing a standard set of Python modules that we need.  \\n This is a typical list.  \\n It's expedient to load often used modules  \\n by giving them a shorter alias.  \\n NP is the community standard for NumPy, PD for pandas.  \\n We also load this simple commander entity interface  \\n to matplotlib, pyplots,  \\n and finally, we ask the Jupyter notebook  \\n to keep the plots that we make in the notebook itself  \\n instead of opening a different window.  \\n So I shall now execute this cell  \\n by pressing Shift + Return.  \\n If you've worked in programming before,  \\n you must be familiar with loops.  \\n They allow us to automate repetitive operations.  \\n And loops are a good topic  \\n to start a quick review of the Python core language,  \\n which will focus on the features that are most important  \\n to work with data.  \\n So, how exactly do loops work in Python?  \\n We see them in a concrete example.  \\n Consider the combinatorial problem of breaking a U.S. dollar  \\n into all possible combinations of coins.  \\n For instance, $1 coin,  \\n two half-dollar coins,  \\n one half-dollar coins and two quarters, and so on.  \\n You can already see how we're going to need  \\n several nested loops for this.  \\n The basic structure of a loop in Python  \\n is for variable in iterable  \\n followed by a block that is executing multiple times  \\n with the variable that can own the values provided  \\n by the iterable.  \\n But what is an iterable?  \\n We can think of it as a black box  \\n that keeps providing new values until it runs out.  \\n A simple example is a Python container  \\n such as a list or a dict.  \\n Perhaps the most important iterable is range,  \\n which provides integer value from a start to a stop,  \\n exclusive of the stop.  \\n That means that range zero 10 counts from zero to nine.  \\n There are many reasons for this convention  \\n about the end value.  \\n For instance, by looking at the end value,  \\n we see immediately that the total number of elements  \\n in the range is 10.  \\n In the end, however, we just have to accept this  \\n as one of the building assumptions of Python.  \\n Range has a couple more interesting features.  \\n We can omit the stat value,  \\n and then it's assumed to be zero.  \\n We can provide a step argument to move through the range  \\n in increments larger than one.  \\n And if I give the step,  \\n I must also give the initial value to avoid confusion.  \\n Notice that the step is the third argument  \\n that I give in line four.  \\n Let's go back to the dollar.  \\n To generate all possible ways to break it up,  \\n we will use a very simple minder strategy.  \\n We will consider all possible candidate combinations,  \\n including the zero to one $1 coins,  \\n zero to two half-dollar coins,  \\n zero to four quarters, and so on.  \\n And at the end for each,  \\n we will check whether it adds up to a dollar.  \\n Therefore we need six nested loops.  \\n A loop within a loop within a loop.  \\n Luckily, it's Python that will keep track of them.  \\n This means that the first loop will be over range two.  \\n So, looping over zero and one.  \\n To keep the maximum number of each coin inside,  \\n we'll write it as range(1+1).  \\n We then proceed with the other coins, one loop for each.  \\n Each nested loop is indented with respect to its parent.  \\n Inside the innermost loop,  \\n we will check whether the total amount is $1.  \\n If so, we will add this combination to a list  \\n called combinations, which will start that.  \\n Let's try this out.  \\n And let's look at the results.  \\n The first few combinations seem to check out fine.  \\n It turns out there are 293 ways to get a dollar in change.  \\n That's a solution to the problem we posed.  \\n However, in data analysis,  \\n it often happens that the solution raises a new question.  \\n For instance, how many ways  \\n to make $2 out of change or three?  \\n Does the number of combinations increase linearly  \\n or quadratically with the amount we're breaking up?  \\n What we need to do, then, is to take the code we wrote  \\n and generalize it to answer those questions.  \\n Creating a function,  \\n we'll call it, say, find combinations,  \\n that will take a dollar amount in cents  \\n and return all possible ways to do it.  \\n Before we do so,  \\n we make a couple of changes to our code  \\n to make it faster and to make it easier to generalize.  \\n This is an example of refactoring.  \\n The first change is that we will not loop by count,  \\n but by value, using the step argument of the range.  \\n For instance, instead of looping over quarters  \\n with count 25 between zero and four,  \\n we will loop over the amount  \\n from zero to 100 in steps of 25.  \\n So, I have rewritten all the loops in these terms.  \\n As you see, the end of the range is always a dollar,  \\n 100 cents plus one.  \\n So the dollar is included.  \\n And the step is 100 for $1, 50 for half dollar,  \\n 25 for the quarter, and so on.  \\n The second change we're making  \\n is that we don't actually need  \\n the innermost loop over the pennies.  \\n As long as the total up to that point  \\n is less or equal than a dollar,  \\n we can always make up the difference.  \\n Therefore, we compute the dollar  \\n and write a different test.  \\n The result is again the same.  \\n Now we can take our code  \\n and turn it into the function find combinations  \\n by replacing the value 100 with a variable argument.  \\n We'll call it total.  \\n We do need to indent our code  \\n to make up the body of the function.  \\n So, here we go, $2.  \\n Or $3.  \\n You may be curious to know how fast this number grows.  \\n A plot will give us an idea.  \\n So let's plot 100 through 500,  \\n and we use a comprehension, which we will explain later,  \\n to find a corresponding number of combinations.  \\n Matplotlib will give us a quick plot.  \\n In fact, the number grows approximately  \\n as the fifth power of the total.  \\n You will find the loops are everywhere in data analysis,  \\n so it's good to get familiar with them.  \\n In Python, you can do a lot with the for construct  \\n and with range.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294374\",\"duration\":319,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Sequences: Lists, tuples, and the slicing syntax\",\"fileName\":\"2825705_02_02_XR30_sequences\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The built-in sequence types\u2014tuples, lists, ranges, strings, and buffers\u2014in which data elements are associated with indices, set the basic framework for accessing sequential data in Python. In this video, refresh the creation and indexing of sequences, review the important distinction between mutable and immutable types, and highlight the slicing interface.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8870275,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this movie, we are going to review lists.  \\n They are the quintessential Python container.  \\n They provide a way to store an arbitrary number  \\n of Python objects such as strings, floating-point numbers,  \\n other lists, or any other object  \\n and to access them using a numerical index.  \\n In Python lists are denoted by brackets and their elements  \\n are separated by commas.  \\n The length of a list is obtained with len.  \\n Indexing, individual list elements can be accessed by index.  \\n Starting with zero for the first element  \\n and ending at the length of the list minus one.  \\n This convention of starting from zero comes from C,  \\n the language that inspired Python  \\n and that was used to write the standard Python interpreter  \\n known as CPython.  \\n For instance, the first nephew is Huey.  \\n We can also look for the last nephew  \\n and we can even look for a nephew beyond the end of the list  \\n which in this case will yield an error.  \\n We can also index from the end.  \\n Starting at minus one and going down.  \\n That gets us Louie and Dewey.  \\n The bracket indexing notation,  \\n can also be used to reassign elements.  \\n Let's do that for all the nephews with a simple loop.  \\n Here we're just adding their last name.  \\n It's important to remember that lists do not need  \\n to have homogeneous content such as all strings  \\n or all numbers.  \\n We can mix it up.  \\n To add a single element at the end of the list,  \\n we use append.  \\n You see that here we are using Python  \\n in an object-oriented way.  \\n By accessing the method, specifically append,  \\n of the list object.  \\n It's so easy that we barely notice it.  \\n To add multiple elements in one go, we can use extend.  \\n To concatenate two lists, we use a plus.  \\n That's an example of operator overloading in Python  \\n where plus does different things for numbers and for lists.  \\n Last, we can insert elements at any position in a list  \\n using the insert method.  \\n How about removing elements?  \\n We can delete them based on their index with del  \\n or based on the value with remove.  \\n If we want a list sorted we can do this in place.  \\n So we modify an existing list with sort.  \\n Or we can make a new sorted list out of an existing one  \\n with sorted.  \\n Which demonstrates also how to sort backwards.  \\n All of this should be very basic to you  \\n if you work with Python in the past.  \\n Moving on to slices.  \\n Beyond working with individual list elements,  \\n we can manipulate them in groups.  \\n The convention is the same as for Python loops.  \\n The first index is included, the last is not.  \\n It's useful sometimes, to think of the indices  \\n as being placed at the edges of the cells in a list.  \\n We make an example based on the first few squares  \\n of the natural numbers.  \\n If we want the first two squares,  \\n we'd write a slice that goes from zero to two.  \\n There are a few more tricks that we can use in slicing.  \\n For instance we can omit the starting index  \\n to start at the beginning,  \\n omit the ending index to include elements to the end.  \\n Omit both, to get a copy of the list.  \\n Move through the indices in steps.  \\n And even use negative indices to count from the end.  \\n Slices can also be used to reassign a subset of items  \\n or to delete them.  \\n When we introduce NumPy arrays in chapter four,  \\n we will see that this basic slicing syntax carries over.  \\n So it's good to understand it fully on lists first.  \\n The empty list is written with an empty set of brackets  \\n and obviously it has length zero.  \\n Now for tuples, which look like lists  \\n but with parentheses instead of brackets.  \\n They are sometimes described as immutable versions of lists.  \\n We can do the same indexing and slicing tricks,  \\n but we cannot modify the elements or add new ones.  \\n One context in which one sees tuples often  \\n is tuple unpacking, where Python statements  \\n or expressions are automatically evaluated in parallel  \\n over a tuple.  \\n For instance, to assign multiple variables at once.  \\n The parentheses can even be omitted when there is no  \\n room for ambiguity.  \\n Tuples appear also when we iterate  \\n over multiple variables at once.  \\n For example using the enumerate iterator on a list.  \\n Which lets us loop over list index  \\n and list element together.  \\n We can also unpack a tuple to pass it to a function  \\n that requires multiple arguments such as three args.  \\n It takes a tuple if we prefix it with an asterisk.  \\n This ends our review of lists.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2296097\",\"duration\":317,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Dictionaries and sets\",\"fileName\":\"2825705_02_03_XR30_dicts\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Python dicts associate unique keys with values, while sets express collections of data items without duplication. These data types complement sequences in many common data-analysis tasks. In this video, review the creation, updating, and indexing of Python dicts and sets, and explore the changes to dict in Python 3.6 and later.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8565831,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] While lists give us a way  \\n to retrieve values by their index.  \\n Python dictionary or dicts  \\n associate keys with values.  \\n After my imports,  \\n let me write a simple dictionary.  \\n Dicts are written with curly braces,  \\n separating items with commas  \\n and prefixing them by their key in a column.  \\n For instance, the capitals of a few countries.  \\n Just as we do with lists,  \\n values are accessed with a bracket notation.  \\n But instead of a number, we're going to use a key.  \\n For instance,  \\n we may wish to look at the capital of Italy.  \\n The same notation can be used to add items to a dictionary.  \\n Accessing a nonexistent item results in a key error.  \\n We can also check  \\n whether an item exists or not  \\n with the in operator.  \\n So we have Italy, but not Germany.  \\n Combining two dictionaries requires  \\n a little more thought than combining two lists.  \\n Unlike lists, we cannot just use the plus to add them.  \\n That's because we need to specify what happens  \\n if both dictionaries define the same key.  \\n What we then do is to update a dict using another,  \\n which will replace existing items as appropriate.  \\n This happens in place and modifies the dict.  \\n Similarly to lists, we can delete items by key.  \\n In fact, keys do not need to be strings.  \\n Any Python object that is hashable may be used as a name.  \\n Hashable means that Python can convert it to a number.  \\n That's true for many types of objects.  \\n For instance, tuples  \\n which may be used to encode a birthday.  \\n We can see the internal representation  \\n of the keys with hash.  \\n Just very large numbers.  \\n The empty dictionary is written with an empty set of braces  \\n and has length zero.  \\n Looping over a dictionary  \\n is very similar to looping over a list.  \\n However, there are three different kind of loops  \\n you may want to write.  \\n The most straightforward syntax loops over the keys,  \\n for key in dictionary.  \\n Here, I'm using bold to denote language keywords.  \\n Whereas Roman words are the names of the variables  \\n that you will be using.  \\n You can loop also explicitly over the keys,  \\n you can loop over the values,  \\n and you can loop over the keys and values together.  \\n Let's see an example of each of these  \\n For country in capitals,  \\n we loop over keys.  \\n So will for country in capitals keys.  \\n Note that capitals dot keys is not a list,  \\n but a special iterator object.  \\n We can make it into a list though  \\n by feeding it to the list constructor list.  \\n The other two dict loops are over values, dot values,  \\n and over keys and values together using tuple unpacking.  \\n Beginning in Python 3.6 for the C Python interpreter,  \\n and in python 3.7, for the very language definition,  \\n the order of insertion is preserved for dicts.  \\n This means then when we loop over the keys or the items,  \\n we get them in the order  \\n in which we originally added them to the dict.  \\n That was not the case in previous versions of Python  \\n and in fact, the standard library defined a special object  \\n called order dict to preserve that order.  \\n That is not necessary now.  \\n Last, I want to mention sets.  \\n You can think of them as bags of item,  \\n which can be of mixed types  \\n and which do not have duplications.  \\n For instance, the continents.  \\n Sets are written with braces, but without columns.  \\n You can see that Africa only appears once,  \\n even if we had it twice when we define the set.  \\n We can check if an item exists in a set.  \\n We can add items  \\n or remove them  \\n or loop over the set.  \\n but there's no way to do indexing.  \\n Sets and especially dicts are very important in Python,  \\n since they underlie many aspects of the language itself.  \\n For instance, the methods and attributes of classes  \\n are stored internally in dicts,  \\n and a dict key based interface is also used  \\n in many third party packages, including pandas.  \\n So it's very good to become familiar with them.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295361\",\"duration\":284,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Comprehensions\",\"fileName\":\"2825705_02_04_XR30_comprehensions\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Python comprehensions provide a legible and expedient way to create, transform, and filter sequences, dicts, and sets; you use these extensively in chapter 3. In Python 3, comprehensions largely replace functional calls such as map and filter. In this video, review the comprehension syntax, including multilevel comprehensions, and draw analogies to Python loops.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7527162,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In Python, especially when  \\n you're dealing with data, there are many cases  \\n where you want to iterate over a list  \\n or a dict performing operation on every element  \\n and then collect all the results in a new list, or dict.  \\n You can certainly do that with a loop.  \\n For instance, picking up the example  \\n from the last video,  \\n let's compute the first 10 squares,  \\n starting with an empty list and adding  \\n elements in the body of the loop with append.  \\n This works, but we can do better.  \\n We can be more pythonic, that is,  \\n we can respect Python's specific style and spirit.  \\n Python offers a great feature, comprehensions,  \\n that let us write shorter,  \\n more easily readable code,  \\n that achieves the same effect as the loop.  \\n In fact, the comprehension  \\n is a compressed version of the loop.  \\n Let's go through the steps to write one.  \\n It's a list we want, so we have brackets.  \\n Next, we have the loop.  \\n And then we backtrack to the beginning of the expression  \\n and we write code for the computation  \\n that we want to collect.  \\n In this case, taking the square.  \\n The result is the same,  \\n but we managed to write it  \\n in a very readable and efficient way.  \\n We can also filter the list of elements that we are creating  \\n by adding an if clause.  \\n For instance, we may want to collect only the squares  \\n that are divisible by four,  \\n which in fact, I need to do with the modulus operator.  \\n Again, quick and readable.  \\n In Python three, comprehension largely replace  \\n the map and filter built-in functions,  \\n which are important and so called functional languages,  \\n but did not really belong in Python.  \\n The syntax for dictionary comprehensions  \\n is also rather intuitive.  \\n For instance, let's create a dictionary  \\n that will get us the square  \\n of an integer from the integer itself.  \\n It's a dictionary, so we need braces.  \\n The loop part is the same  \\n for variable and iterable.  \\n But now, instead of the list items,  \\n we need to write key colon value pairs.  \\n We can also add an if clause if we want.  \\n I don't need one here.  \\n Here is the result in dict.  \\n Dict comprehensions are sometimes used  \\n to transpose an existing dict.  \\n Going back to our capitals,  \\n which we wrote as a dictionary index by country,  \\n we can get the countries index by capital.  \\n In the comprehension, we loop over the dict items,  \\n so we get tuples of country and capital,  \\n and we invert them by writing capital colon country.  \\n Sometimes, you see what look like naked  \\n comprehensions without the brackets.  \\n Those are in fact generator expressions,  \\n which are useful when you want to generate a sequence  \\n and consume the elements one by one  \\n without ever storing them in a list or a dict.  \\n For instance, to take the sum of the first 10 squares,  \\n we may write the interior part of our comprehension  \\n without the brackets and feed it directly to sum.  \\n Doing this, saves memory and time  \\n which is important if you deal with large amounts of data.  \\n In fact, the built-in range which we used earlier  \\n to demonstrate loops does something very similar.  \\n It never builds a list, but it keeps  \\n adding new values to the loop.  \\n If you don't currently use comprehension,  \\n I'm sure that if you try them  \\n you'll become addicted quickly.  \\n And you'll start doing all sorts  \\n of acrobatics, such as nested looping comprehensions.  \\n For instance, look at this nested loop,  \\n which creates a list of one,  \\n one two, one two three,  \\n one two three four, and so on.  \\n We can do the same with a nested comprehension  \\n just by writing the two loops  \\n in the same order in sequence.  \\n Comprehensions are incredibly useful  \\n to manipulate lists, dicts, and data.  \\n You should be familiar with both,  \\n understanding and writing them.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293498\",\"duration\":474,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Advanced Python containers\",\"fileName\":\"2825705_02_05_XR30_advanced\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The Python standard library offers powerful extensions of the built-in container types, which can help you write shorter and cleaner code. In this video, explore namedtuple, defaultdict, and the powerful data classes introduced in Python 3.7.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12995764,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] As I mentioned in the video about sequences,  \\n tuples are similar to lists,  \\n but we cannot change the arguments after creating the tuple.  \\n The formal way of saying that is that tuples are immutable.  \\n Tuples are very useful to store data records  \\n when we think that we are not going to modify the values.  \\n For instance, a list of people with their first names,  \\n last names, and birthdays.  \\n For each element in this list, for each person,  \\n we access the data fields by index.  \\n Zero for the name, one for the family name.  \\n This lets us write useful list comprehensions.  \\n For instance, to find all the people  \\n with a given birthday.  \\n We loop over every person in People,  \\n and for each we check if the third element  \\n of the tuple, index two, is July 15.  \\n I share a birthday with a very famous astronomer,  \\n Jocelyn Bell Burnell.  \\n Field access by index means that  \\n we have to remember which is which,  \\n creating the potential for bugs,  \\n and certainly reducing the expressiveness of our code.  \\n To help us out, the module Collections  \\n in the standard Python library offers  \\n a name tuple that lets you create a specialized object,  \\n a specialized tuple, that has a name and that  \\n associates labels with fields.  \\n For instance, a person type would be called Person  \\n and have fields first name, last name, and birthday.  \\n We can then create instances of the Name tuple  \\n by using the type and giving the field values sequentially.  \\n Or we can even use the field names,  \\n which lets us shuffle the fields if we need to.  \\n Name tuples have the advantage that they print nicely.  \\n Now let's look at accessing the fields.  \\n Indices still work.  \\n So we get a zero, one and two gives me  \\n first name, last name, and birthday.  \\n But field names using the object-oriented DOS syntax  \\n are now what we're going to use,  \\n because they make our intentions clear in the code we write.  \\n Let's convert our little database to name tuples.  \\n We can't use a standard tuple directly  \\n and feed it person type, because person type  \\n needs three arguments.  \\n Here, Python is complaining that two are missing.  \\n So this is a case where tuple unpacking comes useful.  \\n I use a star to unpack tuple zero into its three elements.  \\n To do all of them, we will, of course,  \\n use a list comprehension.  \\n Now our birthday search reads better.  \\n It shows me explicitly that I'm looking at  \\n the birthday field of each tuple.  \\n Python 3.7 introduced an alternative  \\n to tuples index for storing data records, data classes.  \\n To use them, we need to import data class  \\n from the data classes module.  \\n If you are for some reason in Python 3.6,  \\n you can still use data classes,  \\n but you need to install them explicitly as a package.  \\n For instance, with PIP Install.  \\n So I do my import, and this is how we would  \\n set up a personal record with first name, a string,  \\n last name, a string, and a birthday,  \\n and say again a string,  \\n with the default value for the birthday.  \\n If you're not familiar with Python classes,  \\n class decorators, the At data class that appears at the top,  \\n and if you're not familiar with that annotation  \\n the syntax will look somewhat alien.  \\n But basically, we're instructing Python  \\n to create the type of records that will have fields  \\n called first name, last name, and birthday,  \\n all of which will be strings.  \\n We'll create an instance of this class, a person,  \\n making the fields sequentially or by keywords.  \\n You see here that the field of that known birthday  \\n is applied, since I didn't provide a birthday  \\n to the definition.  \\n We can access the field by name but not by index.  \\n And again, the data class prints nicely.  \\n In contrast to name tuple,  \\n data classes are full Python classes,  \\n so we can define methods that operate on the fields,  \\n such as a method that returns a person's full name.  \\n If you're not familiar with object-oriented  \\n programming in Python, do not worry.  \\n We will not need this feature in what follows.  \\n Nevertheless, for person class two,  \\n calling full name as a method runs the code that we wrote  \\n and returns my full name.  \\n Data classes have many other useful features,  \\n such as freezing, disallowing modifications,  \\n ordering, allowing the comparison of class instances,  \\n defining data classes by inheritance, and a lot more.  \\n So I encourage you to learn more about them  \\n if you are somewhat familiar with  \\n object-oriented programming  \\n and specifically classes in Python.  \\n Now we move on to our last topic  \\n about data extractions in Python.  \\n In a video about dict, I discussed how  \\n a special variant of dictionary,  \\n collections order dict, is now much less useful  \\n because the standard dict preserves the order  \\n in which elements were inserted.  \\n There's another variant of dict that remains useful,  \\n collections default dict.  \\n The point here is to define a default for values  \\n that will be returned if we ask for a key  \\n for which there was no entry.  \\n More precisely, we have to provide a function  \\n that returns that default.  \\n Let me write out the function that we will use.  \\n We'll call it mydefault, and it will return a simple string.  \\n So here's my default dict.  \\n If I go in and ask for a key that doesn't exist yet,  \\n I will just get the default back.  \\n Not only, that key will be now part of the dictionary.  \\n This makes default dict useful  \\n when we want to build a dictionary  \\n where each key can correspond to a list of items.  \\n Let's make an example based on birthdays.  \\n With standard dict, we need to write code  \\n that behaves differently if the birthday  \\n has been seen already, and then we can append  \\n to the list of people with the same birthday  \\n or if the birthday has not been seen,  \\n in which case we need to create a list with one element.  \\n That is quite inconvenient.  \\n The repetition of code is annoying and prone to bugs.  \\n We'll use the full dict instead,  \\n and we will take advantage of the fact  \\n that list called as a function returns the empty list.  \\n So we can use it to provide a default.  \\n Thus, we can write birthdays  \\n as collection_defaultdict  \\n with list as the default maker,  \\n and then simply look over person in our name tuple  \\n and constraint to get in that key the birthday  \\n and appending to the resulting list.  \\n There are more useful container types  \\n in the standard library module collections.  \\n I encourage you to look them up  \\n and to use them in your work instead of  \\n reinventing those wheels.  \\n \\n\\n\"}],\"name\":\"2. Data Structures in Pure Python\",\"size\":49694852,\"urn\":\"urn:li:learningContentChapter:2294388\"},{\"duration\":824,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2294375\",\"duration\":67,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Anagrams overview\",\"fileName\":\"2825705_03_01_XR30_overview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this chapter, practice Python data structures with a simple example of textual data: listing and analyzing anagrams in the English dictionary. In this video, explore the basic technique\u2014signature\u2014that you use to find anagrams, and outline your general strategy to map the technique to data structures.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1734395,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In chapter two,  \\n we have reviewed Python loops,  \\n data containers, and comprehensions.  \\n Now we will set them to work  \\n in a simple, practical project,  \\n finding anagrams in the English dictionary.  \\n As you know, two words are anagrams of each other  \\n when their letters can be rearranged  \\n to turn one word into the other.  \\n For instance, elvis and lives.  \\n We will use this simple strategy to find anagrams.  \\n We defined a signature of a word  \\n as the sorted list of its letters, including duplicates.  \\n So the signature of post would be opst.  \\n And then we find that spot, stop, tops, pots, and opts  \\n have the same signature as post  \\n and therefore they're all anagrams of each other.  \\n We're going to make a Python dict  \\n of all the words in the dictionary indexed by signature.  \\n And then to find out if a word has an anagram,  \\n we will just compute the signature  \\n and look it up in the dict.  \\n Let's begin.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294376\",\"duration\":250,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading a dictionary\",\"fileName\":\"2825705_03_02_XR30_loading\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In many cases, parsing a text file manually is the fastest way to complete a simple data-analysis task. In this video, load a list of words from a file, and briefly explore Unicode strings in Python 3, which allow you to handle international character sets transparently.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6615853,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We begin.  \\n By loading a list of words from a file.  \\n Your exercise files.  \\n Already contain a list that we can use as an example.  \\n The file is words.txt  \\n and it sits in the same folder as this Jupyter notebook.  \\n That file is, in fact, the nineteen thirty four dictionary.  \\n That is distributed with many UNIX systems.  \\n If you wish, you can find a better one and use that instead.  \\n Now in Python.  \\n We talk of idioms  \\n to refer to code constructs.  \\n That have become the preferred way  \\n to achieve a certain goal.  \\n A classical example is looping through  \\n all the lines of a text files.  \\n To do so.  \\n We open the file for reading.  \\n Let's open  \\n with a mode of \\\"R\\\"  \\n and then, we can use the file as an iterable.  \\n In a fold loop.  \\n Which has the result  \\n or giving us the lines one by one.  \\n For the moment.  \\n All that we will do with each line,  \\n is just collect it in a list.  \\n What did we get?  \\n More than two hundred thousand words.  \\n Let's look at the first few using slicing.  \\n As we learned in chapter two.  \\n That's good.  \\n I see two problems though.  \\n Every word ends in the new line character.  \\n Denoted in \\\"C\\\" and in Python  \\n as backslash \\\"n\\\".  \\n Also some of the words are capitalized.  \\n Which will interfere  \\n with our scheme of computing signatures.  \\n We can fix both issues using Python string methods.  \\n To strip leading and trailing whitespace.  \\n Including new lines.  \\n We can apply strip.  \\n let's take our own for example.  \\n The new line is stripped away.  \\n Now to switch the entire string to lowercase.  \\n Who use the method lower.  \\n So now.  \\n There's something more interesting to do  \\n in the body of a loop.  \\n Will append to the empty list  \\n is stripped and lowercase version of each line.  \\n Now I see a duplicate.  \\n Which comes from \\\"a\\\"  \\n appearing both in uppercase and lowercase.  \\n One way to get rid of duplicates  \\n is to build not a list but a set.  \\n so I will do my loop once more.  \\n Replace the empty initial list with the empty set  \\n and replace a pen with ADD  \\n and given that the body of the loop is just one line.  \\n There is an even more  \\n idiomatic way of writing it.  \\n You probably guessed it already as a comprehension.  \\n The comprehension will have  \\n the expression I want to collect  \\n and then the loop over lines in the file.  \\n Here it is.  \\n If we wish to restore the alphabetical order.  \\n We can just wrap the set  \\n in the Python built-in sorted.  \\n Which produces a list.  \\n A list however without duplications.  \\n We are now ready to make Anna Graham's.  \\n By the way.  \\n If you want to try in a different language  \\n such as French.  \\n You can follow along what we did  \\n with the appropriate file.  \\n The good thing is that in Python three  \\n all strings are natively unicode.  \\n Meaning that they can handle  \\n international character sets transparently.  \\n The characters are encoded internally  \\n using multiple bytes as needed.  \\n They only care that we need to take  \\n is to tell Python which encoding to use for  \\n the files we read and write.  \\n There are multiple mappings  \\n between character sets and bytes.  \\n So we need to know which one was used.  \\n Your exercise files include a French dictionary.  \\n Written using  \\n the iso-eighty eight five nine encoding  \\n also known as latin one.  \\n Let's read all of its lines.  \\n In this case instead of a loop.  \\n We use the built-in method with lines.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293499\",\"duration\":329,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Finding anagrams\",\"fileName\":\"2825705_03_03_XR30_finding\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, use Python comprehensions to create Python dicts that let you list anagrams and sort them in various ways. These examples show the flexibility and legibility of Python comprehensions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9579381,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We pick up our exercise  \\n where we left it in the last video.  \\n We have made a sorted list of lowercase words.  \\n lets load it up.  \\n Now, remember our strategy of comparing signatures.  \\n Those are the sorted lists  \\n of the component letters of each word.  \\n We need a function to make them.  \\n Taking the string N again as an example,  \\n let's see what happens if we sort it.  \\n Which we do with the built-in sorted.  \\n Indeed, we get a sorted list of the letters,  \\n which is already the signature.  \\n We can use it to verify say  \\n that Elvis is an anagram of lives, but not of sings.  \\n For convenience, we will collate the list  \\n of characters back into a single signature to string.  \\n The way this is achieved in Python looks a little strange,  \\n since we need to call the method join on a string  \\n that specifies the connector so to speak of the join.  \\n If it's a dash, we get a-a-n-o-r.  \\n So the connector we really want is the empty string.  \\n We're ready to make a function  \\n that performs this operation in general.  \\n Now, I remind you that our anagram finding strategy  \\n is to build a dictionary of words indexed by signature.  \\n Of course, we could also try a brute-force search  \\n that loops to the dictionary,  \\n computes the signature for every word  \\n and compares it with the signature  \\n of the word we want to anagram.  \\n That's what find anagram does.  \\n This works and seems fast enough  \\n to see just how fast we can use the IPython magic %time.  \\n So 200 milliseconds, that is not a long time to wait  \\n but we become unbearable if we need  \\n to compute long lists of anagrams.  \\n So let's do this the smart way.  \\n As we said, we will build the Python dict  \\n of words indexed by signatures.  \\n In fact, the values in the dict will be set,  \\n that indeed, contain all the words with the same signature.  \\n We call it words by SIG.  \\n If you think about it,  \\n this is the perfect application for default dict.  \\n Which we introduced in chapter two.  \\n Since the first time that we meet the signature,  \\n we have to somehow produce an empty set  \\n and add to it, perfect.  \\n Perhaps we could perform one last filtering operation  \\n by removing signatures with a single word.  \\n After all, every word is an anagram of itself,  \\n but that's not very interesting.  \\n To do the filtering, we can use a dictionary comprehension.  \\n Remember, to iterate on both key  \\n and value we use dict items.  \\n Then with the clause to select non-trivial anagram sets  \\n will length greater than one.  \\n Excellent, we can allow the simple function  \\n find anagram first that looks up a word  \\n in the dict by signature.  \\n This works fine, let's see for my name.  \\n Nothing, I didn't really expect one,  \\n But perhaps we shouldn't get an error  \\n when no anagram is found just the empty set.  \\n To fix that, we'll use a try except close.  \\n And we'll catch the key error exception with  \\n accept key error and just return the empty set in that case.  \\n If you're not familiar with exceptions in Python,  \\n I encourage you to go look them up  \\n in the Python documentation.  \\n So let's try again to anagram my name and get the empty set.  \\n This new function is much, much faster.  \\n Now that we have set this machinery up,  \\n there are many interesting investigations we could do.  \\n For instance, how about finding the sets  \\n of anagrams with the longest words?  \\n We get that by sorting the signatures,  \\n which we get from keys applied to anagrams  \\n by SIG using length.  \\n So we use the sorted built-in,  \\n given a sorting key of Len and a sync for reverse order.  \\n These are the longest signatures,  \\n but to see the actual anagrams,  \\n we can wrap it in a list comprehension.  \\n The longest anagrams have 22 letters.  \\n Looking at this list though, I must say  \\n that these are compound medical words  \\n that are not too creative in anagrammatical terms.  \\n How about the set of anagrams with the most words?  \\n For this, we will sort the dict values instead of the keys.  \\n And again use Len as the sorting key.  \\n The two longest groups have 10 elements,  \\n though some of these words are not very easily recognizable.  \\n Well done, this completes our exercise.  \\n Next, let's put what you learned to good use  \\n and take on a challenge again about wordplay.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294377\",\"duration\":49,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Palindromes\",\"fileName\":\"2825705_03_04_XR30_CH30_challenge1\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In the challenge, you are asked to find palindromic pairs in English, which are pairs of words that become each other when reversed. To do so, you can modify your anagram code.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1274685,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (bright electronic music)  \\n - [Instructor] For your challenge,  \\n you should extend the anagram machinery  \\n that we built together to find all palindromic pairs  \\n of words in the English language,  \\n or at least, in our dictionary.  \\n That is, you should find pairs of words  \\n that become each other when we reverse  \\n the order of their letters.  \\n For instance, reward and drawer.  \\n That will also include true palindromes, such as radar,  \\n where the reverse of the word is the word itself.  \\n I'll give you a hint, to reverse a string,  \\n go back to what we learned  \\n about slicing sequences in Python.  \\n This challenge should take you 10 minutes.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294378\",\"duration\":129,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Palindromes\",\"fileName\":\"2825705_03_05_XR30_SO30_solution1\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3805977,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Narrator] Here is my solution to the challenge.  \\n You were asked to find all palindromic  \\n pairs of words in the English dictionary.  \\n We start by loading our list of words  \\n with the one line of comprehension.  \\n We will explore the fact that if two words are palindromic,  \\n then they are also anagrams of each other.  \\n We will also need the code we wrote in this chapter  \\n to compute signatures  \\n and to associate words to signatures.  \\n In Python, there is no built-in function  \\n or method to reverse a string,  \\n but we can achieve it easily by slicing.  \\n The slicing step will need to be negative backwards.  \\n We will omit the slice start and stop  \\n to get the entire string.  \\n So for Mickela, we do a slice of colon, colon, minus one.  \\n We now look over all the word sets,  \\n one for each signature,  \\n and then overall pairs of words in the word set,  \\n checking if one of them equals the reverse of the other.  \\n It's a little annoying to write the loops,  \\n so that we are only checking the same pair twice,  \\n in reversed orders.  \\n One way is to check pairs on if they are sorted.  \\n Here's the list.  \\n It includes also the true palindromes  \\n where in order, reverse order,  \\n equals itself.  \\n But manual dis-sorts do not seem very common.  \\n I'm going to give you, also, more elegant solution.  \\n Using the stand a library module, intertools.  \\n Intertools includes an iterator combinations  \\n which return all combinations,  \\n say of two items,  \\n from a list of three.  \\n We can then simplify our solution,  \\n by again looping over word sets,  \\n and then by selecting pairs of words in the word set  \\n using intertools combinations.  \\n The code is cleaner and more expressive.  \\n But the solution is the same.  \\n \\n\\n\"}],\"name\":\"3. Wordplay: Anagrams and Palindromes\",\"size\":23010291,\"urn\":\"urn:li:learningContentChapter:2295370\"},{\"duration\":1412,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2294379\",\"duration\":195,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"NumPy overview\",\"fileName\":\"2825705_04_01_XR30_numpyoverview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Whenever you need to manage large one-dimensional or multi-dimensional collections of homogeneous data, such as numerical arrays, you turn to the NumPy library, which provides speed and memory savings. NumPy is also a basic building block to interface with C or Fortran code. In this video, get introduced to the basic structure of NumPy arrays and the notion of dtype.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5335233,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this chapter, we introduce NumPy,  \\n a third-party package for Python  \\n that extends the language with multi-dimensional arrays  \\n that are fast, memory-efficient,  \\n and that can manage very large data sets.  \\n NumPy is an important part of the Python ecosystem.  \\n It has become a fundamental package for data analysis,  \\n and for any kind of mathematical application with Python.  \\n Let's talk about how NumPy arrays are different  \\n from Python containers, such as lists.  \\n Python variables are often described as labels.  \\n They are not little boxes in computer memory  \\n ready to receive a value.  \\n Rather, the values are independent objects  \\n with their own space in memory,  \\n and Python variables are labels or names  \\n that are attached to the values.  \\n So you can have more than one variable,  \\n referring to the same object.  \\n It's a very flexible mechanism,  \\n and it makes it possible to have lists and dictionaries  \\n with heterogenous elements.  \\n However, it's not very efficient when we need to  \\n deal with many values of the same type.  \\n In that case, you want to reserve space in memory,  \\n and store all the values side by side,  \\n and that's exactly what a NumPy array is.  \\n Organizing data in this way  \\n is both faster and more efficient in memory.  \\n It's also a necessary step if you want to  \\n interface Python with other languages,  \\n such as C or Fortran,  \\n which count on data being laid out in memory like this.  \\n In this slide, I'm showing you a schematic representation  \\n of a one dimensional and a two dimensional array.  \\n The actual data items sit side by side in memory,  \\n and they all have the same size.  \\n If there is one dimensional,  \\n we identify items by a single index,  \\n or two indices for a two dimensional array.  \\n The index ranges from 0 to one minus one,  \\n where N is the dimensional array.  \\n In the case of a two dimensional array,  \\n the dimensions can be different of course.  \\n Since, as we said, all the data items in an array  \\n need to have the same size,  \\n NumPy needs to be very precise about identifying data types.  \\n In fact, more precise than Python.  \\n While Python has just one type of integer,  \\n and one type of floating-point number,  \\n NumPY has several.  \\n NumPY identifies different types of integers,  \\n dependent on the number of bits  \\n that each of them takes up in memory,  \\n int8, int16, int32, and int64 the most common.  \\n There are also unsigned version of the integers.  \\n As for floating-point numbers,  \\n we have float16, 32, 64, and on some platforms 128.  \\n The most common is float64.  \\n There are other more special I-Types,  \\n complex numbers, booleans, true or false,  \\n bytes, unicode strings,  \\n for which you need to specify lengths,  \\n void, used for record arrays,  \\n and object, which is in effect a pointer  \\n to arbitrary Python objects.  \\n So let's see NumPY arrays in action.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294380\",\"duration\":314,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating NumPy arrays\",\"fileName\":\"2825705_04_02_XR30_createarrays\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are various ways to create NumPy arrays, depending on your needs. In this video, learn to make empty arrays, to transform Python data structures into arrays, and to load arrays from files in various formats.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9152433,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The easiest way to get  \\n a NumPy array is to load it from a file.  \\n NumPy recognizes several file formats,  \\n including, of course, simple text files.  \\n I have prepared one for you  \\n that describes a very well-known painting.  \\n The file is called monalisa.txt  \\n and it's included in your exercise files  \\n in the same directory as this notebook.  \\n Let's have a look at the content.  \\n We open the file with open in reading mode,  \\n and we use the readlines method  \\n to get all the lines of the file.  \\n So we see that we have 200 lines  \\n and that each line is a sequence of integers.  \\n NumPy loads the file without any trouble using loadtxt.  \\n The result is a two-dimensional array.  \\n If we display it, NumPy omits some rows and columns  \\n so it fits on the screen.  \\n We can query the object, the array,  \\n for the number of dimensions, which are two,  \\n the shape, which is 200 by 134,  \\n 200 rows by 134 columns,  \\n the total number of elements,  \\n and the type of element.  \\n In this case it's the very common 64 bit  \\n floating point number.  \\n Okay, so we have a two-dimensional array called monalisa.  \\n I wonder, is it an image that we can display?  \\n We can use the Matplotlib function imshow  \\n to display two-dimensional arrays as images.  \\n Although, we should perhaps use a better column map,  \\n such as gray.  \\n I've also prepared a colored version of the painting  \\n and I have saved it in NumPy's native binary format,  \\n which works across all platforms.  \\n The file is monalisa.mpy.  \\n This is now a three-dimensional array,  \\n where the last dimension is used to store  \\n red, green and blue components.  \\n Imshow understands this without any problem.  \\n We have lots of pixels, so we can make the image bigger  \\n by instructing Matplotlib to have a larger figure size.  \\n Five by eight refers to inches,  \\n although how that turns out in pixels  \\n depend on the resolution of your screen.  \\n We now know how to load the NumPy array.  \\n How about making one ourselves?  \\n The easiest way is to take a Python list  \\n or a nested list of lists and pass it to NumPy array.  \\n The data type is automatically set.  \\n And we can query the object as we did before.  \\n Another common way to create  \\n an array is to make an empty one.  \\n We give the shape and the data type.  \\n For instance, we can do a one-dimensional array  \\n a vector of length eight.  \\n Here d is just a shorthand for a float 64, an 8-byte float.  \\n We can do a two-dimensional array, a matrix.  \\n And we can query these objects for their metadata,  \\n and plot them on the same line.  \\n It is sometimes useful to make an array of zeros  \\n in the shape of another existing array.  \\n That's done with zeroes_like.  \\n Otherwise, we can make a really empty array.  \\n Here, the memory is allocated, but not even cleaned,  \\n so we get some nonsensical values.  \\n We can also create a regularly spaced array  \\n of number with linspace with specified extrema,  \\n for instance, zero and one,  \\n and the total number of elements, here 16.  \\n We can't show a one-dimensional array as an image,  \\n but we can certainly plot it with Matplotlib.  \\n Here, I will use a thick marker  \\n as specified by lowercase o.  \\n Instead of choosing the number of elements  \\n between two extrema as we did with linspace,  \\n we can use NumPy arange, which has the same convention  \\n as Python's built-in range.  \\n In this case, we have elements  \\n between zero and 1.5 spaced by 0.1.  \\n NumPy can also give us an array of random numbers.  \\n We just need to specify the shape.  \\n By default, we get numbers uniformly distributed  \\n between zero and one.  \\n If we plot them with color, they look suitably random.  \\n We could also use random.randint and NumPy random.randn  \\n to get either integers in a given range  \\n or normally distributed numbers.  \\n To close this video, let me show you  \\n how to save an array to a file.  \\n Np.save will create a cross-platform binary file.  \\n The file ending is conventionally .mpy,  \\n but it doesn't need to be.  \\n Numpy savetext, instead, will create a readable ASCII table.  \\n And if we load it, we see that it's all there.  \\n Now that we've created our arrays,  \\n let's see what we can do with them.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294381\",\"duration\":320,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Indexing NumPy arrays\",\"fileName\":\"2825705_04_03_XR30_indexing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In the analysis of large data collections, you often need to focus on subsets of data or to restructure its storage. In this video, learn how to select subarrays by specifying boundaries and strides\u2014slicing\u2014or by applying conditions to the data\u2014fancy indexing. Also, explore restructuring data\u2014for example, adding or removing axes\u2014and the distinction between views and copies.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9422227,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let's see how we can access  \\n individual elements and ranges of elements in NumPy.  \\n We will demonstrate on our good old friend Mona Lisa.  \\n So let me load up the file.  \\n I remind you, this is a three-dimensional NumPy array  \\n with dimensions that correspond to  \\n height 1198 pixels with 804,  \\n and color three, for red, green and blue.  \\n Imgshow shows us the picture.  \\n The syntax to get that individual pixels  \\n is just an extension of Python list indexing,  \\n except that we can now include  \\n multiple indices among brackets.  \\n For instance, a point roughly in the middle  \\n would be on row 600, column 400  \\n and we grabbed the red component.  \\n If we wish to go to the bottom right corner,  \\n we may count back from the boundary of the array,  \\n just that we would do for a list.  \\n This should be the same as  \\n 1148, 754 and one.  \\n If we try to index elements beyond the boundary,  \\n we get an index error.  \\n And of course, we can use indexing to assign values  \\n to the elements.  \\n Once you get used to multi-indexing like this,  \\n you'll have the temptation of trying it  \\n on nested Python lists,  \\n but there it doesn't work.  \\n So let me demonstrate with a rather uninspired list.  \\n We cannot ask for element one comma two,  \\n rather, we need to ask for list number one,  \\n and then element two.  \\n One more reason to like NumPy arrays.  \\n Slicing also works in a very similar way to Python lists.  \\n For instance, we could grab a section  \\n in the middle of the painting  \\n from rows 400 to 800, columns 200 to 600s.  \\n Here's the detail.  \\n Often we want to grab the entire range  \\n over one or more axes, in which case,  \\n we can use the shorthand column for the full slice.  \\n There's an even shorter hand  \\n for multiple full slices, ellipses sign.  \\n We can also specify a step,  \\n which has the effect of reducing the resolution  \\n of the picture  \\n because we've taken every 20th pixel.  \\n See the black dot in the middle?  \\n It's there because earlier we assigned zero  \\n to all three color channels for pixel 600 and 400,  \\n the single pixel was invisible at higher resolution,  \\n but it's one of those selected by this slice  \\n with steps of 20.  \\n How about slicing backwards?  \\n That works too.  \\n And in this case, it inverts the rows.  \\n And if we mix slicing and indexing,  \\n we reduce the dimensionality of the array.  \\n In this case, it becomes just a vector.  \\n We can show a vector as an image or we can plot it.  \\n Note that fixing one of the indices  \\n is not the same as asking for a slice of one.  \\n In that case, the array remains two-dimensional.  \\n Slicing can also be used on the left side  \\n of an assignment statement.  \\n We can use this to modify elements in bulk,  \\n such as deleting a square in the top corner of the image.  \\n Doing so, assign the same value to all the pixels there.  \\n But we can also match slices on both sides  \\n of the assignment.  \\n So let's replace the white square  \\n with a random set of pixels.  \\n NumPy arrays also support  \\n an especially useful form of indexing  \\n that is not available with lists.  \\n This is known as fancy indexing.  \\n It means that we're using arrays to index another array.  \\n To demonstrate that,  \\n let me grab my lower resolution grayscale image.  \\n I'm going to threshold this image  \\n by first figuring out all the pixels  \\n that are darker than a certain value.  \\n The result is a two-dimensional Boolean array,  \\n the same size as monalisa_bw.  \\n I can then use this Boolean array  \\n to select the corresponding subset of pixels  \\n and modify only those.  \\n Here's the thresholded image.  \\n Finally, let me point out another very important difference  \\n between lists and NumPy arrays.  \\n Whenever you slice a list, you make a copy of it.  \\n Say I have a simple list of six elements  \\n and I take a slice of the first four.  \\n Assigning to the slice does not modify the original list.  \\n By contrast, a slice of a NumPy array  \\n is a new NumPy object  \\n that points to the same area of memory,  \\n but we modified meta data that represents  \\n the different boundaries.  \\n So if I assigned to the slides,  \\n I'm also assigning to the underlying object.  \\n If we want a true copy pointing to new memory,  \\n you have to make the copy explicitly.  \\n Acting on the copy does not affect the original.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293500\",\"duration\":321,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Doing math with NumPy arrays\",\"fileName\":\"2825705_04_04_XR30_math\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"With NumPy, speed and agility arise from the ability to operate on entire arrays at once. In this video, learn how to perform mathematical operations that transform arrays or combine them together, while preserving or modifying their structure.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9501463,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] NumPy is extremely useful  \\n in numerical calculations.  \\n That's because in addition to packing numbers  \\n efficient in memory, NumPy makes it easy  \\n to perform mathematical operations  \\n with entire arrays.  \\n For instance, in a study of mathematical functions,  \\n we may start with a vector of equally-spaced real values  \\n between say zero and five times pi.  \\n Here it is.  \\n Note that with the list space, the extreme of zero  \\n and five pi are included.  \\n Then we may want to complete the sine  \\n of all these values.  \\n We cannot do this with a function  \\n in the standard math library.  \\n Math dot sin.  \\n But we can with the NumPy version,  \\n which is called the universal function for this reason.  \\n It can operate on any array, in element by element fashion.  \\n There is always another NumPy array  \\n with the same shape as X.  \\n Using map dot lib, I can now plot sine X against X.  \\n Specifying first the coordinates along the horizontal axis  \\n and then the coordinates along the vertical.  \\n Map dot lib takes care of setting the Y range automatically.  \\n By repeating the plot statement,  \\n I can show multiple functions together.  \\n Map dot lib will automatically cycle through colors  \\n so it can distinguish the lines.  \\n So let's try our sine together with a cosine  \\n and then logarithm.  \\n We can add labels to remind us which is which,  \\n and then collect the labels in a legend.  \\n There are many more options in map dot lib  \\n regarding the style of the lines,  \\n the formatting of the plot, and more.  \\n You can look at the documentation to learn more.  \\n We can also perform operations  \\n that involve more than one array  \\n and everything goes smoothly if we match array shapes.  \\n So let's make the cosine in addition of the sine,  \\n and let's try combining the two.  \\n By contrast, operations between arrays of different shapes  \\n generally fail.  \\n NumPy doesn't quite know what to do.  \\n There is one important exception,  \\n which is known as broadcasting.  \\n NumPy, when it can, makes sense of operations  \\n between arrays of different dimensions  \\n rather than shapes.  \\n The simplest case, which is rather intuitive,  \\n is just to add a single number to an entire array.  \\n We see that W is offset by 1.5 with respect to sine X.  \\n The plot would also be self-explanatory.  \\n Let's go up to two dimensions  \\n and then we'll straighten our friend, the Mona Lisa.  \\n The image is 200 rows by 134 columns.  \\n I can multiply every column by a different number  \\n by making a vector of length 134.  \\n In this case, NumPy matches the second dimension  \\n of the array, with a single dimension of the vector.  \\n I want to show you the result  \\n side by side with the original image.  \\n So I need to do a little work with math dot lib.  \\n I will start with a larger figure size,  \\n figure and fix size,  \\n and then I set up one row  \\n with two plots using subplot.  \\n The arguments to subplot go one row, two columns,  \\n and then the subplot that I want to make.  \\n Multiplying the array in this way  \\n had the effect of applying horizontal gradient.  \\n What about the other way around?  \\n If I make a vector of length 200,  \\n you'd think we could apply it on the left  \\n to multiply every row by a single value.  \\n That however doesn't work.  \\n What works is to add a new dimension of length one  \\n to the gradient vector, which we can do  \\n with a special indexing notation, NP dot new axis.  \\n The shape of Y grad is now 200 by one.  \\n NumPy broadcasting then matches the first dimension  \\n of the two arrays, Mona Lisa BW and Y grad,  \\n and broadcasts the second dimension of Y grad  \\n to fill up the corresponding range in Mona Lisa.  \\n The result is the vertical gradient.  \\n NumPy supports many other useful mathematical operations,  \\n including fast fully transforms, random numbers,  \\n statistics, interpolation, and linear algebra.  \\n If you need any of them,  \\n you can go read the NumPy documentation.  \\n There is one thing I want to show you here.  \\n It's that since version 3.5,  \\n Python implements a special matrix multiplication operator.  \\n The at symbol, which is put to good use by NumPy.  \\n For instance, we can use it  \\n to make the dot product of two vectors.  \\n A and B, each of three elements.  \\n This is the same as writing NumPy dot dot AB.  \\n Or we could write the products of a three by three matrix  \\n in a three vector.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293501\",\"duration\":262,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Special arrays: Records and dates\",\"fileName\":\"2825705_04_05_XR30_special\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"NumPy offers very convenient facilities for managing data of different types together\u2014record arrays\u2014and to handle dates with the datetime64 dtype. In this video, learn how to create and use record arrays and datetime64 data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7397157,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In the last video for this chapter,  \\n I want to show you two NumPy features  \\n that are not always covered in tutorials,  \\n but they're still very useful.  \\n One is record arrays, where we can mix different data types  \\n and give descriptive names to fields.  \\n The other is date time objects,  \\n which as the name says, can encode a date and time.  \\n Let us load up a simple example of a record array,  \\n which I have prepared in the NumPy binary format.  \\n This is a partial David Bowie discography.  \\n Each entry shows the record name, the date of release  \\n and the top rank in the UK charts.  \\n Let's look at the data type.  \\n It's a list which shows the name of each field  \\n and the actual D type.  \\n For title, it's U32, which denotes a Unicode string  \\n of maximum length 32.  \\n For release, it's M eight brackets D  \\n which denotes a date time object with granularity of days.  \\n It could be as small as a nanosecond in fact.  \\n The eight refers to the size in bytes  \\n of each date time object.  \\n Last, the top rank, is an eight byte integer data type.  \\n If you're wondering about the less symbol in each of these,  \\n those refer to the endianness of the data types,  \\n the order in which the bytes are stored in memory.  \\n Inter-processors are little endian.  \\n So what can we do with a record array?  \\n Each record looks like a Python tuple,  \\n and we can extract the elements as we would for a tuple  \\n but we can also modify them.  \\n We can also use a dict like interface  \\n using the field names in brackets.  \\n This, in fact, will also get us a full column.  \\n To create a record array,  \\n you have to be a little careful in specifying the D type.  \\n It's useful to go read about data type descriptors  \\n in the NumPy documentation.  \\n But let's try one.  \\n We specify a subset of the information  \\n we have in discography, just the title and release date.  \\n This array is empty right now,  \\n but we can copy over the two columns.  \\n Here we see that the title strings  \\n have been truncated to 16 characters.  \\n Since all the data is stored contiguously in memory,  \\n the lengths that we prescribe for the fields  \\n are very important and set the limit for the data  \\n that we can store.  \\n We see also that we specified a finer granularity  \\n for the date time object, seconds,  \\n although it's all zeros because the discography array  \\n didn't have that information.  \\n We move on to the date time object,  \\n which is called datetime64  \\n to avoid confusion with the object in the standard library,  \\n and also to remind us that each element takes 64 bits.  \\n We can initialize date time object with strings,  \\n and we can give it as much detail as we want,  \\n just the year, a full date,  \\n and date and hour minute combination, or even beyond that.  \\n Date times can be compared,  \\n so noon came before 6 p.m. on that day, like any day.  \\n Date times can also be subtracted,  \\n resulting in a time delta object,  \\n which here is specified in minutes.  \\n The nice thing about these date time objects  \\n is that they are understood across NumPy.  \\n For instance, we can use the NumPy function diff,  \\n which computes the differences between  \\n successive elements of a vector  \\n to see how long it took David Bowie  \\n to come up with a new record after each one.  \\n Ziggy Stardust was especially quick.  \\n Another example may be making a range of these.  \\n NumPy in a range understand date times.  \\n And we see that the last day is excluded  \\n consistently with the conventions of range and a range.  \\n This functionality is extended even further in Pandas.  \\n And in fact, the whole idea of record arrays  \\n has a much stronger implementation in Pandas DataFrames.  \\n We'll learn about those later in this course.  \\n \\n\\n\"}],\"name\":\"4. Arrays with NumPy\",\"size\":40808513,\"urn\":\"urn:li:learningContentChapter:2295371\"},{\"duration\":1606,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2295362\",\"duration\":64,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Overview of use case\",\"fileName\":\"2825705_05_01_XR30_weatheroverview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this chapter, practice NumPy by loading, modifying, and plotting weather data from the National Oceanic and Atmospheric Administration. In this video, examine the files that you are going to analyze and outline your analysis goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2103321,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this chapter,  \\n we are going to experiment with NumPy  \\n on a real world use case,  \\n analyzing weather data from NOAA,  \\n the National Oceanic and Atmosphere Administration.  \\n The GHCN, the Global Historical Climatology Network Daily  \\n is an integrated database of daily climate summary  \\n from land surface stations across the globe.  \\n Many in big cities for instance.  \\n Climate summaries, in this case,  \\n means variables  \\n such as the minimum and maximum temperatures,  \\n the total precipitation, and so on.  \\n The data files that we will be using  \\n can be obtained from the NOAA website.  \\n Together we will download a station list  \\n and use it to locate temperature data for cities.  \\n We will load the data files, fill missing values,  \\n and smooth time series.  \\n Finally,  \\n we will create a visualization of daily temperatures  \\n inspired by the New York Times weather plots.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294382\",\"duration\":372,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading station and temperature data\",\"fileName\":\"2825705_05_02_XR30_loading\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"NumPy allows you to load data in many different formats without writing custom code. In this video, learn how to use Python to download files from the web and use NumPy to load a fixed-width table.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14833489,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this chapter,  \\n we download several data files from the web.  \\n However, all the files that we analyze  \\n are also included in your exercise files,  \\n in case they became unavailable online,  \\n or you're unable to download them for any other reason.  \\n And before we load the data itself,  \\n it's also a good idea  \\n to start by looking at it's documentation.  \\n Browsing through the file listing at the NOAA website,  \\n we see a README file, and we start there.  \\n Instead of clicking on that link in our browser,  \\n let's use Python to download the file.  \\n There are several Python modules we could use,  \\n but for a simple download,  \\n the standard library module, urllib,  \\n is quite appropriate.  \\n urllib.request.urlretrieve needs the URL  \\n and the name of a local file.  \\n It's done already.  \\n We can use the Jupyter Notebook  \\n to look at the README file, by clicking on it.  \\n We see that it describes the contents of the directory,  \\n the format of DLY data files,  \\n which contain data for a single station,  \\n and are formatted with fixed-width columns.  \\n And the format of a file, GHCND stations,  \\n thank you, says the location, elevation, and ID  \\n for each station in the network.  \\n That's where we need to start,  \\n so we download that file with urllib.  \\n I've copied the description of the format  \\n into a text field in this Notebook,  \\n for our reference.  \\n To load a fixed-width text file, such as this,  \\n we can use NumPy genfromtxt.  \\n It needs rather precise information.  \\n We specify the width of each field  \\n in the parameter delimiter.  \\n We can derive the widths from the table above,  \\n or we need to increase them  \\n to include the spaces between the columns.  \\n Next, we provide the name,  \\n a descriptive name for each column.  \\n And we specify the dtype,  \\n the NumPy data type for each column.  \\n For the first field, for instance,  \\n we need a string of 11 characters.  \\n Then, we have three floats,  \\n and a few more strings of various lengths.  \\n And last, we'll tell NumPy  \\n to remove all the leading and trailing spaces  \\n from all the strings it parses.  \\n There result is a NumPy record array  \\n with more than a hundred thousand entries.  \\n Thankfully, Jupyter chooses to show us only a few lines  \\n at the top and the bottom.  \\n By plotting longitude against latitude,  \\n we get an idea of the impressive global coverage  \\n of the database.  \\n We need to make the dots small,  \\n so that they're not too crowded.  \\n Even so, the US and Europe are basically  \\n just solid masses of ink.  \\n How about stations in California?  \\n We can use fancy indexing with a Boolean expression,  \\n stations state equals equals CA  \\n to downselect our dataset.  \\n Coverage is still impressive.  \\n What if we need a specific station?  \\n Fancy indexing again comes to the rescue.  \\n We select all stations,  \\n for which it is true that the name field equals 'Pasadena'.  \\n We find one.  \\n If we want all stations that start with a given string,  \\n the syntax would be more esoteric.  \\n What np.char.find does,  \\n is to return the index at which a certain substring,  \\n 'Pasadena' in this case,  \\n appears in the field,  \\n or minus one if the substring is not there.  \\n If we required the index to be zero,  \\n that's the same as saying  \\n that the station name begins with 'Pasadena'.  \\n So, we see that there are several stations,  \\n a few of them in Pasadena, Texas and Pasadena, Maryland.  \\n Only one, however,  \\n is in the quality-controlled HCN network.  \\n Let's get that one.  \\n I've built this URL by looking at the structure  \\n of the directories on the website.  \\n You see that it ends in Pasadena's ID, USC00046719.dly.  \\n Locally, we'll download to the file Pasadena.dly.  \\n Let's look at that file.  \\n Again, with Jupyter Notebook.  \\n It's quite messy, but we recognize the station ID  \\n in the beginning of each line,  \\n followed by year and month.  \\n Here, we are in 1918.  \\n The name of an element, such as TMAX,  \\n and 31 data points, one for each day of the month.  \\n Each data point itself,  \\n consists of the value and three flags.  \\n We could use genfromtxt again,  \\n but it's going to take us a while,  \\n so, I prepared a small module for you, getweather.py,  \\n that takes care of parsing the file  \\n and returning consecutive daily values for a year.  \\n The module uses Pandas to clean and reformat data,  \\n but returns it as a pure NumPy array.  \\n After you've learned about Pandas later in this course,  \\n I encourage you to go look at getweather.py  \\n and see what I did there.  \\n We import the module  \\n and then we look at the help, known as docstring.  \\n This function does what I described,  \\n returning data for one year, for one station.  \\n Let's try it out on Pasadena.  \\n We request both TMIN and TMAX for year 2000.  \\n Some measurements are missing,  \\n and they are here represented as 'nan', nan, not a number.  \\n This function would be a great foundation  \\n for our work in the next few videos.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294383\",\"duration\":310,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Filling missing values\",\"fileName\":\"2825705_05_03_XR30_filling\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Data often needs to be cleaned or otherwise edited before analyzing it. In this video, learn how to integrate missing data in the weather files you have loaded using a simple interpolation technique.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9559456,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We pick up where we left  \\n and load temperature data for Pasadena, California  \\n using our getweather module.  \\n This is a time series, a sequence of values,  \\n organized chronologically, usually with equal cadence,  \\n that is the same time interval  \\n between every two consecutive samples.  \\n To get a sense of the data, one of them begins  \\n by computing its average value  \\n and perhaps its extreme, the minimum and maximum.  \\n With NumPy, we can use mean, min, and max.  \\n But wait, in this case, we seem to get NaNs.  \\n What's going on?  \\n It shouldn't be surprising, if we remember  \\n that the data contains missing values,  \\n which are indeed represented as NaNs.  \\n And NaNs can't really participate  \\n in any mathematical operation, NaN plus one is still NaN.  \\n In fact, how many do we have?  \\n The NumPy function isnan,  \\n creates a Boolean array of NaN-ness, so to speak.  \\n We can then count the instances of true  \\n in this array by using a neat trick.  \\n If we do arithmetics with Booleans in Python,  \\n they are converted to integers  \\n with false counting as zero and true as one.  \\n So, for instance, false plus true plus true is two.  \\n It follows that we can count the trues  \\n in a Boolean array just by summing it up with NumPy sum.  \\n So what can we do?  \\n Missing values are so common, in fact,  \\n the NumPy offers versions of its functions  \\n that simply ignore them.  \\n For instance, NumPy nanmin and nanmax.  \\n If we do need an uninterrupted series of numbers,  \\n we could just set the NaNs to the average of the column.  \\n This is yet another application of fancy indexing  \\n because we want to modify only the NaN elements.  \\n So we write something like Pasadena to mean  \\n fancy indexed to the true NaN Boolean mask  \\n is set equal to the NaN mean of the same variable.  \\n This works fine.  \\n We can tell which elements we changed  \\n because they have more digits than all the others,  \\n which were encoded with limited precision  \\n in the GHCN data.  \\n The integrated dataset can now be plotted  \\n without discontinuities.  \\n A more powerful approach to restoring missing values  \\n is to interpolate.  \\n That is, we can use neighbor values  \\n to compute a plausible number  \\n for the values that are missing.  \\n Let me demonstrate in a tall problem.  \\n Let's say we measure a function y,  \\n defined at integers x between zero and eight,  \\n but we don't have some of the values.  \\n In this case, we don't have value set x  \\n of two, three, and six.  \\n Let me show you all of this in a plot.  \\n I will now define an array of the integers  \\n at which we do want new interpolated values.  \\n I use NumPy linspace, so if I sat down  \\n and I said zero and eight, it's nine elements total.  \\n The function of NumPy interp takes as arguments  \\n the desired location, my xnew, followed by the data we have,  \\n x and y.  \\n It returns values that are interpolated linearly  \\n by fitting segments between existing data points.  \\n Here I'm plotting interpolated points as orange squares.  \\n This seems to make sense and to be rather conservative.  \\n The newx sequence, if you needed to,  \\n could well be the answer.  \\n 30 points between zero and eight.  \\n So let's use interpolation to fill missing values  \\n in the Pasadena temperature data.  \\n I need to load it again, since I fixed it already  \\n by replacing NaNs with nints.  \\n Here, now it's broken again, so to interpolate,  \\n we select the good data points, those that are not NaNs,  \\n and a tilde in this expression denotes logical notation.  \\n Then we make an array of the x-values  \\n for which we want interpolation.  \\n All days from one through 365,  \\n and then we can apply NumPy interp.  \\n This seems to work well.  \\n We celebrate by generalizing our Pasadena-centric code,  \\n so that it can fill up holes in any array by interpolation.  \\n It's just a question of replacing Pasadena  \\n with a generic array argument, and 365  \\n with the length of that array.  \\n Finally, we can plot interpolated temperature series  \\n in all their glory using our new function.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295363\",\"duration\":386,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Smoothing time series\",\"fileName\":\"2825705_05_04_XR30_smoothing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Many interesting data sets are organized as time series: numerical sequences sorted by date and time. In this video, learn how to use NumPy to perform basic time-series analysis tasks: computing means and standard deviations and smoothing time series.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11602546,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now we know how to load  \\n temperature data from any station,  \\n how to compute basic summaries  \\n such as mean, min and max,  \\n and how to integrate missing data points  \\n using interpolation.  \\n We'll continue with more data analysis in NumPy.  \\n I've copied your fill NaNs function here  \\n since we will need it.  \\n We looked at data for Pasadena in the last video,  \\n now let's move to even sunnier skies  \\n by looking at weather in the town of Hilo,  \\n big island Hawaii.  \\n We use our custom loader  \\n and again, I encourage you to go look under the hood.  \\n This is data in fact from Hilo International Airport  \\n we now fill the missing data for both T min and T max.  \\n Once more two pole unpacking is very useful.  \\n Let's look at some data summaries.  \\n The yearly average which gives us a sense  \\n of the typical value for T min, and it's min and max.  \\n Will span the range of variation of these measurements.  \\n We can plot the summaries together with the time series.  \\n The map load live function adds each line,  \\n plots a horizontal line that spans the entire graph.  \\n Also useful for reference values,  \\n and we'll make them dotted.  \\n Another common way to measure the range of variation  \\n of a time series is to compute the standard deviation  \\n defined at the square root of the values.  \\n If you don't know about this you can go to statistics,  \\n text book, or to Wikipedia.  \\n Mean and variance are computed in NumPy with NP Mean  \\n and NP Var, we can plot the time series again  \\n using the mean and the mean minus  \\n and plus the standard deviation as references.  \\n Most of the time the temperatures are included in this range  \\n and given that this is Hawaii it's also interesting  \\n to look at precipitation.  \\n We grab those values with Get Weather and just plot them.  \\n The rainy season starting in November is quite evident.  \\n Now looking at the data this way is very informative,  \\n but we also see lots of noise, rapid variations between  \\n one day and the next, which can obscure underlying trends.  \\n To remove the noise, we can smooth the data.  \\n So that we see the slower long-term behavior  \\n below those still issues and the simplest approach  \\n to smoothing is replacing each value with the average  \\n of a set of its neighbors.  \\n With NumPy we can do this with correlate.  \\n I will demonstrate first with a very simple  \\n and short data set consisting of two peaks  \\n over a background of zeroes.  \\n I then define a roughly triangular correlation mask  \\n which is highest in the middle and drops down to the sides  \\n and I have arranged the values so they sum to one,  \\n next I write the correlation.  \\n What it does is to multiply each element  \\n in the series with the mask  \\n and then sum up all the resulting short series.  \\n Sliding them so they are centered around the sample  \\n that we multiply, thus as you see in this figure,  \\n each peak generates a triangle centered  \\n on its location.  \\n I have not explained the keyword same that we gave  \\n to correlate, what it does is to request that  \\n the output of the correlation be the same length  \\n as the input.  \\n Even as this means that the points on the boundaries  \\n get sums from fewer masks.  \\n So we may see some anomaly there.  \\n To smooth our temperature series we will use  \\n an even simpler mask, uniform values normalized  \\n so that they sum to one.  \\n We're going to get that in NumPy with NumPy once,  \\n let's try this out.  \\n We plot the regional temperature series as dots,  \\n maybe a little smaller than usual,  \\n and the smoothed series has a continuous line.  \\n This works fine, we are reducing oscillations  \\n while emphasizing the underlying slower trend.  \\n We do see something strange happening  \\n at the beginning and end of the data set.  \\n The values are going way low.  \\n That has to do with the keyword same,  \\n and we detect that the values on the boundaries  \\n have fewer neighbors than everybody else.  \\n If we can do without a few points at the end  \\n and at the beginning we can change our request  \\n to amply correlate to valid and avoid this problem.  \\n We can now make a function to apply smoothing  \\n of any length to any array.  \\n The length of the smoothing mask is sometimes called window  \\n and by default we'll use valid mode.  \\n We then plot T min and T max together for Hilo.  \\n It's an interesting plot  \\n and I'd like to see it for other cities,  \\n so once again let's take a code  \\n and generalize it to arbitrary station and year.  \\n So we get the data, we fill in the NaNs  \\n and we plot both the original data and a smooth version.  \\n We need to offset the plot a bit since we lose points  \\n with valid mode, so the range if the smoothing is over  \\n 20 days would just be from day 10  \\n to day 356 of the year.  \\n Let me try this out, for instance over multiple years  \\n for Hilo to see if the Hawaii climate is stable.  \\n Quite so.  \\n How about comparing cities in different climates?  \\n Let me look over Pasadena, New York, San Diego,  \\n and Minneapolis and then create a sub-plot  \\n in two rows and two columns for each one of them.  \\n I'll focus on the year 2000.  \\n There's some downloading and then we see the plots  \\n come out together, if you can choose based on weather alone  \\n where would you live?  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295364\",\"duration\":303,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Weather charts\",\"fileName\":\"2825705_05_05_XR30_charts\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Using NumPy and matplotlib together, you can create insightful visualizations with little effort. In this video, learn how to compute daily temperature records and plot weather charts in the style of the New York Times.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9494132,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We're going to conclude a NumPy practice,  \\n by making a quick but impressive weather visualization,  \\n that showcases the power  \\n and flexibility of NumPy and Matplotlib.  \\n It's inspired by the New York Times  \\n weather chart shown here.  \\n And it shows daily minima and maxima,  \\n the proper band in the context of their normal range,  \\n dark gray and of their records, light gray.  \\n We will again use Pasadena as an example,  \\n but you can do your own city,  \\n if it's included in the NOAA data set.  \\n Remember, we want to show Records,  \\n which means that we need all the data we can get.  \\n The Gateway, the module,  \\n that's a query for one year of data at a time.  \\n So, we'll call it repeatedly collecting the results  \\n in a comprehension and feeding that to NumPy vstack,  \\n which makes a two-dimensional array formally  \\n so one-dimensional arrays.  \\n The result can be visualized with matchshow.  \\n We've added also a colored bar to provide a reference  \\n of the mapping of values to color.  \\n And we have specified the extent  \\n to get more informative labels on the axis.  \\n We see some missing data, the white patches,  \\n and we can observe winter and summer nights getting warmer  \\n towards the end of the century.  \\n For simplicity, we will forego filling a nance  \\n and use NaN robust functions.  \\n We want record temperatures for every day of the year.  \\n This means that we can use NumPy nanmin on the demand data  \\n and specify axis equals zero,  \\n so that the minimum will be taken  \\n across all rows for each column.  \\n We do the same for tmax using NumPy nanmax.  \\n Let's see the records.  \\n Now for the normals.  \\n In the New York Times plot the normal temperature range  \\n for each day is defined as the average  \\n of the low and high from 1981 to 2010.  \\n So we build another stacked array with a reduced year range.  \\n And again, we take nan robust means, across rows.  \\n So that's axis equals zero.  \\n Here's the normal range.  \\n We're ready to get the plot together.  \\n We do Pasadena in 2018, just like the Times,  \\n so I'd better get that data.  \\n To plot the band,  \\n we use Micro-LIBS fill between which needs an x-axis  \\n to coordinate the array.  \\n It needs also the lower  \\n and upper lines that delimit the band.  \\n So for the x-axis,  \\n I will use the day of the year for one to 365.  \\n Here it is, I will do similar bands  \\n for the records and normal ranges.  \\n I also want to show the average temperature for the year.  \\n I have to compute that though.  \\n That would be the mean of the minimum temperature  \\n plus the mean of the maximum  \\n all across the year, divided by two.  \\n In 2018,  \\n that was 19.46 degrees Celsius.  \\n I'm going to put this average temperature in the title,  \\n so I need to build up a string for that.  \\n For that, I will use the very convenient formatted string  \\n literals introduced in Python 3.6.  \\n If I start the string with an \\\"F\\\" before the quotes,  \\n I can include variable names in braces,  \\n which are then replaced by their values.  \\n I can also specify formatting instructions as I would,  \\n using the string format interface.  \\n For instance, two decimal digits  \\n for the average temperature.  \\n Let me put everything together.  \\n I plot the three bands for record normal and current year.  \\n I have also looked up the red green blue,  \\n the composition of the New York Times colors,  \\n which Matplotlib bonds as values between zero and one.  \\n The optional step equals myth makes the band look blocky  \\n so the individual days are in evidence.  \\n And last, the alpha setting makes  \\n the current year band partially transparent.  \\n I set reasonable access limit and finally add a title.  \\n Let's fire it off, very nice.  \\n In 2018, some values are missing,  \\n we see the purple band is interrupted  \\n and those are actually the hottest days.  \\n So you can play with other cities we'll turn this example  \\n into a function that can plot any year in any station.  \\n So here's New York in 2018.  \\n NumPy is extremely powerful and flexible,  \\n so you should learn about it in depth.  \\n Coupled with Matplotlib it offers a direct route  \\n to beautiful and informative visualizations.  \\n In my course, Python Statistics Essential Training,  \\n explores statistical plots in more detail  \\n and with more examples.  \\n You are now ready for your challenge.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293502\",\"duration\":46,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Weather anomalies\",\"fileName\":\"2825705_05_06_XR30_CH30_challenge2\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In the challenge, you are asked to make a visualization of temperature anomalies over the historical record by computing yearly averages and comparing to midcentury averages. To do so, build on the code that you developed in this chapter.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1250849,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat chime)  \\n - For your challenge,  \\n I'm asking you to plot the temperature anomaly for New York  \\n by computing yearly temperature averages for each year  \\n and comparing those with a mid-century average  \\n in the 1945-1955 decade.  \\n You can make yearly averages  \\n just as we did for the title  \\n of the New York Times inspired plot.  \\n TMIN plus TMAX over two  \\n averaged across the year.  \\n To make the mid-century average,  \\n just sum up results for 1945 through 1955  \\n and then take the difference.  \\n This challenge should take about 15 minutes.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293503\",\"duration\":125,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Weather anomalies\",\"fileName\":\"2825705_05_07_XR30_SO30_solution2\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4073114,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] We start by importing getWeather,  \\n since we need temperature data.  \\n It will also be good to show smoothed plots,  \\n so we'll grab the smooth function that we made.  \\n We need all the available historical data for New York,  \\n say 1880 through 2019,  \\n which we collect in a stacked array.  \\n We sum TMIN and TMAX for this large array  \\n and then take the average across the columns.  \\n So x is equal one,  \\n so that we get a value for each year.  \\n The shape isn't yet what we expect.  \\n Next, the mid-century average.  \\n We need to figure out the index of 1945 and 1955,  \\n in this all avg array.  \\n For lists, we can use index  \\n to figure out the location of an element.  \\n But unfortunately,  \\n that doesn't work for NumPy arrays.  \\n However, we can turn array into lists quite easily  \\n by feeding them to the list constructor,  \\n and then index works.  \\n So now we can perform the mid-century average  \\n over the correct slice of the array.  \\n It's 12.8 degrees.  \\n And here's the plot.  \\n The anomaly is all avg  \\n minus the mid-century mean.  \\n It's quite noisy,  \\n so let's smooth it out.  \\n If we use valid mode to avoid artifacts at the edges,  \\n we need to remove some years from the x-coordinate.  \\n The solution is complete really,  \\n but we can collect this code in a more general function  \\n so we can compare a few cities.  \\n So here's the comparison,  \\n with some complaints from NumPy  \\n by way of Jupiter  \\n that there's really no data before 1910 for Pasadena,  \\n and 1940 for Minneapolis.  \\n Still, the upward trend for all these three locations  \\n is quite evident.  \\n \\n\\n\"}],\"name\":\"5. Use Case: Weather Data\",\"size\":52916907,\"urn\":\"urn:li:learningContentChapter:2295372\"},{\"duration\":1258,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2293504\",\"duration\":68,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"pandas overview\",\"fileName\":\"2825705_06_01_XR30_pandasoverview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"pandas' powerful table objects, DataFrames, are extremely useful in the analysis of structured data that associates textual, date, and numerical information. In this video, you are introduced to the basic structure of pandas series and DataFrames, and compare them with NumPy arrays.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1758373,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Pandas has gained broad acceptance  \\n in the Python community  \\n as the data analysis tool for Python.  \\n As of January 2020,  \\n it should reach version 1.0 very soon,  \\n signaling the stability of its API,  \\n its programming interface.  \\n Pandas is built on top of NumPy so it's very fast.  \\n And it extends NumPy in ways that are extremely useful  \\n to data analysis.  \\n For instance it attaches labels to table columns and rows.  \\n It lets us access data using indexes  \\n built from any variable.  \\n It allows us to modify table structure  \\n by adding and dropping columns  \\n and by performing other transformations.  \\n It recognizes many common data formats.  \\n It handles missing data easily.  \\n It implements database operations such as joins  \\n and it can even make plots.  \\n So if you want to do data analysis  \\n or data science with Python,  \\n I really recommend that you learn Pandas.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294384\",\"duration\":395,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"DataFrames and Series\",\"fileName\":\"2825705_06_02_XR30_dataframes\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"To be efficient in data analysis, you need to ingest data sets in many formats, reorganize them into usable tables, and select subsets of their rows or columns. In this video, learn how to create DataFrames from Python data structures or from files; to inspect DataFrames; to extract and modify their columns; and to select data based on conditions\u2014the pandas version of fancy indexing, and the query method.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12008064,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The two key objects in pandas  \\n are the DataFrame and the Series.  \\n A DataFrame is basically a table of data.  \\n Each column has a name and an assigned data type as a NumPy.  \\n In addition though, the DataFrame has an index,  \\n which is not necessarily the ordinal number of the row.  \\n In this example, where the columns contain name,  \\n date of birth and city, the index could be  \\n the social security number or an alphanumerical employee ID.  \\n A Series is effectively a single column  \\n from a DataFrame with its own index.  \\n Having an index makes it more powerful  \\n than a simple NumPy array.  \\n For instance, if we have two time Series  \\n that have partially overlapping indices, times,  \\n we can still combine them and pandas will figure out  \\n which entries it can actually compute.  \\n Just as for NumPy arrays the easiest way  \\n to get a pandas DataFrame is to load it from a file.  \\n And pandas can read and write  \\n an even larger variety of formats than NumPy  \\n These include ASCII tables, json, Excel,  \\n the hierarchical data format HDF  \\n using many scientific application, SAS, SAS, Strata,  \\n Big data storage formats, such as Apache Feather and Parquet  \\n SQL and even HTML tables, which is great  \\n if you want to scrape data from a website.  \\n In this table, I show you the formats  \\n with the pandas functions that read and write them.  \\n Some of them may require the assistance of another package  \\n that you need to install separately.  \\n We start with a simple text file.  \\n Nobels.CSV, which contains a list of Nobel Laureates  \\n with a year in discipline  \\n in which they were awarded their prize.  \\n We can have a look.  \\n This is quite simple, the values are separated by commas.  \\n Pandas read CSV with this without breaking a sweat.  \\n We do need to provide names for the columns  \\n since the file itself doesn't have that information.  \\n Read CSV has many other options  \\n including specifying separators other than commerce,  \\n skipping columns or rows, converting dates and more.  \\n Let's look at the DataFrame.  \\n The method Info gives us basic information.  \\n And the method Head prints the first few rows,  \\n Tail the last.  \\n We have a total of 950 records.  \\n And we see that indeed the columns are named year  \\n discipline and the Nobelist.  \\n The data types are integer for the year  \\n and Python object for discipline and Nobelist.  \\n That's an important observation while in NumPy,  \\n we represent strings as fixed with runs of characters.  \\n In panda strings are effectively the immutable strings  \\n of Python, which are more versatile.  \\n As I mentioned, the index plays a very important role  \\n for data frames, but this one in particular,  \\n is a boring Numerical index.  \\n To grab the individual columns, which become Series,  \\n we use a dict like syntax with brackets,  \\n or a class like syntax with dot.  \\n Either way, the result is a pandas series,  \\n the object there represents a column.  \\n Consequently, the series has a name, ID type,  \\n and it carries with it the index of the original DataFrame.  \\n If we need a naked NumPy array of the values,  \\n we can still get it with dot values.  \\n Here's a small slice.  \\n Sometimes it's useful to get a list or really a NumPy array  \\n of all the unique values in a column.  \\n Other times, it's useful to have counts of the times  \\n each item appears.  \\n This accounting confirms that three scientists  \\n were awarded two prizes.  \\n To select records, we can use fancy indexing,  \\n building a Boolean expression that involves the columns.  \\n For instance, select the Nobels in Physics.  \\n Or you can use the convenient and fast Query Interface  \\n which takes a logical expression given as a string.  \\n We have to mind our quotes here making sure that we use  \\n single quotes for the query  \\n and double quotes for any values inside it.  \\n Sometimes it's not evident how to write  \\n a filtering operation.  \\n For instance, if we seek all the Nobelists  \\n whose name contain Curie, we like to write  \\n something like this, Nobel's fancy indexed by Curie  \\n in Nobel's Nobelist but that fails quite spectacularly.  \\n Instead we need to dig down in the string methods  \\n supported by the series to find Contains,  \\n which does what we need.  \\n The selection confers incredible winning streak  \\n of the Curie family.  \\n Marie her husband Pierre,  \\n her daughter Irine and her son in law Frederic  \\n Be sure how to create a data frame yourself.  \\n First from a NumPy record array.  \\n For instance, the David Bowie discography  \\n that we use as an example in chapter four.  \\n This is almost like cheating because NumPy record arrays  \\n are in fact the very back end of pandas.  \\n Nevertheless, the fixed length strings  \\n are converted to Python objects, when we get a DataFrame.  \\n Starting from scratch, we may build a DataFrame  \\n from a list of dictionaries, which means  \\n that we'll be repeating the column names over and over.  \\n Or from a list of tuples by providing names for the columns  \\n here title and top rank.  \\n Name tuples would also work great here.  \\n Otherwise, we can build the DataFrame in the other direction  \\n from a dictionary of vectors or lists.  \\n Here I'm just copying information  \\n from the NumPy record array to make actual lists.  \\n And then I feed them to DataFrame.  \\n We have DataFrames, let's move on to using them.  \\n Now that we know how to load or make DataFrames,  \\n let's do something interesting with them.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293505\",\"duration\":349,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Indexing in pandas\",\"fileName\":\"2825705_06_03_XR30_indexing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Once you have your data organized, you may need to find the specific records you want. In this video, learn how to index DataFrames with NumPy-like indexing, or by creating indexes. Also, explore powerful but confusing MultiIndexes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10651500,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We have seen how to load  \\n and create dataframes  \\n and how to select records based on boolean conditions  \\n both with fancy indexing  \\n and with a string expression-based query interface.  \\n Now we'll see how we can make selections even more directly  \\n and more efficiently using indices.  \\n So let's load up our Nobel list data set again.  \\n The index is currently the simplest possible  \\n just numbers from zero through 949.  \\n We elevate the years to serve as index.  \\n We do this with a set index method  \\n which does not work in place  \\n but other creates a new dataframe.  \\n Now the years appear as the index  \\n at the front of each row.  \\n And here's the index itself.  \\n This shows that in Pandas,  \\n indices do not need to have unique values.  \\n That's a feature, not a bug.  \\n It lets us select all records for a year, for instance,  \\n using the indexing notation  \\n and here things get a bit complicated.  \\n There are several ways to do indexing and slicing in Pandas,  \\n some equivalent to each other, some not.  \\n I'm going to show you the two interfaces  \\n that I think are the least confusing.  \\n To select all records for a given index,  \\n we use .loc followed by brackets, not parentheses,  \\n with the index value.  \\n For instance, 1901.  \\n We can also add a column name  \\n just as if we were selecting a cell in a numpy array.  \\n The result is a series.  \\n In addition to selecting individual index values  \\n .loc allows for slices.  \\n But in a break from Python new search,  \\n the range is inclusive of its end value.  \\n If we choose the years of the great war, 1914-1918,  \\n then 1918 appears in the selection.  \\n We are not limited to all micro-indices.  \\n We can set up a dataframe  \\n indexed by discipline, for instance.  \\n And it's always best to keep the index sorted  \\n which we do with sort_index.  \\n Then we can select not just individual index values,  \\n but also ranges, which again, are inclusive.  \\n So physics,  \\n or medicine through peace.  \\n Here there are 353 rows  \\n but Pandas is only showing us a few at the beginning  \\n and at the end.  \\n That's what the ellipses symbols mean in the middle.  \\n If you want numpy style indexing,  \\n looking only the progressive count of the records,  \\n you can have it with .iloc, again, brackets.  \\n Here we get the first 10 records, whatever they are,  \\n in the dataframe in its current order.  \\n But this is not the end of the story.  \\n Pandas supports multi indices.  \\n For instance, a dataframe indices nobelists by year first,  \\n and then discipline.  \\n It looks like this.  \\n The underlying index is a very complicated beast.  \\n But we can isolate the values set at two levels  \\n using, appropriately, get level values.  \\n Armed with this multi-index dataframe,  \\n we can select records by both year and discipline.  \\n Passing it two-pole to .loc.  \\n For instance, physics and 2017.  \\n Slicing however, can get complicated.  \\n Say we want chemistry prizes between 1901 and 1910.  \\n What we would like to do is to write a slice  \\n with a column in a two-pole.  \\n But Python doesn't allow that.  \\n How about we use the long-hand expression for the slice?  \\n Slice by indices start and end value.  \\n That's still confusing to Pandas  \\n because then it tries to use chemistry as a column name.  \\n What works is to request the set of columns  \\n explicitly in the .loc expression.  \\n In this case, all of them with a comma.  \\n Fancy indexing works also.  \\n Here, slice none means that we're taking all the years  \\n but we select a list of the disciplines.  \\n And again, all the fields.  \\n Finally, while multi-indexing is powerful,  \\n it can be confusing.  \\n And so you may have to resort to trial and error.  \\n Any selection that you make that way, however,  \\n you can also achieve without multi-indexing  \\n by using criteria on the values in the columns.  \\n For instance, chemistry prizes between 1901 and 1910.  \\n Where I have built a three boolean arrays,  \\n years are going to equal the 1901,  \\n years less or equal to 1910,  \\n and discipline equals equals chemistry  \\n and I have taken the logical end with the ampersand.  \\n Or again, with query,  \\n which lets me write the same selection  \\n in a more intuitive form.  \\n Note, however, that all these queries return new dataframes.  \\n So you cannot use them to modify values  \\n in the original table as you could do with the indices.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293506\",\"duration\":446,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Plotting\",\"fileName\":\"2825705_06_04_XR30_plotting\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In data analysis, you often need to transform tables by applying operations to one or more columns. Visualizing the transformed datassets is also crucial to understanding them. In this video, learn about the basics of performing mathematical operations and of plotting with pandas.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14191300,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We have seen how to load  \\n and create data frames, and how to select records  \\n or ranges of records, but we have not done much  \\n with the values in the tables.  \\n In many data analysis tasks, you're interested  \\n in running computations with the columns  \\n and then making plots.  \\n Let's try that with Pandas.  \\n We'll load the data set consisting  \\n of global population health and wealth statistics,  \\n from the amazing Gapminder website.  \\n Gapminder is a Swedish foundation created  \\n by the late Hans Rosling to promote a fact-based worldview  \\n and to fight misconceptions about global development.  \\n If you want to make plots in the Gapminder style  \\n internalize their data in some depth,  \\n you can try my LinkedIn learning course,  \\n Python Statistics Essential Training.  \\n In this video we'll do simpler things  \\n but still learn a lot.  \\n So we load the comma-separated file.  \\n And we see that the data set includes a number  \\n of global statistics.  \\n Each row identifies a country, a year,  \\n the corresponding region, and then they count us  \\n population, life expectancy, the percentage  \\n of children born alive who survive to age five,  \\n the average number of babies per fertile woman  \\n and the domestic product per person in 2011 dollars.  \\n We can ask Pandas to compute single statistics  \\n on all the fields.  \\n We do that with data frame describe.  \\n We see that there are almost 15,000 records  \\n in the data set for years ranging from 1800 to 2015.  \\n We can read off the minimum, maximum, mean,  \\n and standard deviation for all the fields  \\n as well as the 25th, 50th, and 75th percentiles.  \\n If you don't know about these don't worry.  \\n They give us an idea of the typical values  \\n and typical range of variation of a quantity.  \\n One of the points that Gapminder makes to great effect  \\n is that life expectancy improves with wealth,  \\n the Gross Domestic Product per person, GDP,  \\n and that the correlation is even clear  \\n if we look at the logarithm of the GDP per person per day.  \\n We don't have a column with that information,  \\n but it's very easy to compute it and to store  \\n it in a new data frame column.  \\n So we divide GDP per capita by the average number  \\n of days in a year, apply a non-pi log 10,  \\n and store that in a new column which then appears  \\n in the data frame.  \\n To see global trends as a function of time  \\n or to examine individual countries,  \\n it makes sense to index by year and then country.  \\n We will have two versions of the data frame  \\n with those two indices.  \\n Pandas has its own plotting interface  \\n which focuses on choosing the variables with which to plot.  \\n Say for instance we want to show life expectancy  \\n is a function of log GDP.  \\n So we select data for 1960 with dot log,  \\n and then generate a scatter plot of those two variables,  \\n it's sufficient to give the column names to Pandas.  \\n If we want to compare a more recent year in the same plot,  \\n we need to grab a map of lib axis object from the first plot  \\n and then pass it to the second.  \\n This is the kind of solution you find  \\n on http://www.stackoverflow.com.  \\n You should also change colors  \\n and label the two clouds of points.  \\n We see that in going between 1960  \\n and 2015, the dots flatten towards the top,  \\n towards higher life-expectancies.  \\n Thanks to significant progress  \\n in public health policy and practice.  \\n The trend is the same for other statistical indicators  \\n such as survival by age five.  \\n The data frame index by country lets us make easy plots  \\n of the chronological evolution of an indicator  \\n such as life expectancy for a country such as Italy.  \\n But the result is jumbled  \\n if we don't first sort the values by year.  \\n I'll do it here with sort values.  \\n The style of coding where I concatenate one Pandas method  \\n after the other is in fact quite idiomatic for Pandas,  \\n if not for Python.  \\n So when we say that Pandas speaks  \\n its own Python dialect.  \\n Here's a comparative plot for three countries.  \\n Again we grab the math.lib axis and pass them  \\n to the second or third plots.  \\n We see that Italy caught up with the United States  \\n in terms of life expectancy and China is coming close  \\n after the disastrous 1960 famine.  \\n Another interesting and important correlation  \\n was between fertility rate and survival to age five.  \\n To look at this question globally we can compute the average  \\n fertility rate over all records,  \\n that however doesn't mean much,  \\n since it misses data from many years.  \\n We can use the Panda's group by functionality  \\n to segment the data frame by year  \\n before computing the average.  \\n The result is a series indexed by year  \\n which shows the average fertility rate as a function of time  \\n and we plot it against age five survival,  \\n treated in the same fashion.  \\n The Pandas plot allows us to add a second axis  \\n on the right to show the range of the second variable  \\n that we plot.  \\n This shows forcefully that high natality  \\n is a consequence of infant mortality,  \\n and that women have many fewer children  \\n when they believe they will survive.  \\n On a small scale, we see that post 1950 baby boom.  \\n To gain even more insight we can create a pivot table.  \\n This segments the fertility means by both year  \\n and geographical region.  \\n Pandas is very happy to plot the resulting timelines.  \\n The drop in fertility came after the baby boom  \\n for Africa, America, and Asia.  \\n Europe was already low and decreasing  \\n since the beginning of the 20th century.  \\n And here's the corresponding plot for age five survival.  \\n Africa is now roughly where Europe was in 1950.  \\n Using Pandas plotting functions is the quickest way  \\n to make insightful statistical illustrations.  \\n But for maximum flexibility,  \\n you can always extract the values  \\n from the frames as non-pras  \\n and pass those to standard math.lib functions,  \\n which are fully customizable.  \\n There's a lot more you can do in Pandas,  \\n and there's a lot more to learn  \\n that I can cover in this course.  \\n I try instead to give you a feel  \\n for what is possible and practical.  \\n I encourage you to start working  \\n on a data set that interests you  \\n and to pick up more techniques and knowledge  \\n using the many resources available on the web.  \\n \\n\\n\"}],\"name\":\"6. pandas\",\"size\":38609237,\"urn\":\"urn:li:learningContentChapter:2293508\"},{\"duration\":1033,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2293507\",\"duration\":44,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Overview of use case\",\"fileName\":\"2825705_07_01_XR30_babyoverview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this chapter, practice pandas by analyzing the popularity of baby names in the U.S. as recorded by the Social Security Administration. In this video, outline your analysis goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1315728,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We are now going to apply pandas  \\n to an intriguing real world use case.  \\n We will analyze the U.S. Social Security Baby Name Catalog,  \\n which reports the names given to male and female newborns  \\n for every year since 1880.  \\n This is a very simple data set,  \\n but it's great fun to play with,  \\n and it has been mined, analyzed, and visualized  \\n in many publications and websites.  \\n Specifically, I will show you how to load it,  \\n how to track the popularity of a name across all years,  \\n and how to extract the 10 most popular names every year.  \\n Your challenge will be about finding  \\n the most common unisex names.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295365\",\"duration\":196,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading data sets\",\"fileName\":\"2825705_07_02_XR30_loadingbaby\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Using Python and its libraries, you can gather and organize data very efficiently. In this video, download compressed archives from the web, use Python to open them, load their contents, concatenate them into DataFrames, and save the resulting well-organized data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5780382,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] You can download the Social Security  \\n name data set from their website.  \\n But I have also included the archive names.zip  \\n in your exercise files.  \\n We need to uncompress it,  \\n which we can do in Python using the ZipFile module.  \\n The interface is object oriented.  \\n You first create a ZipFile object,  \\n then called extract all in the current directory.  \\n That's the dot.  \\n Jupiter lets us browse the contents  \\n of the current directory with ls.  \\n We see that names.zip,  \\n unpacked into a directory with many text files,  \\n presumably one for every year.  \\n Let's have a look at one.  \\n We open it in read mode  \\n and print out the first few lines.  \\n It's a very simple comma separated format.  \\n Name, sex, presumably F or M,  \\n and then the number of babies born that year with that name.  \\n Pandas read CSV shouldn't have any problems.  \\n But we did do something wrong.  \\n The first record in the file, Sofia,  \\n was used to set the names of the columns.  \\n We need to provide the column names explicitly,  \\n since they're not in the file.  \\n We've already done this for the Nobel data set.  \\n Better.  \\n We will need to load all the tables  \\n and concatenate them in a single data frame.  \\n To avoid confusing data from different years,  \\n we can prepare the individual data frames  \\n by adding a new column that specifies the year.  \\n To do it on the fly, directly from the output of read CSV,  \\n by chaining a method,  \\n we can use data frame assign.  \\n In this case, a new column year appears with value 2011.  \\n Excellent.  \\n We managed to load the file in a one liner,  \\n so you can see that I'm going to use a comprehension  \\n to concatenate all the data frames.  \\n There are several things happening here.  \\n So let's look at this carefully.  \\n We loop over all the years between 1880 and 2018.  \\n We build up the file name using an f-string,  \\n and feed that to read CSV.  \\n We specify the column names,  \\n and we add the column that gives the correct year  \\n from the loop variable.  \\n Finally, we pass all the resulting data frames  \\n to pd concat, pandas concat.  \\n You see there are no brackets here,  \\n so this is in fact a generator expression,  \\n not the comprehension,  \\n which pd concat accepts quite happily.  \\n It's a very efficient way to build a data frame,  \\n and it's all there.  \\n Almost two million entries.  \\n The year range is what we expect.  \\n We can save the merged data frame using to CSV.  \\n We don't need to say the index  \\n and if we specify a file name that ends in .gz,  \\n the resulting file will be automatically compressed.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295366\",\"duration\":260,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Comparing name popularity\",\"fileName\":\"2825705_07_03_XR30_popularity\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Organizing pandas DataFrames with the appropriate index is important to gain easy access to the records we seek. In this video, learn how to create a MultiIndex for your data set, sort it by index value, and compare the popularity of common and similar names by plotting the corresponding time series together. Parallel and stacked plots of timelines are often insightful visualizations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7870708,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We are ready to start analyzing this data.  \\n How we load and look  \\n at the combined data frame we just created.  \\n We want to examine the change in popularity of a name.  \\n So we need to reframe the data in a way,  \\n that will make this easier.  \\n We will use a multi-index.  \\n We will index the date on sex first,  \\n then name, and then year.  \\n And we will also sort the index.  \\n Getting the data for any given name  \\n is then a simple exercise  \\n of indexing with dot loc.  \\n For instance Mary,  \\n this series is ready to plot.  \\n Notice how Metro-lib automatically uses  \\n the index to set the x-axis.  \\n We see two peaks.  \\n At approximately 1920 and 1950.  \\n It probably makes sense also  \\n to consider the frequency of a name as a fraction  \\n of the number of babies born in a year.  \\n To get that, we can apply group by  \\n on the un-indexed data frame and take the sum.  \\n Then we can normalize Mary  \\n by all the newborns in every year.  \\n So as a percentage of all babies,  \\n Mary was actually more popular  \\n at the beginning of the 20th century.  \\n But there were altogether  \\n more Marys born in the 1920s and 50s.  \\n For simplicity, we continue with unnormalized counts.  \\n So let's make a generic function plot name  \\n to make a plot like this.  \\n In another function compare names  \\n to plot a few names together.  \\n You see that we pass a list of names through compare names.  \\n We look over the list called plot name for each of them  \\n and then add a legend, which is always good.  \\n Let's for instance compare Michael, John, David and Martin.  \\n Or for girls Emily, Anna, Claire and Elizabeth.  \\n It's already a popularity contest that we make in here.  \\n Another interesting investigations  \\n is to compare variance of the same name.  \\n For instance, there are two spellings of Claire.  \\n There's an older version Clara,  \\n and an Italian and Irish spelling  \\n for the pronunciation Ciara.  \\n Here's the plot.  \\n Notice how Metro-lib tries to put the legend out of the way.  \\n Claire is now dominant,  \\n but Clara is having a resurgance  \\n after having been the dominant variant  \\n at the beginning of the 20th century.  \\n We can make a slightly different cumulative  \\n or stacked plot that adds up the counts  \\n on top of each other.  \\n For that, we need a table of the frequencies  \\n for all the variance as a function of time.  \\n That would be an exercise in multi-indexing.  \\n We start by selecting all the Claires  \\n and then we can apply data frame and stack  \\n to move one of the index levels to a column name.  \\n In this case the year is level two of the multi-index.  \\n So the years become the columns.  \\n I must say that sometimes it's hard to make sense  \\n of what unstack does, so expect some trial and error.  \\n By contrast, unstacking level one  \\n would have made columns corresponding to the name variance.  \\n We can now try this stack plot.  \\n On the x-axis we will have the years  \\n just a simple range will suffice.  \\n And on the y-axis, the stacked values.  \\n This works but we see that the plot  \\n is truncated around 1974.  \\n That must be because of some of the Nans in the table,  \\n which do not lend themselves to be summed up.  \\n That's easy to fix  \\n with data frame fill and A.  \\n We'll replace the Nans with zeros.  \\n And here's the final plot.  \\n I have also added a legend,  \\n seeded by the labels given to stack plot.  \\n And I've restricted the x-axis,  \\n quite nice and informative.  \\n Except perhaps for the garish different colors  \\n chosen by map plot lib.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295367\",\"duration\":263,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Yearly top ten names\",\"fileName\":\"2825705_07_04_XR30_toptennames\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In many cases, you need to sort and subset DataFrames based on values rather than indices. In this video, find the top ten names over a range of years, which involves several pandas operations that are broadly useful.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8221776,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n we will create yearly top 10s for male and female names.  \\n We load the data, and this time,  \\n we index it slightly differently, by sex and year only  \\n since we will need to compare all the names in the database.  \\n We now build up a query by chaining pandas methods.  \\n Getting males in 2018  \\n is a simple matter of a multiindex.log.  \\n Then we get the most popular names  \\n by sorting our number in descending order.  \\n Head gives us a top 10.  \\n In 2018, Liam was king, followed closely by Noah.  \\n How about girls?  \\n We index sex with f, and the year is still 2018.  \\n For girls, it was Emma and Olivia.  \\n If we to build a table of the top 10 names  \\n over multiple years,  \\n we should get rid of the index with Reset Index,  \\n and select the name, Column Only.  \\n I will make this into a generic function.  \\n As I was saying, in pandas,  \\n one sees this operator chaining style often.  \\n And we can make the code clear  \\n by giving each method it's own line.  \\n It's a good idea, however, to add comments  \\n to explain what you're doing,  \\n either for your collaborators or your future self  \\n since pandas can be obscure.  \\n To form a table,  \\n we collect the series for different years  \\n as the columns of the data frame, labeled by the year.  \\n So in effect,  \\n we're creating a data frame from a dict comprehension.  \\n For males, you can see Liam gaining popularity  \\n and Jacob dropping.  \\n For females, we see that Emma has been dominant  \\n for a few years while Sophia dropped.  \\n Olivia is there, waiting to take the crown.  \\n How about the popularity plot for the 2018 top 10?  \\n For a change, we'll use the query interface,  \\n which conveniently lets us use the values of variables  \\n with the Add Notation.  \\n So here, we're passing sex and name to the function.  \\n And we select in All The Records  \\n where the sex column equals the sex argument,  \\n and the name column equals the name argument.  \\n This is not very pythonic,  \\n but it's nice to have once you know about it.  \\n Once we have the records, we plot number against year.  \\n So let's loop over the 2018 female top 10 and plot each.  \\n It's interesting to see  \\n that all the top names seem to have surged quite recently  \\n except perhaps for Evelyn, which was popular in the 1920s.  \\n As for the male names, two are classics, William and James.  \\n Let's look at the others then.  \\n This is the list, and I will copy  \\n a subset of it to the loop over which I plot.  \\n So now, I'm excluding William and James.  \\n And I see that, yes, the other eight  \\n have also been recent discoveries.  \\n How about all-time favorites?  \\n We get there quickly by selecting females, say,  \\n grouping by name, summing the numbers,  \\n sorting by the values, and then taking the top 10.  \\n Mary is in fact the all-time favorite among girls.  \\n If we look at the popularity over time of these names,  \\n we see that they've gained their spots  \\n in the first half of the 20th century except for Jennifer.  \\n Now that given the structure of the all-time f data frame,  \\n I'm looping over the index rather than the value.  \\n Next, you'll be asked to use what you learned  \\n in a challenge about unisex names.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295368\",\"duration\":63,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Unisex baby names\",\"fileName\":\"2825705_07_05_XR30_CH30_challenge3\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In the challenge, you are asked to identify unisex names and to plot their male/female distribution, by building on the code that you developed in this chapter.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1715937,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (playful music)  \\n - [Narrator] For your challenge,  \\n I would like you to find a top ten unisex names  \\n and to plot their popularity throughout the years  \\n for both the male and female usage of the name.  \\n We will define unisex names as those for which  \\n the total number of boys and a total number of girls  \\n born across all years and within a factor of two.  \\n That means that you're going to compute  \\n the total number of boys,  \\n divide by the total number of girls,  \\n and verify that that's between 0.5 and two.  \\n Given the technical nature of some Pandas computations,  \\n I have some hints for you.  \\n Try using DataFrame.groupby().  \\n Take advantage of the fact that Pandas  \\n can execute a mathematical operation between two series  \\n even if they have different indexes.  \\n And finally, if you need to drop not a number,  \\n nan values, use DataFrame.dropna.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295369\",\"duration\":207,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Unisex baby names\",\"fileName\":\"2825705_07_06_XR30_SO30_solution3\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6047873,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - As I mentioned already, in Pandas there are often  \\n several ways to get the same result.  \\n So if your results are similar to mine,  \\n but you get them in a different way,  \\n don't worry, your solution may even be better.  \\n We'll load our data set as usual.  \\n We need to compute the total number of boys and girls  \\n for a given name.  \\n This seems a good place to use group by,  \\n which lets us segment the data before applying  \\n an aggregation, in this case, the sum  \\n of the number of babies.  \\n So we use group by over sex and name,  \\n we select the number column and we take the sum.  \\n From this list with a multi-index,  \\n we can grab the males and females respectively,  \\n using dot lock.  \\n As you see, the two indices are going to be different.  \\n Epon doesn't appear in the females.  \\n Nevertheless, we can combine the two series  \\n and pandas will align the indices for us.  \\n The results would be none where either series  \\n doesn't have an element.  \\n For instance we check where the ratio between  \\n males and females is less than two.  \\n We can certainly get rid of those nones  \\n with drop in A.  \\n Now, remember the definition of unisex names  \\n as those with a ratio between .5 and two.  \\n This is a good expression for fancy indexing,  \\n and after we apply it,  \\n we see that 1660 names pass the test.  \\n Here, I've taken the index, because we don't actually need  \\n the ratio itself, but just the names.  \\n The next thing to do is to find the ten most common  \\n unisex names, so we sum the male and female counts  \\n using the unisex array to index our two totals.  \\n We sort the resulting series,  \\n and we cut it off at the top.  \\n Jessie seems to be the winner of this particular contest,  \\n followed by Reilly, Casey, and Jackie.  \\n Now to clock popularity, it's convenient to use  \\n a fully indexed data frame.  \\n We also remember to sort that index.  \\n Now we'll loop over the most common unisex names,  \\n which remember, are the index of the common series,  \\n and we plot by selecting male or female in the name.  \\n Matplotlib type layout helps improve the spacing  \\n of the subplots, while Jessie is the absolute winner,  \\n it appears to have fallen out of favor somewhat.  \\n Reilly is ascendant, but not for boys anymore,  \\n and Casey, which peaked around 1990,  \\n may be the most unisex name of all,  \\n with the male usage of the name tracking the  \\n female usage very closely.  \\n Great, we've been through a lot in this course,  \\n and I hope you've gained an understanding  \\n of what is possible with NumPy and Pandas and matplotlib,  \\n and more generally, with Python as a language  \\n for data analysis.  \\n I hope you'll go out to discover and learn  \\n even more and that you use Python happily  \\n in your every day work.  \\n \\n\\n\"}],\"name\":\"7. Use Case: Baby Names\",\"size\":30952404,\"urn\":\"urn:li:learningContentChapter:2295373\"},{\"duration\":58,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2294385\",\"duration\":58,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"2825705_08_01_LA30_NextSteps\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are many resources on the web that can help you master data analysis with Python and explore more advanced topics. This video suggests a few options.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12669699,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Well done.  \\n Thank you for following along  \\n through some rather challenging material.  \\n You are at the start of your road to mastery.  \\n You can now move on to my more advanced courses  \\n on programming efficiently in Python  \\n and on statistics with Python.  \\n Back to the topic of this course,  \\n here are some resources that can help you learn more.  \\n You can find the answer to any question about Python  \\n or about NumPy, Matploylib and pandas  \\n on the official websites.  \\n These packages are also discussed in  \\n \\\"Python Data Science Handbook\\\" by Jake Vanderplas,  \\n a very insightful and no-nonsense textbook.  \\n If you get stuck, look for help  \\n in an internet forum such as Stack Overflow.  \\n You'll find that Python has a very helpful  \\n and supportive community.  \\n Many have said that the best thing about Python  \\n is that it's a language that makes you happy.  \\n I agree so have fun and do great things.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":12669699,\"urn\":\"urn:li:learningContentChapter:2293509\"}],\"size\":310335127,\"duration\":9035,\"zeroBased\":false},{\"course_title\":\"pandas Essential Training\",\"course_admin_id\":4493047,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4493047,\"Project ID\":null,\"Course Name\":\"pandas Essential Training\",\"Course Name EN\":\"pandas Essential Training\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;pandas is an open-source data analysis library that provides high-performance, easy-to-use data structures, and data analysis tools for Python. In this intermediate-level, hands-on course, learn how to use the pandas library and tools for data analysis and data structuring with instructor Jonathan Fernandes. Take a deep dive into topics such as DataFrames, basic plotting, indexing, and groupby. To help you learn how to work with data more effectively, Jonathan guides you through a series of practical coding exercises that are based on the same large, public dataset.&lt;/p&gt;&lt;p&gt;Note: A basic working knowledge of Python is a prerequisite of this course.&lt;/p&gt;\",\"Course Short Description\":\"Discover how to work with the pandas library and tools for data analysis and data structuring.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":10223359,\"Instructor Name\":\"Jonathan Anand Fernandes\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Expert in Generative AI and Large Language Models\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-05-24T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/pandas-essential-training-24082178,https://www.linkedin.com/learning/pandas-essential-training-revision-fy-2024-q4\",\"Series\":\"Essential Training\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Data Science\",\"Primary Software\":\"pandas\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":11448.0,\"Visible Video Count\":42.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":44,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5916304\",\"duration\":44,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Welcome to pandas\",\"fileName\":\"4493047_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Use live action take 1 3rd atttempt\\n\\n4:20 time\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":260,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2257025,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Two things I'm totally into, coding and Python\\nand anything Olympics-related.\\nThe Summer Olympics, I don't do snow.\\nI've come up with a great way\\nto share these two passions with you.\\nWe'll work with data using Pandas.\\nIt's this awesome data analysis library\\nbuilt on top of Python.\\nAnd get this, we'll be using an Olympic\\nmedal winners data set.\\nI'm super excited\\nto dive into Pandas using this Olympics data\\nand see what kind of insights we can uncover.\\n\\nI think this might be the closest I get to an Olympic goal.\\nIt's going to be a blast.\\nPut on your coding hats\\nand let's crunch some numbers.\\nOn your mark, get set, let's go.\\n\"}],\"name\":\"Introduction\",\"size\":2257025,\"urn\":\"urn:li:learningContentChapter:5915595\"},{\"duration\":1082,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2719581\",\"duration\":222,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using Google Colab\",\"fileName\":\"4493047_en_US_01_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"exerciseFileUrl\":\"https://github.com/LinkedInLearning/pandas-essential-training-new-dataset-dupe-4493047\",\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":410,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This course uses Google Colab. After watching this video, you will be able to use basic functions in Google Colab.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6854987,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] You're going to love this course,\\nwe'll have loads of fun.\\nAnd regardless of how experienced you are with Pandas,\\nyou'll learn something along the way.\\nWe'll be building on material from each section,\\nso you really want to work your way in order\\nfrom the start to the finish.\\nSo head over to the course page\\nand you should find a section\\nthat says exercise files on GitHub,\\nand a link that says get files.\\nYou'll end up on a page that looks something like this.\\nSo what we'll want to do is just go ahead\\nand copy this link.\\n\\nNow when you do any coding, you need an editor,\\nso that's somewhere you write your code.\\nNow I've chosen to use Google Colab\\nbecause you don't need to install anything\\nand you can just see your code and your comments\\nand any visualizations you might have,\\nall in the same place.\\nSo you'll need a Google account,\\nso this is the same one that you might use for Gmail.\\nSo let's head over to Google Colab.\\nSo that's colab.research.google.com.\\nAnd because we're getting our code from GitHub,\\nI'm just going to select GitHub\\nand paste in the link that I copied earlier.\\n\\nSelect search.\\nSo this is the notebook that we want,\\nPandas essential training,\\nand so go ahead and just open this in a new window.\\nAnd this is going to be the notebook\\nthat we'll be using for our time together.\\nNow what's really nice about Colab, as I said,\\nis it allows you to have code and commentary\\nand visualizations all in the same place.\\nSo let me go ahead and enter a little bit of code\\nup at the top.\\nNow each of these sections are called cells\\nand I can go ahead and just hover over here\\nand insert a code cell or a text cell.\\n\\nSo let me go ahead and enter a text cell\\nand I'm just going to type a little bit of text\\nand I'm going to say the following cell\\nhas the year for the first Olympics.\\nAnd then when I'm done with that,\\nand I can go ahead and enter a code cell\\nstraight after that.\\nAnd then I can say year = 1896,\\nwhich is the year of the first Olympics.\\nNow, in order for me to get any output from this,\\nI actually need to run the cell,\\nand so there are a couple of options.\\n\\nI can go ahead and select the play icon over on the left,\\nand you can see I'm getting a message,\\nthis notebook is being loaded from GitHub and so on.\\nSo I'm going to go ahead and select run anyway,\\nand it's going to go ahead and run this code cell for me.\\nNow you can see it didn't return anything to us\\nbecause I haven't said that I want to be able to see\\nwhat those results are.\\nSo I can say year = 1896, and then enter a new line\\nand just put the variable for year over there.\\n\\nAnd you can see I get the output 1896.\\nSo if I wanted to calculate the next Olympics,\\nI could go ahead and just say year + four,\\nand then run this code cell again.\\nAnd you can see I get the result, 1900.\\nNow if you want, you can go ahead and just run\\na single cell, or you can go ahead up to the menu,\\nselect runtime, and run all the cells.\\nAnd that's about all you need to know about Google Colab.\\n\\nThe most important thing to remember with Google Colab\\nis to run the cells in order.\\nSo sometimes things don't work\\nbecause you might have run a cell lower down in the notebook\\nbefore you've run something that's higher up.\\nSo all you need to do in that case\\nis to just select runtime and run all,\\nand this will run all of the cells in the notebook.\\nSo we've seen how we're going to use Google Colab\\nas our code editor for this course,\\nallowing you to write code and comments\\nin the same workspace.\\n\\nAnd we'll be using this for the rest of this course.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5912592\",\"duration\":100,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What is pandas?\",\"fileName\":\"4493047_en_US_01_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":179,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"pandas is an excellent tool for data analysis. After watching this video, you will be able to describe the benefits of pandas.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2947014,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Presenter] Now, I'm assuming you're either\\na data scientist or a data analyst,\\nor you want to become one, and Pandas is definitely\\none of the tools you want to be good at.\\nYou can work with large data sets in a variety of formats.\\nSo, you've got spreadsheets and CSV files and databases\\nand all sorts of messy data sources\\ncoming at you from different directions.\\nOh, and Pandas got its name from panel data,\\nwhich is where you have data over multiple time periods.\\nNow, you can use Pandas to clean up, organize,\\nor manipulate data.\\n\\nSo you can focus on the fun stuff, like finding insights\\nand telling stories with your analysis.\\nAt its core, Pandas is all about working with tabular data,\\nso think of spreadsheets or SQL tables.\\nIt provides two main data structures,\\nthe series, like a single column,\\nand the data frame, like a table with rows and columns.\\nAnd Pandas can help you handle things\\nlike missing data or data in different formats,\\nbut that's just the beginning.\\nWith Pandas, you can slice and dice your data\\nin 100 different ways.\\n\\nSo you want to filter your data based on certain conditions?\\nEasy peasy.\\nDo you need to group and aggregate your data?\\nPandas lets you do that.\\nDealing with date and time data?\\nPandas is a pro at that too.\\nAnd the best part, Pandas integrates seamlessly\\nwith other Python libraries,\\nlike NumPy for numerical operations,\\nor Matplotlib for data visualizations,\\nand even machine learning libraries like Scikit-learn.\\nAlright, so we know that Pandas is great for data analysis.\\nYou can work with series, which is a column,\\nor a table, which is a data frame,\\nand it integrates with other Python libraries\\nfor visualizing data\\nor working with machine learning libraries.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5915594\",\"duration\":254,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using pandas\",\"fileName\":\"4493047_en_US_01_03_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":364,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Like other Python packages, pandas comes with great documentation. After watching this video, you will be able to access pandas's documentation.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11445562,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] You've probably come across the saying,\\ngive a man a fish\\nteach a man to fish and you feed him for a lifetime, right?\\nWell, that's exactly what we're going to do in this video.\\nI want to show you how to help yourself\\nby looking up any documentation you might need\\nwhen working with Pandas.\\nAnd it's all about empowering you to find the answers\\nto your questions any time you need them.\\nNow, Pandas, like many other Python packages,\\nis under constant development and has great documentation.\\nNow, one of the best ways to learn Pandas effectively is\\nusing this built-in documentation as your starting point.\\n\\nSo let's head over to the\\nnotebook and let me show you what I mean.\\nSo the first thing we're going to do is go ahead\\nand install Pandas.\\nNow I'm going to be using the version here.\\nSo that's Pandas 2.02.\\nAnd the reason I've stuck with this version is\\nbecause there's always going to be changes\\nand development work to Pandas,\\nand I want to make sure that the features\\nand functionality that I demonstrate are ones\\nthat are available with this specific version of Pandas.\\nNow you can see that there's an error over here\\nand you can ignore it because all it means is\\nthat the version of Pandas\\nthat we are installing is different to the one\\nthat's currently available on Google CoLab.\\n\\nSo like with any other Python package,\\nall you need to do is import it.\\nSo we're going to import Pandas.\\nNow, what you'll often find is that people use aliases.\\nSo you use the alias PD for import Pandas,\\nand so you can say import Pandas as PD,\\nand then this means that any further time you use Pandas,\\nyou can just use the alias PD instead of having\\nto type Pandas.\\nNow, let's just go ahead and confirm that the version\\nof Pandas that we've installed is 2.02, which it is.\\n\\nNow when I do a DIR with PD, I get a list\\nof the methods\\nand the attributes that are available in the Pandas package.\\nSo you've got things like is now, JSON, normalize,\\nand so on.\\nAnd you can see that there's an awful lot of attributes\\nand methods that are currently available in\\nthe Pandas library.\\nNow, if you ever get stuck\\nand you want to get a little bit more details about a\\nspecific attribute\\nor a method, you can go ahead and do a help.\\n\\nAnd then within those brackets you can do PD dot\\nand the name of the method or the attribute.\\nSo in this case, what I'm looking at is trying\\nto get some help on the Read CSV method.\\nNow this is one way you can look up the\\ndocumentation for Pandas.\\nAnother great way\\nthat's available within Google CoLab is you do pd.read_csv.\\nSo that's exactly the same method,\\nand then you have a question mark at the end.\\n\\nNow, I really like this one\\nbecause what happens is I can get my documentation over at\\nthe right hand side of my screen\\nand then I can continue to go ahead and work,\\nand then I can reference the documentation when I need it.\\nSo what you have here is the PD.read CSV,\\nwhich is the method name.\\nAll of these over here are parameters.\\nNow if I want to get into the details of these,\\nI just need to scroll down.\\nAnd so for example, I've got file path or buffer,\\nand I can get the details of what is involved there.\\n\\nWhat's also really helpful is I have a doc string,\\nand a doc string is a one\\nor two liner that tells me what this method does.\\nSo in this case, you can see that\\nthe pd.read CSV reads a comma separated values\\nfile into a data frame,\\nand it also supports optionally iterating\\nor breaking of the file into chunks and so on.\\nNow, the other place where you might want to go\\nfor documentation is in the official\\nPandas documentation.\\n\\nSo I've provided a link over here\\nand you can see that we've got the API reference guide,\\nand you can look up all of the methods\\nor attributes as you need them over here.\\nSo let's head back to our notebook.\\nSo you've seen the documentation for Read CSV.\\nSo go ahead and find another couple of methods\\nand attributes and read the documentation and try\\nand figure out what they do.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5917325\",\"duration\":506,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Reading tabular data into pandas\",\"fileName\":\"4493047_en_US_01_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":654,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This course uses the Olympics dataset. After this video, you will know how to download the dataset for this course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":26218949,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] One of the reasons I started using Pandas\\nwas that as part of my job,\\nI received these massive spreadsheets\\nwith thousands of rows and columns\\nand I needed to analyze them.\\nBut every time I tried to open it in Excel,\\nmy computer froze.\\nThe game changer when dealing with large datasets\\nwas Pandas and the Read CSV Method.\\nSo let's head over to our Notebook\\nand let's download our dataset.\\nNow in Google Colab, I can go ahead\\nand run a couple of commands using the Unix or Linux Shell\\nby having a exclamation mark at the start.\\n\\nAnd so what this is going to do,\\nit's going to use the wget command\\nand that's going to pull this dataset down.\\nNow, let's say I wanted to upload my own dataset, right?\\nThen I can go ahead and run this command.\\nNow the reason that I have these hashes in front of this\\nis that these means that these are comments.\\nAnd so these cells don't normally need to be run.\\nSo for example, if I have my own dataset\\nand I want to upload a CSV file here,\\nI could run this command or this cell.\\n\\nSo I can go ahead here and select Run Cell.\\nAnd what I need to do here then is just choose a file\\nfrom my computer and I can go ahead\\nand upload this into Google Colab.\\nSo let me just go ahead and select Cancel Upload.\\nNow what I can do is I can go ahead\\nand see whether that file is in Google Colab.\\nSo in Linux, if you want to be able\\nto see your current directory, you can do an ls.\\nAnd you can see that the file that I've downloaded,\\nwhich is the Olympics CSV file from 1896 to 2004\\nis available over here.\\n\\nSo let's go ahead and take a look\\nat the Read CSV Method again.\\nSo you can see that I've got a couple\\nof different parameters over here.\\nAnd the first parameter here is filepath or the buffer.\\nAnd so what I can then do is I can provide the filepath\\nto the Olympics CSV file over here.\\nAnd that's exactly what I've done here.\\nAnd so this allows me to open the CSV file.\\n\\nAnd so let me just make a little bit more space for myself.\\nAnd you can see that this is the file that's been open.\\nNow you can see that there's a whole load of NaNs,\\nwhich means it's not a number and so on.\\nAnd this doesn't seem to be a very easy\\nto use file in the current format.\\nSo let's take a look at the original file\\nto try and figure out why it looks like the way it does.\\nSo you can see that we've got a line\\nthat says Summer Olympic Games 1896 to 2004 and so on.\\n\\nAnd then you've got a whole load of Unnamed-1,\\nUnnamed-2, and so on.\\nSo let's look at the original CSV file\\nto try and make sense of it.\\nAnd you can see that that first line corresponds\\nto the first line that we have over here.\\nNow all of those NaNs correspond to the spaces\\nthat you have over here in each of these different columns.\\nSo what we need to do is to try\\nand figure out a way to actually ignore\\nthe first five rows when reading\\nthat file into Read CSV.\\n\\nSo the other option that I have is instead of specifying\\nthe file name like I did,\\nI can actually specify the parameter name,\\nso filepath or buffer, and use that instead.\\nAnd you can see that we'll have exactly\\nthe same output as earlier.\\nNow, often what I'll want to do\\nis I'll want to actually store the information\\nfrom that file in a variable.\\nSo in this case, I've called it OO,\\nthat corresponds to Olympics.\\n\\nAnd what I'll often do when working with Pandas\\nis I want to pick a two or three letter code that corresponds\\nto a data frame that I'll be using.\\nAnd the reason I do this is because\\nI know that I'm going to be using that data frame a lot.\\nAnd so I want to make sure that the name\\nof the data frame isn't very long.\\nSo this is the CSV file and this has been stored\\nin something known as a data frame, which is a table.\\nNow you see that we've still got the problem\\nwhere we've got a whole load of these NaNs.\\n\\nAnd as I said earlier, what we'll want to do\\nis we'll want to get rid of the first five rows.\\nSo let's go ahead and take a look\\nat the Pandas documentation and let's try and see\\nif there's an obvious way\\nwhere we can ignore the first five rows.\\nSo I'm going to just go ahead and take a look\\nat the different parameters over here.\\nSo there's a little bit of a description over here.\\nSo it's filepath.\\nSo I know that I've already used filepath\\nand that's the path to the file that I'm uploading.\\nSEP seems to refer to a delimiter,\\nso that's not what I need.\\n\\nThe header corresponds to the row number\\nthat I'm using as a column name,\\nso that doesn't seem to be what I'm looking for.\\nSo if I scroll down a little bit\\nand just take a look at the different parameters\\nthat's available, I see something\\nthat's looks quite promising and that's a skiprows.\\nAnd you can see over here at skiprows it's saying,\\nthe \\\"Line numbers to skip or the number of lines\\nto skip at the start of the file.\\\"\\nAnd that's exactly what I want,\\n'cause I want to be able to skip the first five rows,\\nbecause if you remember from that CSV file,\\nI want to be able to skip these five rows,\\nbecause I'm not able to get any\\nuseful information from there.\\n\\nAnd this is not relevant to the dataset that I need.\\nSo I can use that as another parameter.\\nSo I've got the original parameter, which is the filepath,\\nand now I've got this additional parameter\\nand I say skiprows=5.\\nAnd this is stored in the variable OO.\\nSo if I then look at what's stored in the variable OO,\\nI've got a much better output here.\\nAnd I have the column names,\\nso that's Year, City, Sport, Discipline, and so on.\\n\\nAnd then I've got the different rows over here.\\nNow another thing I often like to do\\nis to provide the name of the file.\\nAnd instead of having to keep using that filename,\\nI just store that again in a variable\\nand I just call that filename.\\nAnd then the next time I want to open that file,\\nI just need to head over to pd.read CSV,\\nand then I just say filename over here,\\nand it'll automatically enter the name of that file.\\nAnd so I've stored that in the variable filename.\\n\\nAll right, so we've taken a glimpse at the Read CSV Method,\\nwhich is your go-to method for opening any CSV file.\\nNow this is a really powerful method\\nand we could easily spend a couple\\nof hours just looking at all\\nof the available options over here.\\nSo let me just show you what I mean.\\nRight, so within Read CSV,\\nyou've got all of these different parameters\\nthat give you a variety of options of what you want\\nand what you can do with that CSV file.\\nSo I've got two really quick exercises for you to do.\\n\\nSo go ahead and use pd.read CSV and try\\nand figure out what the parameter SEP does.\\nSo SEP or SEP is this one over here.\\nSo pause the video here,\\nand I'll let you know what SEP does in a few seconds.\\nSo what SEP is all about is what delimiter to use.\\nNow, CSV or the CSV file extension stands\\nfor Comma Separated Values,\\nbecause each of the components in the file\\nare separated by commas.\\n\\nNow there are other files that are separated by tabs\\nor semicolons and so on, and you can specify\\nthat you're not going to be using your default comma,\\nbut perhaps you're going to be using a semicolon and so on.\\nNow, for the second exercise,\\ngo ahead and upload one of your own CSV files\\nfrom your computer and see if you can read it\\nin using the Read CSV Method.\\nAnd try an experiment with some\\nof the other parameter options.\\nSo what you'll want to do\\nis you'll want to uncomment these two lines.\\n\\nAnd then go ahead and run this cell,\\nand upload a CSV file from your computer.\\n\"}],\"name\":\"1. Technical Setup\",\"size\":47466512,\"urn\":\"urn:li:learningContentChapter:5911598\"},{\"duration\":3224,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5910589\",\"duration\":503,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Get an overview of the data and displaying it\",\"fileName\":\"4493047_en_US_02_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":658,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Many times you want to get an overview of the data, including displaying all of the rows. After watching of this video, you will be able to display data in different ways.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":19596788,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now one of the first things you'll notice\\nis that we've got this new cell over here.\\nAnd all I'm doing over at this cell is I am going\\nto go ahead and install Panda's version 2.02\\nif it's not already installed.\\nAnd then what I'm doing is I'm going to look for the file.\\nSo that's the Olympics 1896 to 2004 file.\\nAnd if it doesn't exist, I want to go ahead\\nand pull it down and then that's it.\\nAnd the reason I do this is because I don't expect you\\nto go through this entire course in one sitting.\\n\\nSo if you ever to come back to this course,\\nyou'll always be able to download the files that you need\\nby running this cell\\nbefore you go ahead and run that section.\\nSo let me go ahead and run this.\\nAnd let's go ahead and use our read_csv method\\nto store the values in oo.\\nAnd let's take a look at the first attribute\\nthat we're going to be looking at.\\n\\nSo it's oo.shape, right?\\nNow I use the word attribute\\nbecause it's very difficult to determine\\nwhether something is a method or an attribute, right?\\nSo if it doesn't have a bracket,\\nthen that means it's an attribute.\\nAnd so for example, shape is an attribute,\\nbut if it has an open and closed bracket,\\nthat means it's a method.\\nSo read_csv is a method, head is a method,\\ntail is a method, shape is an attribute.\\n\\nNow what's shape all about?\\nWell, let's go ahead and run the cell.\\nAnd you can see that the documentation tells us\\nin this doc string that this returns a tuple\\nrepresenting the dimensionality of the data frame.\\nSo what this means is that\\nthis specific dataset has 27,174 rows and 11 columns.\\nNow let's go ahead and take a look at the next method.\\nAnd so that's oo.head.\\n\\nAnd what the head method does\\nis it displays the first N rows,\\nand now by default you can see that it's five, right?\\nSo for example, if I wanted\\nto just display the first three rows,\\nI could just do oo.head and three,\\nand that's going to display the first three rows of my dataset.\\nAnd as you can imagine, we also have a tail, right?\\nAnd the tail will display the last five rows of my dataset.\\n\\nNow, head and tail are the most common ways of being able\\nto take a look at parts of your dataset.\\nBut what I prefer,\\nespecially if I'm working with a new dataset,\\nis to use oo.sample(5) or sample three,\\nwhatever the case might be.\\nNow, the reason I do this is especially if I'm working\\nwith a new data set,\\nI want to be able to try and see what I can expect\\nfor the different columns and the rows,\\njust so that I can get a better feel\\nof this specific new dataset that I'm working with.\\n\\nAnd so for example, you can see here\\nthat here I'm randomly given five rows from this dataset.\\nSo this is from row 14,595.\\nThis is row 14,842 and so on.\\nAnd so for example, if you want to be able to specify\\nand ensure that you're able\\nto get exactly the same rows every time\\nas part of your sample,\\nthen you can go ahead and set the random state.\\nSo if you could go ahead and look at the documentation\\nthat we have for random state, right?\\nAnd this, I can set a random state\\nand give it as a number like one,\\nand then every time I run the cell,\\nI'll get those same three or five rows.\\n\\nNow another method\\nthat you might be interested in is oo.info.\\nAnd this gives me information about how many entries\\nthat I have in my dataset.\\nSo I've got 27,174 entries or rows in my dataset.\\nAnd what's interesting about this\\nis that I've got a whole load of different columns, right?\\nAnd so I've got the column year,\\ncity, sport, discipline and so on.\\nAnd if you notice in the next column, non-null,\\nI don't have any missing information\\nbecause you can see that the information that I have here,\\nI've got 27,174 entries for the year,\\nfor the city, and so on.\\n\\nThe next column is the Dtype or the data type, right?\\nAnd so you can see\\nthat the year has a data type of integer,\\nwhich is what you'd expect, so int64,\\nand then you've got object\\nfor most of the other ones, right?\\nAnd that's because they correspond to text.\\nSo you've got city and sport and so on.\\nAnd then the final column,\\nwhich is position, has a data type of integer.\\n\\nLet's take a look at another entry, which is describe,\\nand you can see that describe\\nSo for example, you can get the mean values\\nfor the column, year, or position\\nand describe will give you these statistical values\\nfor the numeric columns.\\nNow, because we only have two numeric columns,\\nthat's why we're only able\\nto get information about the year and the position.\\nSo now that you've seen a couple of rows and columns,\\nI want you to pause this video\\nand in a couple of sentence,\\ntry and describe what this dataset is all about.\\n\\nAnd as soon as you're ready, I'll let you know\\nwhat I think this dataset is all about in a few sentences.\\nAll right, so this dataset is all about medal winners\\nin the summer Olympics from 1896 to the year 2004.\\nNow I know that there are both summer and winter Olympics,\\nbut because this dataset is all about the summer Olympics,\\nI'll just call this the Olympics dataset\\ninstead of stating it's the summer Olympics.\\nNow for each of the medal winners,\\nit lets you know which Olympics it is.\\n\\nSo the year, where it was held,\\nthe sport and the discipline\\nthat the Olympian took part in,\\nwhich country they represented\\nusing the Olympics three letter code,\\nwhat gender for the event.\\nSo was it only for males or females?\\nThe medal, so what medal the Olympian received.\\nWas it a gold, silver, or bronze?\\nAnd then finally, the position which corresponds\\nto the gold, silver or bronze medal.\\nNow before we wrap up this video,\\nlet me just show you really quickly how you can go ahead\\nand change the number of rows\\nand columns that you are able to view.\\n\\nSo I could use the get_option\\nand this will show me the maximum number of rows\\nthat is currently set.\\nSo by default it'll show you 60 rows.\\nBut if I wanted to be able\\nto see all of the rows for this dataset,\\nI can go ahead and set that to none.\\nAnd now I can view all of the rows of this dataset.\\nSo let me just go ahead and scroll all the way up.\\nAnd so you can see that I've got entries\\nfrom the 1896 Olympics in Athens\\nand I can scroll all the way down\\nand then make my way all the way down\\nto the entries from the 2004 game.\\n\\nSo I have the ability to take a look at\\nand to be able to view all of the rows\\nin my data frame if I want.\\nSo let me just go ahead\\nand set that back to the default of 60.\\nAnd I can also change the number of columns.\\nSo by default I can view 20 columns.\\nI'm going to leave it at that.\\nBy default, the width is 80 characters.\\nI'm going to increase that to 100\\nbecause you can see that some of the columns are quite wide\\nand I want to make sure\\nthat this is not going to overflow to the next row.\\n\\nAll right, so we've had a good overview\\nof what this dataset is all about\\nand how you can go ahead\\nand view different parts of this dataset as needed.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5910588\",\"duration\":291,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Select a Series (column)\",\"fileName\":\"4493047_en_US_02_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":365,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Another key data structure in pandas is Series. After this video, you will be able to describe a Series and select one from a DataFrame\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11322299,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] With pandas I have the option of being able\\nto select a single column or view a couple of columns.\\nSo let's head over to our notebook.\\nSo I'm just going to go ahead and run the first cell\\nand let's go ahead and get our data frame.\\nAnd let's view three random rows from this data dataset.\\nNow, if I take a look at the type of this variable, 00,\\nI can see that this is a data frame\\nand that corresponds to the entire table.\\n\\nNow, I can also view just one of the columns.\\nSo for example, if I just wanted\\nto view the column discipline,\\nI can just do an 00.Discipline within square brackets\\nand I can use a double quote,\\nor I could also use a single quote\\nand I'll get exactly the same response.\\nNow, what I can't do, and\\nso I'm just going to remove the comment over here,\\nis say discipline.\\nBut if the actual column name is a discipline\\nwith a capital D, use a lowercase discipline,\\nthat won't work.\\n\\nAnd you can see the key error is discipline,\\nbecause what we're expecting here\\nis a Discipline with a capital D.\\nNow if I take a look at the column discipline,\\nI can see that this is in fact a series.\\nNow, it just so happens that every time a series is added\\nto a data frame, the series\\nbecomes an attribute of that data frame.\\nAnd attributes in Python can be accessed by a dot notation.\\n\\nSo instead of having an 00\\nand in square brackets discipline,\\nI could just do 00.Discipline.\\nNow why would I want to do that?\\nIt just makes it easier and it just means\\nthat I need to type less.\\nSo I can also view all of the columns within this dataset.\\nAnd you can see that I've got all\\nof the column header names.\\nSo year, city, sport, discipline, and so on.\\nAnd let's take a look at athlete name.\\nSo I've got 00 and then in square brackets,\\nathlete name within double quotes.\\n\\nNow this is where the square brackets\\nand the dot notation vary.\\nIf my column name has a space in it,\\nthen I cannot use the dot notation.\\nSo if I was to go ahead and uncomment this and try\\nand view the column name, athlete name,\\nyou can see I get invalid syntax.\\nSo anytime a column name has a space, I'll need\\nto use the square bracket notation.\\nSo let's go ahead and take a look at a random three rows\\nand let's look at the method unique.\\n\\nAnd so what this is doing is for the column year,\\nit's giving me all of the unique values.\\nAnd of course this corresponds to all of the years\\nthat we had an Olympics game.\\nSo that's 1896, 1900\\nand so on, all the way up to 2004 in this dataset.\\nAnd I can go ahead\\nand check out the documentation for unique.\\nAs you can see that it returns unique values\\nof the series object.\\nAnd my series or my column name here is Year.\\n\\nI can do the same for Sport and this will give me all\\nof the unique sports within my dataset.\\nAnd then I also have something known as value counts.\\nNow, value counts for a series,\\nreturns a series containing counts of the unique values.\\nAnd so the resulting object will be in descending order.\\nAnd so you can see for example,\\nthat we have 2015 medals for the year 2000.\\n\\nWe have 1,998 medals for the year 2004 and so on.\\nNow, if I don't want to see the actual numbers,\\nbut I want to be able to normalize this, right?\\nAnd this is where I have the option\\nof having the relative frequencies,\\nI can provide the parameter normalize equals true,\\nand all of these values will add up to one.\\nAll right, so what we've been able to see here is to be able\\nto view or select a column from the data frame\\nand to be able to access it via a dot notation\\nor a square bracket.\\n\\nNow, if you're ever in doubt,\\nthen always use the square bracket\\nbecause you'll never run into any problems with that.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5912591\",\"duration\":55,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Fundamentals\",\"fileName\":\"4493047_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Needs Challenge Bumper\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":62,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1519100,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] I've put together some specific questions\\nabout this Olympics dataset.\\nNow this is an opportunity\\nfor you to get to know this dataset a little better.\\nNow you won't necessarily be able to answer\\nall of the questions just using pandas.\\nYou might need to use Wikipedia or a search engine too.\\nSo here are the questions,\\nso answer the following questions.\\nIndicate the pandas command where relevant.\\nSo what's the time range covered in this dataset?\\nThe Olympics takes place every four years.\\nWhy are there missing years,\\nand what are the types of medals awarded?\\nAcross all of the Olympic Games,\\nhow many gold, silver, and bronze medals have there been?\\nAnd why are there not an equal number of gold,\\nsilver, and bronze?\\nNow, you'll also notice\\nthat there are more gold medals than silver\\nand more silver than bronze.\\n\\nWhy might that be?\\nAnd what are the different NOCs\\nor National Olympic Committees?\\nAnd finally, what does the NOC ZZX represent?\\n\"},{\"urn\":\"urn:li:learningContentVideo:5911597\",\"duration\":376,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Fundamentals\",\"fileName\":\"4493047_en_US_02_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Needs Solution Bumper\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":612,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17255572,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Okay, let's head over to the notebook.\\nSo what's the time range covered in this dataset?\\nSo we can just use 00.Year.unique\\nand we can get all of the years.\\nThe second question is,\\n\\\"The Olympics takes place every 4 years.\\nWhy are there missing years?\\\"\\nNow, this is primarily because of the World War.\\nSo World War I broke out in 1914 and lasted until 1918.\\nAnd so that's why we don't have a 1916 Olympics\\nand the 1940 and the 1944 games.\\n\\nSo because of World War II, that lasted from September\\nof 1939 to September of 1945.\\nSo the next question is,\\n\\\"What are the types of medals awarded?\\\"\\nSo we can just use 00.Medal.unique\\nand you can see that we've got a Gold,\\na Silver, and a Bronze.\\nNow this is a really good data validation query here\\nbecause you want to make sure that the types\\nof metals are only going to be Gold, Silver,\\nand >Bronze, and nothing else.\\n\\nNext, \\\"Across all of the Olympics, how many Gold, Silver,\\nand Bronze medals have there been?\\\"\\nNow you'll want to use value counts here.\\nSo, 00.Metal.value_counts,\\nand you can see that there have been 9181 for Gold,\\n9014 for Silver and so on.\\nNow, \\\"Why are there not an equal number of Gold, Silver,\\nand Bronze medals?\\\"\\nNow, there are a couple of reasons for this.\\nSo there could be tide results in some events leading\\nto the award of multiple medals of the same type.\\nOr there could be team events,\\nso this is where all the team members receive medals,\\nand this can potentially skew the distribution based\\non the number of participants in these events.\\n\\nOr there could be disqualifications\\nand adjustments that need\\nto be made in the metal distribution.\\nSo this is after the events have concluded.\\nNow you'll notice that, \\\"here are also more Gold medals\\nand Silver and more Silver than Bronze.\\nWhy might that be?\\\"\\nWell, to answer this question,\\nlet me give you a couple of examples\\nand a couple of fun facts from some of the earlier Olympics.\\nSo if we take a look at the men's 100 kilometer cycling,\\nand we'll be able to see that over here\\nby just looking at the first 10 rows.\\nSo what I'm referring\\nto here is the 100 kilometer cycling event,\\nwhich is the first two entries over here.\\n\\nYou can see that we've got only a Gold\\nand a Silver, but no Bronze.\\nAnd if you wanted to get into some of the details of this,\\nyou can head over to Wikipedia\\nand you can see here that there were\\nin fact these two winners.\\nSo Leon Flameng and Georgios Kolettis of Greece,\\nand you can take a look at all of the participants.\\nNow, what's quite amusing is\\nfor this 100 kilometer cycle race,\\nthere were in fact only two winners\\nand the rest of the participants didn't finish.\\n\\nBut we also had a couple of people who helped\\nto act as pacemakers.\\nAnd for example, you have Paul Masson from France\\nwho was a pacemaker to Leon,\\nand we've got a couple of others who didn't finish.\\nNow these Olympics are full of fascinating facts.\\nSo if I take a look at Aristidis\\nand look at the entry in Wikipedia for his race,\\nthis is an absolutely fascinating view\\nof what actually happened.\\n\\nSo we can see there's an entry\\nfor his success in the 1896 race.\\nAnd what's really amusing is that the race was done\\nwith the help of pacemakers.\\nAnd some of the sources say\\nthat he finished the race on a pacemakers bicycle\\nbecause his bicycle had broken down.\\nAnd other sources say that he finished the race\\nwith a bicycle from a spectator.\\nSo there's obviously a whole lot of stuff\\nthat's taking place in these early Olympics\\nthat we would not see.\\nAnd as our final example,\\nlet's take a look at the men's 100 meter freestyle.\\nSo that's the Gold and Silver.\\n\\nYou can see that there is no Bronze metal winner here.\\nAnd let's take a look at what information there is\\non this particular race on Wikipedia.\\nSo this is really amusing.\\nSo for the Men's 100 meter freestyle Game,\\nso this is presumably a photo from the event.\\nThe men's 100 meter freestyle was one\\nof the four swimming events in the swimming\\nin the 1896 summer Olympic Games.\\nAnd the first and second winners were\\nfrom Austria, Hungary, which we know.\\n\\nSo that's Alfred Hajos and Otto Herschmann.\\nAnd what's really amusing about this race\\nis that the swimmers,\\nso this is again very different from the swimming\\nthat we have today.\\nThe swimmers were taken out by ship into the bay\\nwhere they'd swim towards the shore\\nand boys marked the starting line\\nand you were able to determine the end of the finish line\\nbecause there was a red flag there.\\nNow, what's also quite amusing is that we've got a couple\\nof swimmers who were entered into the race,\\nbut for whatever reason, we only have results\\nfor the Gold and the Silver.\\n\\nAnd so we don't really know what happened\\nto the rest of the swimmers.\\nSo the next question is about the different NOCs\\nor National Olympic Committees,\\nand we can get that easily by\\nusing the NOC column and unique.\\nAnd so for example, we have the three letter code\\nfor the National Olympic Committees.\\nSo we've got France, Greece, USA and so on.\\nNow what does the NOC \\\"ZZX\\\" represent?\\nNow, clearly we can't determine this from pandas.\\n\\nSo if we were to head over to Wikipedia,\\nwe can get some interesting historical facts\\nabout these Olympics.\\nSo the IOC grouped results under the mixed team designation,\\nso that's ZZZX, and this is where the early Olympic games\\nallowed for individuals in a team\\nto be from different nations.\\nAnd so we have an interesting scenario\\nwhere we've got teams from France\\nand England working together over here\\nand other examples in some of the other events.\\n\\nNow this data set is full\\nof other such interesting stories and history.\\nAs a final challenge,\\ngo ahead and explore this a little more.\\nIf you find some really interesting fact\\nabout this Olympics data set,\\ngo ahead and post it on LinkedIn and tag me.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5916303\",\"duration\":122,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Python lists and dictionaries\",\"fileName\":\"4493047_en_US_02_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":159,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3708291,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] If you want to take your pandas skills\\nto the next level, one of the things you'll want to do\\nis to make sure you've got the basics of Python covered.\\nSo medals here is a list,\\nand lists are ordered collections of things.\\nNow, we can create a new list by using square brackets,\\nand inside those square brackets,\\nwe put each of the items that we want our list to contain,\\nand they're all separated by commas.\\nSo you've got Gold, Silver, Bronze.\\nNow, I can confirm that this is a list\\nby using the method type.\\n\\nAnd you can see that I've got\\nconfirmation that this is a list.\\nNow, list can contain any type of object.\\nSo each item in a list doesn't need to be of the same type.\\nSo you could have a string and an integer, and so on.\\nBut in practice, lists usually have the same type of object.\\nNow, lists are also fine with duplicate items,\\nso it doesn't matter if we're adding a value\\nthat's already in our list.\\nAnd lists in Python are normally used\\nfor storing items in a particular order.\\nFor example, the column names of the table.\\n\\nThe other structure you'll want to know about\\nare dictionaries.\\nAnd dictionaries are all about mapping keys to values\\nor mapping one item to another.\\nSo in this instance, we have a dictionary called position,\\nand we're mapping First to Gold,\\nSecond to Silver, and Third to Bronze.\\nAnd I can confirm that this is a dictionary\\nby using type again, and you can see that I've got\\na response of dict.\\nAnd the real purpose of dictionaries\\nare to make it easy to look up the value\\nthat corresponds to a particular key.\\n\\nSo for example, I can take a look at First,\\nand if I want to try and determine what First maps to,\\nI can do position, which is the name of the dictionary,\\nand First, and I'll get the response back being Gold.\\nAll right, so lists in Python\\nare used for storing items in a particular order.\\nFor example, the column names of the table.\\nAnd dictionaries are great\\nif you want to map things together.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5911596\",\"duration\":356,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Rename a Series (or column)\",\"fileName\":\"4493047_en_US_02_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":429,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Sometimes you need to rename a column in a DataFrame. In this video, learn how to give columns new names.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15136661,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] I'm sure you've worked with spreadsheets\\nwhere the column headings were just really unhelpful things\\nlike col_1, col_2, and so on,\\nand it doesn't tell you anything about\\nwhat that heading or that column's all about.\\nNow if you just rename those column names\\nwith something that's more descriptive,\\nit becomes significantly easier\\nto work with this kind of spreadsheet.\\nSo let's take a look at a couple of ways\\nthat we can rename a series or a column in our dataset.\\n\\nSo what I want to do here is I want to be able\\nto map or rename athlete name\\nso that it has Athlete_Name\\nand event gender so that it becomes Event_Gender.\\nNow one of the reason I might want to do something like this\\nis because this will then allow me to use a dot notation.\\nSo I have my mapper, which is a dictionary,\\nand let's take a look at the rename method.\\nAnd you can see that the purpose of the rename method\\nis to rename columns or index labels.\\n\\nAnd one of the options available within rename is columns.\\nSo this is where you provide your mapping as a dictionary.\\nSo for example, I could say, oo.rename and then columns=,\\nand then provide my dictionary, which is mapper.\\nAnd now you can see that I've got the athlete\\nwith Athlete_Name and Event_Gender.\\nAnd let's go ahead and just take a look\\nat a random three values.\\n\\nAnd you'll notice that the athlete name\\nand the event gender have gone back to the previous values\\nand this is because we need to be able\\nto save those variables back to itself.\\nSo if you go back to the rename method,\\nyou can see that what's returned by this method,\\nwhich is under the section called returns,\\nis it returns either a dataframe or none.\\nSo it returns a dataframe with the renamed axis labels\\nor none if in place equals true.\\nSo what I'm going to go ahead and do here is I'm going to say\\nthat I want it to return a dataframe\\nand so I have oo = oo.rename\\nand I provide the dictionary over here\\nand you can see that I get the athlete name\\nand the event gender with the underscore values here.\\n\\nNow what I can also do\\nis I can chain these methods together.\\nSo what I'm doing over here is I first read in the CSV file\\nand then I change it by using a dot\\nand then the method rename.\\nAnd this is going to first read in the file\\nand then the next thing it's going to do\\nis to rename the columns\\nbased on what we have in the dictionary.\\nAnd this allows us to achieve exactly the same output\\nas we had previously.\\n\\nNow instead of specifying the dictionary\\nor the mapping as a separate variable\\nlike we've done here with mapper,\\nI could just specify a dictionary directly over here.\\nAnd so I say columns =,\\nand then provide the actual mapping that I want\\nand I'll get exactly the same response\\nand the same results as earlier.\\nNow the other thing you could do is also if you want,\\nyou can go ahead and take a look at all of the headings\\nand you can see that this is a list.\\n\\nSo we've got year, city, sport, discipline and so on.\\nAnd if I wanted to go ahead\\nand rename the column names,\\nI could go ahead and change this\\nby modifying the column names\\nso that I have Athlete_Name and Event_Gender.\\nAnd so now I say oo.columns\\nwhich corresponds to the headers\\nand I can say oo.columns = column_names\\nwith the changes that I have to my column names.\\nAnd you can see that this achieves exactly the same results\\nas using the rename of the columns earlier.\\n\\nAnd so this means that I can go ahead\\nand make those changes when I read in the file.\\nSo I'm reading in the CSV file\\nand I'm providing the changes to the column names\\nby providing the names parameter =column_names.\\nNow the problem here is that row zero is over here\\nand this is the old column name.\\nYou can see that this is the old column name\\nbecause we've got a space here.\\nSo Athlete Name and Event_Gender.\\n\\nAnd to get around this, we need to say header=0\\nbecause just providing a names=columns_names,\\nI'm going to have an additional row,\\nwhich is the old column names.\\nAnd so if I have both names=column_names,\\nwhich is my list of the updated columns, and header=0,\\nI get the results that I want.\\nSo just to recap,\\nif you want to rename the columns\\nwhile reading in the file names,\\nyou need to remember two things,\\nprovide the column names as a list to the parameter names,\\nand you must have header=0.\\n\\nAll right, so we've seen a couple of different ways\\nof renaming the column names.\\nSo how can you decide which one you should use?\\nWell, if you're just renaming one of the column names,\\nthen you're probably better off\\njust using a Python dictionary\\nand mapping the old column name to the new one.\\nIf you want to make changes to several of the columns,\\nthen you're probably better off\\njust specifying the new column names just as a list\\nand making the changes there.\\nWhen working with a list option,\\nI always display the current column names,\\nfor example, oo.columns,\\nand then use that as my starting point.\\n\\nSo what I mean by that is\\nif I head over to here, oo.columns,\\nI always display that over here.\\nAnd this way I'm less likely to make a mistake\\nwith forgetting a column or misspelling something.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5915593\",\"duration\":519,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Remove a Series (column) or row\",\"fileName\":\"4493047_en_US_02_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":682,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Deleting unnecessary columns is key to working with data. In this video, learn how to use pandas's drop() function.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":20046300,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Narrator] Imagine you're working on a project\\nwhere you've gathered data from multiple sources,\\nand now you have this massive data frame\\nwith columns upon columns of information.\\nAnd some of it's relevant,\\nbut some of it might just be redundant data.\\nThat's where the drop method comes into play.\\nNow, why drop and not delete or remove?\\nThat's because drop comes from database terminology.\\nNow, in our collab notebook,\\nlet's take a look at the drop method.\\nNow, the first thing to remember\\nis that in Pandas, we always refer to rules\\nor the index as having an axis of zero\\nand the columns as having an axis of one.\\n\\nNow, I think the position column is pretty useless\\nbecause I already have gold and silver and bronze\\nto know what position the medalists have.\\nSo let's go ahead and remove it.\\nNow, because position is a column,\\nI need to specify that the axis is one.\\nAnd so if I go ahead and do that,\\nyou can see that the position column\\nis missing from this data frame.\\nRight now, if I was to go ahead and uncomment this line,\\nand if I say axis equals zero,\\nso that means I'm specifying a row\\nand then I specify position,\\nyou can see I get an error\\nand it says key error, position is not found in axis,\\nso I need to make sure\\nthat I'm specifying the right direction.\\n\\nSo is it a column or a row?\\nBecause positions are related to columns,\\nI need to make sure that I always have an axis equal one.\\nSo let's go ahead and take a look at our data frame again.\\nNow you'll notice that position is back, right?\\nSo we obviously haven't dropped it.\\nAnd the reason we haven't dropped it\\nis because when we make these changes\\nor when we go ahead and drop a column from a data frame,\\nwe need to update our data frame.\\nAnd so we need to say, oh, drop\\nand then pass that to our data frame here.\\n\\nAnd so now you can see\\nthat the position column has been removed.\\nNow what I can also do is I can chain\\na couple of commands together, right?\\nSo what I could do is I could read the CSV file in\\nand then knowing that I'm going to get rid of the position,\\nI can chain the drop method\\nand it's going to go ahead and drop the position column.\\nSo let's take a look at that\\nand you can see that we've got rid of the position column.\\nNow what I can also do is I can do this chaining,\\nbut I can do it across multiple rows\\nby having all of the commands within these brackets.\\n\\nSo for example, I have pd.read_csv as my first line.\\nThe second line is drop,\\nand then I've got the sample as my final line.\\nNow, the reason why I'd want to be able\\nto order my chaining in this way,\\nis because I've got a whole load of steps\\nor instructions here.\\nAnd so that way I can troubleshoot very easily\\nand understand that each row corresponds\\nto a specific instructional step.\\nAnd so you can see here that I've got\\nexactly the same output as earlier,\\nwhere I'm getting rid of the position column.\\n\\nNow, let me just go ahead and demonstrate\\nhow you can actually troubleshoot that.\\nSo now, if I just wanted to go ahead\\nand troubleshoot these lines,\\nI could add a comment in the second line,\\nand this will show me\\nmy entire data frame with the position.\\nAnd then if I wanted to add that line again,\\nI could uncomment that line.\\nAnd then this will go ahead\\nand read the CSV as the first line.\\nAnd then the second line or that second step,\\ngo ahead and drop the position column.\\nNow, if you've used Pandas before,\\nyou're probably thinking\\nthat you can also use the in place parameter option instead\\nof having to pass my data frame back to the variable OO.\\n\\nAnd so I can do that here, and you're absolutely right,\\nbut I prefer not to use in place.\\nSo let's go ahead\\nand just take a quick look at the documentation for drop.\\nAnd so we've got exactly the same output as earlier.\\nSo we're displaying the CSV file,\\nwe're going to drop the column,\\nand then we have in place equals true,\\nand that gets rid of the position column.\\nNow if I take a look at oo.drop,\\nnow the reason that the in place works\\nis because what's returned is either the data frame,\\nand this is what I return to the variable oo\\nor the data frame oo,\\nor I can have a return of none,\\nand then in place equals true.\\n\\nNow, the reason I suggest you don't use in place\\nis because it doesn't allow for chaining.\\nSo when I go ahead and try and run this command,\\nso I've got these multiple steps across multiple rows,\\nyou see that I end up with an attribute error,\\nnone type, object has no attribute sample.\\nAnd the reason for this\\nis because this step is going to return a none.\\nAnd so it doesn't allow me\\nto do chaining when I use in place equals true.\\n\\nSo you're much better off just not using in place\\nand just returning the data frame.\\nAnd so you'll get a result like this.\\nNow, I can also go ahead and delete rows.\\nSo I specify that the axis equals zero,\\nand if I wanted to get rid of the row with index equals two,\\nso this one over here,\\nI specify that index number and axis equals zero.\\nAnd you can see that we've got rid of the row too.\\n\\nI can also get rid of a couple of rows.\\nAnd the way I do that is I provide the index numbers\\nfor all of the rows that I want to get rid of in a list.\\nSo I want to get rid of zero, one, and three.\\nI say axis equals zero.\\nAnd you'll be able to see\\nthat we now get rid of rows zero, one, and three.\\nNow what I can also do is I can go ahead\\nand delete a couple of the columns.\\nSo I can say that I want to get rid of city and sport,\\nfor example, and I need to specify that axis equals one.\\n\\nAnd in just the same way,\\nI need to provide that information in a list.\\nAnd let's go back to our original state\\nwhere we've gone and dropped the position column.\\nLet's talk a little bit more about why using\\nin place equals true is not a good idea.\\nSo Pandas encourages a method chaining approach,\\nso where you can add\\nand apply multiple operations, one after the other.\\n\\nSo using in place equals true\\nbreaks this chain as I've shown you earlier.\\nAnd that's because the in place method\\ndoesn't return a reference to the data frame.\\nAnd so it makes it impossible\\nto chain further operations directly.\\nNow, the second reason\\nwhy you probably don't want to use in place equals true\\nis because it's not available in several Pandas methods\\nlike merge, for example.\\nSo let's just take a look at the merge documentation.\\nNow, if you go ahead and take a look\\nat all of the parameters,\\nyou'll find that there is no in place here.\\nAnd it's exactly the same case for the pd.concat again,\\nwhich is another popular method.\\n\\nAnd if you scroll through,\\nyou'll find that there's no in place there or group by.\\nAnd these are three really popular methods in Pandas,\\nand none of them have the in place option.\\nNow, if you're still not convinced,\\nthe third reason I suggest you don't use\\nan in place equals true is because it makes a debugging code\\nthat much more difficult because it modifies data in place\\nand it can make it way more challenging.\\nSo if something goes wrong after an in place operation,\\nyou've lost the original data frame,\\nand it makes it harder to understand\\nwhat changed or what went wrong.\\n\\nAnd the final reason I suggest you don't use\\nin place equals true is for future proofing reasons.\\nThere's been some discussions in the Pandas community\\nabout deprecating, that means not supporting\\nthe in place parameter in future versions of Pandas.\\nSo while it's still available,\\nrelying on it might mean that you might have to make changes\\nto your code if Pandas decides to phase out this feature.\\nSo for these reasons,\\nmany Pandas users and the community at large\\nrecommend avoiding in place equals true,\\nand you can use the assignment operations instead,\\nwhich are clearer, they're more consistent,\\nthey're more flexible.\\n\\nAnd we'll do this for the rest of this course.\\nOkay, we've covered a lot in this video.\\nSo let's do a quick recap.\\nWe can use the drop method to remove series.\\nNow, if you want to remove a row,\\nthen we have axis equals zero.\\nAnd if you want to remove a column, then axis equals one.\\nAnd I hope I've convinced you\\nnot to use in place equals true.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5917324\",\"duration\":226,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Filtering rows for a single condition\",\"fileName\":\"4493047_en_US_02_08_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Add pause animation at 3:56\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":342,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Boolean indexing allows you to filter based on certain conditions. After watching this video, you will be able to demonstrate how to use boolean indexing.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8041955,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] One of the reasons I switched\\nto Pandas was because I was working\\non these really large data sets at work,\\nand I could do it efficiently.\\nNow, one of its most useful features is the ability\\nto filter row based on specific conditions.\\nThis way, you and I can focus on the data that matters most.\\nSo here's a whole load of operators\\nand the associated symbols.\\nTake a quick look at the operators\\nand the symbols here,\\nand make sure that you memorize them\\nso that you can use them quickly when you need to in Pandas.\\nAnd now let's take a look at an example in our notebook.\\n\\nSo this is our sample data frame with no position column.\\nNow, if I want to go ahead\\nand take a look at what the type is for true,\\nyou can see that it's a Boolean, or a Bool.\\nAnd in exactly the same way, the type\\nfor a false is also a Bool.\\nSo if I go ahead and take a look at the year,\\nand I want to try and determine what the type\\nis for the year, you can see that that's an integer.\\n\\nSo this means if I want to be able\\nto compare the year with a specific year,\\nbecause it's an integer, I need to just specify that number.\\nSo what I'm doing here is I'm saying oo.Year,\\nso that's filtering all of the years that are 1896,\\nand I'm assigning that to the variable first_olympics.\\nAnd what's happening under the hood\\nis that for that series, year,\\neach of the values are being assigned a value\\nof true or false based on whether\\nthat specific entry is 1896.\\n\\nSo I can go ahead and apply that condition in my data frame.\\nAnd because the condition is creating a series of Booleans,\\nwhich is exactly the same link as the data frame,\\nyou are able to then get all\\nof the corresponding components\\nin the data frame where the year is 1896.\\nAnd you can see that these are the first couple\\nof entries and these are the last entries,\\nand all of them have the year 1896.\\nSo instead of having to have this across multiple steps\\nwhere I'm having a first Olympics\\nand so on, I can just specify that condition within oo.\\n\\nAnd so I can say oo, and then the condition\\nthat I used, and I'll get exactly the same result.\\nNow, I can also go ahead\\nand try a couple of other conditions.\\nSo let's say I want to try\\nand see all of the years that are less than 1896.\\nSo I want you to pause the video here,\\nand explain why we have no information in our data frame.\\n(offbeat uplifting music)\\nSo the reason that we have no entries\\nin the data frame\\nis that the first year in our dataset is 1896.\\n\\nOur condition here is asking for any years\\nthat are less than 1896.\\nSince that doesn't exist,\\nthere are no entries in our data frame.\\nNow, instead, if we change the condition, so that's the year\\nand less than or equal to 1896, then we'll be able\\nto see all of the entries from the data frame\\nthat correspond to that first year, or 1896.\\nAnd we can confirm that that's the case.\\nNow, just a tip that I often will use\\nis that if I have a single condition,\\nwhat I'll often do is include the condition within brackets.\\n\\nAnd the reason I do that\\nis because when it comes to having multiple conditions,\\neach of these conditions need to be in these brackets,\\nand this just ensures\\nthat there won't be any problems if I decide\\nto include a couple of other conditions further down\\nthe road.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5917323\",\"duration\":246,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Filter rows for multiple conditions\",\"fileName\":\"4493047_en_US_02_09_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":311,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Boolean indexing allows you to filter based on more than one condition. After watching this video, you will be able to demonstrate how to use boolean indexing for multiple conditions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9911320,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In the previous video,\\nwe looked at filtering a row based\\non a single condition.\\nNow let's take a look at multiple conditions.\\nSo we've got our data frame with no position column,\\nand let's take a look at the data types for all\\nof the series or all of the columns in our data frame.\\nAnd in particular, let's look at city.\\nNow because city has a type object,\\nthat means it's most likely going to be a string.\\nAnd so if I want to do a comparison\\nor I just want to capture all of the cities that are Athens,\\nI need to make sure that it is within\\nsingle or double quotes.\\n\\nAnd you can see that I've got a data frame here with\\nall of these city entries being Athens.\\nNow, just to show you,\\nso let me just go ahead and un-comment this.\\nIf I didn't use the single\\nor double quotes Athens, I'll get an error.\\nAnd I've got a name error because Athens is not defined.\\nSo Pandas is expecting you to have a string there for city\\nbecause it's of a type object.\\nNow I can combine a couple of conditions\\nand you'll notice that each\\nof the conditions are within these brackets.\\n\\nSo I want the year to be 1896\\nor the year to be 2004.\\nAnd again, you can confirm that the first couple\\nof years are 1896 and the last couple of years are 2004.\\nSo if I wanted to make sure that that's in fact the case,\\nI could always just chain a unique\\nand you'll be able to see that I've only got two entries,\\n1896 and 2004.\\nSo you can see that I've got an attribute area here\\nbecause the data frame object has no attribute unique.\\n\\nAnd so what I need to do is I need to specify that I want\\nto determine the unique values for the series here.\\nAnd so if I go ahead and just add here,\\nwhich is now a series,\\nI've got just the values for 1896 and 2004.\\nSo here I've got the city is Athens and the year is 2004.\\nNow the reason I have that is\\nbecause Athens hosted the Olympics twice.\\n\\nOnce in 2004 and once in 1896.\\nSo there are a couple of ways that I can specify\\nthat I want the city's Athens\\nand the years 2004, I can say Athens and year equals 2004\\nor city equals Athens,\\nand not the year 1896, which is the other year\\nthat Athens hosted the Olympics.\\nSo just a word of warning about these conditions.\\nMake sure that they are clear\\nand as future proof as possible.\\nSo this means that if they're going to be possible future\\nconditions such as Athens hosting the Olympics again,\\nthen we don't want any future data to break some\\nof the conditions that we have over here.\\n\\nLet's take a look at another example.\\nSo we want to get the year 1896.\\nSo what we have here is the a hundred meters\\nOlympic sprint for men.\\nAnd you can see that our data frame has captured that here.\\nAnd we've got two bronze medals.\\nSo there was a tie for the bronze medals\\nand then you've got a gold and a silver.\\nNow if I just want to be able to see a couple\\nof these columns, so just say I want to just see the year\\nand the athlete's name, the country they represented\\nand the event and the medal, I can do that\\nby including the columns that I want in a list.\\n\\nAnd so now I'm not displaying the entire data frame,\\nbut just the columns that are specified in the list.\\nAnd I can also do that by specifying\\nor by taking the original data frames\\nof first men 100 meters\\nand then specifying the columns that I want to display.\\nAlright, so we've seen that we have a lot of flexibility\\nwith matching multiple conditions in Pandas.\\nThat's really important to remember\\nthat if you have multiple conditions,\\nthat each of the conditions are enclosed in bracket.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2719580\",\"duration\":272,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using String methods\",\"fileName\":\"4493047_en_US_02_10_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Add pause animation at 4:45\\nAdd pause animation at 6:08\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":430,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"str methods allow you to clean and transform your data easily. After watching this video, you will be able to use many of the methods available in str.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10714613,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] If you want to work with lots of text data,\\none of the skills you'll need to pick up really quickly\\nis cleaning and transforming text data.\\nThe pandas str methods are perfect for this.\\nIf you take a look at the athlete names in our dataset,\\nthe surname is in capitals followed by the first name.\\nSo I can use the str methods in pandas to change that.\\nAnd so I can go ahead and change all of the athlete names\\nto lowercase,\\nand you can see that it's done that for the entire column.\\n\\nAnd I can do exactly the same thing for the events.\\nSo I could go ahead and take all of the events\\nand you can see that some of the events\\nare lower case at the start and some of them have uppercase.\\nSo if I wanted it to be a little bit more consistent,\\nI can ensure that the first letter is capitalized\\nand I can use the str.capitalize for that.\\nAnd if I go ahead and take a look at all of the values now,\\nso if I go ahead and do a unique here,\\nyou can see that the first character\\nhas been capitalized for all of the events.\\n\\nNow what I'll need to do\\nif I want to make sure that this is saved,\\nis I need to take the oo event, for example, str.capitalize,\\nand apply that to oo.event,\\nso that's actually stored in the column event.\\nAnd then that way those changes are permanent.\\nNow one way to determine\\nwhat's possible with the str methods\\nis to do a dir of the str methods.\\n\\nSo the oo.event is the Pandas series.\\nAnd then I want to do a dir of all of the methods\\nthat are going to be available here.\\nAnd you can see that I've got a whole load\\nof different options available to me,\\nthings like casefold and cat and count and decode and so on.\\nNow, Larisa Latynina has the most medals\\nof any female athlete in Olympics history\\nwith a total of 18.\\nShe competed for the Soviet Union\\nin 1956, 1960, and 1964.\\n\\nSo if I was to go ahead and do\\na oo athlete name.str.contains, what's happening here is\\nthat it's doing a comparison for every single entry\\nin that series, athlete name,\\nand determining whether that name contains Latynina.\\nAnd if it does, you get a true and if it's not the case,\\nyou get a false.\\nNow I want you to pause the video here\\nand try and explain to me why we get no results back.\\n\\nEven though I've specified\\nthat within the athlete name column,\\nit should contain Latynina.\\n(upbeat music)\\n(gentle music)\\nNow her name is Larissa Latynina,\\nand if you remember from this dataset,\\nthe surname is always capitalized.\\nAnd because her surname was not capitalized here,\\nit doesn't match the conditions,\\nand that's why we have no entries here.\\nNow if I change her surname to all capitals,\\nI'll be able to see all of the medals that she has won.\\n\\nSo the str methods are your go-to\\nif you need to transform your text data.\\nSo now as we wrap things up,\\nSo dir.oo.event.str will give you all of the methods\\nthat are available,\\nand go ahead and make all of the city names\\nin capital letters.\\nSo go ahead and pause the video again\\nand I'll give you the answer in a few seconds.\\n(upbeat music)\\n(gentle music)\\nSo if I want to make those changes to the city\\nand I want to make those permanent,\\nI need to apply that to oo.city.\\n\\nAnd the str method I'm looking for is upper.\\nAnd if we take a look at the city names here,\\nyou can see that in our random sample of three,\\nwe've got all of them as upper.\\nAnd I can go ahead and confirm that for all of the cities.\\nSo, 00.city.unique.\\nAnd you can see that all of the city names\\nare now in uppercase.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2719578\",\"duration\":258,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Sorting a DataFrame or Series\",\"fileName\":\"4493047_en_US_02_11_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":429,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"sort_values() allows you to sort values along either axis. After watching this video, you will be able to demonstrate how to use this method.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12305256,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] If you've found yourself staring\\nat a jumbled mess of data,\\nwishing there was an easy way to bring order to the chaos,\\nthen the sort_values method is your friend.\\nYou can arrange your data alphabetically\\nor numerically to start with.\\nSo this is our DataFrame with three random indexes or rows,\\nand let's sort by the athlete name.\\nAnd you can see that we're sorting by the surname,\\nand so we've got Edgar and Arvo Ossian and so on.\\n\\nNow let's take a look at what the type is for this output.\\nAnd you can see visually that this is a series.\\nNow what you can also do is to sort by athlete name\\nfor the entire DataFrame.\\nSo you do oo.sort_values\\nand then you specify which column you're looking to sort by.\\nAnd here, you can see, again,\\nthat we've got the entire DataFrame here\\nand we're sorting by the athlete names that we saw earlier.\\n\\nSo that's Abbye, Edgar and Aaltonen, Arvo and so on.\\nAnd you can see that this is in fact a DataFrame\\nand you can confirm that visually\\nbecause this looks like a table.\\nSo let's take a look at the first couple\\nof entries in our DataFrame,\\nand what I could do is I can sort in reverse order,\\nso I say sort_values and I say ascending=False,\\nbecause by default, ascending=True.\\n\\nNow you might be a little bit surprised\\nbecause you're not seeing any results\\nor athlete names that start with a Z,\\nand this is because of Unicode.\\nNow Unicode is an encoding standard,\\nand all of the letters and numbers and symbols\\nand emojis are assigned a Unicode code point,\\nwhich is a number.\\nAnd so when you use sort_values, it uses these numbers,\\nand so this O with an umlaut, so Ostrand,\\nhas a higher value than the letter Z,\\nwhich is why it appears after.\\nSo I'll prove this to you\\nby displaying the first 25 entries,\\nand you can see that we've got a couple of other names\\nwith the umlaut, so we've got Ostmo and so on.\\n\\nSo if we take a look at the first 25 entries,\\nwe can see that we've got all of the names with the umlauts\\nwhich have the higher Unicode values,\\nand then we've got the Latin Z and so on.\\nNow, I can also sort first by one column,\\nso I can sort first by year, and then by athlete name.\\nAnd so we've got all of the entries from the first Olympics,\\nso that's 1896, and then sorted by the athlete name.\\nOr I could sort by year and athlete name\\nand then specify what order I want,\\nso I actually want descending for the year\\nand I want ascending for the athlete name.\\n\\nAnd so I specify a True or a False\\nfor each corresponding column by providing that in a list.\\nLet's take a look at the first seven entries.\\nSo what I can do is I can sort by the year first\\nand then the event,\\nand then I can sort by the medals.\\nBut I want to sort by the medals\\nin the reverse order, right?\\nBecause I want to be able to see the ones that are first gold\\nand then the ones that are silver,\\nand then the ones that are bronze.\\n\\nAnd so I'm sorting by year and then the event,\\nand then quite annoyingly,\\nI have silver before gold, followed by bronze.\\nAnd the reason for this is that it's sorting the medals\\nby alphabetical order.\\nBecause if you remember,\\nif we take a look at the data types,\\nMedal is a string.\\nSo it's sorting\\nby the alphabetical order rather than the order\\nof the medal, as in gold is higher than silver,\\nwhich is higher than bronze.\\n\\nAll right, so we've seen the power of sort_values\\nand it's very easy to have a variety\\nof different combinations,\\nand so go ahead and experiment with sort_values\\nand make sure that you are happy with ascending\\nand descending orders\\nfor different columns in your DataFrame.\\n\"}],\"name\":\"2. Fundamentals of Working with pandas\",\"size\":129558155,\"urn\":\"urn:li:learningContentChapter:5916305\"},{\"duration\":4707,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5914609\",\"duration\":308,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with data types (dtype)\",\"fileName\":\"4493047_en_US_03_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":404,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"pandas has a variety of different data types. After watching this video, you will be able to describe them and compare the benefits.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11152985,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] What really winds me up when working\\nwith data are errors about data types.\\nNumbers are treated like characters\\nor strings, years have a decimal point\\ninstead of just being an integer.\\nSo we're going to get to the bottom of this by understanding\\nhow dtypes or data types in pandas work.\\nSo we've got our data frame 00\\nand let's take a look at the different types\\nfor the columns.\\nAnd so you can see that year has a data type of integer 64,\\nand all of the others are of type object.\\n\\nAnd this normally means that they're strings.\\nNow categoricals are a pandas data type, corresponding\\nto categorical variables in statistics.\\nSo a categorical variable takes on a limited,\\nand it's usually a fixed number of possible values.\\nSo for example, you have things like medals and gender\\nor event gender.\\nLet's take a look at some of our columns.\\nYou can see that medal, for example,\\nhas gold, silver, or bronze.\\nAnd this is a great data validation technique\\nbecause you want to make sure\\nthat your medals are only going to be gold, silver, and bronze\\nand no other category.\\n\\nSo what we can do is we can assign the medal column\\nto the categorical or category type,\\nand we do that by using the astype method.\\nSo we say O0.Medal.astype category,\\nand then we assign that to medal.\\nNow when we look at the columns, you can see\\nthat now medal has a data type of category.\\nNow in the same way where we've got gender\\nand we've got two types, men and women,\\nand we've got event gender, so that's M and X and W.\\nSo that's men, women, and where there are mixed teams for X.\\n\\nSo let's go ahead and change all of these\\nto a category type.\\nAnd so now you can see we've got gender\\nand event gender and medal as categories.\\nAnd let's take a look at medal.\\nAnd if we were to take a look at the series, you can see\\nthat this is now off type category with bronze\\nand gold and silver.\\nNow, what if we wanted to actually order our categories\\nbecause we want to make sure\\nthat gold is considered better than silver,\\nwhich is considered better than bronze.\\n\\nBecause if we take a look at this category type over here,\\nit's all sorted alphabetically.\\nYou can see that bronze is first,\\nand then you've got gold and then silver.\\nBut we want to make sure that we've got gold which is better\\nthan silver, which is in turn better than bronze.\\nSo if we take a look at the categorical method,\\nand let's take a look at the definition.\\nSo you've got categoricals can only take on a limited\\nand usually fixed number of possible values.\\nAnd we know that these are the categories,\\nbut it seems to be that there's also an option\\nof ordering them.\\nSo order is defined by the order of the categories,\\nand if we scroll down, you can\\nprovide the different categories as a parameter,\\nand then you can specify that you want them to be ordered.\\n\\nSo by default it's false.\\nAnd so all we need to do is just flick that flag to true.\\nSo I can provide the medal order here,\\nand it's important that I specify the order correctly here.\\nSo I want bronze to be at the bottom\\nand then followed by silver and then gold.\\nAnd then I specify that order equals true.\\nAnd so now if I take a look at the column medal, right?\\nI've got all of the different types and let me just go ahead\\nand take a look at medal.\\nSo I'm just going to do 00.Medal.\\n\\nYou can see that I've got gold is greater than silver,\\nwhich in turn is greater than bronze.\\nSo in a previous video we were trying to sort the medal so\\nthat we first had the gold followed by the silver\\nand then the bronze, but we were not able to get this\\nto work because we were representing the medals as strings.\\nNow that we've got the medals as categories, this allows us\\nto order them in that way.\\nSo what we can have here is we have this first by year,\\nthen by event, and then we want to reverse the order\\nfor medals so that we first see the gold\\nand then the silver, and then the bronze.\\n\\nAnd you can see that that's the case here.\\nSo we've got the year 1896, all of these are year 1896.\\nThen sorted by event.\\nSo you've got the 100 km cycling event followed\\nby the 100 meters and so on.\\nAnd then you can see that we first got the gold,\\nthen the silver, and then the bronze.\\nNow before you think that categories are the next best thing\\nto sliced bread, they're also very fragile.\\nIt doesn't take much to move a column\\nor a series back to an object type\\nfrom a categorical variable.\\n\\nSo if you combine different columns\\nor have missing values, these all can result\\nin your column moving back to an object type.\\nOkay, so we've seen that categorical variables take\\non limited values, and previously we weren't able\\nto sort medals by their position,\\ngold being higher than silver, being higher than bronze\\nbecause they were represented as strings.\\nNow that they're represented as categories, we're able\\nto order them in the way that we want.\\nBut be careful with categorical variables,\\nthey're very fragile\\nand you can easily move back to an object type.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5916302\",\"duration\":276,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Memory usage of dtypes\",\"fileName\":\"4493047_en_US_03_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":379,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10296507,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Different data types\\nare represented differently,\\nand so some of them will take up less space\\nin memory than others.\\nLet's take a look at how things fare\\nwith the categorical variables.\\nNow this time I'm storing the Olympics dataset\\nin a data frame called DF, but I'm not doing any\\nof the processing that we've done so far.\\nSo if you'll notice we have the different data types.\\nSo most of them are of type object and then only year\\nand the column position are integers.\\n\\nNow if you take a look at the data frame\\nthat we've been working with all along, so that's OO,\\nlet's just try and compare the different data types here.\\nAnd you can see that we've got a couple\\nthat are category which we assigned in the previous video.\\nWe've got a couple of integers,\\nand then most of them are of type object.\\nNow if you remember, categoricals are a pandas data type\\ncorresponding to categorical variables and statistics.\\nSo they have a limited number of possible values,\\nbut let's take a look at what difference that makes in terms\\nof the memory usage.\\n\\nSo if you want to take a look at the documentation,\\nyou can go ahead and check that out here.\\nSo what I'm going to do is I'm going to compare the memory usage\\nof the data frame OO, which is the one\\nthat we've been using all along, versus the data frame DF\\nwhich is the one that doesn't do any\\nof the processing that we've done.\\nSo you can see for example that with DF,\\nthe metal type is an object.\\nWhile as with the OO data frame,\\nthe metal type is a category\\nand there's a significant difference in the amount\\nof memory that's used.\\n\\nSo this uses 27,000 bytes while this uses\\njust under 1.7 megabytes when representing it as an object.\\nAnd in fact, if you were to compare the two,\\nthe memory usage\\nof the metal data type when it's represented\\nas a category is only about 2% that\\nof when it is represented as an object.\\nNow if you were to go ahead\\nand compare the other categorical variables,\\nso things like gender and event agenda\\nwith these two different data types.\\n\\nSo OO being a category type and DF being an object type,\\nyou can see that we've got a similar amount\\nof memory savings.\\nSo it definitely makes sense to consider using categories\\nwhen working with larger data sets\\nbecause you'll get the memory saving\\nand the response time will be much quicker in terms\\nof querying datas.\\nNow another thing that's worth considering is in general,\\nwe know that object data types are typically string,\\nbut what if we could actually assign them\\nor be explicit about them being a string type?\\nAnd so we can do that by using the as type method.\\n\\nAnd so we can assign some of the object types as string.\\nSo for example, we do that to city\\nand you can see that city is of type over here.\\nAnd if you were to take a look at a sample\\nof the data frame, and let's go ahead now\\nand update all of the other object types\\nand make them of type string where they were of type object.\\nLet's just take a look at our current state of things\\nbefore I make that change.\\n\\nSo that's OO dot D types with an S.\\nAnd you can see that most of these are object type.\\nAnd so what we're going to do is we're going to change all\\nof these which have an associated type of object to string\\nand we assign that to the corresponding column\\nand you can see that now they're all string.\\nAnd then if you were to do a comparison of the amount\\nof savings that we have in terms of memory,\\nwhen we represent the column city\\nas a string type versus an object,\\nand you can see that there isn't any difference\\nwhen a column such as city is represented as a string\\nor as an object, but I still prefer\\nto keep it as a type string just\\nto be a little bit more explicit about things.\\n\\nAlright, so categoricals have the advantage\\nthat they take up less space in memory\\nand then all those strings don't seem to take up less space.\\nI prefer to define them as strings\\nand just to be more explicit\\nrather than having a type called object.\\nIt also reminds me that I can always manipulate them\\nusing the SDR methods.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5917322\",\"duration\":216,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining dtypes when you read in a file\",\"fileName\":\"4493047_en_US_03_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":337,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"You can also specify the dtypes in advance of reading in a file. After watching this video, you will be able to define dtypes when reading in a file.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7261736,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Imagine if someone handed you\\na toolbox for a job,\\nbut didn't tell you what each tool was for.\\nYou might figure it out eventually,\\nbut it'll be a lot of trial and error, right?\\nSo that's a bit like loading your data into Pandas\\nwithout specifying Dtypes.\\nToday we're going to crack open that toolbox\\nand show you exactly which tool\\nor data type is right for each job,\\nmaking your data analysis\\nthat much smoother and faster.\\nJust as a quick reminder, our current data types\\nare int 64 for the year,\\nand then everything else is an object.\\n\\nSo we're going to use a dictionary\\nand we're going to map each of the different columns\\nto the data type that we want.\\nSo we will have year as in 64, we'll have city\\nas string and so on.\\nNow, just for the sake of completeness, I've specified\\nthat a year should be in 64,\\neven though that's the case by default.\\nAnd so if we take a look at our dictionary,\\nwe can see we've got the mapping that we want.\\nNow we can go ahead and apply that.\\nNow, previously we used the categorical method.\\n\\nWe can go ahead and use the categorical Dtype method.\\nAnd this will allow us to specify the ordering\\nthat we would want when reading in the data as our file.\\nAnd so you can see that we've got the categoricalDtype,\\nwe've got them in the order that we want,\\nso bronze and then silver, and then followed by gold.\\nAnd we then specify that metal type is not only a category,\\nbut it's ordered metals\\nwhere we specify the order that we require.\\nAnd that's the only one of the categories\\nwhere we actually require an order.\\n\\nSo now we're ready to read our CSV file in.\\nSo we've got our CSV file, our file name,\\nand that's where we use the parameter Dtype\\nand we provide our mapping.\\nNow, if we take a look at our Dtypes,\\nhopefully we should see the mapping\\nthat we specified earlier.\\nAnd you can see that we've got integers followed\\nby strings and so on.\\nBut we do have one event gender,\\nwhich is still an object.\\n\\nNow remember I warned you earlier\\nthat these category types can be very fragile.\\nSo in this case, it's not obvious\\nto me why we have an event gender type,\\nwhich is still an object\\nbecause if I take a look at the unique values,\\nso that's oo event gender, and then unique.\\nI've only got these three categories, M, X, and W.\\nSo, what I'm going to do is I'm going to again read in\\nthat CSV file along with the Dtype mapper that I specified.\\n\\nBut because I have event agenda as of type object, I'm going\\nto hard code that as a category by specifying\\noo event gender as type category.\\nAnd this should allow me to then have the event gender\\nas type category.\\nSo let's just confirm that that's the case.\\nAnd we can see that by specifying\\nthat the event gender is of type category for a second time,\\nthat seemed to have fixed the problem.\\nAlright, so you can see that we can define the data types\\nwhen reading in the files,\\nbut I also warned you\\nabout how the categorical data types can be very fragile.\\n\\nAnd we saw an example of this in this video\\nand how we were able to fix that.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5910587\",\"duration\":290,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Python functions\",\"fileName\":\"4493047_en_US_03_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":395,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11154153,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] By now you're probably thinking\\nwe're having to do a fair bit of tweaking of our dataset\\nand I hope I don't forget any of the steps,\\nwe needed to remove the position column,\\nwe then needed to specify the different types of data types.\\nSo once I find that I'm having to reuse\\na whole load of code,\\nthe best solution is to define functions.\\nSo let's take a really quick look at Python functions.\\nSo functions allow you to make reusable code\\nand these can be called later.\\nSo you define a function by specifying the def keyword,\\nand then functions can have inputs,\\nso these are in the form of arguments,\\nand so that's whatever comes after this bracket.\\n\\nAnd then the output from the function\\nis in the form of a return value\\nand that's whatever's followed by the return statement.\\nSo in this case, we have the function called show_df,\\nso that's show data frame.\\nThe argument is the file name Olympics 1894,\\nand so on, CSV file.\\nWhat we're doing in the function is to read in that CSV file\\nand store it in this variable called df,\\nwhich is our data frame,\\nand we then go ahead and return that data frame.\\n\\nSo if we wanted to call this function,\\nwe do it by specifying the function name,\\nso you got show_df and then using these\\nopen and close brackets.\\nSo this will call the show_df function.\\nAnd the purpose of the show_df function\\nis to just return that data frame.\\nAnd you can see that you're able to view that data frame\\nbecause that's what's been returned by the function.\\nNow what type is returned by the function?\\nAnd you can see that that's a data frame\\nand that's what we were able to see earlier.\\n\\nSo if we take a look at all of the steps\\nthat we're trying to automate,\\nso specifying the different data types\\nfor the different columns,\\nso we've got that in dtype_mapper,\\nwe've got the ordered medals and so on.\\nThe other thing we were trying to do\\nwas also to drop the position column.\\nSo we can combine all of these steps in a function,\\nand I've called my function pre-process,\\nand my argument is the file name,\\nwhich is the CSV file that we're using.\\n\\nI could just provide file name without the actual file name.\\nAnd then I would always need to provide the file name\\nwhen I call that function.\\nBecause I know I'm only going to be using\\nthis one file for now,\\nI provide that as a variable over here,\\nso that that's going to be the default variable.\\nAnd that just means that I don't need\\nto keep specifying pre-process,\\nand then Olympics_1896_2004.CSV.\\nSo that's just a shortcut.\\nSo this is my pre-process function.\\nThis is the bits that we're trying to automate\\nor that we're doing a couple of times.\\n\\nSo it's the ordered medals, specifying the data types,\\nand then dropping the position column.\\nAnd then all we need to do\\nis to just return that data frame.\\nYou can see that we've got the output that we would expect.\\nWe'll obviously need to check the data types\\nto make sure that those changes have been done.\\nNow if we just call the function in this way,\\nit's returned that data frame.\\nBut now ideally we want to save the data frame\\nin a variable like we've done all along.\\n\\nSo if I was to go ahead and do oo,\\nso oo is going to save the data frame\\nthat is going to be returned by the pre-process function.\\nAnd we'll be able to see the sample\\nthat we've seen in our videos.\\nNow let's just confirm that the pre-process function\\nhas in fact gone and changed the data types\\nfor all of the columns as per the definitions\\nin the pre-process function.\\nAnd you can see that we've got int64 strings and so on.\\n\\nWe still have that problem with the event gender\\nand that's because I didn't specify that\\nor I didn't include that as part of the function.\\nSo all I need to do now is to go ahead\\nand hardcode that again\\njust like we did in the previous video,\\nand we will then be in a position to have our data types\\nin the format that we want.\\nSo it's really important that when you define a function\\nthat you include all of the steps.\\nNow in this case, I forgot to include this important step\\nwhy I need to actually respecify that the event gender\\nhas to be of type category\\nand that's the reason why I didn't see it earlier.\\n\\nSo what you'll want to do is when you define a function,\\nyou'll want to follow exactly the same steps that you did\\nand that you're trying to automate.\\nSo we've seen that functions are the way to go\\nif you have to do operations a couple of times.\\nNot only can it automate things for you,\\nbut it reduces the risk of you making errors\\nif you do things manually.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5914607\",\"duration\":375,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with indexes\",\"fileName\":\"4493047_en_US_03_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":574,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Indexes allow you to access a row or column in pandas. After watching this video, you will be able to describe what an index is.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13843633,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Have you ever tried to find\\nyour friend's phone number in a huge contacts list\\nwith no names or organization?\\nJust scrolling through endlessly is a real pain.\\nIndexes, I suppose I could say,\\nindices in pandas\\nare like having your contacts neatly sorted by name.\\nThey make your life so much easier\\nwhen working with data.\\nSo we've got a newly defined preprocess function,\\nwhich will return our preprocess DataFrame\\nand we store that in the variable oo.\\n\\nNow let's take a look at oo.index.\\nNow every DataFrame has an index,\\nso it's not optional.\\nAnd these correspond to the rows.\\nAnd you can see that we've got a RangeIndex object.\\nSo you have the start, which is zero,\\nall the way up to 27174 in our case.\\nNow if we take a look at oo.columns,\\nit also says Index.\\nBut this is just an Index object,\\nso it's not referring to the row index,\\nbut it just so happens that the columns\\nare also called an index type.\\n\\nNow in a table or a DataFrame,\\nyou have indexes to reference the rows and columns,\\nwell for the columns.\\nAnd by default, the rows and the columns\\nof a DataFrame are just integers.\\nSo let me show you that.\\nSo if I specify header=None in the read_csv method,\\nyou can see that we've got numbers for our rows\\nand numbers for our columns.\\nNow most of the time we leave the rows\\nor the index as integers\\nand we give the columns column names.\\n\\nNow why do we need indexes?\\nWell, it just allows us to identify a certain row.\\nSo for example,\\nif I wanted to access all of the events\\nthat the famous US Olympian Carl Lewis took part in,\\nI could get the indexes\\nand they'd stay with the rows\\nand those won't change.\\nSo for example, I specify here athlete name\\nand it contains Carl Lewis.\\nThese numbers here will never change\\nregardless of what transformation I might do.\\n\\nNow if I want to pick a certain event,\\nso for example, if I take row 22719,\\nand I'm looking for the last discipline\\nthat Carl Lewis took part in,\\nwhich was the long jump event in Atlanta.\\nSo row 222719\\nand the event, I should be able to find\\nthat the last event was long jump.\\nNow what I can also do is I can set the index\\nto something that's a little bit more useful\\nthan just a numeric value.\\n\\nSo I could set to the index, for example,\\nto the athlete names.\\nAnd so now let's take a look at the indexes.\\nSo you've got oo.index,\\nand then these are the names of all of the athletes.\\nSo now if I want to take a look at the events\\nthat Carl Lewis was involved in,\\nI could specify over as the row value his name, Carl Lewis.\\nAnd I can take a look at all of the events\\nhe took part in.\\n\\nAnd I can take a look at the first three rows\\nin the DataFrame.\\nYou can see that the athlete's name\\nis no longer in the columns here\\nbecause this is now the index.\\nAnd if I was to take a look\\nat the shape of the DataFrame,\\nyou'll notice that now\\nthis doesn't have 10 columns anymore,\\nit has nine columns\\nbecause I have moved the column name to an index.\\nNow I could also use oo.loc\\nto allow me to identify a portion of the DataFrame.\\n\\nSo I could specify again\\nthat I want information about Carl Lewis,\\nbut I could specify that I only want the Year,\\nthe Event, and the Medal columns.\\nAnd I do that by providing that information in a list.\\nAnd here I have the Year, the Event, and the Medal\\nfor all of the medals that Carl Lewis won\\nbetween 1984 and 1996.\\nNow I could get all of the information for Carl Lewis\\nby specifying the name Carl Lewis for the row\\nand by using a colon for the columns.\\n\\nAnd this is a shortcut for saying\\nthat I want to be able to display all of the columns.\\nNow another way you can do that\\nis to totally ignore the colon\\nand to just specify his name in this way.\\nBut again, I prefer to be more explicit\\nabout the fact that I'm having both an index\\nand a column component.\\nAnd so I would normally use\\nthis as opposed to just oo.loc and Carl Lewis.\\nNow because the athlete names is the index,\\nI can sort it by the athlete names\\nor I could go ahead and get the index\\nback to what it was earlier\\nby using the reset_index method.\\n\\nAnd this will allow me\\nback as one of the columns over here.\\nNow this is because under the hood,\\nthe DataFrame is just represented\\nby rows and columns, which are just integer values.\\nSo I could say iloc[0, 0].\\nAnd so zero in Python is the first component\\nor the first element,\\nand zero over on the column\\nis the first element here.\\nSo I've got the first row and the first element over here.\\nAnd so I should see AABYE, Edgar.\\nSo if I wanted to be able to see the fifth element here,\\nyou can see that it's 0, 1, 2, 3, 4, 5.\\n\\nAnd so I can see that this is the NOC country,\\nwhich is ZZX, which is when we had combined teams\\nin the early Olympics.\\nAnd similarly, I can view the entire row\\nby just specifying a colon.\\nAnd I have the shortcut\\nwhere I can not use the colon at all,\\nas we saw with loc.\\nAll right, so we've seen that by having indexes,\\nwe can gain access to that exact bit of data that we want.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5911595\",\"duration\":560,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Being productive in pandas: My best practices\",\"fileName\":\"4493047_en_US_03_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":764,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Over the years, the instructor has refined several best practices when working with pandas. After watching this video, you will be able to replicate some of them.\",\"captionsStatus\":\"IN_PROGRESS\",\"cdnStatus\":\"AVAILABLE\",\"size\":20281494,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":null},{\"urn\":\"urn:li:learningContentVideo:5915592\",\"duration\":132,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating Series and DataFrames\",\"fileName\":\"4493047_en_US_03_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":195,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Sometimes you want to create Series and DataFrames from scratch. After watching this video, you will be able to create Series and DataFrames from Python lists and dictionaries.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4213933,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] All along, we've looked\\nat creating DataFrames and Series\\nby reading in data from a CSV file.\\nLet's look at how we can create them from scratch.\\nNow, there are a couple of ways\\nand I'll show you the ways I use most often.\\nSo I've got two lists here.\\nOne with the city, so that's London, Rio, and Tokyo.\\nAnd the other is a list with the corresponding start_date.\\nSo the London Olympics started on the 27th of July, 2012.\\nThe Rio Olympic started on the 5th of August,\\n2016 and so on.\\n\\nSo I can create a Series by taking in that list,\\nso the list of city and passing it to pd.Series.\\nAnd you can see that I've got a Series here with London,\\nRio and Tokyo and the corresponding index.\\nNow, a DataFrame is made up of multiple Series,\\nand so I could take in a dictionary\\nand create a DataFrame by having a dictionary of Series.\\nSo then I've got a city\\nand the corresponding Series or column,\\nand then I've got a start_date\\nand the corresponding Series or column.\\n\\nAnd this is within a dictionary.\\nAnd you can see that I've now got a DataFrame,\\none column being city, or one Series being city,\\nand the other Series or column being the start_date.\\nNow, I don't even have to go ahead and create that Series.\\nI could just go ahead and say city\\nand provide the city as a list\\nor the start_date and the start_date as a list,\\nand I'll get exactly the same DataFrame.\\nThe other option that I have\\nis to go ahead and zip the two lists.\\nNow, what I do by zipping the list\\nis that I combine the corresponding components.\\n\\nAnd so what I'm doing over here\\nis I've got London with the corresponding start_date,\\nRio with the corresponding start_date and so on.\\nNow, you'll notice that I don't have a column name,\\nand so I can go ahead and specify a column name in this way.\\nAnd so I provide the column names as a list\\nand I go ahead and zip the two lists.\\nAnd this will allow me to create that DataFrame, okay?\\nSo we've seen that we can create a DataFrame from scratch\\nusing Series, lists, or dictionaries.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5914608\",\"duration\":241,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with dates\",\"fileName\":\"4493047_en_US_03_08_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":347,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"When working with data, sometimes you need to work with date and time values. After watching this video, you will be able to work with dates in pandas.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8582102,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Dates can be a real headache\\nwhen you're working with data.\\nThere's one format that's used in the US and Canada.\\nThe rest of the world pretty much uses another format.\\nPandas comes to the rescue again.\\nSo I've got three lists here.\\nCity has the Olympic cities, London, Rio, and Tokyo.\\nThe start date is the 2012, 2016 and 2020 Olympics.\\nAnd then we've got the corresponding end dates.\\nFor some of them you'll notice that we've got\\nthe month first, and then followed by the day.\\n\\nAnd for others we've got the day first,\\nand then followed by the month, and then the year.\\nSo let's see if Pandas can cope\\nwith these different formats of dates.\\nSo let's go ahead and create our DataFrame,\\nand we'll do that by zipping these three lists.\\nAnd adding the column names.\\nSo this is our DataFrame\\nwith the corresponding Olympic cities.\\nAnd their corresponding start and end dates.\\nAnd if we take a look at the data types,\\nyou can see that all of them are of type object.\\n\\nNow one of the things I'm sure that Pandas has\\nis some way to work with dates.\\nSo instead of going online, I'm going to go\\nand check to see if the string date\\nis in any of the methods or attributes for Pandas.\\nAnd if I take a look at the different methods\\nand attributes available here,\\nthe most relevant seems to be to_datetime,\\nso let me just go ahead and check out the doc string.\\nAnd you can see from here that it says\\n\\\"convert argument to datetime.\\\"\\nAnd this is exactly what we want to do.\\n\\nWe want to convert the object to a datetime type.\\nAnd this seems logical because if you're familiar\\nwith Python, Python also has a datetime library.\\nSo let's go ahead and convert the start date.\\nTo a datetime.\\nAnd you can see that we end up with a value error.\\nAnd the reason that we have a value error\\nis because there seems to be different formats\\nas we discussed earlier, so some of them\\nseems to be in the American and Canadian format.\\n\\nAnd others seem to be in the format\\nthat's used in the rest of the world.\\nSo let's go ahead and check our documentation again.\\nAnd we'll be able to see that there is\\nin fact a parameter called format\\nthat allows us to have a mixture of formats.\\nAnd in fact there's information here in the value error.\\nAnd it says \\\"the format will be inferred\\n\\\"for each element individually,\\\"\\nso this looks like what we need.\\nSo if I use the parameter format equals mixed,\\nI'm able to convert that to a datetime format\\nwhere I have the year first,\\nfollowed by the month, and then the day.\\n\\nSo let me go ahead and convert\\nall of the dates to a datetime format.\\nAnd we'll convert the Olympic cities to strings.\\nAnd here the games data type looks a lot more healthy.\\nSo let's take a look at the end date.\\nThe start date.\\nNow what would be really nice is to try\\nand figure out what the duration might be, right?\\nSo I want to subtract the end date from the start date.\\n\\nAnd quite interestingly, it looks like\\nall of these Olympic events had a duration of 16 days.\\nSo I can go ahead and assign this,\\nor create a new column called duration,\\nand I can use the assign method.\\nAnd that will allow me to create this new column\\ncalled duration which will subtract\\nthe end date from the start date.\\nLet me go ahead and just confirm\\nthe data types for all of the columns.\\nSo City is still string.\\n\\nWe've got a datetime for the start and end date.\\nAnd the duration has a timedelta data type.\\nOkay, so we've seen how to use\\nthe two datetime to convert objects to dates.\\nAnd then calculate the difference between these dates.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5911594\",\"duration\":360,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Combining DataFrames\",\"fileName\":\"4493047_en_US_03_09_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":495,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Sometimes you need to update DataFrames with new information for analysis. After watching this video, you will be able to combine DataFrames.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12406655,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] You know that feeling\\nwhen you're trying to merge data from different sources\\nand it's like mixing oil and water?\\nWell, Pandas has a couple of helpful methods\\nthat allow you to combine the DataFrames together\\nwithout the drama.\\nSo our first DataFrame is start,\\nwhich has the Olympic city,\\nso that's London, Rio, and Tokyo,\\nand their associated start dates.\\nThe other DataFrame end has the Olympic City,\\nso that's London, Tokyo, and Paris,\\nand their associated end dates.\\nNow anytime I'm looking to combine DataFrames,\\none of the methods I'm going to be thinking about is\\nthe Concat method.\\n\\nSo let's take a look at the documentation\\nand you can see that the purpose of the Concat method is\\nto concatenate pandas objects along a particular axes.\\nSo if I specify that the axis equals zero, so that means\\nthat's along the rows, you can see that it's combined,\\nthe start and the end DataFrame.\\nAnd we've got two separate columns, one for city,\\nand then oddly another one for city.\\nAnd that's because one of the cities is spelt\\nwith a capital C and the other one has a low case C.\\n\\nSo if you go ahead and make the changes so that we have\\nboth DataFrames with the column name with a low case city,\\nand let's go ahead and try and concatenate the start\\nand the end DataFrame.\\nSo you can see now that we have a single column called city\\nwith the start date and the end date.\\nNow Nan corresponds with the fact\\nthat there are missing values there,\\nbut it looks like there's no intelligence in the way that\\nthese two DataFrames have been concatenated.\\n\\nSo for example, you can see that we have London\\nwith the start date\\nand I was hoping to have a table where it's able\\nto understand that the fact that we've got London\\nand to have the associated end date\\nand in the same way we've got the start date for Tokyo,\\nbut no end date even though that information is available.\\nSo you can see that Concat does not take into account\\nsome of the columns when you want\\nto be intelligent in the way\\nthat you're combining the DataFrames.\\n\\nSo let's take a look at the Concat with an axis equals one\\nbefore we take a look at a couple of other options.\\nAnd you can see that Concat with an axis equals one\\nconcatenates, the two DataFrames along the columns axis.\\nAnd so we have a repeat of the city,\\nthe start date and the end date.\\nNow let's look at merging the DataFrames\\nin a more intelligent way.\\nSo we have a start DataFrame,\\nthe end DataFrame,\\nand let's look at how we might want to be able\\nto merge these two DataFrames.\\n\\nSo what we get as an output of this is merging DataFrames\\nor name series objects with a database style join.\\nSo what we'll want to provide are things like the left data\\nframe, the right DataFrame, how we want to merge them.\\nSo are we looking for an inner join,\\nan outer join, and so on.\\nAnd I'll talk through the differences\\nbetween them in a couple of seconds time.\\nAnd then what's the key\\nor the common column in both of the DataFrames\\nthat we want to be merging on?\\nSo here I'm going to say PD merge.\\n\\nThe left DataFrame's going to be start,\\nthe right DataFrame is going to be end.\\nI'm going to be merging on the common column city\\nand I want to do an inner merge.\\nNow an inner merge is an intersection of the keys.\\nSo that's information\\nthat's available in both the DataFrames.\\nAnd if we take a look at the DataFrames,\\nwhat's common to both the city columns is London and Tokyo.\\nAnd that's why we end up with the associated start date\\nand end date information.\\n\\nNow merging with an outer join is a\\nsimilar operation except\\nthat we are going to be combining the information\\nfrom the cities.\\nSo if it's available in either the start city\\nor the end city, that information is going\\nto be available in that merged DataFrame.\\nAnd so we can see we have information for all\\nof the four cities here.\\nNow the reason that we have a nan or a missing value here is\\nbecause we don't have any information about the end date\\nfor the Rio games.\\n\\nAnd similarly, we don't have information about the start\\ndate for the Paris games.\\nAnd so if I go ahead to the start DataFrame,\\nyou'll be able to confirm that there is no Paris\\nin our start DataFrame.\\nAnd similarly, there is no Rio in our end DataFrame.\\nNow I can also do a left join.\\nAnd so what we're doing over here is we're taking all\\nof the keys from the left DataFrame, so that's London, Rio,\\nand Tokyo, and then merging with the right one\\nwith the corresponding values if they exist.\\n\\nAnd you can see that we've got corresponding values\\nfor the end dates for London and Tokyo,\\nbut no information for Rio.\\nAnd in the same way with the right join,\\nmy starting point are the keys in the cities\\nfor the right hand DataFrame, which is London,\\nTokyo, and Paris.\\nAnd then I'm going to add the associated start dates\\nfor those cities.\\nAnd again, you can see that we have a missing value\\nfor Paris\\nbecause we don't have any start date information for Paris.\\n\\nAlright, so we've seen a couple of different ways\\nof combining DataFrames with Concat and with merge.\\nAnd depending on how you want to be able to use\\nor work with these DataFrames will determine whether you\\nuse the Concat method or the merge methods.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5912590\",\"duration\":308,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Combining datasets\",\"fileName\":\"4493047_en_US_03_10_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":396,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"There are several considerations to keep in mind when combining two different datasets. After watching this video, you will be able to perform some of the necessary checks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12608209,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, make sure you are sitting down for this\\nbecause I've got some thrilling news.\\nAfter some serious data hunting\\nand wrangling, I've managed\\nto get my hands on some 2008 Olympics data.\\nCan you believe it?\\nWe're now sitting on a gold mine\\nof Olympic data spanning a whopping 112 years\\nfrom 1896 all the way to 2008.\\nLet's take a look.\\nSo this is our original data set\\nand let's go ahead and grab the new file.\\n\\nNow I'm going to go ahead and open it\\nbecause I don't know what format the data is in\\nand it looks like there are no missing rows.\\nAnd so we've got City, Edition, Sport and so on.\\nNow let me go ahead and take a sample\\nof our original Olympics dataset.\\nSo that's from 1896 all the way to 2004.\\nAnd it looks like we have the same columns except they seem\\nto be in different orders.\\nSo let's try and combine these two data frames\\nand we'll use pd.concat and we're going to try\\nand combine them across the axis-0.\\n\\nAnd let's see how things pan out.\\nAnd you can see this is pretty messy.\\nSo we've got year, city, sport\\nand then there seems to be a little bit of a duplicate here.\\nNow what I was hoping for is that we would have a table\\nwith all of these nicely lined up.\\nSo it looks like we're going to have\\nSo if I take a look at the new dataset\\nand I look at the column names, I've got nw.columns\\nand I've got City, Edition, Sport and so on.\\nAnd if I take a look at the old\\nor my previous dataset, I've got Year, City and Sport.\\n\\nBut it's clear that there's a couple of differences, right?\\nIt looks like in the old dataset, all\\nof the column names have a capital first letter.\\nAnd in the new dataset, all\\nof the column names have a lowercase letter.\\nSo I can go ahead and manually update that\\nand I've done that over here.\\nAnd let me go ahead and read that in.\\nSo what I want to say is I've got names equals\\nand I'm going to give it the names of my updated list.\\n\\nSo let me just call this new names or new_columns.\\nAnd we've got the updated list in this way.\\nOr the other way to do that instead\\nof manually updating each column\\nand changing the first letter to uppercase is\\nto use a list comprehension.\\nAnd what we're doing here is making the first letter capital\\nby using the capitalize method.\\n\\nAnd this will achieve exactly the same thing.\\nSo if I now go ahead and try\\nand combine these two data frames,\\nyou can see that things are starting\\nto look a little bit better.\\nWe've now down to 15 columns\\nwhere we originally had 21 columns.\\nSo things are starting to sync up a little bit better.\\nNow let's compare the old data frame\\nand the columns with the new one.\\nSo we still need to make a couple\\nof modifications to the column names.\\n\\nSo if example, instead of country code, we have NOC\\nand instead of event_gender,\\nwe should be having a space between them.\\nSo I'm going to go ahead and make a couple of those changes\\nto my NW columns and let's go ahead\\nand combine these two data frames now.\\nOh, brilliant.\\nSo now we have a table with 11 columns\\nand they seem to have lined up very nicely.\\nNow one thing I'm not sure about\\nis this column called results.\\nSo let's take a look at the values in that column.\\n\\nAnd so you can see that I've got the values 3, 1, 2\\nand there are a couple of nans here.\\nAnd and nan means it's not a number.\\nNow it looks like result\\nis a lot like position in my previous dataset.\\nSo I'm going to go ahead and drop that.\\nAnd let's go ahead and combine the two data frames.\\nAnd so now we have 10 columns across the axis-0.\\nAnd let's confirm the data types of this.\\nAnd unfortunately all of the data types seem\\nto be of type object.\\n\\nSo we're going to have to do a bit of pre-processing,\\nbut let's combine all of the stuff that we've done\\nand put it into a function\\nand we'll call that pre-process 2008.\\nSo we are taking in our 2008 CSV file.\\nWe're going to go ahead and read it.\\nWe don't need to do any manipulation there.\\nThere are no missing rows.\\nWe want to change the column names so that it satisfies\\nand maps to the old data set.\\nWe want to go ahead and drop result and we want to go ahead\\nand return that data frame.\\n\\nAnd this is the sample rows\\nthat we get as a result of that.\\nAlright, so we've got the new data,\\nbut we've had to massage it a bit and move things around.\\nIt looks like we'll need to do a few more checks\\nbefore we can combine the data sets together.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5911593\",\"duration\":342,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with missing data\",\"fileName\":\"4493047_en_US_03_11_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":489,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Many real-world datasets contain missing data. After watching this video, you will be able to handle missing data in pandas.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12711070,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In the world of data analysis,\\nmissing values are like puzzle pieces\\nthat fell under the table.\\nYou can still see the big picture without them,\\nbut it's just not complete.\\nSo let's go ahead and reuse our preprocess\\nfile from earlier.\\nAnd let's take a look at the info method.\\nSo we can see that we've got 2059 entries in total,\\nbut we seem to have a couple of non values.\\nAnd the reason I know that\\nis because if I have 2059 entries in all of these columns,\\nI've got 2033, 2025 and so on.\\n\\nBut there certainly seems to be some missing values.\\nNow in previous videos we've seen\\nthat missing values are called NaN or sometimes NA.\\nSo what you could do is hazard a guess and try\\nand look for that search string NA,\\nor perhaps let's go ahead and try and look for missing\\nand see if there's a method called missing.\\nSo you can see that we've got an empty list.\\nSo that means there are no methods\\nwith the substring missing.\\nSo let's go ahead and try na.\\nNow because we're going to be looking for na,\\nI'm expecting there to be a whole lot of other strings\\nthat are captured, things like name and names and so on.\\n\\nSo let's make a change to our search string.\\nLet's make sure that na is right at the end.\\nSo if I go ahead and modify that pattern condition,\\nyou can see that I've now got a couple of methods\\nthat seem to be more logical.\\nSo you've got dropna, fillna, isna, and so on.\\nLet's take a look at isna.\\nSo if I was to take a look at the city column, so nw.City,\\nlet's take a look at the documentation for the isna,\\nlet me just give myself a little bit more space.\\n\\nAnd you can see that the doc string says that the purpose\\nof this isna method is to detect missing values,\\nwhich is exactly what we want to do here.\\nSo let's take a look and see if City has any missing values.\\nAnd we know that it does\\nbecause we've got 2033 non-null entries,\\nbut we've got a total of 2059 entries in our data frame.\\nSo again, this is going to return a false\\nor a true for every single entry within that series.\\n\\nNow what I can also do is\\nbecause each false is represented by a zero\\nand a true is represented by a one,\\nI can go ahead and sum all the isnas\\nfor that particular column.\\nAnd so this means I have a total of 26\\nmissing entries because I've got 26 entries that correspond\\nto a false for the nw.City.\\nNow I can go ahead and take that\\nand put that into a data frame.\\n\\nAnd these are the 26 entries\\nwhere we don't have any information for the city.\\nAnd you can see that these are all NaN.\\nAnd so there are missing values for the city information.\\nNow this seems a bit odd\\nbecause we know that in the 2008 Olympics\\nthat this was held in Beijing.\\nSo let's go ahead\\nand take a look at the values that we have for City.\\nAnd you can see that we've got Beijing and NaN.\\n\\nSo if I take a look at the number of rows\\nand the number of columns, I've got 2059 and 10.\\nSo what I'm going to want to do is to see\\nwhat methods might make sense for me to be able to deal\\nwith these NA values.\\nAnd if I take a look at the methods,\\nfillna seems to be a reasonable candidate.\\nSo let's check out the documentation for fillna.\\nAnd you can see that the doc string says fill NA\\nor NaN values using the specified method.\\nNow since we know that this is data for the 2008 Olympics\\nand we know that this was all held in Beijing,\\nwe can go ahead and ensure\\nthat the entire city column is Beijing.\\n\\nAnd so what we can do is we can use the fillna\\nand give it a value of Beijing.\\nAnd when we then go ahead\\nand take a look at the unique values in city,\\nyou can see that they've all been filled up.\\nWe don't have any more NAs, and we are good there.\\nLet's take a look at the year.\\nNow for some strange reason,\\nthe year seems to have a floating point representation,\\nso that's like a decimal value rather than an integer.\\nLet's take a look at the options within the year.\\nAnd you can see that we've got NaNs again.\\nSo these are not the numbers, and 2008.\\n\\nSo let's go ahead and update the year with the value 2008.\\nAnd so now we've got the city with 2059 entries\\nand we've got the year with 2059 entries.\\nNow the reason that I'm not going to go ahead\\nand update the year to a type of integer\\nis because I'm going to do that\\nfor all of the columns later on.\\nAnd so I'm going to treat that as a batch\\nand I don't want to just go ahead\\nand update just the year right yet.\\nSo let's make those changes\\nto our preprocess_2008 function.\\n\\nSo our additions are that we've gone ahead\\nand updated the city with a fillna to Beijing\\nand we've updated the year with a fillna to 2008.\\nAnd when I take a look at the data types,\\nyou can see that I've got a float of 64 for the year\\nand everything else seems to be an object.\\nSo what we've done here is to take a look at a couple\\nof the columns where there have been missing values\\nand we've gone ahead and updated the city and the year.\\n\\nAnd in the next few videos, we're going to go ahead\\nand deal with some of the other columns.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5917321\",\"duration\":257,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Removing missing data\",\"fileName\":\"4493047_en_US_03_12_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":321,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"There are many ways of dealing with missing data. After watching this video, you will be able to remove missing data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10637364,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] There are going to be some instances\\nwhere instead of filling our DataFrame with missing data,\\nwe might actually want to go ahead and remove\\neither some of the rows or the columns.\\nSo this is our preprocess_2008 function\\nthat is starting to work with making changes to that file.\\nLet's take a look at the overall status for the columns.\\nSo we've got 2059 entries\\nand we still have a couple of columns with missing values.\\n\\nSo given that we have 2048 entries for sport,\\nthat means we have some missing values,\\nso let's take a look at the values that are missing.\\nAnd so we've got a whole load of missing values\\nfor sport, but this also includes discipline, athlete name,\\nNOC and so on.\\nSo it looks like for whatever reason\\nthat 2008 file has a couple of rows\\nwhere we've just got the city and the year\\nand no entries in terms of the athlete or the medals,\\nand so we probably want to get rid of these.\\n\\nAnd there are a couple of ways that we can do that.\\nSo we can use the dropna method and we can specify all,\\nand this will remove all of the rows\\nif all of the columns are NaN.\\nThe other option is to use dropna\\nand where we have how equals any,\\nso if any of the columns are NaN,\\nthen we're going to go ahead and delete that row.\\n\\nSo if we take a look at the missing values again.\\nNow what we'll probably want to do\\nis to be a lot more prescriptive\\nabout the rows that we want to delete.\\nSo let's take a look at the options available within dropna.\\nNow we know that dropna will remove missing values,\\nbut if we scroll down,\\nyou can see that there's the subset parameter\\nthat allows us to drop rows based on a list of columns.\\n\\nAnd this seems to be a very prudent way of removing data\\nbecause you are being very prescriptive\\nabout which columns can be empty.\\nSo if I take a look at nw columns\\nand I've got city, year, sport and so on.\\nNow when I do a dropna, I can specify a subset\\nand then I want to make sure that all of these rows\\nare deleted because sport, discipline, athlete name\\nand so on are all NaN.\\n\\nAnd so I display all of the column names\\nand then I can just go ahead and copy them from here,\\nso I want sport, discipline, athlete name and so on,\\nand I'm going to provide that as a parameter to subset\\nand I say how equals all.\\nAnd so what's going to happen here\\nis that this is going to delete all of the rows\\nthat have missing values for the corresponding columns.\\nSo by that I mean sport discipline, athlete name,\\nand all the way up to medal.\\nNow these changes don't take place automatically,\\nso I actually need to provide the original DataFrame here.\\n\\nAnd so when I make those changes here,\\nwe'll be able to see that now with the updated info method,\\nwe have 2048 entries in total\\nfor city, year, sport and so on.\\nAnd it looks like all of the entries\\nhave now rectified themselves,\\nand so we now have no missing values.\\nSo if I go ahead and make those changes\\nto the preprocess_2008 functions file,\\nwe've now added this new entry to the function.\\nSo that's where we're going to go ahead\\nand drop all of the rows where these corresponding columns\\ncorrespond to an NaN value.\\n\\nSo we've seen that sometimes\\nwe don't just want to be filling in the values\\nin a DataFrame,\\nsometimes it makes really good sense\\nto actually drop some of the rows,\\nespecially when the majority of the columns are empty.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2719579\",\"duration\":190,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with duplicates\",\"fileName\":\"4493047_en_US_03_13_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":531,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Many real-world datasets have duplicates and you need to know how you want to deal with them. After watching this video, you will be able to remove duplicate data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7378900,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Have you ever been at a magic show\\nwhere the magician pulls the same rabbit\\nout of the hat multiple times?\\nWell, having duplicate data in your pandas DataFrame\\nis kind of like that,\\nexcept it's not nearly as funny or entertaining.\\nSo let's take a look at our DataFrame nw,\\nand you can see that we've got 10 columns and 2048 rows.\\nNow, if we look at the duplicated method,\\nand we sum them.\\n\\nActually, before we do that,\\nlet's just take a look at\\nwhat the duplicated method is all about.\\nAnd you can see that the duplicated method\\nreturns a boolean series denoting the duplicate rows.\\nAnd so, you can see that we've got six duplicates here.\\nAnd so if I want to go ahead and display them,\\nthese are the six rows that are duplicates.\\nYou can see we've got identical entries\\nfor every single row.\\n\\nSo we've got 2048 rows and 10 columns.\\nSo if we go ahead and drop the duplicates,\\nwe should find that we're now at 2042 rows,\\nwhich is exactly what we have here.\\nNow, let's say I want to use the duplicated method\\nto help me achieve something totally different.\\nLet's see if we can determine if there are any athletes\\nwho have won medals in multiple events.\\nSo if we take a look at the athlete_multiple_events,\\nand we do an nw.duplicated across just the athlete name,\\nthe NOC, and gender.\\n\\nAnd let's take a look at the results of that.\\nAnd because of the way that the duplicated works,\\nby default, it'll keep the first instance\\nand the rest are duplicates.\\nSo the reason that we are seeing mostly single entries here\\nis because the first is kept.\\nAnd so these are athletes who have won two medals\\nin these games.\\nNow, let me go ahead and sort by athlete name,\\nand this will allow us to see if there are any athletes\\nwho have won medals in multiple events.\\n\\nNow, if we take a look at Kai Zou, for example,\\nyou can see that he has won medals in the team competition\\nand the horizontal bar.\\nSo that means he's won three medals.\\nThe first being the instance that's kept,\\nand the rest being the duplicates.\\nAnd so if we take a look at Kai Zou,\\nso if we look up his name,\\nwe'll be able to see that we've got the three entries.\\nFloor exercises, horizontal bar, and team competition.\\n\\nSo, so much for pulling rabbits out of a hat,\\nwe've really gone down a rabbit hole.\\nSo let's head back to modify our pre-process function.\\nAnd what we'll want to do is we want to go ahead\\nand drop any duplicates.\\nAnd so we add that to our function.\\nAnd so now we have a DataFrame\\nwhere the duplicate entries have been removed.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5917320\",\"duration\":429,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Validating data\",\"fileName\":\"4493047_en_US_03_14_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":452,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"One important skill is to be able to validate data before incorporating it into your dataset. After watching this video, you will be able to use multiple tools to validate data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17133780,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Data validation is about as exciting\\nas going through security at the airport.\\nIt might seem tedious, but it's absolutely crucial\\nto ensure a smooth journey ahead.\\nNow, based on your dataset, you'll want\\nto be thinking about edge cases,\\nand making sure your assumptions about your data are valid.\\nLet's go ahead and get our original functions\\nand the function for our new dataset.\\nNow, as part of data validation, we want to make sure\\nthat there are unique values\\nfor columns such as event gender, gender, and so on.\\n\\nSo we can see that for our new dataset,\\nwe've got event gender as men, women, and mixed.\\nFor gender, we've got men and women.\\nNow we want to check a few edge cases.\\nSo we want to make sure that if the event gender is for men,\\nthen we don't have any athlete who isn't a man taking part.\\nAnd so when we try and display this DataFrame,\\nwe should get no entries.\\nAnd we want to do exactly the same thing for women.\\nNow we want to check if the event gender is not for women\\nand not a mixed event,\\nthat means the event gender is for men,\\nthat we don't have women athletes taking part.\\n\\nAnd similarly, if the event gender is not for men\\nand not a mixed event,\\nthat means the event gender is for women,\\nthen we don't have men taking part.\\nSo our new dataset seems to be in good shape.\\nLet's go ahead and check our original dataset,\\nbecause we didn't have many of these skills\\nwhen we started off.\\nSo I'm going to work through this reasonably quickly,\\nbecause we've done these tests a couple of minutes ago.\\nSo for our old set,\\nwe've got the event gender,\\nwe've got the different unique values for the gender.\\n\\nAnd then I'm just going to pass\\nthrough the different edge cases,\\nand I'm expecting to get no entries\\nfor all of these edge cases.\\nNow, very surprisingly, we seem to have the case\\nwhere the event gender is not for men and not a mixed event.\\nSo this is an event gender for women,\\nbut we have a man taking part.\\nAnd if we take a look at the entry,\\nthis is Joyce Chepchumba taking part in a marathon.\\nThe event gender is for women, but for some strange reason,\\nwe have Joyce Chepchumba having a gender as a man.\\n\\nAnd if we were to go ahead\\nand look Joyce Chepchumba up on a search engine,\\nyou'll find that she is in fact a woman.\\nAnd so this seems to be a data entry error.\\nSo let's take a look at the Olympics 2000\\nwith the marathon event.\\nAnd you can see we've got all of the results for the men.\\nSo we've got a gold, silver, and bronze,\\nand we seem to have two bronze medals for the men.\\nAnd this is because we've got this incorrect entry\\nfor Joyce Chepchumba, which is the second row.\\n\\nSo let's go ahead and make a change to that.\\nSo if we take a look at index 24676, which is this row,\\nwith the gender, we're going to change that to women.\\nAnd let's re-look at our DataFrame.\\nAnd so we can see now that we have entries\\nfor gold, silver, and bronze,\\nand we have the correct genders\\nand the associated event gender.\\nNow let's go ahead and make that change\\nto our original function.\\n\\nSo we're going to add that change right\\nat the end of that function.\\nSo we have that as part of our pre-processing step,\\nbecause remember, one of the best practices is\\nto never make changes to the original CSV file.\\nInstead make changes to a pre-processing file.\\nAnd let's just confirm\\nthat it hasn't messed up our data types.\\nAnd you can see that we've still got the integers,\\nstrings, and the categories.\\nNow let's go ahead and try\\nand automate the comparison between the different values\\nfor the old dataset and the new dataset.\\n\\nSo the new dataset has a year of 2008.\\nWe have no missing values there.\\nWe have no missing values for the city.\\nIf we look at the event agenda for the new dataset,\\nwe have men, women, and mixed events.\\nLet's convert that to a list by using the tolist method.\\nSo we now have men, women, and the mixed gender events.\\nAnd let's do that for the previous dataset.\\nSo that's the oo dataset.\\n\\nSo we've got men, mixed, and women.\\nSo what we're trying to do is\\nto try and automate this task,\\nso that we can compare the columns from the old dataset\\nto the columns from the new dataset.\\nAnd so if I compare these two lists,\\nI surprisingly get the output that they aren't equal.\\nAnd the reason for that is,\\nbecause the second entry and the third entry don't match,\\nbecause they've been swapped around.\\nSo what we'll want to do is we'll want\\nto sort the entries in the list, and then compare them.\\nAnd so we can use the Python sorted command\\nto help us achieve that.\\n\\nSo I now have the event agenda sorted in both cases,\\nand now I expect there to be no problems.\\nSo this should print out, Passes all tests.\\nNow we're going to do exactly the same tests\\nfor the gender and the medal.\\nAnd this is what I mean\\nabout being able to automate this task,\\nwhere we want to do exactly the same tests\\nacross the multiple columns.\\nAnd we've ended up with a problem again.\\nNow this time we've got problems with the medal column.\\nIn our original dataset,\\nwe had medals as bronze, gold, and silver.\\n\\nAnd in our new dataset, we have bronze, gold, and silver.\\nNow you'll notice that the first letter is not capitalized\\nfor our new dataset.\\nSo what we'll want to do is we'll want to capitalize it\\nand make those changes to our column name.\\nSo once I've made those changes to my column,\\nI should be able to see that all the tests have passed,\\nand we can confirm that that is in fact the case.\\nLet's do the same thing for the sport.\\n\\nSo the new dataset has all\\nof the different sports in lower case.\\nIn our original dataset, it was capitalized.\\nAnd we're going to have to change the format,\\nso both of these datasets match up.\\nIf I take a look at the countries participating, you can see\\nthat they're all in uppercase for the new dataset,\\nand that matches what we saw in the previous dataset.\\nSo I'm going to combine all\\nof the changes that I need to make over here,\\nand let's go ahead and add this\\nto our preprocess_2008 function.\\n\\nAnd so I'm going to add them all at the end of this function.\\nAll right, so we've taken a look\\nat a couple of the columns in these datasets,\\nand we've been able to confirm\\nthat we have the same sort of values\\nand we have the same format\\nfor both the old and the new dataset.\\nIn the next video,\\nwe'll take a look at the remaining columns.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2719577\",\"duration\":287,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Updating the dtypes\",\"fileName\":\"4493047_en_US_03_15_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":202,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Many times the data format isn't in the format you require. After watching this video, you will be able to change the data format for some of the columns.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9645242,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, so we are still working our way\\nthrough airport security.\\nImagine you're at the stations\\nwhere you have to do a bit more work,\\nremove your laptop from your backpack, remove your shoes.\\nWell, it's all good, but we've got the equivalent,\\nslightly harder work coming up for our dataset.\\nNow, earlier, remember how we said\\nthat lists have square brackets,\\nand each item is separated by a comma.\\nSo we've got a list here of medals with five entries,\\ngold, silver, bronze, bronze, and gold.\\nWell, it turns out that if I want to access the first entry,\\nI need to just provide the name of the list\\nand provide the square brackets,\\nand zero is my first entry.\\n\\nAnd so I should be able to see gold.\\nMy second entry is given by an index of one,\\nand so I should get an output of silver.\\nAnd if I were to determine the length of this list,\\nthen I can use the len method.\\nAnd I've got five entries here,\\ngold, silver, bronze, bronze, and gold.\\nNow what we're going to be working on here is the athlete name.\\nSo let's take a look at what this looks like.\\nAnd you can see that we have the family,\\nor the surname first in capitals, followed by a comma,\\nand then the first name.\\n\\nSo what we'll want to check in terms of formatting\\nis if our new dataset has the same format,\\nat least for the family name as the older dataset.\\nWe're not going to worry about\\nthe rest of the names for now.\\nNow, if you're familiar with Python,\\nyou'll know that if you want to separate\\nout different strings, you can use the split command.\\nSo let's check if there's an equivalent\\nsplit command in Pandas.\\nAnd you can see that there is a split method.\\nAnd let's take a look at what the split method does.\\n\\nSo you can see that it returns a list\\nof the substrings in the string\\nusing the separator for the string.\\nSo what we're going to use as our separator\\nis the comma and the space.\\nAnd then this means that we will then have each of the names\\nreturned as a list.\\nThe first entry being the family name or the surname,\\nand the second entry being the first name.\\nSo you can see that we've got a list for each entry\\nwith the family name and the first name.\\n\\nNow let's go ahead and convert list to a list\\nby using the tolist method.\\nAnd I'm going to store this in a variable called athlete_names.\\nNow what I'm after is to be able to confirm\\nif the family or the surname is in capitals.\\nNow, from my knowledge of basic Python,\\nI know that if I want to confirm\\nif something is all capitals,\\nI need to use the upper method.\\nSo I'm going to go ahead and check\\nif there's a upper method in Pandas,\\nand you can see that there is an isupper,\\nand that's exactly what we'll want.\\n\\nSo let's take a look at how we might go ahead and do this.\\nNow, what we'll want to check is only\\nthat first entry in the list is in capitals.\\nSo this list comprehension will allow me to get\\nall of the athlete names,\\nand I then want to go ahead\\nand just pick up the first entry.\\nAnd so I can do that by providing an index of zero.\\nAnd now I've only got the surnames.\\nNow what I want to then do is to confirm\\nthat these are in uppercase\\nfor all of the entries in my column.\\n\\nAnd I can do that by using the isupper method.\\nAnd what I have is a list of Booleans.\\nNow I want you to pause the video here\\nand try and figure out how you will be able to confirm\\nif a list of Booleans\\nhas all of the family names in uppercase.\\nNow, one of the ways you can do this\\nis to sum up the length of that list.\\nAnd so in this case, we get 2,042 entries\\nwhere the first name, or the family name, is in uppercase.\\n\\nNow, if this number is the same as the number\\nof entries in the athlete name,\\nthen we know that all of the names are in uppercase\\nand we don't need to make any changes to our function.\\nAnd you can see that we've got 2,042 entries in total,\\nwhich correspond to the number of athlete names.\\nThis means that the new dataset has the same format\\nfor the family names as our previous Olympics dataset.\\n\\nAlright, so we did a lot of work here,\\nbut it turns out that all the new data is in good shape\\nand we don't need to make any changes\\nfor the athlete names after all.\\nIt's a lot like passing through airport security\\nfor a smoother journey ahead.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5911591\",\"duration\":136,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Combine the datasets\",\"fileName\":\"4493047_en_US_03_16_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":172,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In order to combine datasets accurately\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5151081,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- So far, for the old dataset and the new dataset,\\nwe've confirmed that the column names\\nmatch in terms of the formatting.\\nSo we need to update our functions to reflect that.\\nAnd then we also need to go ahead and update the data types.\\nSo in our original pre-processing function\\nfor our older Olympic dataset,\\nwe make changes to the sport discipline and event\\nensuring that these are all lowercase\\nand that the Olympic countries is uppercase.\\n\\nAnd similarly, we make those changes to\\nthe corresponding fields in our new dataset.\\nSo let's go ahead and run that cell.\\nSo if we look at our data types for our new dataset,\\nwe can see that we have primarily objects and floats.\\nSo we need to ensure that they match the original dataset,\\nwhich correctly has integers, strings and categories.\\nNow, unfortunately, unlike our original dataset\\nwhere we could provide the dataset\\nas part of reading in the CSV file,\\nbecause our new dataset had missing values,\\nwe can't read in the new data types\\nas part of reading in that file,\\nand so we need to specify that after reading in the file.\\n\\nAnd this is what we do in our function.\\nSo after providing the necessary formatting\\nin our new pre-process 2008,\\nwe're going to go ahead and specify the correct data types\\nand you can see that we are doing that for\\nthe city, the year, the sport, and so on.\\nNow, go ahead and pause the video here\\nand make sure that you're comfortable\\nwith all of the different columns and the data types\\nthat we've assigned them to.\\n\\nSo if I now go ahead and take a look at the new data types\\nafter the pre-processing function,\\nyou can see that they match with the data types\\nthat we had for the original Olympics dataset.\\nSo now both the formatting for the columns\\nand the data types match\\nand we are ready to combine these two datasets.\\n\"}],\"name\":\"3. Intermediate pandas Techniques\",\"size\":174458844,\"urn\":\"urn:li:learningContentChapter:5911599\"},{\"duration\":1816,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5917319\",\"duration\":258,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Plotting data\",\"fileName\":\"4493047_en_US_04_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":324,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Matplotlib integrates with pandas seamlessly. After watching this video, you will be able to demonstrate using matplotlib with pandas.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9892871,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's be real,\\nstaring at rows and columns of data\\nis about as exciting as watching paint dry,\\nbut using matplotlib,\\nwhich is a Python visualization library,\\nbrings your data to life.\\nSo I'm going to go ahead and pre-process both the data frames\\nand we're going to import the library,\\nso that's import matplotlib.pyplot\\nand we're going to give it the alias, PLT.\\nAnd so we're going to learn about plotting\\nby answering a question.\\n\\nSo for the first Olympics, how many events were there\\nfor each of the different sports?\\nPlot them using different graphs.\\nSo if I want to go ahead and get the first Olympics,\\nthen I have the updated data frame or my updated dataset.\\nSo, up.year.\\nAnd that equals 1896.\\nI can go ahead and determine all of the different sports\\nthat were involved.\\n\\nNow I want to be able to plot the different sports involved.\\nNow, matplotlib is well integrated with pandas\\nand so let's take a look\\nand see if there is a plotting library available here.\\nAnd you can see we end up with a object plot not found.\\nSo, let's try and understand\\nwhat type the first_games.Sport.value_counts is.\\nAnd we know that this is a series,\\nand so sometimes if you want to go ahead\\nand try out some of the documentation,\\nyou might have to go back to the basic building blocks.\\n\\nAnd so we know that this is a series.\\nSo if I take a look at the methods available\\nwithin the series,\\nyou can see I then get a couple of options\\nand you can see now that we're able to find the plot method.\\nSo let's go ahead and find the documentation for plot.\\nAnd you can see this makes plots of series or data frames.\\nAnd so now what I'm going to do is I'm going to go ahead\\nand plot a line.\\nAnd so I say first_games.Sport.value_counts\\nand I want to go ahead and plot this line.\\n\\nYou can see it does a reasonably good job.\\nWe've got a line plot with the values\\nor the numbers of sports in the y axes\\nand the actual sports and the x axes.\\nNow that's difficult to read,\\nbut if I go ahead and check out the documentation\\nand try and figure out how I might be able\\nto make this image or this figure larger,\\nyou can see that there's a parameter called figsize,\\nwhich is a tuple of the width and the height,\\nand I can use that to make this a larger image.\\n\\nSo let me just go ahead and close the documentation\\nand let's use figsize of 10,3.\\nAnd you can see that we get a much bigger plot\\nthat allows us to see what the x axis is about more clearly.\\nNow, what I can also do is I can go ahead\\nand separate that instruction across several lines\\nand I'll get exactly the same result.\\nAs you said before,\\nthe reason you'll do that is because it allows you to\\ntroubleshoot this.\\nSo for example, if I don't want to be able to see the plot\\nand I just want to see the original series or the value count,\\nI can go ahead and get the different components\\nand the numbers for the sport.\\n\\nI can also go ahead and use different graphs.\\nI can use a bar graph.\\nAnd there are two ways to get a bar graph.\\nOne is to use the plot method and say kind = bar,\\nor I could use plot\\nand then there is a sub method called bar\\nand I'll get exactly the same output here.\\nSo you can use whichever one seems more logical to you.\\nI can also go ahead and plot different kinds of graphs.\\nSo I can use a horizontal bar.\\n\\nI can go ahead and change the colors for the bars,\\nso instead of them being a default of blue,\\nI can change that to red.\\nAnd if I want, I can go ahead and alternate the colors.\\nSo I specify blue and red in a list,\\nand I'm able to do this.\\nSo you can see that we can bring our data to life\\nby using library search as matplotlib.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5911592\",\"duration\":287,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with colormaps and seaborn\",\"fileName\":\"4493047_en_US_04_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":623,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Colormaps allow you to adopt a more intuitive color scheme for your dataset. After watching this video, you will be able to choose and use your own colormap.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11617781,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Seaborn is a visualization library\\nbased on Matplotlib.\\nSeaborn has an excellent examples gallery\\nthat provides plots on the website.\\nAnd if you click on any of the plots,\\nit provides the code to generate that plot.\\nNow, one of the reasons to use Seaborn\\nis that it produces beautiful statistical plots.\\nIt's very important to realize\\nthat Seaborn is a compliment\\nand not a substitute to Matplotlib.\\nNow, one of the advantages, again, with using Seaborn\\nis that it works very well with pandas.\\n\\nSeaborn, as with Matplotlib, has methods\\nfor bar plots, histograms, and pie charts.\\nLet's take a look at an example using Seaborn.\\nSo we've got our original dataset\\nand the associated pre-processing functions.\\nLet's use the example that we used in the previous video.\\nSo this is just the games for the 2008 Olympics.\\nAnd we're going to import Seaborn and give it an alias sns.\\n\\nNow, the reason we do this\\nis because if you were to go online,\\nyou'll find that this is the common nomenclature for Seaborn\\nand plt for Matplotlib.\\nNow let's take a look at an example\\nof one of the methods called count plot.\\nNow, count plot has very similar parameters to Matplotlib.\\nThe data parameter for count plot\\nis where you provide the data frame\\nor the source for the data,\\nand then you can plot different columns.\\nNow because Matplotlib is built on top of Seaborn,\\nI can also give the plot a title using plt.title.\\n\\nAnd so you can see the title over here,\\nMedals from the 2008 Games.\\nNow, I can also reorder the bar chart\\nso that the gold shows first\\nand then the silver, and then the bronze.\\nAnd so I do that by using the order parameter.\\nSo now that we've got the plot in the correct order,\\nlet's switch gears and talk a little bit about color maps.\\nColor maps allow you\\nto find a good representation for your data.\\nSo is there an intuitive color scheme for the data?\\nFor example, gold and silver and bronze for medal winners,\\nor blue for male and pink for female.\\n\\nThere are a couple of different classes of color maps.\\nThe sequential should be used\\nfor representing information that has ordering.\\nSo there's a change in lightness, often over a single hue.\\nDiverging is to be used when the information being plotted\\ndeviates around some middle value.\\nSo here there are often two different colors being used.\\nCyclic or cyclic color maps are good for representing things\\nthat take place in cycles like the time of the day.\\nAnd finally, the qualitative class is used\\nto represent information\\nwhich doesn't have any ordering or relationship,\\nand is often miscellaneous colors.\\n\\nNow it's important to remember\\nthat the most common form of colorblindness\\ninvolves differentiating between red and green.\\nSo avoid color maps with both red and green\\nwill avoid many problems in general.\\nLet's head back to the notebook.\\nNow Seaborn is excellent for categorical data.\\nNow, categorical variables are the ones\\nthat can take a fixed number of values.\\nSo in the Olympics dataset, we've had a couple of examples\\nlike the medals are gold, silver, or bronze, and so on.\\nNow the hue is for the categorical variables.\\n\\nSo the hue allows you to specify a categorical variable\\nin a different color.\\nSo let's go ahead and take a look at what this looks like.\\nThe order parameter allows you\\nto determine the sequence of the categorical variables.\\nAnd finally, I also have the palette option.\\nThe palette parameter allows you to specify colors\\nfor the different levels of the hue variable.\\nSo what I've done here is to pick a color map\\nthat allows me to have a blue and a pink.\\n\\nSo here's one with a palette that's called seismic.\\nI've tried a couple of other examples.\\nSo if I try coolwarm,\\nI can then again get the blue for the men\\nand the orange or pink for the women.\\nAnd finally, let's try a pallet called BWR.\\nNow, I think this one works the best.\\nAnd if I wanted to reverse the color maps,\\nall I need to do is add an _r suffix to swap them around.\\n\\nSo when would you use Seaborn versus Matplotlib?\\nNow if you're running a couple of scripts,\\nthen Matplotlib with pie plot is easy to use\\nand great for bar charts and pie charts and so on.\\nIf you're looking to write short scripts\\nto deal with things like categorical data\\nor more advanced statistical plots,\\nor creating other kinds of plots like heat maps,\\nthen Seaborn is going to be your tool of choice.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5915590\",\"duration\":400,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with groupby\",\"fileName\":\"4493047_en_US_04_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":669,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"A groupby operation involves some combination of splitting the object, applying a function, and combining the results. After watching this video, you will be able to demonstrate how to use groupby.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13889126,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Have you ever found yourself\\nstaring at a spreadsheet filled with data\\nwishing you could make sense of it all\\nwith just a few lines of code?\\nWell, that's where you get the power of Pandas' groupby.\\nNow groupby is one\\nof the most important functionalities available in Pandas,\\nand it does three things.\\nIt splits a DataFrame into a group based on some criteria.\\nIt applies a function to each group.\\nAnd then it combines the results into a DataFrame.\\nLet's take a look at this.\\nNow, one of the events I love in the Olympics\\nare the sprints,\\nand I'm talking about the 100-meters and 200 sprints.\\n\\nSo let's take a look at the 100-meters\\nand 200 sprints for the 2008 Olympics.\\nAnd so we've got the results over here.\\nAnd we've got the results for both men and women.\\nAnd one of the things I can try and do is\\nto group by the country, the gender, and the event.\\nAnd you can see the result of this is a groupby object.\\nNow let's go ahead and try and visualize this,\\nand we're going to head over to pandastutor.com\\nto help with that.\\n\\nPandas Tutor is great for visualizing many\\nof the methods available in Pandas.\\nAnd so you can see\\nAnd so we've got our 12 rows here, which are the entries\\nfor the 100-meters and 200-meters sprints\\nfor both men and women.\\nNow if I want to go ahead and visualize the groupby operation,\\nI'm just going to uncomment this line,\\nand I'm going to groupby and then perform the count operation.\\n\\nAnd you can see what's happening here\\nwith the groupby operation.\\nSo we're splitting this DataFrame,\\nand so that's the sprints DataFrame, into groups.\\nAnd our group here is the NOC,\\nso that's the country they represent,\\nthe agenda, and the event, and that's given\\nby the columns that we have over here.\\nWe then apply a function,\\nand in this case it's the count function,\\nand it combines all of the results in this DataFrame.\\nSo let's see how Pandas comes up with this DataFrame.\\n\\nSo if you take a look at Walter Dix, you can see\\nthat his 100-meter bronze is responsible\\nfor this entry over on the right.\\nIf I was to scroll down to the next one,\\nso that's Usain Bolt and his 100-meter gold,\\nyou can see he's responsible for the 100-meter gold.\\nIf I was to head down a little bit further,\\nbecause we've got three medal winners from Jamaica,\\nthey're all responsible for that entry,\\nand that's why we have three entries\\nfor the 100-meters that you can see in this DataFrame.\\n\\nAnd if we were to work our way down, so you can see\\nthat Walter Dix and Sean Crawford are responsible\\nfor the count of two,\\nbecause they're both from the US,\\nand they were both in the 200-meter race\\nwhere they won the bronze and the silver medals.\\nLet's head back to our notebook.\\nSo now let's go back to our updated DataFrame\\nand let's group by year.\\nAnd you can see\\nthat the object that we have is a groupby object,\\nand we can get some more details on that type we wanted.\\n\\nNow we can go ahead and perform an operation\\non that groupby object.\\nAnd so we can perform a count, and we get this DataFrame.\\nNow there are two components to the groupby object\\nand we can go and pick them apart.\\nOne is the groupby key,\\nand the other one is the group value.\\nSo let's go ahead and take a look\\nat these separate components.\\nNow, because we're grouping by year,\\nthe groupby key is the year, so we've got the year 2004.\\nAnd then these are all of the entries\\nthat correspond to the 2004 Olympic Games.\\n\\nSimilarly, we've got the 2008 key,\\nand then these are all of the entries\\nthat correspond to the 2008 games.\\nNow let's take a look at what type that group value is.\\nAnd you can see that this is a DataFrame,\\nso we could go ahead and group by year,\\nand the operation we'd perform there is a count operation.\\nAlternatively, you could also use the size method.\\nNow size is similar to count,\\nbut it also includes null values in its count.\\n\\nAnd so you can see\\nthat we get a very neat looking series.\\nSo I could group by the year\\nand the country that the athletes represent,\\nand I could get a count.\\nNow if I just want to be able to see the medal column,\\nI can filter by the medal column by just providing that\\nas a list here, and then applying the count.\\nAnd you can see that we then get a series as an output.\\nI can get exactly the same information\\nby using the size method.\\n\\nAnd similarly, I can go ahead and group by the year,\\nthe country that's represented, and a medal.\\nNow I want you to pause the video here,\\nand try and figure out what this instruction will do.\\n(upbeat music)\\nSo what this does is it's grouping by the country\\nand then it's filtering by the year,\\nand then the function you're performing is the minimum.\\nSo what this is giving you is the first time each\\nof the countries received their Olympic medal.\\n\\nSo for example, you can see that AFG, which corresponds\\nto Afghanistan, won their first Olympic medal in 2008.\\nVIE, which corresponds to Vietnam,\\nwon their first Olympic medal in 2000.\\nZZX, which corresponds to the mixed group,\\nreceived their first medal in 1896.\\nNow correspondingly the max is the most recent year\\nthat each of these countries have received a medal.\\nNow, if I want to be able to combine a couple\\nof these statistical operations, so that's min, max,\\nand count together, I can use the aggregate function\\nand then combine them in a list.\\n\\nAnd so you can see that for each of the countries,\\nI filter by year, and then I aggregate the minimum,\\nthe maximum, and the count.\\nAnd so what this is saying, for example, is\\nthat Afghanistan won its first Olympic medal in 2008,\\nand the last time that it won an Olympic medal\\nwas in 2008 also.\\nAnd this is just based\\non the 1896 to 2008 dataset that we're using.\\nAll right, so we've seen that groupby is one\\nof the most important functionalities available in Pandas,\\nand it allows you to make sense of your data.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5912589\",\"duration\":379,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Reshaping data: Stacking, unstacking, and MultiIndex\",\"fileName\":\"4493047_en_US_04_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":735,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"stack() takes levels from columns to the index. unstack() returns a DataFrame with a new level of column labels. After watching this video, you will be able to demonstrate how both of these work.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12357911,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Imagine you're trying\\nto build a house of cards,\\nbut the cards are all scattered in a messy pile.\\nThat's kind of what it's like working with data\\nthat's not structured in the way you want.\\nNow, one of the ways you can order your data in Pandas is\\nto use the stack and unstack.\\nLet's head over to our notebook.\\nSo we're going to be working with the sprints data again.\\nSo, that's the 100 and 200 meters sprints for the men\\nand women in the 2008 Olympics.\\nNow, one of the best ways to understand\\nwhat stack and unstack does is\\nto see it at work visually first,\\nand then we'll come back to this notebook.\\n\\nSo let's head over to pandastutor.com.\\nSo we've got our data over here\\nand the first thing we'll do is we will count\\nthe values using size.\\nNow based on this group by operation,\\nso, that's the NOC gender and event.\\nWe have these corresponding counts.\\nLet's perform our first unstack operation.\\nSo, what's happening with an unstack is we are taking items\\nfrom the column over on the left\\nand moving them to the items over on the right.\\n\\nSo if you were to take a look at the series over in blue,\\nwe are taking these items\\nand we are distributing them among the men\\nand women columns over on the right.\\nNow, the reason that we have an NAN or a naughty number is\\nbecause we have no women runners in the a hundred meters\\nfrom either Trinidad or the USA who won a medal.\\nNow I can go ahead and perform the second unstack operation,\\nbut let's take a look\\nat what the unstack operation is doing.\\n\\nWe are taking the associated levels from the rows\\nor the index, and we are moving them over to the column.\\nSo when we perform successive unstack operations,\\nso this time we're going to be doing an unstack on the NOC\\nand let's go ahead and visualize that.\\nYou can see that the NOC column over on the left is\\nmoved over to the right.\\nAnd so if I was to just take a look at the entries in blue,\\nyou can see how they've been redistributed in the data frame\\nover on the right.\\nNow, as you can imagine, stacking is the reverse operation.\\n\\nSo we are taking the associated levels from the column\\nand we are moving them to the index of the row.\\nOr you can think of it this way with stacking,\\nwe are making the resulting data frame taller,\\nand with unstacking we are making\\nthe resulting data frame wider.\\nSo now that we have a good visual representation\\nof the unstack operation, let's head back to our notebook\\nand we'll review much of what we saw in the notebook.\\nSo we're doing a group by operation on the NOC gender\\nand event, and we're doing a count of that\\nusing the size function.\\n\\nLet's take a look at the documentation for unstack\\nso you can unstack with a couple of parameters.\\nNow, every time we have a naughty number value, we can fill\\nthat with a number that makes sense for that data set.\\nSo for us here with the Olympic medals, it would make sense\\nfor us to have a fill value of zero.\\nSo let's go ahead and check this out on our unstack.\\nSo we've got fill values of zero\\nand we are unstacking based on gender.\\n\\nNow, if we perform the unstack on both gender\\nand event, we get the resulting data frame.\\nNow alternatively, we could do an unstack on both gender\\nand event and we'll end up with the same result.\\nSo if we take a look at our original group by,\\nso we've got grouping by NOC gender and event\\nand the operation we're performing there is a size.\\nSo we end up with this series.\\nNow we can also unstack by specifying a level.\\n\\nSo instead of saying gender, we can say level one\\nbecause in Python counting, the first column corresponds\\nto zero, the second one to one.\\nSo an SP unstack level one will give us exactly the same\\noutput as unstacking by the gender.\\nNow let's go ahead and create a table called sprints table.\\nAnd what we're going to want to do here is we want to be able\\nto stack this sprints table,\\nand we're going to store this in the variable sprints NOC.\\n\\nSo this is our corresponding data frame.\\nNow you'll notice that we have an index that seems\\nto have these two components.\\nOne is Jamaica men, and the second one is Jamaica women.\\nSo if you want to be able to identify the Jamaican men\\nwho took part in the 100 and 200 meters, you'd want\\nto specify this section here\\nand you'll be able to get these results over here.\\nAnd so the way we do that is by using what's known\\nas a multi-index.\\n\\nAnd so this representation\\nfor this index over here is what's known as a topple\\nbecause they're in brackets.\\nAnd so if I want to get all of the results\\nfor the Jamaican men, I can do a sprints, NOC LOC,\\nJamaica comma men, and then all of the results over here.\\nAnd so we should expect to see the 100 meters\\nand the 200 meters.\\nNow, similarly if I just want to be able to get the results\\nfor the a hundred meters over here\\nand so that's just this result over here,\\nI can specify the row which corresponds to this multi-index,\\nJamaica and men and the column entry is a hundred meters.\\n\\nAnd this is where I'll get to the count of one.\\nNow, I can also identify each of the components\\nby using an eye look.\\nAnd so I can specify that I want the first row\\nand all of the entries in the first row,\\nor I want the first row and the first column,\\nand I end up with that count of one.\\nNow if you want to take a look at further documentation,\\nthen you can do so with the stack and the unstack.\\nAlright, so just a quick summary of that.\\nWith stacking, we're making our resulting data frame taller\\nbecause we're taking the associated levels from the column\\nand moving them to the index of the rows.\\n\\nAnd with unstacking,\\nwe are making our resulting data frame wider\\nbecause we are doing the reverse,\\nwe're taking the associated levels from the rows or index\\nand moving them to the column.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5914606\",\"duration\":42,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Visualizations\",\"fileName\":\"4493047_en_US_04_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Needs Challenge Bumper\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":57,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1273943,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat electronic music)\\n- [Instructor] Time for some challenge questions.\\nSo the first one is using a line graph\\nplot the number of gold medals won by the USA male\\nand female Olympians throughout the history of the Olympics.\\nDistinguish between the male\\nand female Olympians in the line graph using blue and pink.\\nSo blue for male and pink for female.\\nAnd the second question is using a bar chart\\nplot the five Olympians\\nwho have won the most gold medals from the dataset.\\n\\nSo that's 1896 to 2008.\\nand when there is a tie,\\nconsidered the number of silver medals\\nand then bronze medals.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5914605\",\"duration\":347,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Visualizations\",\"fileName\":\"4493047_en_US_04_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Needs Solution Bumper\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":609,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12515139,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(techno music)\\n- [Instructor] Now I'm going to show you just one way\\nof solving this challenge problem.\\nSo the challenge question is using a line graph,\\nplot the number of gold medals won by the USA male\\nand female Olympians throughout the history of the Olympics.\\nDistinguish between the male and female Olympians\\nin the line graph using blue for male\\nand pink for female.\\nSo we've run our pre-process functions.\\nNow because we want USA Olympians who've won gold medals,\\nwe filter by NOC of USA and medal being gold,\\nand we store that in the variable usa_gold.\\n\\nThe next thing we'll want to do is to group by the year\\nand the gender and get a count of that.\\nNow let's take a look at the index that we have here.\\nAnd you can see not surprisingly, this is a multi-index.\\nNow we're looking to plot a graph.\\nIt'll be quite interesting to see\\nwhat a multi-index graph looks like.\\nSo let's plot our line graph\\nand see what we get when we have a multi-index\\non the X axis.\\n\\nAnd you can see that we've got these tuples\\nwith 1896 and men, 1920 for men and so on.\\nSo clearly having a multi-index is not going to allow us\\nto get the line graph that we want.\\nSo let's go back to our original groupby,\\nand let's now go ahead and unstack this series\\nand we unstack it by gender.\\nSo we're moving the men and the women across to the columns.\\nNow the reason we do this is\\nbecause then this way we will be able\\nto plot separate line graphs for the men and the women.\\n\\nSo now we have in the index or on the rows, the year,\\nand over on the columns we have the men and the women.\\nAnd so you can imagine visually\\nthat over on the X axis we'll have the year.\\nAnd over on the Y axis we'll have\\nthe count for the men and the women.\\nSo let's go ahead and plot this line graph.\\nAnd this looks a lot more like what we're looking for.\\nSo you've got the men represented by blue\\nand the women represented by orange.\\n\\nNow if you remember, when we tried to get the documentation\\nfor the plot in this way, we always ended up\\nwith this message \\\"Object 'plot' not found.\\\"\\nSo we can go back to first principles and try\\nand determine what the objects we're working with are.\\nAnd so since we're working with a series object here,\\nwe can go ahead and try\\nand get the documentation for the plot in that way.\\nNow, if we want to try and change the colors\\nfrom orange and blue to blue and pink,\\nlet's see if there's a corresponding\\nparameter over here.\\n\\nAnd you'll find that if you look through the documentation\\nthat there's a parameter color.\\nAnd so we can experiment and if we try a color\\nand we provide a list, so blue and pink in a list,\\nwe'll be able to get the output we want.\\nSo what we'll have to do is experiment a little bit here\\nbecause you can see that here I've got both the men\\nand the women with,\\nand I've got it right the first time round.\\nSo I've got men in blue and women in pink.\\nI could have got it wrong the first time\\nand so I might have had to have swapped them around.\\nAnd so for example, what I could have had here is pink\\nand then blue and I could swap them around\\nand get the colors that I want in this way.\\n\\nLet's head over to the second question.\\nSo using a bar chart plot the five Olympians\\nwho've won the most gold medals from the data set.\\nAnd that's from 1896 to 2008.\\nWhen there's a tie, consider the number of silver medals\\nand then the bronze medals.\\nSo we're going to use our updated dataset here\\nand we're going to group by the athlete name and their medal.\\nIf you do a groupby\\nand they do a count of this, we get this groupby object.\\n\\nNow let's go ahead and separate this out.\\nAnd so we will have a size on one line\\nand then let's go ahead and unstack this.\\nAnd we remember to have the fill values so that we have\\nthat for any end values.\\nSo this data frame is starting to look quite promising.\\nThe next thing we'll want to do is we'll want\\nto sort the values by gold and then silver and then bronze.\\nAnd so we can do that using the sort_values method.\\nBut because we want the numbers with the highest number\\nof golds and then the highest number of silver\\nand then the highest number of bronze,\\nwe'll want to sort in reverse order.\\n\\nAnd so we'll say ascending equals false.\\nAnd so we have the highest number\\nof golds over here followed by silver and bronze.\\nNow, it would be helpful if we could actually get this data\\nframe so that we had first the gold\\nfollowed by the silver and then the bronze.\\nAnd so we can change the order of the columns\\nby providing them as a list over at the end here.\\nAnd so we now have the athlete names,\\nthe corresponding gold, silver, and then bronze.\\n\\nNow because we're looking for the top five athletes,\\nI'm going to use the head method\\nwith the default parameter of five.\\nAnd we're going to be explicit and specify five.\\nAnd so we have these five athletes\\nwho've won the most number of medals.\\nNow because we want to plot it as a bar plot,\\nI'm going to go ahead and chain the plot method.\\nAnd there we have it.\\nWe've got Michael Phelps leading the way,\\nfollowed by the most decorated woman,\\nwhich is Larissa Latynina and so on.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5911590\",\"duration\":103,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating your own colormaps\",\"fileName\":\"4493047_en_US_04_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":163,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Sometimes the default colormaps do not meet your requirements. After watching this video, you will be able to define your own colormaps.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3841785,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's go ahead and create our own color maps.\\nNow, our starting point is going to be\\nthe solution from the previous challenge.\\nSo if you haven't reviewed that,\\nyou probably want to take a look at that solution.\\nSo the result that we got for that was this bar graph\\nwhere we have the gold, silver, and bronze\\nfor the Olympians.\\nAnd you can see that we've got gold represented in blue,\\nsilver in orange, and bronze in green.\\nNow, this would be so much more effective\\nif you could actually use the colors\\ngold, silver, and bronze.\\n\\nSo let's go ahead and try and do that\\nand define our own color map.\\nNow, one of the classes available in Matplotlib\\nis the listed color map class.\\nLet's take a look at the documentation for this.\\nAnd you can see that one of the parameters is colors\\nwhere you can provide a list\\nof Matplotlib color specifications.\\nAnd so these can be RGB values or red, green, and blue.\\nSo let's go ahead and do exactly that.\\nSo I've gone over to the internet\\nand looked up the corresponding values\\nfor gold, silver, and bronze.\\n\\nAnd these are the corresponding Hexadecimal values\\nbecause these are the values that you will need.\\nAnd I've stored them in a list.\\nSo I'm going to pass this to the listed color map class,\\nand the result is going to be our color map\\nthat we're going to be using with our gold, silver, and bronze.\\nNow all we need to do is to update the last line\\nwhere we specify that we want to be using\\nour corresponding color map and we're able to get\\na far more compelling visual representation\\nusing gold, silver, and bronze.\\n\\n\"}],\"name\":\"4. Visualizations\",\"size\":65388556,\"urn\":\"urn:li:learningContentChapter:5911600\"},{\"duration\":536,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5910586\",\"duration\":49,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Final challenge: Recap\",\"fileName\":\"4493047_en_US_05_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Needs Challenge Bumper\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":51,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1507252,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Narrator] All right, we're onto our final challenge.\\nSo for each Olympic year present in the dataset,\\nshow the US Olympian\\nand their sport, who's won the highest number\\nof medals in that particular year.\\nNow, in the case of a tie, a gold is better than a silver,\\nwhich is in turn, better than a bronze medal.\\nInclude only one Olympian for each Olympic year.\\nSo this means if there are two Olympians in one year\\nwho've won exactly the same number and type of medals,\\nthen show only the first one, based on sorting the names\\nin reverse alphabetical order by surname.\\n\\nYou should show the following columns\\nfor each of the Olympic years.\\nSo that's the athlete name, the sport, and the total.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5915591\",\"duration\":487,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Recap\",\"fileName\":\"4493047_en_US_05_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Needs Solution Bumper\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":752,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":20816266,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Now, this is just going to be one of the ways\\nto go about solving this problem.\\nThere are going to be multiple ways you can go about it.\\nSo we ensure that we have the data that we need\\nand we process our files.\\nSince we're just looking at USA Olympians,\\nwe want to be able to filter by the NOC USA.\\nAnd so we go ahead and do that.\\nAnd you can see that we've got about 4,300 rules.\\nNow, I then want to be able to capture information\\nabout the year, the athlete name, the medal, and the sport.\\n\\nSo let me go ahead and do a group by\\nand a size operation for that.\\nSo that will give me an effective count.\\nAnd now let's go ahead and move the medals\\nfrom this side over here in the index over to the columns.\\nAnd so we'll want to do an unstack operation.\\nAnd you can see as a result\\nthat we've gone from around 4,300 rows here\\nto more than two and a half million rows over here.\\n\\nAnd this is because we now have a row for each athlete.\\nSo you can see that we've got a multi-index,\\nbut we've got a row for each athlete.\\nAnd the vast majority of these rows are going to have\\na total number of medals that are zero\\nbecause the athletes haven't received medals for that sport.\\nIn fact, they didn't even compete in those sports.\\nBut that's okay because what we'll do later on\\nis to just sort them and filter these entries out.\\nSo let me go ahead and save this\\nas a data frame called table because we're going to reuse this.\\n\\nNow, the next thing I want to do\\nis I want to sum up the bronze, silver, and gold medals\\nand I want to store that in a column name called total.\\nAnd so I'm going to use the assigned method\\nand this will give me the total number of medals\\nfor each of these athletes.\\nNow, what I'd really like to do is to be able\\nto move out of these multi-indexes\\nand go back to where we have indexes\\nor indices that are just numeric values.\\n\\nAnd one way to achieve this is to just reset this index.\\nSo I'm just going to go ahead and reset that multi-index.\\nAnd let's take a look at what table looks like now.\\nAnd you can see that this is a much cleaner form\\nand you can see again that most of the rows have\\na total number of medals of zero\\nbecause we don't have these athletes\\ntaking part in these sports.\\nNow, if you remember, we can group by year,\\nand there are two pieces of information that we get back.\\n\\nOne is the key. So for example, that is year.\\nAnd the second component is the group,\\nwhich is a data frame.\\nSo let's go ahead and take a look\\nat what information we have in that group\\nor in that data frame.\\nAnd so for example, this is the grouping for the year 1996.\\nThis is the grouping or the data frame for the year 2000\\nand so on.\\nNow, what I'd like to do is to be able to sort\\nthis data frame by the total number of medals,\\nbut I want to be able to sort it in reverse order\\nso I have the highest number of medals over at the top.\\n\\nAnd so again, you can see that we've got the groups by 1996,\\n2000, and so on,\\nwith the highest number of medals over at the top.\\nSo we've got a total of four medals over here\\nand then heading down to three and then zero.\\nNow, what I'd like to do next\\nis because I want to also be considering the athlete's name\\nas part of the criteria,\\nI don't only want to just use the total\\ngold, silver, and bronze, but I need to include\\nthe athlete name in the event that there is a tie.\\n\\nSo I'm going to go ahead and do a sort values\\nand add the athlete's name.\\nAnd then I want to be able to capture only one entry\\nfrom each of those groups.\\nAnd so I can do that by using the head method\\nand providing a value of one.\\nNow, you can see that I've got something\\nthat is starting to take shape\\nand anytime that I can iterate through items like this\\nusing a for loop means that I can start thinking about\\ntrying to put this into a list.\\n\\nAnd the reason that I'd want to think about a list\\nis because if I have a list of data frames,\\nthen I know that I'm done because all I need to do\\nis to combine all of the items\\nand I can combine them into a single data frame\\nand that will be the answer that I want.\\nSo what I want to do is to just use this for loop\\nand convert this using a list comprehension\\nso instead, I have this as a list of these items.\\nAnd the way that I can do that,\\nand we've seen this a couple of times,\\nis to use a list comprehension.\\n\\nSo let me just call that winners\\nwhere I take that statement.\\nSo that group sort values all the way up to the first item\\nfor each year, and I'm adding that to my list\\nfor each of the years in the table.\\nAnd so let's take a look at the associated list\\nand let's make sure that we understand what this is.\\nSo let me just go ahead\\nand view the first item in this list.\\n\\nAnd you can see that the first item\\ncertainly looks visually like a data frame.\\nLet's just go ahead and confirm that\\nthat's in fact the case.\\nSo now I have a list of data frames.\\nSo I can easily combine them together\\nand I don't have to do any pre-processing on them\\nbecause they're all in the same format.\\nNow, when we had to update our original data set\\nwith the data from the 2008 games,\\nwe just concatenated our list of data frames together.\\nSo what's to stop me from concatenating\\nall of these games together to get a complete data frame?\\nAnd so let's go ahead and provide the winners list\\nto the concat method.\\n\\nAnd we have our data frame with the results that we want.\\nNow, there's just a little bit more work that we need to do\\nto just format this in the way that we need it.\\nSo let me go ahead\\nand ensure that I'm displaying the year,\\nthe athlete name, the sport, and the total.\\nNow, you'll notice that we've got\\na couple of random values over on the left,\\nand they're not random values.\\nThese are the actual index values\\nfrom when we did the unstack operation.\\n\\nSo let's just tidy this up a little bit\\nand let's get rid of these numbers and let's reset this.\\nAnd so we can do that by using the reset index method.\\nAnd that's great, except it seems to have added\\nan additional column called index.\\nSo what we'd like to do is to do a reset index\\nand drop this additional index.\\nAnd so let's take a look at the documentation\\nto try and figure out how we can do that.\\nAnd so if I go ahead and just do a reset index,\\nquestion mark, you can see that we end up with\\na reset index not found.\\n\\nSo let's go back to the first principles.\\nWe know that this is going to be a data frame.\\nSo if you do a PD data frame.reset index,\\nthat will allow us to get access to the documentation\\nfor reset index.\\nAnd now if we take a look at the parameters,\\nso this doc stream will reset the index or a level of it,\\nand we can go ahead and use the drop parameter\\nand that'll allow us to go ahead and drop that index column.\\nSo let's say drop equals true,\\nand let's go ahead and take a look at these values.\\n\\nAnd there we have it,\\na list of US Olympians who've won the most number of medals\\nfor that particular Olympic year\\nacross all of the Olympic games from 1896 to 2008.\\n\"}],\"name\":\"5. Learning Recap\",\"size\":22323518,\"urn\":\"urn:li:learningContentChapter:5917326\"},{\"duration\":39,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5910585\",\"duration\":39,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Your next steps in pandas\",\"fileName\":\"4493047_en_US_06_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":48,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":779048,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Every four years\\nwhen the Summer Olympics are on,\\nI drop whatever I'm doing\\nand enjoy a fortnight of fabulous sport.\\nI'll be running a whole load of data analysis\\nand trivia competitions about the Olympics\\nright here on LinkedIn.\\nYou're welcome to connect with me on LinkedIn if you want to\\nstay in the loop and take part.\\nNow, my main job isn't coding,\\nbut do you know why I still code?\\nIt's the immediate feedback\\nthat I get on my problem solving skills.\\nThe skill to learn how to think clearly step by step\\nand keep improving is one of the biggest benefits of coding.\\n\\nSo learn how to code and keep coding.\\nIt doesn't matter whether it's Python and Pandas\\nor something else.\\n\"}],\"name\":\"Conclusion\",\"size\":779048,\"urn\":\"urn:li:learningContentChapter:5912593\"}],\"size\":442231658,\"duration\":11448,\"zeroBased\":false},{\"course_title\":\"Python for Data Visualization\",\"course_admin_id\":4499006,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4499006,\"Project ID\":null,\"Course Name\":\"Python for Data Visualization\",\"Course Name EN\":\"Python for Data Visualization\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;Data visualization is incredibly important for data scientists, as it helps them communicate their insights to nontechnical peers. But you don\u00e2\u20ac\u2122t need to be a design pro. Python is a popular, easy-to-use programming language that offers a number of libraries specifically built for data visualization. In this course from the experts at Madecraft, you can learn how to build accurate, engaging, and easy-to-generate charts and graphs using Python. Explore the pandas and Matplotlib libraries, and then discover how to load and clean data sets and create simple and advanced plots, including heatmaps, histograms, and subplots. Instructor Michael Galarnyk provides all the instruction you need to create professional data visualizations through programming.&lt;/p&gt;&lt;p&gt;This course was created by &lt;a href=http://www.onlymadecraft.com target=_blank&gt;Madecraft&lt;/a&gt;. We are pleased to host this content in our library.&lt;br&gt;&lt;br&gt;&lt;img src=https://media.licdn.com/media/AAYAAgCwAAoAAQAAAAAAAHppnBQxgeyWS2CsU3aDDPcMgw.jpg height=25% width=25%&gt;&lt;/p&gt;\",\"Course Short Description\":\"Build accurate, engaging, and easy-to-generate data visualizations using the popular programming language Python.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":\"21401000, 20517019\",\"Instructor Name\":\"Madecraft Licensor, Michael Galarnyk\",\"Instructor Transliterated Name\":\",\",\"Instructor Short Bio\":\"Full-Service Learning Content Company|Python Instructor and Blogger\",\"Author Payment Category\":\"LICENSED, NONE\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-01-16T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/python-for-data-visualization-2023\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Data Science\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":4883.0,\"Visible Video Count\":30.0,\"Contract Type\":\"LICENSED, NO_CONTRACT\"},\"sections\":[{\"duration\":133,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3371043\",\"duration\":73,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Effectively present data with Python\",\"fileName\":\"4499006_en_US_00_01_WL24\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":73,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"It is one thing to capture data, but to communicate and understand your data, you need to use tools that will help you visualize your data. After watching this video, you'll be able to see the value of data visualization using Python.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3130200,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - In this vast ocean of data, there hides many treasures.  \\n How do you find, let alone unlock, these treasure chests?  \\n Everyone is on the same quest, wondering how  \\n to leverage this data to gain understanding,  \\n see trends, and gain competitive advantages.  \\n Data science is the key to solving  \\n what businesses need today.  \\n Finding the right tool is critical.  \\n This is where Python comes in.  \\n You can create compelling and publishable visualizations  \\n using Python's powerful data science libraries.  \\n By creating your own visualizations, you'll be able  \\n to explore the data in a new way.  \\n My name is Michael Galarnyk.  \\n I'm a Data Scientist, Python Instructor,  \\n YouTuber, and Blogger.  \\n In this course, you will be able  \\n to create compelling data visualizations using Python.  \\n We'll take a look at some of the various tools available,  \\n and you'll learn how to manipulate data using Pandas.  \\n Also, you get a chance  \\n to create your own visualizations using Matplotlib.  \\n You'll review how to create box plots, heat maps,  \\n histograms, and more.  \\n By the end of this course, you'll feel confident and ready  \\n to go build your own powerful visualizations using Python.  \\n So, if you're ready to dive in, then let's go.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3374061\",\"duration\":33,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Before you start\",\"fileName\":\"4499006_en_US_00_02_MM24\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":33,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Creating data visualizations in Python requires some basic knowledge of lists, tuples, and dictionaries. After watching this video, you'll be able to determine if you know enough to take this course without reviewing additional material.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1329041,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - There are a few things I'd like you  \\n to be aware of as we get started.  \\n First, you should be able  \\n to understand basic Python data structures,  \\n such as lists, tuples, and dictionaries.  \\n Also, you get more out of this course if you have a basic  \\n understanding of Jupyter Notebooks.  \\n I'll be programming using Jupyter in this course.  \\n Having said that, don't worry if you're feeling a little  \\n shaky and unsure where to begin.  \\n As you proceed through this course, it'll provide you  \\n with a number of tips and resources.  \\n As you follow along, you'll quickly see how powerful  \\n Python visualizations can be.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3369055\",\"duration\":27,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Using the exercise files\",\"fileName\":\"4499006_en_US_00_03_MM24\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":27,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"The course includes a folder called Exercise_Files. After watching this video, you'll be able to utilize the course files and code, along with the videos.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":934594,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A folder of exercise files has been included  \\n to help you make the most of this course.  \\n You will be using them throughout the course.  \\n Please download those now so that you're prepared  \\n for when you need them.  \\n Check out your operating system's download folder,  \\n find the downloaded course exercise folder,  \\n and unzip these files.  \\n You'll see this folder here,  \\n which contains the contents of this course.  \\n Once you have done this, you'll be ready to code along.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":5393835,\"urn\":\"urn:li:learningContentChapter:3369060\"},{\"duration\":337,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3372047\",\"duration\":58,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Value of data visualization\",\"fileName\":\"4499006_en_US_01_01_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":58,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Data visualization is all about helping you and your stakeholders understand data on a more intuitive level. After watching this video, you'll be able to decide how data visualization can help your goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1371334,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] At the core of it,  \\n data visualization is all about  \\n communicating results from data.  \\n It's about simplifying data,  \\n cleaning data with the end goal of helping you,  \\n and your stakeholders understand data  \\n on a more intuitive level.  \\n To bring this to life,  \\n I want to give you an example.  \\n Suppose you take out a loan,  \\n and you're given a payment table like this.  \\n When you look at this,  \\n what you really want to do is find out  \\n how much you're paying interest over time.  \\n Now, this table is not really  \\n a great way to see this data.  \\n Instead, we might look to create  \\n a visualization like this.  \\n And as you can see,  \\n you actually pay more interest  \\n at the beginning of a loan,  \\n and this wouldn't have been clear  \\n if we didn't see this graph.  \\n And just like this example,  \\n visualizations can help change our perspectives  \\n or behavior.  \\n Another way to look at this is by using  \\n a visualization like we see here.  \\n It's easy to see.  \\n The longer the term the loan,  \\n the more you end up paying an interest overall.  \\n And just like that,  \\n data visualizations can be really powerful,  \\n and that's a reason why you should use  \\n visualizations in your day-to-day work.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3372048\",\"duration\":178,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Leverage programming languages\",\"fileName\":\"4499006_en_US_01_02_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":178,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Data visualization is an iterative process, and the ability to quickly iterate on a visualization can save a lot of time. After watching this video, you'll be able to explain why you might want to use a programming language to visualize data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4348777,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] There are a lot of great reasons  \\n to use a programming language like Python  \\n to build data visualizations.  \\n First, there are a lot of different types of visualizations  \\n you can make,  \\n including boxplots, bar graphs, line graphs,  \\n histograms, et cetera.  \\n Second, using a programming language  \\n to build the data visualization  \\n allows you to quickly iterate  \\n and improve on a visualization,  \\n as well as try out many different visualizations.  \\n To get you started, I want you to first understand  \\n a data visualization process.  \\n You first have to have data, where you clean it,  \\n you simplify it, and sometimes even augment your data source  \\n if your data source is not rich enough.  \\n From there, you can use that understanding  \\n from your visualization  \\n to improve your data quality  \\n or to explore other aspects of your data,  \\n and this process can keep on going  \\n until you have a visualization  \\n that tells a compelling story.  \\n So there are a few common tools and libraries in Python  \\n to build data visualizations.  \\n In this course,  \\n we're going to utilize the Anaconda Python distribution,  \\n and second, I encourage you to use Jupyter Notebooks.  \\n That's the program I'll be using throughout this course.  \\n Next, there are two major plotting libraries in Python,  \\n Matplotlib and Seaborn.  \\n And lastly, we'll go over the NumPy and Pandas libraries,  \\n as before you can visualize data, you have to get it,  \\n you have to clean it, and sometimes even augment it,  \\n and NumPy and Pandas help you do it.  \\n So as far as why we use the Anaconda Python distribution,  \\n Python has a solid claim  \\n to be the fastest-growing major programming language,  \\n and Anaconda is the strongly recommended way  \\n of installing Jupyter Notebooks.  \\n So what Anaconda is really is a package manager,  \\n an environment manager, and Python distribution.  \\n Think of it as kind of like an app store for Python.  \\n Data visualization projects  \\n require many different packages and libraries.  \\n What's great is that Anaconda comes pre-installed  \\n with many of them.  \\n So what about Jupyter?  \\n Jupyter Notebooks contain both code and rich text elements,  \\n such as visualizations, links, and equations.  \\n So right here is a Jupyter Notebook in action,  \\n and you'll see a lot of that throughout this course.  \\n So I want to quickly tell you about NumPy and Pandas.  \\n Before we can plot data,  \\n we first need data in a portable form.  \\n NumPy and Pandas can be used to efficiently load,  \\n store, manipulate, and export in memory data.  \\n Pandas can also be used as a wrapper for Matplotlib,  \\n which brings us to Matplotlib and Seaborn.  \\n They're very popular Python plotting libraries.  \\n Matplotlib's API is relatively low-level.  \\n This allows for a lot of customization,  \\n but also a lot of code.  \\n A way around this is to utilize a Seaborn wrapper,  \\n which offers high-level graphics  \\n and integrates well with Pandas' library.  \\n It's also important to keep in mind  \\n that with every Matplotlib wrapper like Seaborn  \\n is still often useful to dive into Matplotlib's syntax  \\n to adjust the final plot output.  \\n And that's it.  \\n These are a couple common tools you can use  \\n to build data visualizations.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3373064\",\"duration\":101,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Overview of Jupyter Notebooks\",\"fileName\":\"4499006_en_US_01_03_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":101,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Jupyter Notebooks provide a powerful way to write and iterate on your Python code for data cleaning and visualization. After watching this video, you'll be able to open Jupyter Notebooks and execute some basic commands.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2729351,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] To get started with the Jupyter Notebook,  \\n you first have to open it.  \\n I'm working on a Mac, and on a Windows  \\n and a Mac, you can open up a Jupyter Notebook  \\n through Anaconda Navigator.  \\n I'll click on Anaconda Navigator.  \\n If you're using a PC,  \\n it should look pretty similar.  \\n To open it, I go ahead and click Launch.  \\n As you can see, Anaconda run a process,  \\n and it's open at Jupyter Notebook here in Chrome.  \\n Depending on what your default browser is,  \\n it could open up in a different browser such as Firefox,  \\n Safari, or Microsoft Edge.  \\n I'll go ahead and make this full screen.  \\n I'll click on Desktop.  \\n I'm going to open up a Jupyter Notebook  \\n by clicking New, Python 3,  \\n and traditionally, like you always do, I'll go ahead  \\n and print Hello World.  \\n I'll press Shift + Enter to run the cell,  \\n and there we go.  \\n Jupyter also allows you  \\n to do markdown cells, which are very useful  \\n for annotating your code.  \\n So to annotate your code, go to Sell, Sell Type,  \\n and click on Markdown.  \\n Using Markdown,  \\n I made a secondary header, and I said loading data.  \\n And the reason why I did that is that oftentimes,  \\n it's good to use markdown to organize your code  \\n and to communicate with feature users  \\n of your Jupyter notebook.  \\n In this case, it'll allow others to know  \\n that the cells below are for loading data.  \\n You can also add new cells by doing Insert Above  \\n or Insert Below.  \\n So really, that's all you can know right now.  \\n If you're new to Jupyter Notebooks, don't worry,  \\n you're going to learn a lot more as we go through this course.  \\n \\n\\n\"}],\"name\":\"1. Data Visualization Overview\",\"size\":8449462,\"urn\":\"urn:li:learningContentChapter:3372052\"},{\"duration\":2207,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3372049\",\"duration\":90,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to pandas\",\"fileName\":\"4499006_en_US_02_01_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":90,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"The pandas library is meant for data manipulation and analysis. After watching this video, you'll be able to understand how the Python pandas library stores data in a tabular format with row and columns labels.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2641337,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In order to make a visualization,  \\n we need data,  \\n and we usually need it in organized tabular form  \\n suitable for plotting.  \\n The Pandas library provides easy to use data structures  \\n and data analysis tools you can use  \\n to make your data easier to plot.  \\n Pandas data frames are multidimensional,  \\n labeled data structures similar to tables and spreadsheets  \\n with rows and columns.  \\n With it, you can store and manipulate data  \\n in a table format,  \\n providing a convenient way to analyze and visualize it.  \\n An important data structure of the Panda's library  \\n is a fast and efficient object for data manipulation  \\n called a data frame.  \\n You can manipulate and transform data frames easily  \\n with various Pandas methods.  \\n You can perform operations such as filter rows  \\n based on certain conditions, sort the data,  \\n pick specific columns, merge or join multiple data frames,  \\n and aggregate data.  \\n Another useful feature of Pandas  \\n is its ability to deal with missing data.  \\n With Pandas, you can detect missing values,  \\n fill them with appropriate values,  \\n or remove them all together.  \\n It's crucial to have this capability  \\n when dealing with incomplete or messy datasets.  \\n The image below is a Pandas data frame.  \\n A row represents an observation,  \\n and a column represents a feature.  \\n Rows have labels called indexes.  \\n So for example, this row is the row with index zero.  \\n This row is a row with index one.  \\n Columns also have column names.  \\n So we have the month column.  \\n We have the starting balance column,  \\n the repayment column, and so on.  \\n Once you create a Pandas data frame,  \\n you will more easily be able  \\n to manipulate and clean your data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3373065\",\"duration\":230,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Create sample data\",\"fileName\":\"4499006_en_US_02_02_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":230,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Sometimes you have create your own data, so it is a good idea to know how to initialize your own pandas DataFrame. After watching this video, you'll be able to create sample data and put it into pandas DataFrames.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10506659,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In order to create visualizations,  \\n you first need to have data to work with.  \\n So in this video I'll teach you how  \\n to create sample data in the form of a car loan table.  \\n So what we have here is a car loan of $34,690  \\n with a 7.02% interest rate over 60 months.  \\n There are multiple approaches to structure your data  \\n and to a form acceptable by Pandas DataFrame.  \\n One approach is by using a nested list  \\n where in the first row,  \\n we have the first month of our car payment.  \\n So we have one for the month, we have our starting balance,  \\n we have a repayment, which is $687.23.  \\n We have how much of that repayment is going toward interest.  \\n We have how much of  \\n that payment is going toward the principal of the loan.  \\n And then after a payment we have  \\n how much is our new balance?  \\n We have the terminal loan,  \\n which is how many months we're going to be paying this loan  \\n for in total.  \\n We have the interest rate for the loan  \\n and we also have the car type.  \\n In this case it's a Toyota Sienna.  \\n And then we also have the column names, which are  \\n what I just told you before in the form of a Python list  \\n where we have the month, the starting balance,  \\n the repayment, et cetera.  \\n And then once we have the data in a nice clean format,  \\n we're going to press shift enter to run the cell.  \\n From here we're going to use the PD.DataFrame method  \\n and we're going to insert our carLoans variable  \\n into the data parameter and our colNames variable  \\n into the columns parameter.  \\n And then we're going to press shift enter  \\n to initialize our DataFrame.  \\n And from here we're going to press shift enter again.  \\n And we have our data in a nice clean format.  \\n And obviously this is more readable than a nested list,  \\n but there's also other ways to do this as well.  \\n We could have also structured our data  \\n in the form of a NumPy array.  \\n And this looks very similar to a nested list, except  \\n for a NumPy array is more efficient than a Python list.  \\n And similarly, we have the same colNames as before.  \\n So now that we have the data in a format that we like,  \\n we're going to press shift enter.  \\n And just as before, we're going to have our carLoans variable  \\n assigned to the data parameter  \\n and our colNames variable assigned  \\n to our columns parameter.  \\n We're then going to press shift plus enter  \\n to initialize our dataframe.  \\n And as before, we have our data in a nice clean format,  \\n which is obviously easier to look at than an NumPy array.  \\n The third approach is to use a Python dictionary.  \\n And while this may not seem like as clean for a format  \\n to structure your data, there are times when you're already  \\n going to have your data in a Python dictionary.  \\n It'll just be easier to use that Python dictionary  \\n to then initialize the panda's DataFrame.  \\n So we have our carLoans data, and like before,  \\n we're going to press shift plus enter  \\n to initialize our carLoans variable.  \\n And from here we're initialize our Pandas DataFrame  \\n by having our carLoans variable assigned  \\n to our data parameter.  \\n And our colNames variable assigned to our columns parameter.  \\n And then we're going to press shift plus enter  \\n to initialize our dataframe.  \\n And like before you can see that we have our payment table,  \\n which is clearly an easier  \\n to look at format than our Python dictionary.  \\n So as you can see,  \\n building tables like these aren't all that difficult.  \\n However, there are some limitations of these approaches  \\n that I'd like you to be aware of.  \\n For example, if you have a larger data set,  \\n like the entire payment table for a particular car loan,  \\n for example, like what I'm showing here,  \\n it would be painfully slow to type this out  \\n and get it correctly, for one,  \\n and two, it'd be very memory intensive.  \\n And now that I've painfully typed out this payment table,  \\n we're going to run this cell by doing shift plus enter.  \\n And as before, we're going to initialize our DataFrame  \\n and voila, we have our entire payment table.  \\n This is a very tedious approach and I do not recommend it.  \\n I should note that if you don't know what a command does,  \\n for example PD.dataframe,  \\n you can always use the inbuilt Python function help  \\n to find out what the parameters accept  \\n as valid, and that's it.  \\n In order to create data visualizations,  \\n you need to have data and now you know how to create it.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3364070\",\"duration\":137,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Load sample data\",\"fileName\":\"4499006_en_US_02_03_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":137,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"The ability to load datasets is an essential skill as before you can manipulate and visualize data, you need to load it. After watching this video, you'll be able to load data into a pandas DataFrame from .csv and Excel files.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5846326,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In my line of work as a Python instructor,  \\n one question I often get from students is,  \\n \\\"How do you load your own data?\\\"  \\n In this video, I'm going to show you how to load CSV  \\n and Excel files using the Pandas library.  \\n So the first thing you have to do  \\n is you have to find out where your files are located.  \\n I've provided some exercise files included with the course.  \\n So inside the folder Exercise Files,  \\n inside the Pandas folder, under Data, I have two files,  \\n car_financing.csv and car_financing.xlsx.  \\n In this cell, we have a path to the file car_financing.csv.  \\n And what this here is is a relative path.  \\n So relative to the notebook load_data.ipynb  \\n I have the Data folder  \\n and inside the Data folder is the CSV file  \\n that we want to load.  \\n From here, we're going to use the pd.read_csv method  \\n to load that file into a Pandas DateFrame.  \\n And I'm going to press Shift + Enter.  \\n And then from here, we can look at the data frame.  \\n You can also load files from Excel.  \\n Inside the Exercise Files folder,  \\n we have a folder called Data,  \\n and inside that folder is a file called car_financing.xlsx.  \\n And what we're going to do now  \\n is we're going to read the Excel file  \\n using the method pd_read_excel into a Pandas DateFrame.  \\n And like before, we've loaded the file  \\n into a Pandas DateFrame.  \\n I should note that if you need help  \\n or if you don't understand what a method does,  \\n you can always use the in-built Help command  \\n to understand the documentation for a given method.  \\n And then I'll press Shift + Enter  \\n and I can see what the read_excel method takes in  \\n as parameters because sometimes your file may not load  \\n as perfectly as you may wish.  \\n So that's how you load data into Pandas DateFrames.  \\n And one more note,  \\n there are many different file types you can load  \\n than just CSV and Excel files into Pandas DateFrames.  \\n If you're curious about what other kind of files  \\n you can load, I encourage you to do pd.read_  \\n to see what other kind of files you can load.  \\n And there you go.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3366071\",\"duration\":117,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Basic operations\",\"fileName\":\"4499006_en_US_02_04_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":117,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Once you've loaded data into your pandas DataFrame, it's essential to explore and confirm accurate loading, understand the data types, and validate the dataset. After watching this video, you'll be able to check that your files have loaded properly and, most importantly, see if you have missing data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4371551,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] After reading the contents  \\n of a file into your Pandas DataFrame,  \\n it's important to examine your data for a couple of reasons.  \\n First, you need to ensure  \\n that you've correctly loaded the data.  \\n Second, you have to see what kind of data you have.  \\n And third, you have to check the validity of your dataset,  \\n and I'll go through a couple ways we can do this.  \\n So one of the first things you do  \\n after loading your data is look at the head  \\n and the tail of your dataset.  \\n The method head selects the top N number  \\n of records from your dataset.  \\n The method tail selects the bottom N number  \\n of records from your dataset.  \\n This is really important to do  \\n as oftentimes your data format  \\n could change throughout your dataset.  \\n Another important thing to do  \\n is to check your column data types.  \\n You can do this by using the dtypes attribute.  \\n One thing we'll notice is that certain columns are ints,  \\n certain columns are floats, whereas others can be objects  \\n and you can think of objects as strings.  \\n Another important thing to do is to find out how many rows  \\n and columns you have in your dataset.  \\n To do this, you can use the shape attribute,  \\n and you see that we have 408 rows and 9 columns.  \\n A really important thing to do that is often forgotten  \\n is to use the info method.  \\n And the reason why this is very valuable is that you can see  \\n how many non-null values you have in your dataset  \\n as oftentimes, data analysis tasks  \\n and data visualizations will not work  \\n if you have null values in your dataset.  \\n As you can see in the dataset over here  \\n for the interest paid column, we have one null value,  \\n because we have 407 non-null values  \\n versus every other column has 408.  \\n What this tells me is that I'll either have  \\n to remove the row or fill in the missing data  \\n with some sort of amputation technique.  \\n In the end, it is really important to remember  \\n to verify your data.  \\n Use the techniques I just showed you  \\n to make sure that everything looks good.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3366072\",\"duration\":252,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Simplify with slicing\",\"fileName\":\"4499006_en_US_02_05_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":252,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Before you can visualize data, it often helps to simplify data. After watching this video, you'll be able to select columns in pandas using brackets and the loc attribute, as well as understand how to execute slicing operations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9036411,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When working with large data sets,  \\n oftentimes you're only interested  \\n in a smaller subset of your data,  \\n and that's why slicing is so important.  \\n And in this video,  \\n I'll teach you how to select columns in pandas,  \\n because oftentimes, you're only interested  \\n in a smaller subset of columns in your data,  \\n and I'll also show you  \\n how to use slicing operations in pandas.  \\n I'm working with a car loans dataset,  \\n where I have the DataFrame df,  \\n and I'm looking at the first five rows.  \\n Let's say you're only interested  \\n in looking at a few columns of your dataset.  \\n So let's go over how to use brackets  \\n to select just a few columns.  \\n What the code here does  \\n is we're using double square brackets  \\n to only output one column of our data set.  \\n And as you see, I've only pulled out the car_type column.  \\n Now, we can also select multiple columns  \\n using double brackets.  \\n And let me show you how that's done.  \\n So right here,  \\n you notice that we have a list within these brackets.  \\n So I'm looking at the car_type column,  \\n and I'm looking at the Principal Paid column.  \\n So I run this, and now I have the car_type column  \\n and the Principal Paid column.  \\n And notice that when I use the inbuilt type function,  \\n that this is still a pandas DataFrame.  \\n One thing a lot of beginners often have difficulties with  \\n when working with pandas  \\n is if they just have single brackets,  \\n they end up with something that looks like this.  \\n This is called a pandas series,  \\n and what this is is a one-dimensional array,  \\n which can be labeled.  \\n In this case, our labels are zero or one or two  \\n or three and a four.  \\n These are called indexes.  \\n And notice when I use the inbuilt type function,  \\n I have a pandas series.  \\n Keep in mind that when you use pandas series,  \\n you cannot select multiple columns.  \\n This will result in a key error as you can see here.  \\n And this is a really common error  \\n that a lot of beginners run into.  \\n And this usually results  \\n from people wanting to select multiple columns.  \\n And the simple solution to this  \\n is simply to use a pandas DataFrame.  \\n In other words, use double brackets.  \\n So I have my DataFrame, I'm selecting my car_type column,  \\n and I'm selecting my Principal Paid column.  \\n One reason why you might use a pandas series  \\n as opposed to a DataFrame is that with a pandas series,  \\n you can select rows using slicing,  \\n where you have the series,  \\n the start index of what you want to select,  \\n the end index of what you want to select.  \\n And keep in mind, the end index is not inclusive,  \\n and this behavior is very similar to Python lists.  \\n So I have a pandas series here,  \\n where I'm looking at the car_type column.  \\n And this is the entire car_type column.  \\n Say I'm only interested in,  \\n let's say index zero up until but not including index 10,  \\n in other words, from here to here.  \\n I can use a slicing operation.  \\n So over here, I have my car_type column,  \\n and this is a pandas series, and here's my slice.  \\n And I'm just selecting from index zero  \\n up until but not including index 10.  \\n So from zero to nine.  \\n Keep in mind you can also select columns using dot notation.  \\n However, this is not the recommended syntax.  \\n And as you'll see in this cell over here,  \\n this can result in an error,  \\n as there's a space in this column name.  \\n Keep in mind that this also fails  \\n if your column name is the same as the pandas DataFrame's  \\n attributes, or methods.  \\n So a safer syntax is just to use single brackets.  \\n And lastly, I wanted to show you the preferred syntax  \\n for selecting columns.  \\n And this is by using the loc attribute.  \\n And this allows you to select columns, index,  \\n as well as slice your data.  \\n So over here,  \\n I'm selecting all the rows of my pandas DataFrame.  \\n I'm specifically saying I just want the car_type column,  \\n and then I want the first five rows.  \\n Similarly, if you just want a pandas series,  \\n you just take out the square brackets  \\n around your column name.  \\n So that's it.  \\n If in the future you're presented with a big data set  \\n and you want to look at a subset of it, consider slicing.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3373066\",\"duration\":339,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Filter and clean data\",\"fileName\":\"4499006_en_US_02_06_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":339,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Before you can visualize data, it often helps to clean data. After watching this video, you'll be able to filter pandas DataFrames based on multiple columns of data using various Python comparison operators.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11844319,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When working with a dataset,  \\n oftentimes you're only interested  \\n in a smaller subset of your data.  \\n For example, say I have a car loan dataset  \\n and I want to filter out the data to only have  \\n a car type of Toyota Sienna with an interest rate of 7.02%.  \\n So the first thing I'm going to do  \\n is I'm look at the first five rows in my dataset,  \\n and while it appears that the first five rows  \\n are only Toyota Siennas,  \\n that doesn't mean the rest of my dataset  \\n is all of car type Toyota Sienna.  \\n The first thing I'm going to do  \\n is I'll use the value counts method on the car type column  \\n to see what other kind of cars I have my dataset.  \\n I have my data frame, I have square brackets,  \\n I have the column I'm interested in.  \\n I'm going to close those brackets,  \\n and then I have the value counts method.  \\n When I press shift enter,  \\n you'll see that I have 120 Toyota Siennas.  \\n Say for example,  \\n I was interested in Toyota Corollas instead,  \\n I would have to fix the data entry errors  \\n because I have 111 Toyota Carollas, instead of Corollas.  \\n This is a really important thing to take note of,  \\n as oftentimes you'll have misspellings in your dataset,  \\n you'll have errors,  \\n you'll have things you don't quite understand,  \\n but that's all part of the data exploration process.  \\n And what I'll do now is I'll create a car filter,  \\n and the way this works is I have a data frame,  \\n I have square brackets,  \\n I have the column that I'm interested in.  \\n I close those single brackets.  \\n I have two equal signs because this is equality,  \\n and I have the type of car I'm interested in,  \\n in this case, Toyota Sienna.  \\n And what this produces is a pandas series  \\n of true and false values.  \\n There's a couple different ways  \\n to utilize this pandas filter of true and false values  \\n to get a data frame of just Toyota Siennas.  \\n One way is to have your data frame, square brackets,  \\n your car filter, which is your pandas series,  \\n you close those brackets,  \\n and then I'm just going to look at the first five rows.  \\n The second way is to use a lock attribute,  \\n and the way this works is I have a data frame,  \\n I have .loc, I have single brackets,  \\n I have my pandas series of true and false values,  \\n and this colon just means that I want  \\n to look at all the columns and I'll press shift plus enter,  \\n and these two approaches are equivalent  \\n in the result they produce,  \\n but oftentimes the second approach is more legible.  \\n As you can see, I have identical outputs  \\n for the two different approaches.  \\n One thing to keep in mind is that if I try to use  \\n the value counts method again on the pandas series,  \\n for the car type column, it'll seem like nothing changed.  \\n And the reason why it looks like nothing changed  \\n is because we didn't assign the filtered data frame  \\n back to the original data frame.  \\n And the way to fix this is by assigning  \\n the filtered data frame back to the original data frame.  \\n And now if you look at the value counts,  \\n it looks like we have a filtered data frame.  \\n Now that we've taken care of the car type filter,  \\n we also have to make an interest rate filter.  \\n And if I look at the pandas series  \\n for the interest rate column, and the value counts for it,  \\n you'll see that we have 60 rows with a 7.02% interest rate,  \\n and 60 rows with a 3.59% interest rate.  \\n And what I want to do in this section is filter the data frame  \\n to only have the 7.02% interest rate.  \\n The code here is a filter that produces a pandas series  \\n of true and false values, where the rows that are true  \\n are the ones with the 7.02% interest rate,  \\n and the false ones will be the rows  \\n with the 3.59% interest rate.  \\n So I have the data frame, I have single brackets,  \\n I have a string of the column that I'm interested in.  \\n I close those brackets.  \\n I have two equal signs, and then the 7.02% interest rate,  \\n and this produces a pandas series of true and false values.  \\n What I'm going to do next is I'm going to assign  \\n that pandas series of true and false values  \\n to the variable interest filter.  \\n To utilize my interest filter,  \\n I'm going to use the lock attribute,  \\n followed by single brackets.  \\n I'll have my pandas series of true and false values,  \\n and then I'm going to select all the columns,  \\n and I'm going to take this filtered data frame  \\n and assign it back to the original data frame.  \\n I'm going to do shift plus enter  \\n to create the filtered data frame.  \\n To check that my interest filter worked as intended,  \\n I'm going to look at the pandas series  \\n of the interest rate column.  \\n I'll use the value counts method,  \\n and I'm going to press shift plus enter,  \\n and you'll see that I have 60 rows  \\n with the 7.02% interest rate.  \\n In the previous sections, we created a car filter  \\n and an interest filter and used a lock command  \\n to filter the data by first applying the car filter  \\n and then the interest filter.  \\n A more concise way to do this is shown below.  \\n I have my data frame, I have the lock attribute,  \\n I have single brackets, I have my car filter,  \\n and then I use the and bitwise logic operator,  \\n along with my interest filter,  \\n and then I say, I want all the columns.  \\n And this would've worked just as well  \\n as applying each of the filters individually.  \\n As you can see, by using filtering, you can get the data  \\n that you're just interested in looking at.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3366073\",\"duration\":196,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Rename and delete columns\",\"fileName\":\"4499006_en_US_02_07_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":196,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"You may often need to change your column names to make them more descriptive or remove unnecessary columns. After watching this video, you'll be able to rename pandas DataFrame columns using dictionary substitution and list replacement to more suitable name. You'll also learn how to delete columns when needed.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6974200,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When you have a data set,  \\n it's often the case  \\n where you want to change your column names  \\n to make them more legible, more understandable,  \\n or more easy to program with,  \\n or sometimes you want to remove unnecessary columns.  \\n An advantage of removing unnecessary columns  \\n is it can free up RAM on your computer  \\n and it's also a good data science practice.  \\n There are two popular ways to rename data frame columns.  \\n The first is dictionary substitution,  \\n which is very useful  \\n if you only want to rename a few of your columns.  \\n There's also a list replacement,  \\n which requires a full list of names.  \\n And in my experience, this is more error prone.  \\n The data set we're going to work with is the car loan data set,  \\n and we'll look at the first five rows using the head method.  \\n And one reason why I want to rename a column,  \\n in this case the principle paid column,  \\n is if I try to use the dot notation  \\n where the data frame and a dot  \\n and the column I'm interested in, this will yield an error.  \\n The reason why I have an error  \\n is that there's a space in my column name.  \\n This would've worked if I had single brackets  \\n and a string of the column name I'm interested in  \\n and closed brackets.  \\n However, I still want to fix this  \\n as someone else could run into the same error  \\n with this dataset.  \\n One approach is dictionary substitution  \\n using the rename method.  \\n And the way this works is that I have my data frame,  \\n I have a dot, I have rename,  \\n and I have columns here  \\n because I want to rename my columns as opposed to an index.  \\n I have the original column name,  \\n in this case starting balance,  \\n and I want to rename it to starting_balance.  \\n Additionally, I want to rename the interest paid column,  \\n the principle paid column, and the new balance column.  \\n And after I rename the columns,  \\n I want to take that data frame  \\n and assign it back to the original data frame.  \\n And now you can look at the data frame  \\n after renaming columns.  \\n And as you see, there's no longer a space  \\n between many of the columns.  \\n There's another approach to renaming columns,  \\n and this is through list replacement.  \\n In the case of the code below,  \\n I want to change the month column  \\n where it starts with a capital M to our lowercase m.  \\n However, with this technique,  \\n I still need to list the rest of the columns  \\n and assign it back to the df.columns attribute.  \\n And now as you can see,  \\n I have a lowercase m for the month column.  \\n There are also times  \\n where you may want to delete your columns.  \\n Approach one for doing this is to use the drop method  \\n where I have the data frame, I have .drop  \\n and I'm specifying that I want to drop my columns.  \\n In this case, I only want to drop the term column.  \\n But keep in mind that using this approach,  \\n you can drop multiple columns at a time.  \\n And now looking at the data frame,  \\n you can see that I no longer have the term column.  \\n The second approach to deleting columns  \\n is by using the Dell command.  \\n In this case, I'm going to delete the repayment column.  \\n As you see below, I no longer have the repayment column.  \\n And that's it.  \\n that you want to rename your columns or delete them,  \\n consider some of these approaches.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3373067\",\"duration\":159,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Aggregate functions\",\"fileName\":\"4499006_en_US_02_08_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":159,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Computing summary statistics is a good way of understanding the distribution of the columns of your data. After watching this video, you'll be able to compute summary statistics using aggregate methods like sum, cumsum, mean, median, min, max, std, and quantile.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6389173,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When working with a dataset,  \\n it's often a good idea to compute summary statistics.  \\n Summary statistics can tell you about your outliers,  \\n if your data is symmetrical,  \\n and how tightly grouped your data is.  \\n For the car loan dataset  \\n where we have a payment table  \\n for a $34,690 loan at a 7.02% interest rate  \\n for a Toyota Sienna over 60 months,  \\n it would be interesting to find out  \\n how much total interest paid  \\n would be over the course of the loan.  \\n For this, we're going to use a sum method.  \\n And what the sum method does  \\n is it sums the values in a column.  \\n And the way this works is I have  \\n the name of the data frame, DF.  \\n I have single brackets,  \\n I have the column I'm interested in.  \\n In this case, interest_paid, closing single brackets,  \\n and I do .sum.  \\n And what this gives me is a total amount of interest paid  \\n over the course of the loan.  \\n And as you see, over the course of the loan,  \\n the interest paid is $6,450 and 27 cents.  \\n You can also use a sum method on an entire data frame  \\n to sum across all the values across all the columns.  \\n While the sum for the interest paid column  \\n is what we had before  \\n when we just summed across the interest paid column,  \\n the car type column seems to be a bit different.  \\n And the reason why this is the case  \\n is if you recall with Python,  \\n when you add two strings together, they can concatenate.  \\n It's important to note that if you ever don't know  \\n exactly what a method does,  \\n I encourage you to use the help method  \\n where you have help, open parenthesis,  \\n the name of the data frame, in this case DF,  \\n open brackets, the name of the column,  \\n .sum, shift plus enter.  \\n The way the sum method works  \\n is it sums down all the values in a column.  \\n However, by default, it ignores all NAs  \\n or null values when computing the result.  \\n So if this interest paid column had any NAs or NANS in them,  \\n it ignored them.  \\n And that's why it's always important to know  \\n exactly what a method does or an aggregate function  \\n in this case, as are some potentially did include any NANs.  \\n And the way to check if you have NANs in your data frame  \\n is by using the inbuilt info method.  \\n And as you see here, I have one NAN  \\n in the interest paid column.  \\n When working with a dataset, it's often a good idea  \\n to use aggregate functions on your various columns.  \\n This can tell you how well grouped your dataset is,  \\n what your outliers are,  \\n and potentially useful information  \\n like how much interest you'll pay over the course of a loan  \\n by using the sum method.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3372050\",\"duration\":221,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Identify missing data\",\"fileName\":\"4499006_en_US_02_09_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":221,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Before you graph data, you should determine if you have missing values.  After watching this video, you'll be able to identify where missing values are in your pandas DataFrames.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8151356,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When working with a dataset,  \\n you'll often run into missing values.  \\n Values can be originally missing from a dataset  \\n or be a product of data manipulation.  \\n In pandas, missing values are typically called NaN or none.  \\n Missing data can hint at data collection errors,  \\n indicate improper conversion or manipulation of data,  \\n or they can actually not be considered missing at all.  \\n For some datasets, missing data can be listed as zero,  \\n false, not applicable, entered an empty string,  \\n among many other possibilities.  \\n This is a really important subject  \\n as before you can graph data,  \\n you need to make sure you aren't trying to graph  \\n some missing values,  \\n as that can cause an error or misinterpretation of the data.  \\n And in this notebook,  \\n we'll see where missing data  \\n can cause misinterpretation of our results.  \\n The first thing we're going to do  \\n is we're going to use the car loan data set  \\n and we're going to identify how many missing values we have  \\n by using the Pandas info method.  \\n So I have data frame here,  \\n and then I have the info method.  \\n I'll press shift enter,  \\n and then as you see here, for every other column,  \\n except for interest paid,  \\n I have 60 non-null values.  \\n But for the interest paid column, I have 59.  \\n This means I have one NaN value in that column,  \\n this will cause a problem.  \\n Two common methods to indicate where values are missing  \\n are isna and isnull.  \\n They're exactly the same methods,  \\n but with different names.  \\n The reason why this is the case is in the R language,  \\n NA and null are two different things.  \\n This is to make our programmers have an easier time  \\n when working with Python.  \\n I tend to prefer isna as this tends to be similar  \\n in naming to other Python methods.  \\n As you see it in the code over here  \\n I have the Panda Series interest_paid.  \\n I'm using the isna method,  \\n and what this does is  \\n this is producing a Panda Series of true and false values.  \\n It'll be true where I have a NaN value,  \\n and it'll be false where I don't.  \\n I'll then press shift and enter.  \\n And as you see in the first five rows,  \\n I don't have any NaN values.  \\n The next thing I'm doing  \\n is I'm assigning this true and false filter  \\n to the variable interest_missing.  \\n And the reason why I'm doing this  \\n is I want to take that filter  \\n and eventually use it to isolate my missing data.  \\n What the code here is doing  \\n is I want to look at the row where I have the missing values.  \\n And what you see here  \\n is I have a missing value in the interest paid column.  \\n This will be a problem for later.  \\n It's important to keep in mind,  \\n that you can also use the knot operator to negate the filter  \\n so that every row that's returned doesn't have a NaN.  \\n And as you see in the Pandas DataFrame,  \\n the row with index 35 is no longer here.  \\n It's important to note, you'll often see code  \\n similar to what you see here.  \\n What we have is that same Pandas filter  \\n of true and false values.  \\n And then after, you have the aggregate function sum,  \\n which then sums all the true and false values  \\n to produce a result.  \\n The reason why this works is in Python,  \\n Boolean are a subtype of integer where true are ones  \\n and falses are zero.  \\n So in the code here,  \\n I essentially have one plus zero plus zero.  \\n And the reason why I have a one here  \\n is that I have one NaN in the interest paid column.  \\n When working with a dataset,  \\n it's important to identify your missing values,  \\n as missing values can cause data misinterpretation errors,  \\n or even cause you an error when you try to graph your data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3366074\",\"duration\":303,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Remove or fill in missing data\",\"fileName\":\"4499006_en_US_02_10_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":303,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Before you graph data, you need to handle missing values as they  can cause an error or misinterpretation of the data. After watching this video, you'll be able to remove missing values from pandas DataFrames, as well as fill in missing values.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10998897,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Once you've identified missing data,  \\n it's really important to either remove that data  \\n or fill in the missing data with a reasonable value.  \\n This is a really important subject,  \\n as before you can graph data,  \\n you need to make sure you aren't trying to graph  \\n some missing values, as that can cause an error  \\n or cause a misinterpretation of the data.  \\n We're working with the car loan dataset  \\n and the first thing we're going to do  \\n is we're going to utilize the info method.  \\n And what the info method does  \\n is it shows us how many missing values we have  \\n in each of our columns.  \\n And as you see, we have 60 non-null values  \\n for every column except for the interest paid column.  \\n This means that we have one null value.  \\n There are a couple different ways to deal with missing data.  \\n The first way is simply to remove the missing values.  \\n And in pandas you can remove the missing values  \\n by using the drop NA method.  \\n And what the code here does is I have a pandas data frame  \\n from index 30 up until, but not including index 40,  \\n and I'm dropping the rows where I have any NAN values.  \\n And as you see here, I don't have a row at index 35  \\n because I had a NAN value here.  \\n The other way to deal with missing values  \\n is simply to fill them in and there are a variety  \\n of ways to fill in missing values.  \\n The first thing we're going to do  \\n is we're going to look at where the missing data is located  \\n by using a pandas series  \\n and then slicing it to look at indexes 30 up until,  \\n but not including index 40.  \\n As you see here, I have a NAN at index 35.  \\n The first thing we're going to try  \\n is we're going to try to fill the NAN with a zero  \\n by using the fill NA method.  \\n The reason why filling in a NAN with a zero  \\n is often not a good idea,  \\n is originally the NAN could have been something else.  \\n A zero could help you misinterpret the data.  \\n It's just one option.  \\n The other method we could use is to fill in with a backfill.  \\n And the way this works is perhaps better to show you.  \\n Where at Index 35, before I had a zero or a NAN,  \\n now I have an 89.77.  \\n This is because the index after it was an 89.77.  \\n This is very commonly done with time series data  \\n when you have a missing value.  \\n Another way is to forward fill in your value.  \\n And this is also done with time series data.  \\n The difference between backfill and forward fill  \\n is backfill takes the value after the missing value  \\n and inserts it at the value that's missing.  \\n And what forward fill does is it takes  \\n the value before the missing value  \\n and inserts it where the missing value is.  \\n The reason why you use one versus the other  \\n is really dependent on your domain knowledge  \\n and your application.  \\n This is also a current area of research.  \\n It's called data imputation.  \\n Another way to fill in missing values  \\n is through linear interpolation.  \\n And what this does is it uses a linear model  \\n to fill in the missing value.  \\n And as you see here, this 93  \\n is between the 96 and the 89.  \\n What the code here is doing is I'm finding  \\n the total interest paid over the course of a loan  \\n by using the sum method.  \\n And I should note, the sum method doesn't account for NANs.  \\n And as you see here, this is the total amount of money  \\n paid toward interest over the course of a loan.  \\n It's important to keep in mind that the sum method  \\n by default ignores NANs.  \\n So after we fill in the NAN value with a real value,  \\n this might change.  \\n What the code here is doing is this is producing  \\n a Boolean array of true and false values  \\n where I'll have a true value where I have a NAN  \\n and a false value where I don't,  \\n and I'm assigning it to the variable interest_missing.  \\n From there, I'm utilizing the LOC operator  \\n and filling in that missing N value with the value 93.24.  \\n Now, when I sum over the entire column,  \\n I'll get a different number.  \\n This is perhaps more accurate,  \\n and I should note the value  \\n of removing or filling in your data  \\n is that oftentimes you get more accurate calculations.  \\n In this case, the reason why I filled in the value  \\n with 93.24 is because I knew what the actual value  \\n should have been.  \\n This is due to my domain knowledge of loans.  \\n For whatever application you're working with,  \\n it's often best to try to get the most accurate value  \\n to fill in for your missing values.  \\n And as you can see here,  \\n we don't have NAN values in the data frame anymore.  \\n Once you've identified your missing values,  \\n removing them or filling them in often gives you  \\n more accurate calculations  \\n and makes the results more interpretable.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3372051\",\"duration\":75,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Convert pandas DataFrames\",\"fileName\":\"4499006_en_US_02_11_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":75,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"While pandas DataFrames are highly useful, there are times when DataFrames are not ideal. For example, DataFrames are not an acceptable input for certain methods. After watching this video, you'll be able to convert pandas DataFrames to NumPy arrays and Python dictionaries.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3199851,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When working with Pandas DataFrames,  \\n you'll oftentimes find you want to convert them  \\n to NumPy arrays or Python dictionaries.  \\n The reason why is because certain libraries  \\n prefer NumPy rays or Python dictionaries  \\n as inputs to their methods as opposed to Pandas DataFrames.  \\n In this video, we'll work with the car loan dataset again,  \\n and we're going to look at the first five rows.  \\n There are two ways to convert Pandas DataFrames  \\n to NumPy arrays.  \\n The first approach is to use  \\n the two underscore NumPy method,  \\n and what this outputs is a NumPy array.  \\n The second approach is to use the values attribute,  \\n and this also produces a NumPy array.  \\n I should note that either of these approaches works  \\n just as well as the other.  \\n You can also convert Pandas DataFrames  \\n to Python dictionaries.  \\n You can do this by using the two underscore dict method,  \\n and the reason why you'd want to do this  \\n versus convert your Pandas DataFrame to a NumPy array  \\n is oftentimes you're interested in preserving the indices  \\n of your Pandas DataFrame.  \\n In this video, we've gone over how to convert  \\n Pandas DataFrames to NumPy arrays in Python dictionaries.  \\n The practicality of this is that sometimes certain libraries  \\n don't accept Pandas DataFrames as inputs to their methods.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3370067\",\"duration\":88,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Export pandas DataFrames\",\"fileName\":\"4499006_en_US_02_12_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":88,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After manipulating datasets, it is often a good idea to export your datasets to files to share with others. After watching this video, you'll be able to convert your pandas DataFrames to .csv and Excel files.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3210542,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When working with Panda's DataFrames  \\n it's often a good idea to export them  \\n to either CSV or Excel files.  \\n This is because it's a great way to share  \\n your results with others.  \\n In Pandas, you can export your DataFrame to a CSV file  \\n by using the to_CSV method.  \\n In this case, I have a relative path  \\n where inside my current working directory,  \\n there's a folder called data,  \\n and inside that folder is where I'm exporting the CSV file.  \\n The parameter index equals false,  \\n just means I don't want to export  \\n the Pandas DataFrames indexes.  \\n You can export your DataFrame to an Excel file  \\n by using the to_Excel method.  \\n And in this case, I have a relative path  \\n where inside my current directory,  \\n there's a folder called data,  \\n and then inside that folder  \\n is where I'm writing the Excel SX file.  \\n The index equals false parameter,  \\n just means I don't want to have the indexes from my DataFrame  \\n export to the file.  \\n And keep in mind,  \\n if you ever don't know what a method does,  \\n you can always look them up using the help command.  \\n In this case, I'm looking up the to_CSV method.  \\n In this video, we've gone over  \\n how to export your Pandas DataFrames to CSV and Excel files.  \\n Keep in mind, it's also a good idea  \\n to check your exported files,  \\n in the sense that sometimes,  \\n when you export a file,  \\n it may not always be what you expect.  \\n \\n\\n\"}],\"name\":\"2. Leverage pandas for Analysis\",\"size\":83170622,\"urn\":\"urn:li:learningContentChapter:3366078\"},{\"duration\":1408,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3366075\",\"duration\":229,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Basics of Matplotlib\",\"fileName\":\"4499006_en_US_03_01_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":229,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"The Matplotlib library is a powerful tool capable of producing complex publication-quality figures with fine layout control in two and three dimensions. After watching this video, you'll be able to import Matplotlib, create basic plots using the plot method, and change the default figure style so you can choose an appropriate aesthetic style.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9150662,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n we're going to learn about the Matplotlib library,  \\n which is a powerful tool capable of producing  \\n complex publication-quality figures  \\n with fine layout control in two or three dimensions.  \\n While this is an older library,  \\n so many libraries are built on top of it and use its syntax.  \\n The first thing we have to do  \\n is import the libraries we're going to use.  \\n We're going to utilize the pandas and NumPy libraries  \\n to manipulate data in a format that's suitable for plotting.  \\n We're going to import matplotlib.pyplot as PLT,  \\n and PLT is just an alias for the matplotlib.pyplot module.  \\n And lastly, we're going to import the seaborn library,  \\n which is a wrapper for Matplotlib as SNS.  \\n Before we can graph data,  \\n we have to have data in a form that's suitable for graphing.  \\n So we're first going to import the car loan data  \\n into a pandas data frame.  \\n We're next going to look at the first five rows  \\n of the data frame as this is a good practice.  \\n Next we're going to check to make sure  \\n we don't have NANs in our data frame,  \\n as it is not easy to directly plot data that contains NANs.  \\n And to do this, we're going to use the info method.  \\n And as you can see, we have 60 entries in our data frame,  \\n and we have 60 non-null values for each column.  \\n In this video, we're going to graph month number on the X axis  \\n and interest paid and principle paid on the Y axis.  \\n But to first do that, we have to have our data  \\n in the form of NumPy array.  \\n And what this code over here does  \\n is I have my data frame, I'm using the LOC operator,  \\n I'm saying I want all the rows,  \\n and I just want the month column.  \\n So this is a panda series, and I'm turning this panda series  \\n into a NumPy array by using the values attribute  \\n and assigning this entire thing  \\n to the month number variable.  \\n And similarly, I'm doing the same  \\n for the interest paid column and the principle paid column.  \\n Keep in mind, you can also check that the values attribute  \\n converts a column of values into a NumPy array  \\n by using the inbuilt type function.  \\n Once you have data in an appropriate format,  \\n you can begin to plot it.  \\n In this case, we're going to plot month number on the X axis  \\n and principle paid on the Y axis.  \\n As a reminder, if you don't know what a method does,  \\n you can always use the inbuilt help function.  \\n Now it is time for our first plot  \\n and we're going to do PLT.plot.  \\n And for our X axis we're going to have our month number.  \\n And for our Y axis, we're going to have our interest paid.  \\n And as you can see, it's not the prettiest plot.  \\n You can also plot another line on the same graph.  \\n So before we only graphed month number and interest paid,  \\n but we can also graph month number and principle paid.  \\n This is also not the prettiest plot.  \\n One way to make our plots more aesthetically pleasing  \\n is to choose a figure style.  \\n We'll use PLT.style.available  \\n to select an appropriate aesthetic style for a figure.  \\n The default style is not the most aesthetically pleasing.  \\n On this line, I'm doing PLT.style.available  \\n and pressing shift enter  \\n to see the different styles I can choose from.  \\n The style of classic is very similar  \\n to what we've already plotted.  \\n However, the 538 style is more aesthetically pleasing.  \\n If you're coming from R,  \\n you can also use the GG plot style as you can see here.  \\n You can also use different styles like Tableau colorblind.  \\n You can also use the seaboard style,  \\n which is a wrapper for Matplotlib, as you can see here.  \\n In this video, we've gone over how to use  \\n Matplotlib.plyplot to make line graphs.  \\n And we saw how when you change style,  \\n you can make your graphs more aesthetically pleasing.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3369056\",\"duration\":112,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Set marker type and colors\",\"fileName\":\"4499006_en_US_03_02_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":112,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Changing marker type and color is a fundamental data visualization skill as they can effect the interpretability of your plots. After watching this video, you'll be able to change your Matplotlib plot's marker type and colors.\",\"captionsStatus\":\"NOT_AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3951663,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":null},{\"urn\":\"urn:li:learningContentVideo:3374062\",\"duration\":127,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"MATLAB-style vs. object syntax\",\"fileName\":\"4499006_en_US_03_03_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":127,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"There are two different styles of Matplotlib syntax. After watching this video, you'll be able to utilize Matplotlib MATLAB style and object-oriented style of syntax, and you will also understand how to combine the styles of syntax.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4021429,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] A potentially confusing part  \\n of the Matplotlib library is  \\n that it has two different styles of syntax.  \\n There's the MATLAB style,  \\n and this is a scripted interface designed  \\n to feel like MATLAB, where Matplotlib maintains a pointer  \\n to the current figure and sends commands to it.  \\n There's the object oriented syntax,  \\n and this is more often used in situations  \\n where you want more control over your figure.  \\n An important note is that you can  \\n and often will have plots that will be created  \\n through a combination of the MATLAB style  \\n and the object-oriented style.  \\n We'll start by looking at the MATLAB style syntax,  \\n and this typically starts by using the PLT plot command,  \\n where you have something in the x axis,  \\n you have something in the Y axis,  \\n and you have a bunch of parameters that you set.  \\n In this case, I'm setting the parameter C, which is color  \\n equal to K, which is the color black,  \\n and you can also have additional PLT dot plot commands  \\n to plot on top of the figure.  \\n And you can see the result here.  \\n The object oriented syntax is as follows.  \\n You have PLT subplots.  \\n In this case, I just want one plot,  \\n so I'm making n rows equal to one  \\n and n columns equal to one, and this returns a topple.  \\n And I'm topple unpacking the figure and the axes.  \\n And then from there, I'm just doing axes plot  \\n what I want in the X axis, what I want in the Y axis,  \\n and additional other parameters.  \\n Similar to the MATLAB style syntax,  \\n you can also plot additional things on the same plot.  \\n It's important to note that you can  \\n and often will see the MATLAB style  \\n and the object oriented style used together.  \\n So in this case, I have the object oriented style,  \\n I have the MATLAB style,  \\n and I have the object-oriented style,  \\n and it still produces the same plot.  \\n This video showed that there's two separate styles  \\n of Matplotlib syntax.  \\n There's a MATLAB style  \\n and there's the object-oriented style,  \\n and that sometimes they're used in combination  \\n with each other.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3364071\",\"duration\":261,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Set titles, labels, and limits\",\"fileName\":\"4499006_en_US_03_04_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":261,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Adding text to explain your graph can greatly enhance the interpretability of your plots. After watching this video, you'll be able to set plot titles, labels, and limits for the Matplotlib MATLAB style and object-oriented style of syntax.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9913490,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n I'll show you how to create plot titles, labels, and limits.  \\n Plot titles and plot labels are very important  \\n to convey what you're graphing  \\n and plot limits are very important as, oftentimes,  \\n the default limits aren't always ideal with Matplotlib.  \\n The first thing we're going to do  \\n is we're going to go for the MATLAB style  \\n for how to set plot titles, labels, and limits.  \\n So here's a normal MATLAB-style plot.  \\n Notice in the graph that there's no title in the plot.  \\n There's no y label, there's no x label,  \\n and the limits could be a little bit better on the x-axis  \\n where it looks like the plot should start at one  \\n and should end at 60.  \\n To change the x limit and the y limit, you can do .xlim  \\n where you have your limit on the left  \\n and your limit on the right.  \\n To change your y limit, you can do .ylim,  \\n you can have your lower limit  \\n and you can have your upper limit,  \\n and you can do Shift + Enter.  \\n And obviously, this is not the most practical use  \\n of changing the y limit,  \\n as before, it looked a little bit better.  \\n You can also set your x label and y label.  \\n To set your x label, you can do .xlabel  \\n and the name you want for your x label.  \\n For your y label, you can do .ylabel  \\n and the name you want for your y label.  \\n And as you see here, we have something on our y-axis now  \\n and something on our x-axis.  \\n To set the title, you can do plt.title  \\n and the name of your title.  \\n And as you can see, we have our title here now  \\n in addition to our y label and our x label.  \\n If you find that your x label, y label,  \\n or your title have too small of a font,  \\n you can always make it bigger by adjusting the font size.  \\n In this case, I clearly made it too big,  \\n so feel free to play around with the parameters,  \\n and you can continue to iterate on this almost indefinitely,  \\n and that looks a lot better.  \\n You can also change the size of your x ticks using .xticks  \\n and your y ticks using .yticks.  \\n So notice now that the title is too big,  \\n the x and y label is too big,  \\n as well as the x ticks and y ticks, so feel free to iterate.  \\n Graphing is a very iterative process.  \\n The object-oriented approach for changing the titles,  \\n the labels, and limits is very similar.  \\n Where I first have a graph, setting the x limits  \\n and the y limits is very similar to before.  \\n Where before I did plt.xlim,  \\n now I have axes.set_xlim,  \\n and I have axes.set_ylim for the y limits.  \\n Setting the x label and the y label  \\n is also a similar process to the MATLAB style.  \\n Where before I had plt.xlabel and plt.ylabel,  \\n now I have axes.set_xlabel and axes.set_ylabel.  \\n Similarly, before with the MATLAB style, I had plt.title  \\n and now I have axes.set_title.  \\n And as before, you can change the font size  \\n by adding the font size parameter.  \\n One difference with the object-oriented style  \\n is that you have to do axes.tick_params  \\n to change the tick font size.  \\n In this case, I'm changing the tick font size  \\n for the x-axis,  \\n making them font size of 20,  \\n in this case, it's called label size.  \\n And for the y ticks, I simply change axes  \\n to make it equal to the string y  \\n and make the label size equal to 20.  \\n In this video, I went over how to change the titles, labels,  \\n and limits for both Matplotlib styles of syntax.  \\n The benefit of this is that having labels, limits,  \\n and titles can make your graphs more interpretable  \\n and easier to understand.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3364072\",\"duration\":146,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Add grids\",\"fileName\":\"4499006_en_US_03_05_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":146,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Adding a grid to a plot can add to the aesthetic appeal to your figure. After watching this video, you'll be able to create and tune plot grids for the Matplotlib MATLAB style and object-oriented style of syntax.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5123779,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n we'll go over how to make grid lines in Matplotlib.  \\n Grid lines can't be visually appealing,  \\n but they could also help you determine fine differences  \\n between two quantities in a graph.  \\n The first thing we're going to do is we're going to create a plot  \\n without grid lines where we have month number in the x-axis,  \\n interest paid in the y-axis,  \\n and then we have a secondary y-axis  \\n where we have month number in the x-axis  \\n and principal paid in the y-axis, and we're going to plot it.  \\n This is the graph without grid lines.  \\n So now let's see how it looks with grid lines.  \\n In the MATLAB-style syntax in Matplotlib,  \\n you can add grid lines by using .grid.  \\n And as you can see, we have grid lines here.  \\n Keep in mind, you can also only have horizontal grid lines  \\n by specifying axis equals y  \\n and you can also only have vertical grid lines  \\n by specifying axis equals x.  \\n If you want more customization,  \\n you can also change the color of your grid lines.  \\n You can change the transparency of your grid lines.  \\n And keep in mind for alpha, lower means more transparent  \\n and up to one means not transparent at all.  \\n You can also change the line style of your grid lines,  \\n and this is not going to look too good  \\n because the green seems to really clash with the blue here.  \\n You can also add grid lines  \\n using the Matplotlib object-oriented syntax  \\n where you just do axes.grid.  \\n You can also specify that you only want  \\n horizontal grid lines by doing axis equals y.  \\n You can also specify that you just want vertical grid lines  \\n by setting axis equals to x.  \\n And similar to the MATLAB-style syntax, you can also specify  \\n what color you want your grid lines to be,  \\n how transparent you want them, and the line style.  \\n Keep in mind if you're finding setting grids to be tedious,  \\n use a style that already has grids in them by default.  \\n For example, the seaboard style  \\n has white grid lines by default  \\n as you can see here.  \\n Matplotlib allows you to set grid lines  \\n to make your graph more visually appealing  \\n and to help distinguish quantities across the graph.  \\n It's also important to keep in mind  \\n that just because you can set grid lines  \\n doesn't mean you have to.  \\n You can also use a style of Matplotlib  \\n that has them in by default.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3369057\",\"duration\":85,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Create legends\",\"fileName\":\"4499006_en_US_03_06_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":85,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Adding a legend can greatly enhance the interpretability of your plots. After watching this video, you'll be able to create legends in Matplotlib and put them in an optimal location in the plot.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3528166,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n we're going to learn about plot legends.  \\n Plot legends assist in assigning meaning  \\n to your various plot elements.  \\n It's therefore important to make sure  \\n your legend doesn't cover up your plot elements.  \\n We'll first start by utilizing Matplotlib's  \\n MATLAB-style syntax to create a plot legend.  \\n As you see in this image,  \\n the legend is not in an ideal location.  \\n You can use the lock parameter  \\n to change where your legend is located.  \\n In this case, I'm telling it to go to the center right.  \\n It's important to note you can also move your legend  \\n outside the plotting area.  \\n What the code here is doing  \\n is I'm moving the legend slightly outside  \\n to the right of my plot,  \\n because all the way to the right would be 1.00,  \\n and I'm moving it all the way at the base of my plot.  \\n And as you see here, my legend is outside the plotting area.  \\n Keep in mind, you can also use Matplotlib's  \\n object-oriented syntax to create a legend.  \\n In the case of the code over here,  \\n I'm doing axes.legend.  \\n Similar to Matplotlib's MATLAB-style syntax,  \\n the object-oriented syntax also allows you  \\n to move the legend's location.  \\n As you see here, I have the legend in the center right,  \\n and over here, just like before, I have it outside the plot.  \\n In this video, we learned some tools  \\n to not only create a legend in Matplotlib,  \\n but also to change its location.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3366076\",\"duration\":148,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Save plots to files\",\"fileName\":\"4499006_en_US_03_07_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":148,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"It is important to be able to share your visualizations to others. After watching this video, you'll be able to save images of your plots outside of Jupyter Notebooks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5996589,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video, we're going to go over  \\n how to save your plots to files.  \\n Saving your visualizations  \\n outside your Jupyter Notebook is important  \\n as it allows you to show your visualizations to others.  \\n Equally important is checking your saved visualization  \\n because there's always a possibility  \\n the graph doesn't look the same in the notebook  \\n as in the image file.  \\n So the first thing we're going to do is for this notebook,  \\n we're going to use a seaborn style in Matplotlib.  \\n This will make our graph more aesthetically pleasing.  \\n Using the MATLAB style of Matplotlib,  \\n we're going to save our file using plt.savefig.  \\n This is where we're saving our image.  \\n This is our DPI,  \\n you can think of it as resolution,  \\n and it's really important  \\n now that we have this outputted image  \\n in our Jupyter Notebook,  \\n let's now see how the image saved.  \\n Let's start by looking inside the Images folder  \\n for the filename MS Legend Cutoff.  \\n You'll see that the legend is cut off here.  \\n This is obviously a problem.  \\n You'll also notice that it looks like month  \\n is almost cut off here.  \\n Let's now learn how to fix this.  \\n So we're going to head back over to our Jupyter Notebook.  \\n The way we're going to solve this problem  \\n is we're going to utilize the plt.layout method.  \\n What this does  \\n is it automatically adjusts subplot parameters  \\n so that the subplot fits into the figure area.  \\n And we run the same code before with this new addition.  \\n And here we have the figure.  \\n Now looking inside the Images folder,  \\n we now see that the image is not cut off.  \\n Now there's another way to do this  \\n and that's by using the object-oriented Matplotlib syntax.  \\n And the only thing that differs  \\n is instead of doing plt.savefig,  \\n we now have fig.savefig.  \\n And in this image, it'll be cut off just like we had before.  \\n So inside the Images folder,  \\n we can look for Object Legend Cutoff.  \\n And as you see here, the legend's still cut off  \\n and the month is still cut off.  \\n So let's fix that.  \\n The way to fix this is by doing fig.tight_layout.  \\n Let's go ahead and run that.  \\n And now you'll notice in our Images folder,  \\n the objectlegend.png file  \\n doesn't have anything cut off.  \\n And here's the image. It looks like nothing's cut off.  \\n And that's it, the next time you want to export your images,  \\n consider using some of these techniques.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3369058\",\"duration\":300,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Create plots with Matplotlib wrappers\",\"fileName\":\"4499006_en_US_03_08_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":300,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Matplotlib has two prominent wrappers: seaborn and pandas. After watching this video, you'll be able to create plots using Matplotlib, pandas, and seaborn. Specifically, you will create boxplots using Matplotlib, pandas, and seaborn, you will be able to ascertain the use cases of when each library should be used.\",\"captionsStatus\":\"NOT_AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10901603,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":null}],\"name\":\"3. Simplify Visualization with Matplotlib\",\"size\":52587381,\"urn\":\"urn:li:learningContentChapter:3372053\"},{\"duration\":732,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3373068\",\"duration\":240,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Create heatmaps\",\"fileName\":\"4499006_en_US_04_01_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":240,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Making a plot in pure Matplotlib can be a lot more code than using a Matplotlib wrapper like seaborn or pandas. After watching this video, you'll be able to create Heatmaps using seaborn and Matplotlib.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8437118,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video, we'll learn how to create  \\n heatmaps using matplotlib and Seaborn,  \\n a matplotlib wrapper.  \\n So what is a heatmap?  \\n A heatmap is a graphical representation of data  \\n where values are depicted by colors.  \\n Heatmaps allow you to easier spot where something happened  \\n and where it didn't.  \\n Consequently, what we choose  \\n for our color palette is important.  \\n Two types of color palettes are sequential,  \\n and this is appropriate when data ranges  \\n from relatively low values to relatively high values.  \\n There's qualitative,  \\n and this is best when you want to distinguish  \\n discrete chunks of data that do not have inherent ordering.  \\n To create a heatmap, we first have to import our libraries.  \\n We're going to make sure matplotlib is inline,  \\n which means that our graphics will display inline  \\n in the notebook.  \\n We're going to import NumPy as np, as well as Pandas as pd.  \\n To make a heatmap, we first have to import our libraries.  \\n We're importing matplotlib, seaborn, NumPy and Pandas.  \\n The data that we're going to load  \\n is the data from a confusion matrix,  \\n which is a table that is often used to describe  \\n the performance of a machine learning classification model.  \\n It tells you where your predictions went wrong.  \\n This particular table is derived from predicting labels  \\n for digits from zero to nine.  \\n For an understanding of the data,  \\n you can think of your columns as predictions for zero,  \\n for one, two, three, et cetera.  \\n You can think of your rows as their actual values.  \\n So this row would be actual value of zero,  \\n actual value of one, two, three, et cetera.  \\n So for this number, this is when we predicted a zero,  \\n and we predicted this 37 times,  \\n and the actual value was zero.  \\n For this column, this is when we predicted a one,  \\n and we predicted it correctly 39 times,  \\n because the actual value is one here.  \\n However, we have some misclassifications  \\n where we've made some bad predictions.  \\n In this case, three times we predicted an eight,  \\n when it was actually a one.  \\n To create a heatmap with Seaborn,  \\n you do .heatmap, you import your data.  \\n In this case, I want annotations,  \\n and you'll see what that looks like in a second.  \\n I'm specifying my color map.  \\n In this case, I'm choosing a sequential color map  \\n because my data ranges from relatively low values  \\n to relatively high values.  \\n I'm setting my X and Y labels, and here's our color map.  \\n 37 times we predicted a zero when it was actually a zero.  \\n 39 times we predicted a one when it was actually a one,  \\n but a couple times, we definitely did mess up,  \\n where we predicted a one when it was really an eight.  \\n This heatmap allows us to easily pick out  \\n our higher numbers, like this 51,  \\n from our lower numbers, like these zeros.  \\n This is because we have a sequential color palette.  \\n The only difference with the code here from before  \\n is before, we had a sequential color map  \\n that was called blues.  \\n In this case, we have a qualitative color map,  \\n which is called pastel.  \\n And as you see here,  \\n it's harder to determine which is a higher number  \\n based on color alone using this qualitative color map.  \\n It's important to keep in mind  \\n that you can also create a heatmap using pure matplotlib.  \\n This just happens to be a lot of code,  \\n and as you see the image, even though we had a lot of code,  \\n there's still other things that we could change  \\n to make it equal to our Seaborn color map.  \\n For example, the color here is black instead of white,  \\n which makes it harder to distinguish this 51  \\n from this dark blue.  \\n In this video, we've learned how to create heatmaps  \\n using Seaborn and matplotlib.  \\n It's important to note what you choose  \\n for your color palette can make your visualization  \\n more or less interpretable.  \\n Additionally, sometimes it's easier to use  \\n a matplotlib wrapper like Seaborn,  \\n as it involves less code,  \\n and it's easier to make it aesthetically pleasing.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3366077\",\"duration\":213,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Create histograms\",\"fileName\":\"4499006_en_US_04_02_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":213,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"A histogram is a summary of the variation in a measured variable. It shows the number of samples that occur in a category. After watching this video, you'll be able to create Histograms using the pandas library. By doing this, you will see how to tune a graph to make it more interpretable and more aesthetically pleasing.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7243406,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] In this video,  \\n we'll learn how to create histograms using Matplotlib.  \\n When first evaluating a dataset, it's a common practice  \\n to create histograms to explore your data,  \\n as it can give you a general idea  \\n of what your data looks like.  \\n A histogram is a summary of the variation  \\n in a measured variable.  \\n It shows the number of samples that occur in a category.  \\n A histogram is a type of frequency distribution.  \\n Histograms work by binning the entire range of values  \\n into a series of intervals  \\n and then counting how many values fall into each interval.  \\n While the intervals are often of equal size,  \\n they're not required to be.  \\n If you look at our import statements,  \\n we have Matplotlib inline.  \\n We're going to import pandas as pd,  \\n as not only can we manipulate data with pandas,  \\n we'll see how to create a histogram  \\n using the plotting functionality of the Pandas library.  \\n We're also going to import matplotlib.pyplot as plt.  \\n And even though we'll be creating a histogram  \\n through the plotting functionality of the Pandas library,  \\n you can always use base matplotlib to tune your figure.  \\n The data that we'll use to demonstrate histograms  \\n is the house sales in King County USA dataset.  \\n For convenience, I put a CSV file  \\n of this dataset into your data folder.  \\n We're going to load this data into a Pandas DataFrame  \\n by using pd.read_csv,  \\n and here's our relative path.  \\n And as you can see,  \\n we have various features of a home in this data set.  \\n And what we'll be doing is visualizing a histogram  \\n of the price column.  \\n To do this, we can use the hist method.  \\n And as you can see, this is not very readable.  \\n One way to fix this is by rotating our x tick labels.  \\n To do this, we can do plt.xticks  \\n and specify that we want the rotation to be 90 degrees.  \\n And as you can see,  \\n we no longer have our x tick labels overlapping.  \\n Alternatively, you could have changed  \\n the default plot style, as oftentimes,  \\n different plot styles have different defaults.  \\n And in this case, we're specifying the plot style  \\n to be seaborn.  \\n And as you can see,  \\n we don't have overlapping x tick labels.  \\n One problem with our current visualization  \\n is that we seem to have a lot of white space.  \\n This is most likely due to outliers.  \\n Oftentimes, you're only interested in a subset of your data.  \\n Say for example, you're only interested in visualizing  \\n a subset of your data of homes under $3 million.  \\n To remove homes under $3 million,  \\n we're going to do df.loc  \\n and specifying that we want the price column  \\n and that we only want homes under $3 million.  \\n We're going to assign this Pandas series  \\n of true-false values to the variable price filter.  \\n From there, we can utilize our price filter  \\n by doing df.loc, inserting our filter  \\n of true and false values,  \\n specifying that we only want to look at the price column,  \\n and then creating a histogram off it.  \\n As you can see, we have less white space in our figure.  \\n One important thing to keep in mind  \\n is that data visualization is an iterative process,  \\n so there's always something else you can tune.  \\n Say, for example, I want to be able to distinguish my bars  \\n from each other.  \\n You can do this by specifying the edge color.  \\n In this case, I want to be black.  \\n As you can see here,  \\n I can now distinguish my bars from each other.  \\n You can also keep on tuning your graph  \\n to be more and more visually appealing.  \\n Just make sure that it's worth the effort.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3369059\",\"duration\":279,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Create subplots\",\"fileName\":\"4499006_en_US_04_03_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":279,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"It is often useful to compare different subsets of your data side by side. After watching this video, you'll be able to create subplots using the Matplotlib library.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10474684,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n we'll learn how to create subplots using Matplotlib.  \\n It is often useful to compare different subsets  \\n of your data side by side.  \\n To demonstrate this, we're going to visualize images.  \\n We're going to have our figures appear inline in the notebook,  \\n so we're specifying inline.  \\n We're going to import pandas, NumPy, and Matplotlib.  \\n The next thing we have to do  \\n is you have to load our dataset,  \\n and our dataset is the digits dataset from scikit-learn.  \\n They have arranged into a CSV file for convenience.  \\n The dataset consists of pixel intensity values  \\n for 1,797 images that are eight-by-eight pixels.  \\n This means that the dataset has 64 total values per image,  \\n and each image is labeled with a number from zero to nine.  \\n We're going to load our dataset into panda's data frame  \\n by using the read_csv method.  \\n With any dataset, it's always good  \\n to check the first couple rows  \\n to make sure everything loaded properly.  \\n Columns zero to 63 are pixel intensity values  \\n for an eight-by-eight image.  \\n The label column is what the image is supposed to be.  \\n Each row in the dataset represents one image.  \\n Before we can create a subplot,  \\n it's a good idea to know how to visualize one image.  \\n To get all the column names for the pixel intensity values,  \\n we're going to utilize the df.columns attribute,  \\n and what this slice does is it says we want every column  \\n except for the last column, which happens to be our labels.  \\n The next thing we're going to do is we're going to do df.lock.  \\n We're going to specify that we want the first image  \\n in our data dataset,  \\n and we want all of its pixel intensity values.  \\n I should note that this is not yet the correct form  \\n for viewing the images.  \\n As you can see, we don't yet have an eight-by-eight array.  \\n A lesson you can take from this is that isn't important.  \\n Keep in mind that just because a dataset  \\n is stored in a certain way  \\n doesn't mean it was meant to be viewed that way.  \\n To fix this problem, we're going to utilize the reshape method  \\n to reshape it into an eight-by-eight array.  \\n As it's not easy to understand pixel intensity values  \\n by looking at an array, let's visualize the image.  \\n To do this, we're going to utilize the imshow method,  \\n and we're going to specify that we want a gray color map.  \\n As you see here, this image looks like a zero.  \\n The reason why it looks a little blurry  \\n is because it's only an eight-by-eight image,  \\n We're now going to create a five-by-five subplot.  \\n The way to create a subplot  \\n is by utilizing the dot subplot command,  \\n specifying how many rows you want,  \\n how many columns you want.  \\n The one here is an index, so out of our five plots,  \\n this is saying that this is the first one.  \\n The next thing we have to do  \\n is we have to create our image values.  \\n This bit of code are the image values for our first image,  \\n as you can see here.  \\n What this code is doing is we're specifying  \\n that we want the first image and we want its label,  \\n and we are assigning it to the variable image_label.  \\n And then from here, we're visualizing our image,  \\n and as before, we're reshaping our array  \\n to be eight-by-eight.  \\n Next, we're going to insert a title on our plot,  \\n so that we know what the image is supposed to be of.  \\n From here, the next bit of code  \\n says that this is going to be the second image in our subplot.  \\n We also want the image at index one.  \\n We want the label for the image at index one,  \\n and similarly, we're going to do the same thing  \\n for the third image, the fourth image, and the fifth image.  \\n And as you see here, we have five plots side by side.  \\n As you've probably noticed in the code,  \\n we seem to have a lot of duplication of effort.  \\n Let's eliminate that with a for loop.  \\n In this code, what range is doing is in the first iteration,  \\n zero is assigned temporarily to the variable index.  \\n We're doing one plus our index, which happens to be one,  \\n so we're saying that this is the first subplot.  \\n What this next code is doing  \\n is it's saying that we want all the pixel intensity values  \\n for the row with the index label of zero.  \\n In the next iteration of the loop, we're taking one,  \\n and we're temporarily assigning it to the variable index.  \\n We're doing one plus one, which is two,  \\n which is saying that this is the second subplot.  \\n And what this next bit of code is doing  \\n is it's saying that we want all the pixel intensity values  \\n for the index label of one.  \\n A similar process happens for the rest of the for loop.  \\n As you see here, we now have our images side by side  \\n with a lot less code.  \\n In this video, we've learned  \\n not only how to visualize images,  \\n but also how to visualize images side by side  \\n by using subplots.  \\n It's important to note that there are cases  \\n where we can use a lot less code by utilizing for loops.  \\n \\n\\n\"}],\"name\":\"4. Customize Visualizations with Matplotlib\",\"size\":26155208,\"urn\":\"urn:li:learningContentChapter:3369061\"},{\"duration\":66,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3374063\",\"duration\":66,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"4499006_en_US_05_01_MM24\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":66,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Data visualizations help you communicate and understand your data. After watching this video, you'll be able to feel confident and ready to go build your own powerful visualizations using Python.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2852992,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - I'd like to congratulate you on finishing the course.  \\n I hope you've enjoyed taking this course  \\n as much as I've enjoyed creating and teaching it.  \\n As you probably know, your learning doesn't stop here.  \\n Python is a very expansive topic,  \\n and there's a lot of resources available  \\n that can help you keep learning.  \\n Here are a few resources to help with your journey.  \\n First, check out the Matplotlib gallery.  \\n Here you can find a whole host of plots you can create.  \\n Next, check out interactive data visualization libraries  \\n like Folium and Boca.  \\n Also, be sure to check out my blogs  \\n or visit my YouTube channel.  \\n On my blog, I cover everything  \\n from installations to basic Python  \\n to advanced machine learning.  \\n If you're looking for a data science job,  \\n I encourage you to check out my blog post titled  \\n \\\"How to Build a Data Science Portfolio\\\"  \\n to help you on your way.  \\n And finally, stay in touch.  \\n You can connect with me on LinkedIn.  \\n I'd love to hear from you.  \\n So that's it.  \\n Thanks again for watching this course.  \\n Now get out there and go create  \\n compelling day visualizations.  \\n Good luck.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":2852992,\"urn\":\"urn:li:learningContentChapter:3373069\"}],\"size\":178609500,\"duration\":4883,\"zeroBased\":false},{\"course_title\":\"Python Statistics Essential Training\",\"course_admin_id\":4433355,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4433355,\"Project ID\":null,\"Course Name\":\"Python Statistics Essential Training\",\"Course Name EN\":\"Python Statistics Essential Training\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"The field of statistics has become increasingly dependent on data analysis and interpretation using Python. With the rise of big data and data science, the demand for professionals who can effectively analyze and interpret data using Python has skyrocketed. In this course, Matt Harrison teaches you how to collect, clean, analyze, and visualize data using the powerful tools of the Python programming language. Join Matt as he gives into the various techniques that form the backbone of statistics and helps you understand the data with summary statistics and visualizations. He explains how to create predictive models using both linear regression andXGBoost, and wraps up the course with a look at hypothesis testing.If you\u00e2\u20ac\u2122re interested in exploring statistics using a code-first approach, join Matt in this course as he shows you how to use Python to unlock the power of data.\",\"Course Short Description\":\"Learn to use Python to unlock the power of data and use it to inform decisions.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":9254436,\"Instructor Name\":\"Matt Harrison\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Python and Data Science Corporate Trainer, Author, Speaker, Consultant\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2023-08-17T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/python-statistics-essential-training-19258005,https://www.linkedin.com/learning/python-statistics-essential-training-2023-reboot\",\"Series\":\"Essential Training\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Advanced\",\"LI Level EN\":\"Advanced\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Data Science\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"Yes\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":9565.0,\"Visible Video Count\":31.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":277,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4509084\",\"duration\":50,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Being a Python statistics MVP\",\"fileName\":\"4433355_en_US_00_01_WL30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, explore a compelling example of the topic in action and learn how to use this space to grab the browsing learner. The TOC and course description exist on the course's home page to communicate what's in the course and who it's for.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3187642,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Have you ever wanted to explore statistics  \\n using a code-first approach?  \\n You've come to the right place.  \\n This Python-based course will dive into various techniques  \\n that form the backbone of statistics.  \\n We'll understand the data  \\n with summary statistics and visualizations.  \\n Then we'll create predictive models  \\n using both linear regression and XGBoost.  \\n Finally, we'll explore hypothesis testing.  \\n Because we use Jupyter Notebooks and GitHub Codespaces,  \\n you can easily run the same code  \\n and follow along in a web-based environment  \\n without any complicated installation.  \\n Hi, I'm Matt Harrison,  \\n a Python and data science corporate trainer.  \\n I'm excited to join you  \\n on this incredible statistics adventure together  \\n using a code-first approach.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4509083\",\"duration\":41,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you should know\",\"fileName\":\"4433355_en_US_00_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, discover any use of GitHub or other project tools employed in the course.\",\"captionsStatus\":\"NOT_AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":962095,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":null},{\"urn\":\"urn:li:learningContentVideo:4505089\",\"duration\":186,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Using GitHub Codespaces with this course\",\"fileName\":\"4433355_en_US_00_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to use Codespaces with the course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7492655,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson,  \\n I'm going to show you how to configure codespaces  \\n for this course.  \\n You want to navigate to the course repository  \\n and then click on this green Code button.  \\n You'll see that there's a local tab and a codespaces tab.  \\n If you wanted to run this locally, you could,  \\n if you know how to get a Python environment set up,  \\n there's a requirements.txt  \\n that you can use PIP to install the requirements  \\n if you want to run locally.  \\n Alternatively, you can use codespaces, which is really easy.  \\n Click on this codespaces tab  \\n and then come over here and say create codespace on Main.  \\n That's going to open up a new tab here,  \\n which is going to set up your codespace.  \\n This is going to take a while to run.  \\n We'll let it do its thing,  \\n and then we'll come back when it's finished.  \\n Okay, this has launched codespaces.  \\n If you're not familiar with codespaces,  \\n basically this is a web environment  \\n where you can work on a project.  \\n What it's done is it's launched a virtual machine  \\n and we have a web environment  \\n that lets us talk to the machine.  \\n You can see that I'm in a terminal right here.  \\n I can say LS and I have access  \\n to all of my favorite Linux commands here.  \\n We're also launched in VS Code, so for this course,  \\n all we have to do is click on this Pystats.ipynb.  \\n This is the notebook for the course.  \\n There is a solutions notebook as well  \\n that says -Solutions.  \\n Don't open that one.  \\n You're going to want to open the one that doesn't have  \\n the -Solutions.  \\n So double click on this  \\n and it will open the notebook in VS Code.  \\n If you want to get rid of the explorer over here,  \\n you can click on that to remove that.  \\n Okay, so here is our notebook,  \\n and what I want you to do is just click on  \\n this first cell that has code on it.  \\n I'm just clicking on the left hand side of this rectangle.  \\n Hold down Control and hit Enter.  \\n That's going to run this cell,  \\n and you can see it has some options pop up  \\n when we do that, it says type to choose a kernel source.  \\n It says Python Environments  \\n and it says Existing Python Server.  \\n So we have a Python environment configured here.  \\n Let's just click on that, which is this Python 3.10.8.  \\n Just click on that.  \\n We'll let it do its thing.  \\n You can see in the lower right hand corner,  \\n it says it's connecting to a kernel.  \\n Now you can see it's running and it has finished running,  \\n at this point, you can see it says 2.0.2.  \\n In this lesson,  \\n we showed you how to open a project in GitHub,  \\n create a codespace, and then connect a Jupyter Notebook  \\n to that codespace and execute it through codespaces.  \\n Codespaces is a nice tool that you find  \\n on GitHub that lets you easily start projects  \\n without having to worry about configuring environments.  \\n I recommend using them if you're not familiar  \\n with virtual environments in Python.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":11642392,\"urn\":\"urn:li:learningContentChapter:4509085\"},{\"duration\":2954,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4502196\",\"duration\":328,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading data\",\"fileName\":\"4433355_en_US_01_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"With the skill of loading data with Pandas, you can easily read data from various file formats such as CSV, Excel, SQL databases, and more, manipulate and clean data using Pandas' powerful tools, perform data analysis and exploration, and prepare data for modeling and visualization. Pandas is widely used in the data science community, making it a valuable skill for anyone working with data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12963459,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson, we are going to look at  \\n loading the data.  \\n I've opened the notebook in Codespaces.  \\n If you want to run this locally,  \\n you can run this locally as well.  \\n I'm running the PyStats, IPy and B notebook  \\n and I'm just going to hide this  \\n so we have a little bit more screen real estate.  \\n So we're going to be looking at loading the data.  \\n We're going to be using the Ames, Iowa Housing Data set.  \\n This is a nice little data set.  \\n It's got a couple thousand lines of data  \\n about housing sales in Iowa, and it's got 80 plus columns  \\n of information around those cells.  \\n So this is going to be a great data set for us to look at  \\n and examine some statistics using it.  \\n Let's go down and run some of these cells here.  \\n The first cell I'm going to run is this import cell,  \\n and to run that, I'm going to hold down control  \\n and hit enter.  \\n What that does is it tells Jupiter we want to run the cell.  \\n I like control and enter because it leaves the focus  \\n on the cell.  \\n What that allows me to do is hit enter  \\n and I can go in and edit this cell if I want to after that  \\n and then I can rerun that by holding down control  \\n and hitting enter again.  \\n So we're checking the version of Pandas pd.__version__,  \\n we call that Dunderversion  \\n and we see that we are using Panda's version 2.02.  \\n So one thing to be aware of in this course  \\n is that we are using the latest version of Pandas  \\n as of the recording, Pandas Two  \\n and Pandas Two has a few features that allow it  \\n to do things more efficiently  \\n and with less memory than Pandas One.  \\n So I'm going to be using some Pandas Two functionality  \\n in this course.  \\n If you don't have Pandas Two, some of the code might not  \\n work for you, but hopefully I can convince you  \\n that you probably want to upgrade to Pandas Two  \\n to take advantage of the new features there.  \\n Let's load the data set in this cell.  \\n Again, I'm going to hold down control and hit enter  \\n and this should run.  \\n At the bottom here, you see I'm using the read_CSV function  \\n to load the data.  \\n I'm passing in a URL.  \\n We've got this locally on our code space.  \\n I also have a variable pointing to where you can get this  \\n on the internet if you want to as well.  \\n When you look at this read_CSV function, this probably  \\n looks different if you're used to Pandas One  \\n with the two parameters, engine and dtype_backend.  \\n Both of those we are specifying as pyarrow.  \\n What engine equals pyarrow does  \\n is it uses the arrow library to load the CSV file.  \\n This can be a lot quicker than using the standard  \\n Pandas logic to do that.  \\n And what dtype_backend does is it allows you  \\n to store the data types using the arrow library instead  \\n of NumPy, and that gives you a lot of memory benefits  \\n as well.  \\n Let's inspect the shape of this dataset.  \\n I'm going to go down and execute this next cell.  \\n Again, holding down, control and hitting enter to run that.  \\n You can see that this returns a tupple.  \\n There's 2,930 rows and 82 columns.  \\n Let's look at the first few rows of data.  \\n I'm going to use this head method to do that  \\n and you can see the first five rows.  \\n There are 82 columns in here.  \\n You can scroll over if you want to and see some of it.  \\n Note that we are getting some of the columns truncated here.  \\n You can see that there's an ellipses.  \\n We're only showing you the first 10 columns  \\n and the last 10 columns, but we've got 82 columns of, again,  \\n housing sales data from Ames, Iowa.  \\n One of the things I like to do is run the describe method  \\n and what the describe method does is gives us  \\n summary statistics for each of the numeric columns  \\n in the data frame.  \\n In the index now you can see on the left hand side  \\n where it says count, mean, STD, min,  \\n that is the index of this data frame  \\n and indexes don't have to be numeric.  \\n Pandas will let them be non-numeric, and in this case,  \\n we can see that we have non-numeric,  \\n we have string entries for the index  \\n representing the statistical results  \\n of each of these numeric columns.  \\n So for order, this is the order of cells,  \\n and you can see in the count row, 2,930.  \\n Now, one thing to be aware of with Pandas  \\n is that count probably doesn't mean what you think it means.  \\n Count in Pandas means the number of non missing values.  \\n So, if we look over a little bit at the lot frontage count,  \\n it says that that is 2,440.  \\n So what that means is that there are 2,440 entries there  \\n that had values and that there are a few of them  \\n that are missing values.  \\n We also have the mean, the standard deviation,  \\n the minimum value, and the maximum value,  \\n and then the inner quartiles there.  \\n I like to use this for a gut check to understand  \\n what the data looks like.  \\n You can see that a lot of these numeric values  \\n don't go very high and they're also non-negative.  \\n By default, Pandas is going to use 64 bits of information  \\n to store this data.  \\n We can probably save more memory by changing those types  \\n and I'll show how to do that in a future lesson.  \\n In this lesson, we loaded the data  \\n for the Ames, Iowa dataset  \\n and then we did some basic inspection and sanity checks  \\n to make sure that we have the data loaded.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4504093\",\"duration\":959,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Strings and categories\",\"fileName\":\"4433355_en_US_01_02_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"With the skill of cleaning categorical data, you can ensure that the data is accurate and consistent, which is critical for making meaningful analyses and predictions. You can also effectively handle missing values, outliers, and other anomalies in the data, which can improve the accuracy of your models and prevent biased results.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":34827803,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson,  \\n we're going to look at strings and categories  \\n and understand these types of columns  \\n and how to deal with them in Pandas.  \\n I've listed out some of the goals here.  \\n We want to be able to use the dtypes attribute.  \\n We want to look at using the select_dtypes method.  \\n We're also going to do summary statistics  \\n using the describe method.  \\n And we're going to look at memory usage  \\n and converting string columns to category types.  \\n One of the attributes on a data frame  \\n is this dtypes attribute.  \\n And when you run this,  \\n what this is going to give you is a Pandas series.  \\n In the index of this series,  \\n we have the columns.  \\n Remember a Pandas index does not need to be numeric.  \\n In this case, Pandas is sticking the columns into the index  \\n and then the values for the index,  \\n we can see that says int64,  \\n and then in brackets, pyarrow,  \\n that is the values of this series.  \\n And we can see in brackets it says pyarrow  \\n indicating that we are using Pandas 2  \\n and we are using that pyarrow backend.  \\n Again, because we're using the pyarrow backend,  \\n we're going to get some speed improvements,  \\n we're also going to get some memory improvements as well.  \\n One of the big features of Pandas 2  \\n is that it has a native string type.  \\n We can see for MS zoning that the data type is a string,  \\n and in brackets, pyarrow.  \\n In Pandas 1,  \\n if we wanted to select the columns that were strings,  \\n we would say select_dtypes objects.  \\n And this doesn't work in Pandas 2  \\n because the strings don't have the object type.  \\n This is what we need to do in Pandas 2.  \\n We're going to say select_dtypes and say string,  \\n and we're going to pass that in as a string.  \\n If you look at the output of this,  \\n at the bottom it says you have 2,930 rows and 43 columns.  \\n So this is selecting only the strings column.  \\n You can see in the comment up there I said,  \\n alternatively you can say strings,  \\n and in bracket, pyarrow,  \\n if you'd like the type.  \\n Now, one of the things you can do once you have this  \\n is you can throw on this describe method.  \\n So I'm going to actually throw on a describe  \\n and throw on the transpose on that as well.  \\n I like to sometimes transpose my data  \\n just to see a little bit more.  \\n Let's run this without the transpose,  \\n that's the capital T there.  \\n And you can see that we have 43 columns  \\n and I have to scroll over a little bit to see that.  \\n You can also see that there's an ellipsis here,  \\n so it's not showing all of that.  \\n Sometimes transposing the data,  \\n again, that's flipping the rows and the columns,  \\n lets us see just a little bit more.  \\n Remember we ran describe previously on our data frame  \\n and it gave us summary statistics for the numeric columns.  \\n In this case, we don't have any numeric columns  \\n because we said select_dtypes string.  \\n We just have string columns.  \\n And so when we run describe  \\n on a data frame composed of only string columns,  \\n we get summary statistics for the strings.  \\n In this case, we get the count of non-missing values.  \\n We get the number of unique entries for that.  \\n We also get the most common entry,  \\n so that's the entry with the column top,  \\n and the frequency of that.  \\n So for the MS zoning column,  \\n there are 2,930 values in the rows.  \\n There are seven different values.  \\n The most common value is RL  \\n and it occurred 2,273 times.  \\n You can see for most of these,  \\n that unique value is not very high.  \\n Statisticians sometimes call that cardinality.  \\n So a low cardinality might be a prime candidate  \\n for us to convert this into a categorical type in Pandas,  \\n allowing us to save even more memory.  \\n So in this cell, I'm going to run select_dtypes string  \\n and then I'm going to say memory_usage, deep is equal to true,  \\n and then I'm going to do sum.  \\n And what this is going to give me is the number of bytes  \\n used by the string type columns.  \\n This code is written as a chain.  \\n You can see that we have highlighted the parentheses here.  \\n There's a parenthesis above and below it.  \\n I like to write my code that way.  \\n What it allows me to do is put each operation  \\n on a single line  \\n and it makes your code read like a recipe.  \\n So let me just comment these out  \\n and we'll walk through what's going on in our chain.  \\n Here's our original data frame,  \\n and you can see that there's 2,930 rows here and 83 columns.  \\n If I select just the object columns,  \\n you can see that that goes down to 43 columns.  \\n And then I'm going to say on that,  \\n memory_usage deep is equal to true.  \\n So this is going to return a series  \\n and it's going to tell us how many bytes each column is using.  \\n And then I'm going to sum up this series  \\n and get the total of that.  \\n So it looks like this is using 957 kilobytes of data.  \\n In this next cell,  \\n I'm going to do a similar operation,  \\n but I'm going to insert this astype category.  \\n And when I run that,  \\n you can see that this uses quite a bit less memory.  \\n And what's going on under the covers  \\n is that Pandas is encoding all of the unique types  \\n into a number  \\n and then it's using basically an array  \\n with those unique values pointing back  \\n to the original values.  \\n So it doesn't have to store strings for every entry,  \\n it can just hold a numeric value.  \\n And you save quite a bit of memory if you do that.  \\n You can see that this is almost seven times  \\n more memory-efficient  \\n by converting that to a categorical type.  \\n Okay, so remember we have 2,930 rows.  \\n So one of the things I might want to do  \\n is look at the number of rows that are missing.  \\n And for numeric data,  \\n I would do a chain that looks something like this.  \\n Let me just walk through what's going on here.  \\n I'll comment this out  \\n and explain the code as we're going along.  \\n So the first operation I'm going to do is this isna method.  \\n What that's going to give me back is a data frame,  \\n but rather than having the original values,  \\n it has true/false values.  \\n And then what I'm going to do  \\n is I'm going to do the mean operation on that.  \\n One thing to be aware of in Python,  \\n and also in Pandas because Pandas is in Python,  \\n is that Python treats true and false values as one and zero,  \\n respectively.  \\n So if I take the mean of this,  \\n this is going to essentially be taking the mean  \\n of a data frame with zeros and ones in it.  \\n And what that's going to give me  \\n is the fraction of the values that are missing.  \\n So you can see, for example,  \\n it says that lot frontage,  \\n 0.167 of those are missing.  \\n So if I multiply this by 100,  \\n I get the percentage that is missing.  \\n So 16% of the lot frontage values are missing.  \\n Now what I'm going to do is I'm going to use the pipe method here  \\n and filter out the values that are zero.  \\n What pipe allows us to do is pass in a function into it.  \\n In this case, I'm using a lambda function  \\n that takes the series that is passed in,  \\n the series that you're seeing on the screen here.  \\n And then I'm just going to use a Pandas operation  \\n to filter out the values  \\n where the series is greater than zero.  \\n And here's the entries for that.  \\n You can see that a lot  \\n of the lot frontage values are missing  \\n and the basement year built values are missing,  \\n and then a few of the other values are missing as well.  \\n One of the things that stands out to me  \\n when I look at this is, for example, this 0.03413.  \\n This just kind of makes my spidey-sense tingle a little bit  \\n because that same value is repeated in multiple places.  \\n So that probably means that there's probably a row  \\n or a few rows where these values are missing  \\n for all of those.  \\n That's probably what's happening there  \\n when you see those repeated values.  \\n That previous code cell that we ran,  \\n if you think about it,  \\n is actually not containing any string columns in it,  \\n these are all numeric columns.  \\n So this is a difference in Pandas 2.  \\n In Pandas 2, if a string column is missing a value,  \\n Pandas will actually set that to an empty string  \\n rather than the NA value.  \\n So if we want to find the missing string values,  \\n we actually need to,  \\n instead of making this isna data frame,  \\n we're going to check  \\n whether the data frame is equal to the empty string.  \\n Again, let me just run through this quickly.  \\n I'm going to comment this out.  \\n The chain makes it really easy to comment this out.  \\n So here's our data frame with the string columns  \\n and we're going to say,  \\n are these values equal to the empty string?  \\n And this gives us back our Boolean array,  \\n and then we can just repeat the process  \\n that we did there before  \\n and get the percentage of values that is missing.  \\n In this cell, what I'm going to do is I'm going to select  \\n any of the rows where the values are missing.  \\n So I'm going to pull this out here  \\n and I'm actually going to walk through what's going on here.  \\n Because this is a useful piece of code,  \\n let's walk through what's going on here.  \\n So I have it written in a single line.  \\n It's easier for me to show you what's going on  \\n if I write it in this chain style like this.  \\n And I'm going to comment this out  \\n and we'll just walk through this.  \\n Okay, so here is my string columns.  \\n Where are they equal to the empty string?  \\n And this is a data frame of true/false values.  \\n Now I'm going to do the any along the axis is equal to columns.  \\n So this is going to keep the same index.  \\n So if you look at this, you'll see the same index,  \\n but this is going to return back a series  \\n whether any value in the row was true.  \\n And you can see in this case, there are a bunch of falses,  \\n but presumably some of those are true.  \\n And that's what I'm passing in here,  \\n but I'm also passing in this tilde at the front here,  \\n which negates that.  \\n So what this is going to give me  \\n is it's going to give me the rows  \\n where there are missing values.  \\n And it looks something like this.  \\n We can scroll over a little bit,  \\n and it doesn't look like we're seeing  \\n very many missing values here.  \\n One thing to note  \\n is that we are seeing a bunch of NA values as well.  \\n This dataset is a little messy  \\n in that it has missing values that aren't in there at all,  \\n but it also has NA that is encoding missing values as well.  \\n So that's something to be aware of.  \\n Let's just repeat our operation here,  \\n but instead of looking for the empty string,  \\n looking for the NA string.  \\n And you can see, for example,  \\n that 93% of the alley values are missing  \\n and 48% of the fireplace quality values are missing.  \\n Okay, let's inspect this a little bit more.  \\n I'm going to inspect, where is the pool QC,  \\n the pool quality missing?  \\n Let's run that.  \\n And it looks like there aren't any values  \\n where it's missing.  \\n Again, remember that this Ames dataset  \\n encodes some of the missing values as NA.  \\n Let's run this with isna instead.  \\n And these are all the values where the pool QC  \\n or the quality of the pool is missing.  \\n Presumably, these houses don't have pools  \\n and hence this value is missing.  \\n So that's probably an appropriate encoding there for that.  \\n So one thing I might want to do is I might want to go in  \\n and clean up this data set a little bit.  \\n And so here's one of the ways that I would do that.  \\n I would use the assign method,  \\n and here I'm passing in a chain inside of assign.  \\n So I'm passing in select the dtypes of string,  \\n and with all of the string types,  \\n if there's any missing values,  \\n just fill that in with not applicable.  \\n And then what I'm going to do is I'm going to pass it into assign.  \\n Assign generally takes a parameter,  \\n which is the column name,  \\n and a value for the column name to make a new column.  \\n But if we pass in a data frame  \\n and we put these two stars in front of it,  \\n it will say, take in this data frame  \\n and just update the values with this data frame.  \\n So essentially, what this is giving us back  \\n is a new data frame with the empty string values replaced  \\n by the not applicable values.  \\n Okay, let's go a little bit further here.  \\n Let's look at electrical.  \\n There were some missing values in electrical,  \\n so let's look at that.  \\n And this is how I like to look at string columns.  \\n I like to use this value_counts method.  \\n What that gives me back is a Pandas series,  \\n and it gives me in the index the unique values,  \\n and in the values of the series, the counts of those.  \\n You can see, for example, this row right here  \\n is the empty string values there.  \\n So there's one that is missing, the electrical is missing.  \\n So it'd be good to check, why is the electrical missing?  \\n Is this a house that did not have an electrical system?  \\n Or did this data get dropped?  \\n We probably don't want to leave this as an empty string,  \\n we probably want to figure out what's going on there  \\n and clean that up.  \\n Let's look at the row where it actually is missing.  \\n This is how I would do that.  \\n I would use the query method and say a string, electrical,  \\n equals equals the empty string.  \\n And here's the row where that is missing.  \\n We can inspect what's going on here.  \\n It looks like this was a house that was sold  \\n in May of 2008 for $167,500.  \\n So let's look at another example.  \\n I'm going to do the same thing with fireplace quality.  \\n And in this case,  \\n you can see that there aren't empty strings,  \\n but we do have quite a few NA values,  \\n that's the most common value.  \\n Let's do the same thing with basement condition.  \\n Basement condition has both NA values  \\n and a missing value as well.  \\n So you can see that this dataset is not maybe as clean  \\n as we would like.  \\n Maybe we would want to do something like this  \\n where we say, okay, let's take this data frame  \\n and I'm going to update all of the string columns,  \\n replacing the empty values with not applicable,  \\n and then converting those to a category.  \\n This would be my operation that would do that.  \\n I can just test that out here and check that that does work.  \\n It looks like that was successful.  \\n And this returns 2,930 rows.  \\n Let's check how much memory usage that's going to use.  \\n That's going to give us a data frame  \\n that it looks like is using one meg of memory.  \\n Let's compare that with our original data frame  \\n that is not converted to a category,  \\n and that's using 1.8 megs of memory.  \\n So you can see by converting two categories,  \\n we will save quite a bit of memory.  \\n In this lesson, we looked at some of our string columns  \\n and we looked at various operations  \\n that we would do with string columns.  \\n We did summary statistics on them,  \\n but we also explored some of the missing values.  \\n We did that by using some Pandas manipulation  \\n to find the percentage of values that are missing  \\n and then we dove into those using value_counts  \\n and also using query to examine those.  \\n Understanding what is in your data is an important step  \\n and I highly recommend that you do this step  \\n and don't skip it.  \\n The more you understand your data,  \\n the better you'll be able to explain the data  \\n and share insights with others.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4507091\",\"duration\":957,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Cleaning numbers\",\"fileName\":\"4433355_en_US_01_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The goal of this video is to learn how to clean numbers by handling missing values, handling outliers, and addressing inconsistencies in the data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":40337860,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson we're going to discuss  \\n cleaning numbers.  \\n We're looking at the PyStats notebook  \\n in the 0 1 0 3 section.  \\n Our goals are going to be using select D types,  \\n using describe, finding missing values,  \\n and I'll also show you how to view a little bit more data  \\n than the default values and style the output.  \\n In pandas one, there would be a lot of entries  \\n for the Float D type here.  \\n That's because in pandas one,  \\n when pandas encountered a integer value  \\n that had missing values, it converted it to a float.  \\n You can see that there aren't any missing values here.  \\n That's because we're using pandas two.  \\n Remember that PyArrow backend  \\n actually has support from missing values.  \\n And so if we say select D types is int  \\n we get 39 columns here.  \\n So there are no floating point columns  \\n there's just integer columns in here.  \\n So let's explore some of these columns  \\n and see what's going on.  \\n So again, one thing that we can do,  \\n is run the describe method  \\n to get summary statistics on those.  \\n One of the things I like to do  \\n is look at the count,  \\n just to see how many values are missing.  \\n For example, you can see that lot frontage is missing  \\n quite a few values.  \\n I also like to look at the minimum values  \\n and the maximum values to see what the range is.  \\n You can also look at the mean,  \\n which a lot of people would refer to as the average,  \\n though a statistician would probably get upset  \\n at you if you said that.  \\n And you can look at the 50th percentile  \\n which a statistician would call the median.  \\n If the mean and the median are around the same,  \\n you might have data that's somewhat normal,  \\n though I also like to look at visualizations  \\n to understand what the lay of the land looks like  \\n or the distribution of that data looks like as well.  \\n Okay, so remember,  \\n we've got 2,930 columns there.  \\n So a lot of these columns aren't missing any values  \\n but some of them are.  \\n So let's look at this lot frontage one.  \\n This is how I would explore it.  \\n I'm going to run the query method and say,  \\n I want to look at where the lot frontage is missing.  \\n Let's dive into what's going on inside of query here.  \\n So query expects you to pass in a string that  \\n takes a column and some operation on the column.  \\n In this case, the column is lot frontage  \\n and, because lot frontage has a space in it,  \\n it is not a valid Python attribute.  \\n So if you have a column name that has characters  \\n that aren't valid Python attributes,  \\n you need to surround them by backticks.  \\n That's what we see here.  \\n And then I'm going to say, okay,  \\n we've got that lot frontage column,  \\n let's just look where it is missing.  \\n And you can see that there are 490 rows  \\n where the lot frontage is missing.  \\n You can see it's represented here by NA  \\n in less than and greater than.  \\n One of the questions I frequently get when I teach people  \\n about missing values is how to deal with them.  \\n My typical response is, it depends,  \\n but probably the best way to deal with them  \\n is to find a subject matter expert,  \\n someone who knows why this data is missing,  \\n and they can often point you in the right direction.  \\n For example, lot frontage.  \\n Does NA mean that there is not a front area  \\n of this house or does this mean that lot frontage  \\n is missing that we don't have that information?  \\n That would be something that would be useful to find out.  \\n If there is not a front of the house,  \\n I would probably encode that as zero rather than NA.  \\n So again, it's important to talk to a subject matter expert  \\n and find out why exactly this data might be missing.  \\n Okay, remember I promised I would show you how to  \\n see more data and this is the secret to doing that.  \\n Pandas, by default, is not going to show you all of the columns  \\n and all the rows if you have a large data set.  \\n And, I think this is useful and a lot of people,  \\n as soon as I tell them this,  \\n ask me how do I get around this?  \\n I would caution you to refrain from trying  \\n to get around this as soon as you can.  \\n Humans aren't really meant  \\n for looking at large tables of data.  \\n We're not optimized for doing that  \\n and it's not an effective use of our time, really.  \\n What you want to do is you want to  \\n use something that is effective  \\n for pulling out data that is interesting.  \\n So my recommendation is when you feel that urge to look  \\n at more columns or more rows,  \\n think, can I use a query or a filter,  \\n to pull out the data that is interesting to me.  \\n Alternatively, can I visualize this,  \\n and might that give me more insight into the data?  \\n You can tell a really good story by visualization  \\n that's a lot stronger than presenting someone  \\n with a table of a bunch of numbers.  \\n So how we're going to do this in pandas  \\n is we're going to use the context manager,  \\n that's the with statement.  \\n And we're going to use this option context.  \\n Context manager is a construct in Python that allows you to  \\n enter into a context and exit out of that.  \\n In this case, when we use option context,  \\n in the indented portion here, we're calling display,  \\n while we are indented, what ever we pass  \\n into option context is going to overwrite the values.  \\n When we un-indent from the context manager  \\n it will revert back to what it was before.  \\n So we're going to change the minimum number  \\n of rows that we view to 30 and we're going to change  \\n the maximum columns to 82.  \\n So you can see that we're now seeing quite a bit more data  \\n and if we scroll over  \\n you can see that we are seeing a lot more columns  \\n than we were previously.  \\n If you're not familiar with this feature in Jupiter,  \\n one of the things you can do is put a question mark  \\n after a method or a function in Jupiter  \\n and it will pull up the documentation.  \\n So off of the style attribute,  \\n there are various methods on there.  \\n One of those is set sticky.  \\n What this allows us to do is set the column  \\n or the index to sticky so when we scroll  \\n we can see the index.  \\n This often comes in very handy.  \\n In this example I'm going to show a lot more data  \\n than I normally show.  \\n And then I'm going to run this query  \\n where I'm showing the missing values of lot frontage  \\n and then I'm going to set  \\n the sticky columns  \\n and the sticky index.  \\n The output looks like this, and if I scroll over,  \\n you can see that that index there  \\n stays on the left hand side.  \\n So this comes in useful when you need to find  \\n out what row is going on.  \\n You'll note that I do have a comment here  \\n at the top,  \\n that columns is broken.  \\n I think this is a pandas two bug, where,  \\n the columns are not being sticky here when I scroll down.  \\n Hopefully they fix that.  \\n Okay, let's look at where garage year built is missing.  \\n So here are the rows where garage year built is missing.  \\n It looks like there's 159 of those rows.  \\n Again, we could scroll through this data  \\n and try and determine what a missing garage  \\n year built means.  \\n I am assuming that it probably means  \\n there is not a garage on here.  \\n Hence, the missing value.  \\n In this case because year built is a year,  \\n putting in a default value of a zero to encode missing  \\n probably wouldn't be the right choice  \\n because if you wanted to look at  \\n the average of the year built that's going to throw that off.  \\n So in this case, garage year built,  \\n leaving those values as missing, might be useful.  \\n However, if you want to do some operations  \\n such as running linear regression on this,  \\n that might be problematic,  \\n because, linear regression does not like to  \\n have missing values in the data.  \\n You might need to find a way to encode that,  \\n such that you can run some of these other tools  \\n with columns that have missing data in them.  \\n I'm going to take that year built column  \\n and I'm going to run summary statistics  \\n on that just to see what's going on there.  \\n And, you can see that the count is demonstrating  \\n that we are missing quite a few values.  \\n I like to look at the minimum value and the maximum value.  \\n Now this actually stands out to me, the maximum value here.  \\n 2 2 0 7, remember this is a year,  \\n and as of this recording we're recording this in 2023.  \\n So this garage is being built a few years into the future.  \\n That's somewhat problematic to me  \\n and that probably indicates that there is  \\n some sort of a typo going on here.  \\n This was probably 2007  \\n but it got fat fingered on data entry.  \\n Let's look at that row where that is missing.  \\n And again, I'm going to use my option context  \\n just to display a few more of those columns.  \\n And, I'm going to put in as my query,  \\n garage year built,  \\n remember I'm going to use back ticks around that  \\n because there are spaces ,  \\n and then greater than 2020.  \\n And maybe I'll scroll over here.  \\n You can see that the year remodel or add  \\n is 2006,  \\n and the garage year built is 2,207.  \\n And the year sold is 2007.  \\n So again, I'm going to assume that this is a typo  \\n and we might want to go in and clean that up.  \\n Now, because I've found this by going through the steps  \\n of manually looking at the data,  \\n looking for missing values and also looking at describes,  \\n this makes me want to look at maybe  \\n some of the other year columns,  \\n maybe some of those are  \\n fat fingered as well.  \\n So, one method that comes in handy is the filter method,  \\n and it allows me to pull off various columns.  \\n So I'm just going to pull up the documentation there.  \\n You can see that this says it subsets the data frame rows  \\n or columns according to a specified index.  \\n So there are various ways to do this  \\n using items like or regex.  \\n We can scroll down here  \\n and see that items means keep labels,  \\n which are in items.  \\n So in this case we're passing in a sequence of labels  \\n and we keep the labels which are in that sequence.  \\n You can pass in like which is a string.  \\n It says keep labels from the axis  \\n for which like in label is equal to true.  \\n That would allow us to do SUBSTRING matching,  \\n but apparently it would only allow us to do one substring,  \\n whereas items allows us to match multiple strings.  \\n Doesn't look like there's an option to match  \\n multiple substrings.  \\n However, we could possibly also use this next option,  \\n which is a regular expression,  \\n and we could probably formulate a regular expression  \\n that would allow us to match multiple substrings as well.  \\n Here's an example of using that.  \\n I say filter like is equal to yr.  \\n You can see there are two columns that have yr in them.  \\n If I want to check which of those has  \\n a column greater than 2023,  \\n which is the current year,  \\n I'm going to do this chain here.  \\n So again, here's our first column here,  \\n and let's throw in this pipe.  \\n What is this pipe doing?  \\n It's saying, with the data frame we see on the screen,  \\n we are going to do an index operation  \\n with this result right here.  \\n So we saw something similar to this before,  \\n we said any along columns is equal to axis.  \\n What that's going to give us is a Boolean array.  \\n It's going to have the same index as the data frame  \\n but it's going to have true false values.  \\n The true values will be where it's greater than 2023.  \\n Let's run that.  \\n And we only see that one column,  \\n that index 2, 2, 6, O, so there aren't any other values  \\n for year sold that are greater than 2023.  \\n What about the other columns?  \\n There are some columns that have year in them.  \\n So this would be my process to filter those out.  \\n I'd probably do something like that,  \\n where I'd say, okay let's take our data frame,  \\n rename our columns that are yr and make those year  \\n and then with those, let's do a filter,  \\n and say, take the columns that have year in them  \\n and then with those, let's add in our pipe here  \\n and see which ones are above our limit.  \\n It looks like, in this case,  \\n it was only that one row that was fat fingered.  \\n In this next chain, I'm showing an example of clipping.  \\n So let's take garage year built.  \\n This is just the series here.  \\n And then I'm going to use the clip method from pandas  \\n to say I want to limit this and have the upper values  \\n just be the year built max.  \\n And if we do that,  \\n that gives us a new series that has been clipped.  \\n And if we look at the value counts from that,  \\n we should see that there aren't any values  \\n that are greater than 2023.  \\n Now, this is sorted by the frequency.  \\n We could come in here and say sort index,  \\n and that looks like the highest value in  \\n the garage year built is 2010.  \\n At this point,  \\n I might want to update my data frame with this information.  \\n Now remember, in our previous lesson,  \\n we looked at replacing strings  \\n that had values that were missing  \\n and converting those to categoricals.  \\n So I'm going to leverage that.  \\n I'm going to make a chain here,  \\n and, I'm going to put that operation  \\n to clean up my strings into my chain  \\n and then I'm going to follow that with this other operation  \\n to clean up the garage year built.  \\n Now let's examine this line right here a little bit.  \\n What's going on with this line?  \\n There's quite a bit of syntax here.  \\n I am using what's called dictionary unpacking.  \\n I have a dictionary literal.  \\n and here's my dictionary.  \\n Why am I using a dictionary?  \\n Why don't I just say garage year built  \\n is equal to the current value of garage year built  \\n that's clipped.  \\n I'm using a dictionary because there are spaces in here.  \\n Because there are spaces,  \\n I can't say garage space year built is equal to that,  \\n so I can't use a parameter to do that,  \\n however, I can stick this into a dictionary  \\n and then use dictionary unpacking and that will update  \\n the column with a non-valid attribute name  \\n using pandas.  \\n And then maybe let's just look at our D types  \\n value counts after doing that.  \\n Looks like there are 39 int columns, or integer columns.  \\n And then it looks like there are categorical columns  \\n but, it doesn't sum these up.  \\n Why doesn't it sum these up?  \\n Because presumably, there are four categorical columns  \\n that have the same entries in them.  \\n There are three that have the same entries  \\n and then all of these other ones down here are one-offs.  \\n In this lesson, we looked at examining our numeric columns.  \\n I showed you how to do summary statistics on them.  \\n I showed you how to look for missing values  \\n and I showed you an example of when I looked  \\n at those summary statistics,  \\n I found something off and then I examined it  \\n a little bit more and then I used that to actually feed back  \\n into a chain to clean up the data.  \\n This is a process that you're going to want to go through  \\n when you load your data.  \\n You want to make sure that your data is clean,  \\n so that when you start doing analysis of it,  \\n the analysis makes sense.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4509082\",\"duration\":350,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Shrinking numbers\",\"fileName\":\"4433355_en_US_01_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"With the skill of cleaning integer data, you can ensure that the data is accurate and consistent, which is critical for making meaningful analyses and predictions. Also, learn how to lower the memory requirements if possible.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14071253,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson, we're going to look  \\n at changing the size of our numbers to save memory.  \\n One thing is I will do is create a function  \\n that will automatically convert integer values  \\n to smaller types.  \\n And then I'm going to show  \\n how to apply this function to our dataframe.  \\n You can actually take this function  \\n and apply it to your data as well.  \\n We're also going to make another function.  \\n I'm going to call that clean_housing that combine  \\n some of the steps that we've been looking at  \\n to clean up our data.  \\n This is something that I recommend you do as well  \\n as you're going through your data, cleaning it up,  \\n throw that into a chain  \\n and then take that chain and put it into a function.  \\n This is going to be a practice that, if you use it,  \\n will make your life a lot easier.  \\n We're going to continue where we left off.  \\n In our last lesson, we saw this assign method  \\n where we converted strings into categoricals  \\n and we also cleaned up our Garage Yr Blt.  \\n Here's our summary statistics of that.  \\n Looks like we haven't lost any fidelity by doing that.  \\n We should be good.  \\n We've actually cleaned up that Garage Yr Blt.  \\n Now, remember I said  \\n that I like to go through the maximum values here,  \\n and for example, the Overall Qual column.  \\n You can see that right here has minimum values of one  \\n and maximum values of 10.  \\n Remember that Pandas is using a 64-bit integer  \\n to store that information which is actually a waste.  \\n So we could use a different data type  \\n and save memory without losing any information.  \\n Let me show you how we might want to do that.  \\n In this cell, I'm going to loop through NumPy,  \\n and NumPy has a function in it called, iinfo, integer info.  \\n I'm just going to loop through some NumPy types.  \\n Uint8 stands for an 8-bit unsigned integer.  \\n So if we say np.iinfo(uint8), it tells us  \\n that the minimum value for that is zero  \\n and the maximum value is 255.  \\n This is a type that we could use for that overall quality  \\n because zero and 10 certainly lie within this range.  \\n Now, sometimes you have positive numbers  \\n that go a little bit bigger.  \\n You might need to use 16-bit or 32-bit  \\n before you go up to 64.  \\n One thing to be aware of, these are NumPy types.  \\n These are the types that were used in Pandas 1.  \\n In Pandas 2, you can optionally use that PyArrow backend.  \\n However, these type ranges actually work  \\n for the PyArrow types as well.  \\n So in this cell, I've created a function.  \\n Again, you can use this function  \\n and leverage it for PyArrow-backed dataframes.  \\n What it's going to do is it's going to accept a dataframe  \\n as input, and then it's making a mapping dictionary.  \\n It's going to loop over all of the columns  \\n that are PyArrow 64-bit integers.  \\n And then it's going to look at the minimum  \\n and maximum values for those.  \\n And if the minimum is less than zero,  \\n it's going to continue.  \\n This is only dealing with unsigned integers.  \\n Otherwise, it's going to look at the maximum values  \\n and determine the appropriate type for that.  \\n Once you have this function, all you have to do is use it  \\n in combination with the pipe method.  \\n So if you're not familiar with that pipe method  \\n in Pandas, this is a super handy method,  \\n it allows you to do whatever you want to a dataframe.  \\n All you have to do is pass in a function into it.  \\n In this case, we're passing in the shrink_ints function.  \\n Your function should accept a dataframe  \\n if you're using pipe with a dataframe.  \\n If you're using pipe with a series,  \\n a series also has a pipe method,  \\n your function needs to accept a series.  \\n And then the function can return whatever it wants.  \\n In this case, we're actually returning a dataframe  \\n using that mapping to change the types there.  \\n And with the output of that, we can actually run  \\n a describe on that after we've done that.  \\n So let's run this and test this out.  \\n You'll note that I've still included  \\n what we've done previously here.  \\n So I want to impress upon you  \\n that when you see a chain that's a little bit longer,  \\n I don't create these chains from scratch.  \\n I am building them up as I'm going through my process.  \\n And so let's look at the output from that.  \\n The output looks good.  \\n Looks like we didn't lose any information by doing that.  \\n In this next cell, let's see how much memory this is using.  \\n And it looks like this is using 360 kilobytes of memory.  \\n Let's compare that with our default amount of memory.  \\n So shrinking our integers in combination  \\n with changing our types to categoricals has saved us  \\n five times the amount of memory by doing that.  \\n The next thing I would want to do after doing this  \\n is convert this into a function.  \\n I'm keeping my shrink_ints function that I defined above,  \\n but I'm also making a function called clean_housing.  \\n This is my chain.  \\n I'm just moving this chain into a function.  \\n Let's run the function and make sure that it works.  \\n I'm just going to inspect the dtypes after doing that.  \\n It looks like this is working successfully.  \\n In this lesson, I presented a function that you can use  \\n to shrink PyArrow types without losing data.  \\n We also looked at some of the benefits of that  \\n such as memory usage going down drastically by doing this.  \\n This is one of the ways that you can load  \\n much larger data sets and analyze them  \\n by using the correct types.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4503101\",\"duration\":97,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Clean Ames\",\"fileName\":\"4433355_en_US_01_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3154431,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] We're at our first challenge.  \\n These challenges are a great way for you to practice  \\n and I highly encourage you, in addition to following  \\n along with me in the code space, to try this challenge out.  \\n The science tells us that if you do the challenge,  \\n you're going to use a different portion of your brain  \\n and you will actually remember the content better  \\n if you do the challenge  \\n in addition to following along with the content.  \\n So I highly recommend that you do this challenge  \\n before proceeding to the next video.  \\n Let me explain what the challenge looks like.  \\n I want you to create a cell containing all  \\n of the imports necessary  \\n to run this notebook up to the current state,  \\n and then I want you to create a cell with the clean housing  \\n and the shrink functions that I showed you up above.  \\n I want you to also to add code to load the raw data  \\n and to create a housing variable from calling clean housing.  \\n Then I want you to take these cells that you just created  \\n and move them to the top of the notebook,  \\n restart your notebook, and make sure that these cells work.  \\n What this is going to do is give you a process  \\n that you can use in your own notebooks.  \\n I recommend following this process,  \\n once you've made a chain that is useful,  \\n put it in a function  \\n and then move that to the top of your notebook.  \\n This will allow you to come back  \\n to your notebook and quickly pick up where you left off.  \\n You don't have to scroll through a bunch  \\n of cells to figure out where you were.  \\n You can just have that at the very top,  \\n and then you can just keep working on your data analysis.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4504092\",\"duration\":263,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Clean Ames\",\"fileName\":\"4433355_en_US_01_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14240562,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] In this lesson, I'm going to show you  \\n how to do the first challenge.  \\n So here is my cell.  \\n I'm going to get my imports.  \\n My imports were up at the top already,  \\n so these are my imports right here.  \\n We used NumPy to inspect the types  \\n but we didn't really use it in processing our data  \\n but I will keep the numpy import there as well.  \\n That will allow me, if I'm using this notebook,  \\n to not have to worry about importing NumPy.  \\n Okay, the next thing that it wants me to do  \\n is use the clean_housing and shrink_ints function.  \\n So I'll just come up here and I'm going to copy these  \\n and we'll paste those in here as well.  \\n I'll just put them in the same cell.  \\n I think that's fine.  \\n And then the next thing it says is add code  \\n to load the raw data  \\n and create a housing variable by calling clean_housing.  \\n So I'm going to do that,  \\n and that's this code right here.  \\n And I'll put that at the bottom here.  \\n Maybe I'll just call this raw.  \\n Let me explain why I like to use the raw data  \\n and make a chain.  \\n Invariably, what I've found in my experience working  \\n and consulting, it's that when I make a report  \\n or I make a model, someone asks, \\\"What's going on?  \\n Why is it doing this?\\\"  \\n And if I have the raw data and a chain,  \\n it's really easy to trace back through that  \\n and understand what's going on.  \\n So I'm going to keep that raw data there.  \\n And this exercise asked me  \\n to create a variable called housing.  \\n So I'm going to make a variable called housing  \\n and say that is equal to clean_housing  \\n and passing in raw into it.  \\n At this point, I will have the original data  \\n and my cleaned up data if I need to compare those two.  \\n The next thing it asks me to do is move this cell  \\n to the top of the notebook.  \\n So I'm just going to click on the side here.  \\n I'm going to keep this cell here, but I'm going to also click  \\n on the side so I'm not in edit mode in my notebook  \\n and hit C to copy this.  \\n And then I'm going to scroll up  \\n to the very top of the notebook here.  \\n I'll actually put it below this heading section down here  \\n and hit V to paste it right here.  \\n So the next time I came to this notebook,  \\n I wouldn't have to scroll through all  \\n of those cells to find out what's going on here.  \\n It's just for me right at the top,  \\n the code to get my data so I can be off and running.  \\n And finally, it says restart the notebook  \\n and make sure that those cells work.  \\n You'll notice that as I've been going through my notebook,  \\n I've been trying out my code, commenting it out,  \\n going through it, making sure that it works  \\n and you will want to do that as you're using your code.  \\n I'm going to hit this restart button to restart my kernel.  \\n It's going to pop up this warning.  \\n I'll hit restart.  \\n Note that when you do restart,  \\n you will lose all variables that you've created.  \\n I'm okay with that in this case.  \\n And then I'm going to run the cell  \\n and make sure that it works.  \\n Okay, it did not complain.  \\n I'll just make a new cell below this and look at housing.  \\n And it looks like it worked.  \\n In this lesson, I've given you a nice hint  \\n for how to make your notebooks a lot easier to use.  \\n And that is make a chain that cleans up your code,  \\n stick that into a function, and then pull that up  \\n to the top of your notebook  \\n so that when you come back to your notebook,  \\n you can easily start going and not have to scroll through  \\n and figure out what's going on with your code.  \\n \\n\\n\"}],\"name\":\"1. Loading and Cleaning Data\",\"size\":119595368,\"urn\":\"urn:li:learningContentChapter:4503102\"},{\"duration\":3034,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4504091\",\"duration\":242,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Categorical exploration\",\"fileName\":\"4433355_en_US_02_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"With the skill of calculating and interpreting summary statistics, you can gain valuable insights into the central tendency, variability, and distribution of your data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7604335,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] In this lesson, we're going to look at exploring  \\n our categories a little bit more.  \\n We're going to show the unique values of that  \\n but we're also going to visualize what's going on with that.  \\n Remember, visualization is a powerful tool  \\n you can use to tell a story very quickly  \\n and we're going to show how to do that for categoricals.  \\n I've got my cell that loads my data.  \\n So I've got the raw data and I've got the housing data.  \\n Remember, we can use describe to get summary statistics.  \\n By default, this is going to give us  \\n numerical summary statistics.  \\n It's not going to include the categoricals,  \\n or strings by default.  \\n Let's pull off a categorical.  \\n I'm going to use the zoning value.  \\n One of the things that's interesting about this  \\n is if you look at the dtype at the bottom here,  \\n it says that it is category  \\n and then here are the unique types for that category.  \\n Generally, when I have a category or a string column,  \\n I like to use the value counts method.  \\n We'll tack that on here.  \\n And this gives us a series.  \\n Pandas uses series and data frames all over the place  \\n so it's good to get comfortable with those  \\n and also understand that these operations that we're doing  \\n with series and data frames are like tools  \\n in your tool belt and once you understand  \\n these basic operations, you can start leveraging them,  \\n combining them with other ones.  \\n So one of the things I might want to do with this  \\n is visualize what's going on here.  \\n This is a nice summary.  \\n We can see that the RL Zoning has 2,273 entries  \\n but maybe want to visualize that  \\n and let's see how we can do that.  \\n The common visualization that we would use for this  \\n is a bar plot.  \\n Now look how easy it is to go from this value count  \\n to a plot.  \\n All I need to do is tack on the next operation in our chain  \\n which is .plot.bar.  \\n Let me explain how bar plots work in Pandas.  \\n Once you understand how they work,  \\n they're very easy to leverage.  \\n What a bar plot is going to do is it's going to take  \\n the index and put the index in the X axis.  \\n Note that the index here is not numeric.  \\n It is the unique entries from the MS Zoning column.  \\n That's perfectly fine.  \\n In fact, Pandas converts any index when you do a bar plot  \\n into a categorical or a string in the plot,  \\n which sometimes comes to bite us  \\n if you have dates in the index and you do a bar plot  \\n of that, it actually converts those dates into categoricals.  \\n For this case, it's fine.  \\n So the index is going to go into the X axis,  \\n and then in this case, we only have a single series.  \\n If you have a data frame, each column will be a bar  \\n and those bars will be located above the index.  \\n Let's run this and see what happens.  \\n This allows us to clearly see the RL  \\n is the most common entry for MS zoning, followed by RM  \\n and telling off very quickly.  \\n One of the things I don't like about this bar plot  \\n is that the labels are rotated 90 degrees.  \\n In fact, a common thing to do with a categorical count plot  \\n like this is to convert it to a horizontal bar plot,  \\n and this again, is easy in Pandas.  \\n All we need to do is change the bar  \\n to barh, standing for bar horizontal.  \\n And we get something that looks like this.  \\n Again, telling the same story  \\n but a little bit easier for us to read.  \\n We don't have to tilt our head as much.  \\n In this lesson,  \\n I showed you how to summarize categorical columns.  \\n Again, value counts is going to be your friend  \\n and then once you know how bar plots work,  \\n it's easy to go from value counts to making a bar plot.  \\n And then generally you're going to want to make  \\n a horizontal bar plot.  \\n That is easy as well by using .barh instead of .bar.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4503100\",\"duration\":262,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Histograms and distributions\",\"fileName\":\"4433355_en_US_02_02_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"The goal of this video is to learn how to create and interpret histograms, which are graphical representations of the distribution of numerical data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7903762,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson, we're going to look  \\n at histograms and distributions for numerical columns.  \\n Again, we can start off  \\n with the describe method to get summary statistics  \\n but oftentimes, we want to visualize this as well.  \\n I'll show you some ways to visualize these.  \\n Let's take the SalePrice column.  \\n Note that we can run describe on a single column  \\n or a series in addition to a data frame.  \\n When we run describe on a series,  \\n we get back a series.  \\n Again, in the index of this series,  \\n we have the descriptions  \\n of the statistical summaries that are coming back  \\n and the values,  \\n we have the corresponding values for each statistic.  \\n I'm just going to quickly go through these.  \\n Look at the minimum value.  \\n It looks like there's a house that sold for $12,000.  \\n That seems pretty cheap.  \\n I might want to check out that row  \\n or check out those low values.  \\n Also might want to go on that high side.  \\n We have a house that sold for 755,000.  \\n Make sure that that looks about right.  \\n Also, I could look at the mean and the median.  \\n Those look pretty close to each other and remember,  \\n our count is not the count of rows  \\n but the count of non-missing rows, but it looks  \\n like this is, in this case, the same as the number of rows.  \\n We don't have any SalePrice values that are missing.  \\n One of the ways to visualize a numeric column  \\n is to do a histogram, and again,  \\n this is very easy in pandas.  \\n We just say .hist, and here's the histogram.  \\n You can see that this is somewhat skewed.  \\n It rises quickly to some value  \\n around $150,000 and then tails off  \\n and there's a long tail going out to around $700,000.  \\n We know that it goes up to $700,000 at least.  \\n If it didn't go up to that value,  \\n it wouldn't be on this chart.  \\n However, there aren't very many entries at that end.  \\n Now, you need to be careful with histograms  \\n because you can tell different stories with them.  \\n By default, pandas is going to give you 10 bins.  \\n People often ask, \\\"Is 10 bins the correct number of bins?\\\"  \\n I would say the answer is it depends, but it might not be.  \\n This is one of those things that people  \\n would write dissertations about the correct number of bins.  \\n I'm going to show you how you can change this.  \\n We can say bins is equal to 30,  \\n and we can get a little bit finer granularity in there.  \\n We could also come down here and say bins  \\n is equal to three.  \\n This probably isn't a story that we want to tell  \\n using bins is equal to three.  \\n From inspecting this data, it looks like somewhere  \\n around 150 is the most common value or the mode.  \\n When we do describe, we don't get a mode reported on there,  \\n but we did get a median and a mean,  \\n which were both around that value as well.  \\n You can see that for whatever reason,  \\n there's a little bump here around 550  \\n and there's another bump here around 600.  \\n Those are kind of interesting to me.  \\n They probably indicate that these houses sold  \\n at complete numbers like 600,000  \\n or 550 rather than some value in between there.  \\n It's interesting also that we're not seeing that happen  \\n at other values where we're not seeing like big spikes  \\n at 300,000 or 200,000 or 100,000, and it also doesn't look  \\n like we're seeing bumps at the 50,000 level as well.  \\n We can bump up the number of bins and look  \\n at the finer granularity.  \\n That might yield useful information.  \\n It might just be noise.  \\n In this lesson, we took the SalePrice column  \\n and we did summary statistics on that.  \\n We also showed how to look at a very common visualization  \\n of that, which is the histogram.  \\n We showed how to change the number  \\n of bins in a histogram to tell a different story as well.  \\n Leveraging a histogram is a great way to get a feel  \\n for how the data is distributed.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4502195\",\"duration\":412,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Outliers and Z-scores\",\"fileName\":\"4433355_en_US_02_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Discover how you can objectively identify data points that are significantly different from the majority of the data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":18691501,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson, we are going to look  \\n at how we might find outliers  \\n or values that are at the extremes  \\n and I'll show two different ways to do that.  \\n I'll show one using our classic Z score and another one  \\n by using the inner quartile range, and we'll look  \\n at how we can use the pandas functionality to do that  \\n and make functions that you can use  \\n and leverage in your own code if you need  \\n to calculate values that tend to be on the extremes.  \\n So here is a function right here, calc Z  \\n and you'll notice that the input to calc Z,  \\n the first parameter is a data frame  \\n so a function that has the first parameter is a data frame  \\n is a candidate to use with the pipe method.  \\n This lets us leverage this in a chain.  \\n Let's run this and see what happens when we do this  \\n and I'll walk through the code.  \\n Okay, so what this is returning is a series  \\n and this is the Z-score of the sell price column.  \\n Let's just look at what these lines are doing.  \\n In this case, you'll note, even though I like chaining,  \\n I'm not using chaining all over the place.  \\n This is a case where I'm not using chaining,  \\n I'm calculating the mean  \\n of this column that I'm passing in here.  \\n So the DF that is coming in is whatever is passed  \\n in from the chain.  \\n In this case, this is the original housing,  \\n just coming in as the DF here  \\n and sale price is coming in as the column value.  \\n So we first calculate the mean of sale price,  \\n then we calculate the standard deviation of sale price  \\n and then the Z score is calculated  \\n by taking that column, subtracting the mean,  \\n and dividing by the standard deviation.  \\n We can leverage pandas to make this a vectorized operation  \\n and to make it work relatively easily.  \\n The Z-score gives us a quantification  \\n how many standard deviations we are away from the mean  \\n and generally an outlier is a value  \\n that has an absolute magnitude above three  \\n for data that has a normal distribution.  \\n One of the nice things about making this  \\n as a function is we can also use it in assign.  \\n Let me show you how this is going to work here.  \\n I've got this little chain.  \\n I'm going to comment out this  \\n and if you look at the column at the end here,  \\n you can see that there is now a Z-score column.  \\n This Z-score column is the Z-score of the sale price.  \\n If I want to find outliers,  \\n I can combine this with the query method.  \\n So now that I have a Z-score column,  \\n I can use this query saying,  \\n take the absolute value of the Z-score column  \\n and find out where that is greater than  \\n or equal to three.  \\n You can see the values that we're looking  \\n at here on the screen, none of those are equal to three.  \\n Let's run this and see what happens.  \\n You can see that this row 15 and this row 44,  \\n if we were to scroll over, presumably would have a Z score  \\n with an absolute magnitude greater  \\n than or equal to three, and indeed they do.  \\n Let's look at these values.  \\n These values all look like high-end houses  \\n or houses that are very expensive.  \\n These values all look like they're greater than three.  \\n It's possible that there are values less than three.  \\n Let's just quickly check and see if we can get those.  \\n I'm going to copy this  \\n and I'm going to just change it a little bit and say,  \\n where are we less than or equal to negative three?  \\n So it looks like there aren't any values  \\n that are outliers on the low end.  \\n Again, you need to remember that this is assuming  \\n that we have a normal distribution of the sale price.  \\n I'll show later on in the lesson how to calculate  \\n if that distribution is normal.  \\n Another mechanism for determining outliers is  \\n to calculate the inner quartile range  \\n and then values that are outside  \\n of that are classified as outliers by some statisticians.  \\n Here I'm making a function called calc IQR outlier.  \\n Again, this takes a data frame and a column.  \\n In this case, what it's doing is it's pulling  \\n off the series from that column  \\n and then we're saying calculate the 75th percent quantile  \\n and subtract the 25th percent quantile from that.  \\n That will give us a series of the inner quartile range.  \\n We can also calculate the median  \\n which is the 50th percentile, and the definition  \\n for an outlier using the inner quartile range is  \\n to take the median  \\n and subtract three times the inner quartile  \\n or the median and add three times that.  \\n So I'm making a variable called small mask and large mask  \\n and then I'm using the pipe to combine those together.  \\n What this returns is a boolean array,  \\n let me just show you that.  \\n So boolean array is a series that has true false values.  \\n Where these are true means that either this is true,  \\n it's low or it's high, and when we throw that  \\n into our index operation here,  \\n this gives us back the rows where this is true.  \\n And you can see  \\n by this calculation that 15 and 44 are both outliers.  \\n Let's show how to throw this into a column.  \\n In this example,  \\n I'm going to make a new column called IQR outlier  \\n and that is going to be the result of calling our function,  \\n passing in our data frame  \\n and indicating the sell price column  \\n as the column that we want to figure  \\n out whether those values are outliers or not.  \\n Now let's look at that result here.  \\n I'll scroll down and scroll over.  \\n You see this is true false value,  \\n so this is our boolean array.  \\n What I'm doing in this next part  \\n of the chain is just saying, filter out the roads  \\n where this is true in the boolean array  \\n and all of these IQR outliers should be true in this case.  \\n In this lesson, we made functions that allow us  \\n to calculate the outlier in two different ways.  \\n One by using the Z-score and another  \\n by calculating the inner quartile range  \\n and using that to determine whether values are outliers.  \\n These are functions that you can leverage in your own code.  \\n Feel free to take them  \\n and use them for outlier calculations.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4503099\",\"duration\":422,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Correlations\",\"fileName\":\"4433355_en_US_02_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn how to identify relationships between variables, determine the strength and direction of those relationships, and make informed decisions based on the data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":24607809,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson,  \\n we're going to look at calculating correlations.  \\n We'll look at the Pearson and Spearman correlation.  \\n I'll also show you how to make a heat map  \\n and give you some tips for formatting that,  \\n so you can quickly see where your correlations are.  \\n This is one  \\n of those calculations that's really easy to do in Pandas.  \\n All you have to do is say .corr.  \\n Now, as I said that it was easy to do,  \\n it looked like it failed.  \\n Turns out that in this case, this is a Pandas 2 update.  \\n Pandas 2 is a little bit more strict  \\n about running operations on columns that aren't numerics.  \\n Let's scroll down to the bottom  \\n and you can see that the error is,  \\n that it says it \\\"could not convert string to float: RL.\\\"  \\n That's a little hard to understand  \\n but basically what this is saying is  \\n that we passed in string columns  \\n and it didn't like doing the calculation on those.  \\n To get around this,  \\n what we're going to do is specify this parameter,  \\n numeric_only=True.  \\n What this returns is a Dataframe.  \\n In the index is all the numeric columns  \\n and in the columns is also all of the numeric columns.  \\n So we see the correlation between each numeric column  \\n and all the other numeric columns.  \\n This is using the Pearson correlation coefficient.  \\n That is a value between -1 and 1.  \\n The closer those values are to 1,  \\n the stronger the positive correlation,  \\n meaning as one value goes up, the other value goes up.  \\n The closer that value is to -1  \\n the more negative the correlation is  \\n meaning as one value goes up, the other value goes down.  \\n If those values are around zero,  \\n that means that there is no correlation.  \\n As one value goes up, the other value might go up or down.  \\n They're not related.  \\n This is another one  \\n of those things that humans aren't optimized for looking at.  \\n I could give you this big table of data and ask you  \\n to find the biggest correlation and the smallest correlation  \\n and it would take a bit of time for you to do that.  \\n I'm going to give you some hints on how to get around that.  \\n Also, note that this is  \\n calculating the Pearson correlation coefficient,  \\n which assumes that there's a linear relationship  \\n between two values,  \\n ie. if you were to do a scatterplot of this,  \\n you should see a line.  \\n It's not always the case that there's linear relationships.  \\n Sometimes you have non-linear relationships.  \\n And you might even have a monotonic relationship  \\n meaning when one value goes up, the other value might go up,  \\n but it might be in a shape that is not a line.  \\n It might be like a logistic curve  \\n where it looks like a stretched out S.  \\n In that case,  \\n we might want to use the Spearman correlation coefficient.  \\n To do that, we specify the parameter, method='spearman'.  \\n And again, I'm going to say, numeric_only=True.  \\n And I'm also going to tack on this background gradient.  \\n Remember, we want to be able  \\n to see what's going on here easily,  \\n and one of the ways we can do that  \\n is leveraging visualization and color.  \\n So by default, when you do the background gradient,  \\n it puts on this blue background gradient  \\n that immediately draws our eyes to the diagonal.  \\n And you can see  \\n that along the diagonal is a correlation of one.  \\n If you look at the diagonal, those are actually  \\n the correlations of one value versus the same value,  \\n meaning that as that value goes up, it goes up.  \\n Which in itself is not a particularly interesting insight  \\n and actually we kind of want to ignore the diagonal values  \\n when we're looking at this,  \\n but you could look off diagonal  \\n and see where the largest correlation is.  \\n Remember, this is a Spearman correlation coefficient  \\n so it's not necessarily  \\n there would be a straight line between those,  \\n but as one value's going up the other value's going up  \\n this makes it relatively easy to see  \\n that, for example, right here or right here,  \\n these are actually the same correlation.  \\n Year remodel or added to against year built.  \\n So as the year built goes up,  \\n also the year that it was remodeled goes up,  \\n and we can scroll through here  \\n to see if we see any others pop up.  \\n Here's one that has a particularly high correlation,  \\n garage year built,  \\n and year built.  \\n The default coloring used by background gradient,  \\n this going from white to blue,  \\n is okay for looking at positive correlations,  \\n but it's actually not great  \\n for looking at negative correlations.  \\n Why is that?  \\n This color map starts at a white value  \\n and it's going to pin the white value, so to speak,  \\n at the smallest negative value.  \\n It looks like, for example, here  \\n it looks like pretty white and it's -0.4.  \\n We actually wouldn't want the smallest value to be -0.4.  \\n We would want it to be -1.  \\n And we actually don't want to use this color map  \\n that goes from white to blue.  \\n We'd want to use a different color map.  \\n So let's see if we can change this  \\n and use a better color map.  \\n I'm going to use this RdBu color map here.  \\n This is a red to blue color map.  \\n It's actually what's called a diverging color map.  \\n It goes from red through white to blue.  \\n And now we can look  \\n at the bluest things and the reddest things.  \\n The bluest things are the most positive  \\n and the reddest are the most negative.  \\n Again, we kind of want to ignore the diagonal.  \\n The diagonal by definition is going to be 1.  \\n So you'd want to look at the bluest off diagonal values  \\n and the reddest off diagonal values.  \\n Again, if you look at these,  \\n the reddest values look to be around -0.4,  \\n which is not what we want.  \\n So I'm going to give you one more hint.  \\n When you use a background gradient  \\n with a correlation heat map,  \\n you're going to want to pin the negative value.  \\n Let me show you how to do that.  \\n You specify vmin as -1.  \\n We can also put in vmax as 1,  \\n although by definition the diagonal will have a value of 1.  \\n And this tells a completely different story.  \\n If we look at this, you can see  \\n that those values around zero are indeed white  \\n which is what we want to see.  \\n Those are the values that don't have a correlation.  \\n We kind of want to ignore those.  \\n In the other examples, those were distracting us.  \\n And we can look  \\n for the reddest values now and the bluest values.  \\n We can still see that that -0.42  \\n looks like it is probably one of the reddest values.  \\n Let's just scroll through this and see.  \\n Here's another one that looks like it's pretty red,  \\n and here's one that is actually very red.  \\n This is an example  \\n of leveraging the power of color and visualization  \\n to help us read a table more effectively.  \\n In this lesson, we looked at correlations.  \\n We saw how we can easily calculate these in Pandas,  \\n and we saw how we can leverage color  \\n to help us understand these correlations  \\n and pull out the interesting values rapidly.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4502194\",\"duration\":457,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Scatter plots\",\"fileName\":\"4433355_en_US_02_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn how to create and interpret scatter plots, which are graphical representations of the relationship between two variables.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15216488,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson,  \\n we're going to look at scatter plots.  \\n Scatter plots are an excellent way  \\n to take two numeric columns  \\n and look at the relationship between those.  \\n I'm also going to give you some tips  \\n on how to make more effective scatter plots.  \\n Again, I think the key to understanding scatter plots  \\n is understanding the interface.  \\n The interface here is a little bit different  \\n than what we saw with bar plots or histograms.  \\n In the case of scatter plots, we are going to call .plot.  \\n And .plot has various methods for plotting on it.  \\n One of them is scatter,  \\n and the parameters that we specify for scatter  \\n include the column that we want in the X-axis  \\n and the column that we want in the Y-axis.  \\n Let's run that, and here's our plot.  \\n So this is the year built versus the overall condition.  \\n We want to see what's going on between these two.  \\n I'm going to calculate the correlation between those  \\n so you get a feel for what this looks like.  \\n We'll take housing.  \\n And I'm going to say pull off year built,  \\n and do a correlation with that with housing,  \\n and then look at overall condition.  \\n So that has a -0.36 correlation, meaning  \\n as one value goes up, the other value goes down slightly.  \\n We can also change this  \\n to a Spearman correlation coefficient  \\n and see if that changes that at all,  \\n and it actually makes it slightly more negative.  \\n So just from looking at this, I wouldn't necessarily say  \\n that as one value goes up, the other value goes down.  \\n So let's see if we can tease apart this plot a little bit.  \\n Let me tell you what I'm seeing when I look at this.  \\n I'm seeing a bunch of layers.  \\n What those layers indicate to me is  \\n that our values have been encoded at a certain granularity.  \\n In this case, this is the overall condition  \\n and these are whole numbers between one and nine.  \\n You can kind of consider these to be categorical in nature  \\n though they're encoded as numbers.  \\n I'm also seeing a bunch of dark values,  \\n and when I see dark values in scatter plots,  \\n that gives me pause.  \\n I'll generally want to use transparency  \\n to see what's going on there.  \\n So let's apply this alpha transparency.  \\n I'm going to pass in transparency of 0.1,  \\n and this tells a different story, I believe,  \\n than what we saw above.  \\n This is telling me that we have a lot of values at five  \\n and some values at six and seven.  \\n We could also look at a histogram of overall condition  \\n to see where those distributions lie,  \\n but we're kind of seeing that here.  \\n Again, compare that to what we saw here.  \\n I would not say that we had the most values  \\n at five just by looking at this,  \\n but when we change that alpha, we're seeing that.  \\n Let me give you a hint on how I like to set alpha.  \\n Let's maybe put alpha at 0.5,  \\n and when I see that there are a bunch of dark values,  \\n and there's still a bunch of dark values,  \\n I'm not seeing a transition around those.  \\n I kind of want to keep going down.  \\n So maybe I'll go down to 0.3.  \\n I can see it, five and six and seven.  \\n There are still a bunch of dark values,  \\n and let's put it down to 0.1.  \\n There I'm seeing that six and seven start to get faded out,  \\n so I think that's okay.  \\n I'm also seeing  \\n So I think this is an okay value for alpha.  \\n Now I still am seeing those flat layers.  \\n How would I deal with that?  \\n I like to use jittering to deal with that.  \\n What is jittering?  \\n Jittering is shifting those values up by a random amount  \\n and I'm going to give you the code to do that right here.  \\n So this example, I'm taking my housing Dataframe  \\n and I'm overriding the overall condition column  \\n by taking the value of the overall condition  \\n and using NumPy to randomly add a value  \\n between zero and 0.8.  \\n And then I'm subtracting 0.4 to that, so I'm centering that.  \\n So this should give us a value  \\n between -0.4 and 0.4 on the positive side, but random.  \\n Now I'm going to plot this new overall condition.  \\n And this is what that looks like.  \\n You might ask why did I choose the value of 0.8 and 0.4?  \\n Well, if you look at the overall condition  \\n the overall condition is a whole numeric value,  \\n and I kind of want to see some segmentation  \\n between the five values and the six values.  \\n So if I would put that value instead of 0.8,  \\n put it up to one, then it would stretch all the way  \\n between one value and the next.  \\n So that leaves a little bit of breathing room between those,  \\n and then I subtract four so that it's centered at the value.  \\n Now, if you look at this,  \\n I think this tells a completely different story  \\n than what we're seeing above.  \\n This is telling me that we have a lot of values  \\n around the year 2000 in the condition five.  \\n Again, let's scroll back up to our original scatter plot  \\n and I don't know that you would've been able to tell that  \\n from looking at the original scatter plot,  \\n but by using some of these tricks  \\n such as adjusting the alpha and jittering,  \\n we are able to have some pretty big insight  \\n into what's going on here.  \\n This also helps us understand  \\n that correlation number that we looked at before.  \\n It looks like if you go from the left to the right  \\n the values are going slightly down, and that's easier to see  \\n after we've applied some of these tricks to our plot.  \\n Again, I'm going to go back  \\n to these traditional software engineering things that I do.  \\n If I want to use jitter in other places,  \\n I'm going to make it into a function  \\n so I can take advantage of it.  \\n In this case,  \\n I'm going to pass in a data frame as the first parameter,  \\n a column that I want to jitter, and the amount.  \\n I'm going to default the amount to 0.5,  \\n but we can bump that up to 0.8,  \\n and then I'll just test that function out here.  \\n Instead of using my code that I've commented out right here,  \\n I'm going to use my jitter function,  \\n and let's see if that works.  \\n Indeed, it looks like it does.  \\n One more way to visualize this  \\n that you get for free in Pandas is to use a hex bin plot.  \\n You can see that this plot's little six-sided figures  \\n and then colors those based  \\n on the number of values that fall into those.  \\n In this case, you can see around the year 2000  \\n the overall condition of five has a concentration of values.  \\n I personally don't like this plot as much  \\n as the scatter plot that I did above,  \\n but this gives you similar insights with very little code.  \\n In this lesson, we looked at creating scatter plots.  \\n Remember, scatter plots are a mechanism  \\n to look at the relationship between two numeric columns.  \\n We also looked at the correlation  \\n which is a quantification of that relationship  \\n and saw that we can explore that quantification  \\n by using a scatter plot,  \\n and adding some tricks on top of those.  \\n So the tricks that I like to use  \\n if I'm seeing that there's just a lot of dark spots,  \\n I'm going to lower the alpha  \\n until I start to see a transition between those spots.  \\n And then if I see things that are stacked  \\n up on top of each other in either columns or rows,  \\n I'm going to use jittering to spread those apart.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4506093\",\"duration\":642,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Visualizing categorical and numerical values\",\"fileName\":\"4433355_en_US_02_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn how to calculate and interpret numerical summaries of data based on categorical variables, such as means or medians of groups.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":24933557,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In our previous lesson, we looked  \\n at comparing two numeric columns to each other,  \\n what happens if you have a numeric column  \\n and a categorical column?  \\n Let's look at how we can visualize and understand those.  \\n We're going to take two columns.  \\n We're going to take year built and overall condition.  \\n Now, both of these are numeric, but I'm going to say  \\n that both of them are also somewhat categorical as well.  \\n Some columns can be both numeric and categorical.  \\n You can think of a year  \\n as a numeric sequence that increases, but you can also think  \\n of events that happened in a year that would be categorical.  \\n Similar with overall condition.  \\n Overall condition is a number that represents the condition  \\n of a house.  \\n You could also think of the condition,  \\n one, being a house that is  \\n in very poor condition and a house that has a condition  \\n of nine to be very good condition.  \\n In this example, let's assume  \\n that year built is a categorical value  \\n and overall condition is numeric.  \\n How could we look at the relationship between those two?  \\n One of the things that we can do is we can use  \\n what's called a box plot.  \\n I'm going to say in the X axis, use the year built column  \\n and in the Y axis use the overall condition column.  \\n We get something that looks like this.  \\n It's a little bit unclear what's going on here.  \\n It says overall condition in the bottom  \\n and then on the left it looks  \\n like we have the condition values from zero to nine.  \\n What is happening?  \\n This is basically taking all of the overall condition values  \\n and plotting a box plot for them.  \\n This isn't doing what we wanted to do, which was look  \\n at the conditions over the different categories of years.  \\n Let's see if we can figure that out here.  \\n I'm going to use some pandas code to manipulate my data.  \\n First of all, let's use what's called a pivot.  \\n You can see that I'm putting the year built  \\n into the column along the top, we have all the year built.  \\n I'm putting the overall condition column into the values  \\n but this is giving us as a data frame  \\n with the same number of rows as the original data  \\n but we see a bunch of missing values here.  \\n That's because this is a sparse data frame.  \\n What I want to do is I want to take those values  \\n for each year and basically push them up along the top  \\n and that's what this next line is going to do.  \\n I'm going to say, let's apply a function here.  \\n The function is going to take the values  \\n that are not missing and keep those in each column  \\n and then I'm going to reset the index and that'll gimme  \\n for every column, the values that are in there.  \\n That's what that looks like.  \\n You can see that all of the values are along the top.  \\n We still have missing values  \\n but those are just padding the bottom  \\n for the values that appear to be the longest,  \\n it looks like 2005 at least has 141 entries.  \\n In this case, when we call .plot.box,  \\n it is going to take each column  \\n and it's going to stick each column in the index  \\n and for each column it's going to take the values  \\n in that column and do a box plot.  \\n In my opinion, the key  \\n to plotting in pandas is understanding how pandas moves  \\n from a data frame into a plot and it's not always the same.  \\n Here's the output of that.  \\n I don't think this plot is particularly useful.  \\n There's too much information going on here.  \\n It's hard to even read the X axis.  \\n What would I do to this?  \\n I would limit it to a certain number of years  \\n or I would bin years maybe into decades.  \\n Here's a chain.  \\n Let's walk through this chain and see what's going on here.  \\n Here's our pivot, which looks like what we had before.  \\n I'm going to do my apply, which is going to again,  \\n move the values up to the top, and instead  \\n of having almost 3000 rows, now we have 142 rows  \\n and now I'm going to use loc to filter out rows and columns.  \\n Loc allows us to specify rows  \\n that we want to pull out and columns that we want to pull out.  \\n In this case, this colon here is the row selector.  \\n If you just put a bare colon in the row selector,  \\n it is going to take all of the rows.  \\n So then we have a comma,  \\n that comma separates the row selector  \\n from the column selector.  \\n Here is the column selector.  \\n It looks like we're just going to take the years  \\n 1900, 1920, 1940, 1960, 1980, and 2000.  \\n so at this point we can do our box plot on that  \\n and there are the box plots for those specific years.  \\n To me, it looks like this is saying the condition  \\n of the median house tends to go down over time slightly.  \\n Recall that this is only looking  \\n at the values from those specific years.  \\n Maybe we want to group by decade.  \\n Let's see how we could do that.  \\n I've got a chain that will do that.  \\n Let's walk through this chain.  \\n I've said this previously, but once you understand  \\n that pandas is basically a toolbox for manipulating data,  \\n if you can get your data into the specified forms  \\n by making these chains, that will give you super powers.  \\n Let's look at what this chain is doing.  \\n It is making a new column called decade.  \\n How are we calculating that?  \\n We're taking the year built column  \\n and we're doing an integer or a floor division by 10  \\n and then we're multiplying that by 10,  \\n so if I do a floor division,  \\n let me show you an example of that,  \\n I'm going to do 2006 and then I'm going to do double divide 10  \\n and that gives me 200.  \\n If I just do divide 10, that's going to gimme 200.6,  \\n so this is called floor division or integer division.  \\n If I did 1993, 10, that should give me 199  \\n and then I'm just multiplying  \\n so this is giving us every decade.  \\n Again, we can scroll over and just validate that that works.  \\n Can see that the decades are all multiples of 10.  \\n Now that we have that we can group by the decade  \\n and get summary statistics for each of those decades.  \\n Now that we have that, we can pivot by decade.  \\n I'm going to put the decade into the columns  \\n and we get values that look like this.  \\n This is what we had before.  \\n We're going to push those values up using the same code  \\n that we had before  \\n and now we're going to do our box plot with that,  \\n there we go  \\n and it looks like we're seeing that same thing  \\n that the condition of the house goes down over time.  \\n I'm not a subject matter expert in this dataset.  \\n This might indicate that people  \\n with old houses take good care of them.  \\n Maybe they're antiques.  \\n Maybe the new houses are not up  \\n to par compared to ones that are built in the past.  \\n It is interesting to see this.  \\n I would naively expect the opposite,  \\n that the overall condition  \\n of a newer house would be better than an older house.  \\n I've given you a bunch of tools leveraging pandas  \\n to group by category and look at numeric values.  \\n Let's see if we can use that using some other tools.  \\n I'm going to use the Seaborn library.  \\n If you're not familiar with the Seaborne library,  \\n it is a library that is built on top  \\n of mapplotlib and pandas for doing statistical plotting  \\n and we can say, let's do a box plot.  \\n Here's our data and here's the column, in the X,  \\n we want year built in Y, we want the overall condition.  \\n This allows us to get that plot that we got earlier  \\n but in one line of code.  \\n Again, is this plot useful?  \\n I don't think it's particularly useful.  \\n There's too much going on here.  \\n You can pull the documentation for this  \\n by just putting a question mark on here.  \\n There's actually a lot of documentation  \\n and we're going to use the order here  \\n to filter what is going on with the years.  \\n You can come down here and look at the output.  \\n Right now it's truncated  \\n but the order allows you to specify which things you want  \\n in the X axis.  \\n I'm going to specify a subset of those years.  \\n Let's run this again  \\n and now you can see a box plot for each of those years.  \\n Note that this is not doing any grouping.  \\n This is just pulling  \\n off the values that happened at those years.  \\n A trick that Seaborn has up its sleeve is it  \\n has other plots that you can do as well.  \\n One of those is the violin plot  \\n And this has the same interface as our box plot above.  \\n This is basically doing a kernel density estimation  \\n and flipping it on its side  \\n and putting another one that's mirrored on the other side  \\n of it, so you can see that, for example, there are a bunch  \\n of values here around six or seven for 1940.  \\n For 1900, there are a bunch of values around eight.  \\n Another plot that you might want to make is a boxen plot.  \\n This is a more modern box plot.  \\n In this case, it is showing you a big rectangle.  \\n The big rectangle is between the 25th percentile  \\n at the bottom and the 75th percentile at the top.  \\n The line in the middle is the 50th percentile or the median.  \\n This next rectangle down below here is  \\n from the 25th percentile to halfway between that and zero  \\n so this would be the 12.5 percentile  \\n and basically these diamonds are outliers, above that.  \\n Oftentimes you'll see another rectangle  \\n and another rectangle beyond that.  \\n In this case, it looks like the 12.5  \\n and in this case this is the 75th, and this is halfway  \\n between the 75th and the 100th, so that would be 87.5.  \\n Most of the values in this year, 1920,  \\n are between 12.5 and 87.5.  \\n You can see for 1900, most of the values lie  \\n between the 25th percentile and the 75th percentile.  \\n In this lesson,  \\n I gave you a bunch of tools that you can use  \\n to compare numeric values by category.  \\n Again, once you start understanding how to leverage pandas  \\n and these techniques in pandas,  \\n those are going to be nice tools  \\n in your tool belt to do some very powerful operations.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4506092\",\"duration\":362,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Comparing two categoricals\",\"fileName\":\"4433355_en_US_02_07_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13220169,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson, we are going to look  \\n at how you might take two categorical columns  \\n and compare them and understand  \\n the relationship between them.  \\n Generally we're going to want to use  \\n some sort of cross-tabulation.  \\n We can also do a visualization, a bar plot,  \\n or a stacked bar plot On top of that.  \\n Let's look at some of our dtypes here.  \\n We can see that we have a bunch of categorical values.  \\n Let's pick some of them.  \\n So I'm going to pick the Overall Quality  \\n and the Basement Condition.  \\n Generally when you compare these,  \\n you want to make what's called a cross-tabulation.  \\n For each category in one column,  \\n you want to count  \\n the number of categories from another column  \\n and you make a matrix of the result.  \\n This is how we do this in Pandas.  \\n Here's our original data.  \\n We're going to group by the two columns  \\n that we want the tabulation for.  \\n Pandas is lazy, when you do a groupby,  \\n it does not calculate anything.  \\n So let's do an aggregation to make it run a calculation.  \\n We're going to say size.  \\n Let's look at the output of this.  \\n This gives us a series  \\n and this is a series that has what's called a multi-index  \\n or a hierarchical index.  \\n In the left-hand side,  \\n we see Overall Qual and Basement Condition.  \\n Those are both in the index,  \\n so there are actually two indexes here.  \\n And then zero, zero, zero, three on the right,  \\n that's the values in the series.  \\n What I'm going to do now is a pretty powerful  \\n and sometimes confusing operation,  \\n I'm going to call unstack.  \\n What this is going to do is it's going to take  \\n that Basement Condition index.  \\n It's going to rotate it, pull it out,  \\n and put it in the columns  \\n so every value from Basement Condition  \\n will be a unique column.  \\n Let's run that and see what happens.  \\n Look at that, and here is our cross-tabulation.  \\n We have all of the Overall Quality values in the index  \\n and we have all of the Basement Conditions in the column.  \\n Because this is a common operation,  \\n Pandas actually gives this to us for free  \\n with the crosstab function.  \\n We can call crosstab  \\n and say in the index I want the Overall Quality column  \\n and in the columns I want the Basement Condition column.  \\n You can see that this is the same result  \\n that we see up above,  \\n but it's one line of code  \\n versus those four lines of code up there.  \\n I show you this because again, I think it's useful  \\n to have these powers to understand grouping,  \\n to understand size and unstack.  \\n Even though crosstab will give all of these to you for free,  \\n sometimes you do want to do these grouped by operations.  \\n Going back to what we've said previously,  \\n humans aren't great at looking at tables of data.  \\n This is a table of data.  \\n So generally if you have a table of data,  \\n you want to visualize it if you can  \\n or filter out the pieces of information  \\n that are useful in it.  \\n In this case, we're going to use style  \\n and background gradient to color it.  \\n I'm going to use a color map called Viridis  \\n which is a transitional color map.  \\n It goes from purple to yellow,  \\n passing through blue and green along the way.  \\n This tells us that we have a bunch of entries  \\n with Overall Quality of five  \\n and Basement Condition TA.  \\n So again, if we want to pull up the documentation,  \\n we can stick a question mark after background gradient  \\n and one of the things that you might want to do  \\n is figure out how it's doing this coloring here,  \\n and there is an access parameter here  \\n which determines how it calculates the color.  \\n Is it doing it by row, by column,  \\n or by everything in there?  \\n So you can pull up the documentation for that.  \\n Basically if you say axis is None,  \\n that's going to color by everything in the data frame.  \\n I'm also going to use loc here to reorder my columns.  \\n Note that these condition columns have a meaning.  \\n Ex means excellent, Gd means good.  \\n TA means typical, FA means fair,  \\n and PO means poor.  \\n So I'm going to order these from best to worst.  \\n I also have Missing and NA at the end here.  \\n Let's run this now  \\n and this tells us a little bit different story,  \\n that we have a bunch of values here  \\n that are in this typical value in the middle here.  \\n Another way to visualize this is to do a bar plot.  \\n I'm going to do a stacked bar plot.  \\n This is taking the results of my cross-tabulation  \\n and I'm going to say do a bar plot  \\n but stacked is equal to true.  \\n So let me walk you through what Pandas does  \\n when you do a bar plot.  \\n Again, it's going to take the index  \\n and it's going to put the index in the x-axis.  \\n In this case, the overall condition.  \\n We have multiple columns here  \\n so generally when we do a plot,  \\n it's going to plot each of those values above the index.  \\n So let's look at what  \\n it would normally look like, something like that.  \\n I'm going to say stack this  \\n and it's going to stack those values on top of each other.  \\n In this case, this is allowing us to see  \\n that for Overall Quality five, six, seven, and eight,  \\n we have a lot of TA entries.  \\n We can easily visualize that by looking at this plot.  \\n In this lesson, we looked at taking two categorical values  \\n and understanding how we can summarize those.  \\n Generally if we do that with a cross-tabulation,  \\n we said that a cross-tabulation is a table of data.  \\n We can use our techniques for visualization  \\n to understand that table better  \\n by either coloring the values in there  \\n or actually making a bar plot.  \\n Using a stacked bar plot  \\n is one way to understand a cross-tabulation.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4503098\",\"duration\":27,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Explore Ames\",\"fileName\":\"4433355_en_US_02_08_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":753160,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (electronic music)  \\n - [Instructor] It's time for our next challenge.  \\n In this challenge,  \\n of the first floor square footage against the sell price.  \\n We want to see what that relationship is between the size  \\n of the house and how much the house sold for.  \\n You might consider using some  \\n of the tricks that we talked about  \\n as we visualize the scatter plot.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4507090\",\"duration\":208,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Explore Ames\",\"fileName\":\"4433355_en_US_02_09_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6756332,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] Let's look at the solution for this.  \\n I'm going to take my housing data set.  \\n I'm going to call .plot.scatter,  \\n and let's choose to put SalePrice in the X axis,  \\n and we're going to put first floor square footage  \\n in the Y axis.  \\n Let's run that and see what it looks like.  \\n We get something that looks like this.  \\n So my first thought when seeing this is it looks like  \\n as sell price goes up, first floor square footage goes up.  \\n Also, it looks like there's a hard line here along  \\n the bottom edge, which looks like  \\n there's some relationship going on there  \\n that you can't have a house  \\n that is very small going for a high price.  \\n It looks like we're not really seeing that.  \\n There are some outliers here  \\n where we are seeing large houses that are cheap.  \\n It'd be interesting to know what's going on  \\n with these outliers that are sort of out here.  \\n It looks like there's a cone where most of the values lie.  \\n Now, another thought that I have, when I'm looking at this,  \\n I'm not seeing columns or rows necessarily,  \\n but I am seeing a big dark patch,  \\n and I don't like to see big dark patches in a scatterplot.  \\n Remember, one of the things I said you could do  \\n is adjust the alpha.  \\n Another thing you can do is if you have too much data,  \\n and you just keep lowering that alpha,  \\n but you're not seeing transparency  \\n is to come in here and do samples.  \\n We could say, let's look at maybe 300  \\n of those entries and see what's going on here.  \\n That might be another way to see where the majority  \\n of the data is lying.  \\n However, I'm going to go and use our alpha,  \\n and I'll start off by setting that .5.  \\n That looks okay.  \\n It's telling a different story,  \\n but you can see down here it's just completely dark.  \\n I don't like to see it completely dark.  \\n I like to see some transition in there.  \\n Let's go down to .2.  \\n I think that's looking better.  \\n I might even go down to .1,  \\n and I think that tells a different story.  \\n This is actually fascinating, if you look at this.  \\n I'm maybe going to try a little bit lower here.  \\n Okay, and I'm seeing like a cluster of data here,  \\n but I'm also seeing a cluster down here below that,  \\n which is kind of interesting.  \\n It looks like there's a pattern up here,  \\n and there's another pattern up here.  \\n This looks to me like there is a bunch of houses  \\n that for some given size are less expensive,  \\n and then there's a cluster of houses  \\n for the same size that are more expensive.  \\n Might be interesting to see what's going on there.  \\n Is that a different neighborhood?  \\n Are these built in different years?  \\n These are the the sorts  \\n of ideas I have when I see a scatterplot like this,  \\n and note that if I don't adjust that alpha,  \\n I'm not going to have that insight here.  \\n I don't see that at all  \\n if I leave the alpha as the default value.  \\n I hope this was useful to you.  \\n In this example, I showed you how to plot a scatter plot  \\n and how to adjust the alpha to see some patterns  \\n that aren't apparent with the default scatter plot.  \\n \\n\\n\"}],\"name\":\"2. Exploring and Visualizing\",\"size\":119687113,\"urn\":\"urn:li:learningContentChapter:4507092\"},{\"duration\":1880,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4503097\",\"duration\":441,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Linear regression\",\"fileName\":\"4433355_en_US_03_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Linear regression is commonly used in data analysis and can help you identify significant predictors of a target variable, as well as their effect size and direction.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16203969,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson,  \\n we're going to look at linear regression.  \\n The goal of linear regression is to take data  \\n and predict numeric values from that.  \\n So we're going to take our housing data  \\n and we're going to see if we can predict the sales price  \\n given the other numeric values from that.  \\n I'm going to show you how to do that using Python  \\n and we're going to talk about splitting your data  \\n into a training set and testing set  \\n and evaluating how your model performs.  \\n We're going to be using the scikit-learn library.  \\n The scikit-learn library is a library  \\n that's very popular in academia,  \\n but it's also popular in industry.  \\n One of the nice things about the scikit-learn model  \\n is that it has a common interface.  \\n That common interface makes it very easy  \\n to try out different models.  \\n We're going to be looking at linear regression here,  \\n but we'll also be looking at some other types  \\n of models that can perform regression analysis.  \\n And because they conform to the scikit-learn API,  \\n it's very easy to swap them out  \\n and see how they perform.  \\n In order to run a model,  \\n we have to make two datasets.  \\n One is typically referred to as capital X  \\n and that is a matrix of data.  \\n Generally, it can be a Pandas DataFrame.  \\n And if you look at our X here,  \\n we are saying, okay, take our housing data  \\n and then pull off the numeric columns  \\n and also drop the sales price column.  \\n Remember, we're going to try  \\n This X is the features or the columns  \\n that we're going to try  \\n and use to predict sales price.  \\n So keeping sales price in there would be cheating  \\n if we're training the model with the sales price  \\n and asking it to predict the sales price.  \\n Then the other data set that we need  \\n is the target that we want.  \\n In this case, it is the SalePrice column.  \\n I'm going to use a function  \\n from scikit-learn called train_test_split.  \\n And what that's going to do is,  \\n it's going to take our X  \\n and our Y data and split it up.  \\n We're going to split it up  \\n into a training set and a testing set.  \\n This is very important to do  \\n when you're using machine learning.  \\n The reason is you want to understand  \\n how your model performs.  \\n And if you evaluate your model on data  \\n that's seen before, it's pretty trivial  \\n to make a model that can perform very well  \\n on data that's seen before.  \\n All it has to do is memorize that data.  \\n So we're going to hold out some of our data  \\n and that's what train_test_split does.  \\n The output of train_test_split is four things.  \\n It's the X training data, the X testing data,  \\n the Y training data, and the Y testing data.  \\n Let's run this code and make sure that it works.  \\n Looks like it did work.  \\n Let's look at what X_train looks like after running that.  \\n Here is X_train.  \\n If you look at the index on the left side,  \\n you can see that it's not sequential.  \\n What this has done is randomly pulled out  \\n different rows to train our model on.  \\n If we looked at the X_test data,  \\n it would be the data  \\n that is not in the training data.  \\n The remaining rows in there.  \\n Here's the Y training data.  \\n And you can see that the index for y_train  \\n is actually the same as the index for X_train.  \\n However, this is a series.  \\n Remember, in scikit-learn,  \\n our X is going to be a data frame  \\n and you can have a data frame with one column.  \\n But generally, data frames have multiple columns,  \\n but a series is only a single column.  \\n These are the values that we want to predict.  \\n Here is how we make our model.  \\n We're first going to say linear_model.LinearRegression.  \\n This makes an instance of the model.  \\n And then training the model is one line of code.  \\n It's calling lr.fit.  \\n We pass in the training data with the training label.  \\n In this case, it's y_train.  \\n And then the next line is a mechanism  \\n to score our data and see how it scores.  \\n And we're going to pass in X_test and y_test.  \\n And when we run this, it actually does not work.  \\n Let's look at our error and see what happens.  \\n And we got a value error.  \\n It says the \\\"Input X contains NaN.\\\"  \\n And if you remember,  \\n we had a bunch of missing data in there.  \\n It turns out that linear regression  \\n does not like missing data.  \\n In fact, if you have missing values  \\n in your data, it will not work.  \\n Let's just double-check to see  \\n if there is missing data in there.  \\n And it looks like, for example,  \\n in Lot Frontage, there's missing data  \\n and a bunch of other columns have missing data as well.  \\n We talked a little bit  \\n about handling missing data previously.  \\n Again, my recommendation is to find an expert  \\n to understand why the data might be missing.  \\n That expert might be able to guide you  \\n into appropriate actions to deal with the missing data.  \\n In our case, I'm going to make  \\n this new function called clean_housing_no_na.  \\n And if you look at that,  \\n what that's going to do is,  \\n it's going to add in this extra line  \\n into our chain here that's going to say,  \\n take the current state of the data frame  \\n after shrinking the integers,  \\n and pull off the numeric types,  \\n fill in the missing values with zero,  \\n and stick that back into your data frame.  \\n So housing2 after running this should have a bunch  \\n of zeros instead of missing numbers.  \\n Now, let me make an assign here.  \\n Is this the right thing to do?  \\n I'll say, probably not.  \\n We could have a whole course  \\n that talks about filling in missing values.  \\n For the purposes of this course,  \\n I'm introducing linear regression  \\n and not talking about all the ins and outs  \\n about filling in missing values.  \\n Let's, again, split our data  \\n and now let's run our model.  \\n And it looks like we get a score of 0.84.  \\n So the score that comes out of this  \\n is often called the R2 or R squared score  \\n or the coefficient of determination.  \\n This is a value between zero, typically, and one.  \\n The closer this is to one,  \\n the better the model is.  \\n What this represents is the amount of variance  \\n in the label or target that is explained  \\n by the features or columns in the data.  \\n So 84% of the variance in the label  \\n that we're trying to predict  \\n or that sales price is predicted  \\n by the data that we're passing into this.  \\n If we had another model that had a score of 0.9,  \\n that would be a better model.  \\n If we had a model that scored 0.8,  \\n that would be a worse performing model.  \\n Question people often asks,  \\n is 0.84 good enough or is your score good enough?  \\n And the answer to this is, typically,  \\n an unsatisfying it depends.  \\n It might be good enough, it might not be.  \\n Further analysis and understanding  \\n what the predictions often mean  \\n and how far off they are can often tell you  \\n from a business context  \\n whether it would make sense to deploy a model or not.  \\n We can have a whole class on linear regression.  \\n For the purposes of this class, we're introducing it.  \\n In this lesson, we created a linear regression model.  \\n We were able to predict the sales price  \\n from the training data  \\n from the other numeric columns in our dataset  \\n and we saw that we got a score  \\n of 0.84 when we did that.  \\n We also saw that linear regression  \\n did not like it if we had missing values.  \\n So we took a shortcut.  \\n We filled in those missing values with zero.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4504090\",\"duration\":260,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Interpreting linear regression models\",\"fileName\":\"4433355_en_US_03_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"By interpreting the coefficients, you can understand the magnitude and direction of the effect of each independent variable on the dependent variable.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9957878,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We just made a linear regression model.  \\n Now we want to try and understand what's going on  \\n with the model.  \\n Let me tell you about a convention in scikit-learn.  \\n Again, scikit-learn is full of conventions.  \\n Once you understand these conventions,  \\n it makes it really easy to use the model,  \\n and it also includes a bunch of different models,  \\n so it makes it easy to try out different models  \\n and see how they perform.  \\n One of the conventions in scikit-learn  \\n is that if an attribute ends in underscore,  \\n it was an attribute that was discovered  \\n or learned by fitting the model.  \\n In this case, our linear regression model  \\n has an attribute called coef_.  \\n This attribute represents the coefficients.  \\n If you have taken a math class,  \\n you might have learned about the formula for a line,  \\n y is equal to mx+b,  \\n where m is the slope, and b is the intercept.  \\n It turns out that linear regression has the same thing.  \\n The coefficient is called the slope,  \\n and the intercept is the intercept.  \\n And this coefficient represents the weights  \\n that are multiplied by each of the values in the columns  \\n to make the prediction.  \\n We also have lr.intercept_,  \\n and this is the base value.  \\n In this case, this is saying that our housing value  \\n starts at it looks like $15 million.  \\n To create a prediction,  \\n we add up the intercept value  \\n with the linear combination of the coefficient,  \\n with the values from each corresponding column.  \\n That will give us what the prediction is.  \\n (typing)  \\n Here are the column names  \\n that correspond with those coefficients.  \\n We can stick those into a panda series.  \\n At this point, we can take this panda series and plot it.  \\n So we're going to do a bar plot with this.  \\n And if you look at this bar plot,  \\n what this is telling us  \\n is this is telling us the weights  \\n that impact the model the most.  \\n In this case, it is saying overall quality  \\n pushes the model towards a more positive price,  \\n and kitchen above ground pushes the model  \\n towards a more negative price, as that increases.  \\n You can see in the middle here,  \\n there are a bunch of the features or columns  \\n that have a small value.  \\n These columns are features that don't have a large impact  \\n on the output of the model.  \\n What I'm going to do is use some pandas code  \\n to just do a little bit of filtering here.  \\n So we're going to start off with our series  \\n of the coefficients,  \\n and then I'm going to use this pipe here  \\n to just get the values that have an absolute value  \\n of greater than 100, and we'll do a bar plot of that.  \\n So these are the coefficients  \\n that tend to have the most impact on our model.  \\n One of the nice things about coefficients  \\n is that they have both a magnitude and a sign.  \\n So again, if that sign is positive,  \\n if that value goes up,  \\n it tends to push the value of the final prediction up.  \\n If the sign is negative, if that value would go up,  \\n it would push the result down.  \\n In this cell, I'm pulling off the features  \\n that have the most impact on the model.  \\n It turns out that we might want to use these later on,  \\n and pull those out.  \\n You just pull off the index from the series.  \\n In this lesson, we looked at understanding a model.  \\n One of the nice things about a linear regression model  \\n is that it's completely explainable.  \\n What do I mean by that?  \\n I mean that you can take this intercept value,  \\n and you can take the labels  \\n that are passed into the model to make a prediction,  \\n multiply them by these coefficients,  \\n and if you sum those up,  \\n you get the prediction from the model.  \\n This turns out to be a nice feature  \\n that you can interpret the model.  \\n You can understand why it's making the predictions it has.  \\n Also, you can look at the magnitudes of these coefficients.  \\n The larger the magnitude of them,  \\n the more impact they have on the model.  \\n The coefficients that have a small magnitude  \\n mean that the feature is not having as much impact  \\n on the final prediction.  \\n In future lesson, we'll look at different models  \\n and compare and contrast those with linear regression.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4508090\",\"duration\":382,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Standardizing values\",\"fileName\":\"4433355_en_US_03_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The goal of this video is to learn how to standardize variables, which involves transforming variables to have a mean of zero and a standard deviation of one.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":18358621,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson, we're going to look at  \\n standardizing values.  \\n We're going to talk first about what this concept  \\n of standardization means,  \\n and then we'll learn how to do this from scikit-learn.  \\n Again, once you understand the conventions of scikit-learn,  \\n this is not particularly hard.  \\n And then we'll look and see if this impacts our score.  \\n We're also going to reexamine our coefficients  \\n after doing that and see if those change as well.  \\n So standardization has a specific meaning to statisticians.  \\n And oftentimes, people say normalize,  \\n and when they say normalize, they mean standardization.  \\n What standardization means  \\n is that we're going to take our X or our dataframe  \\n and we're going to basically collapse the values  \\n or shrink them into a given range  \\n or maybe expand them into a given range and center them.  \\n More specifically,  \\n it means we give each column a mean value of zero  \\n and the standard deviation of one.  \\n Why is that?  \\n You could imagine that certain models  \\n are impacted by the scale of the data.  \\n And if you have a housing model that's predicting price,  \\n it might have one column  \\n that represents the number of bathrooms in a house,  \\n which might be like from one to five bathrooms,  \\n might be the maximum in a house.  \\n You might have another column  \\n that represents the square footage,  \\n which might be from like 200 for a mini house  \\n up to like 20,000 for a mansion.  \\n The scale of the 20,000,  \\n that's a couple order of magnitudes bigger  \\n than the number of bathrooms.  \\n And certain algorithms  \\n are impacted by the relationship  \\n between the magnitude of the columns.  \\n One of the ways to do that is using standardization.  \\n Let's look at how to do this using scikit-learn.  \\n There is a pre-processing module in scikit-learn.  \\n And you can make an instance of the pre-processing module.  \\n A StandardScaler is a transformer in scikit-learn.  \\n That means that it has at least two methods.  \\n One is fit and the other is transform.  \\n In the case of the training data,  \\n we're actually going to call fit_transform,  \\n which combines fitting and transforming.  \\n So fit trains the model,  \\n and then transform takes input  \\n and transforms the input to a given output.  \\n In the case of a StandardScaler,  \\n it takes data after it's been trained,  \\n the training tells the model, \\\"Hey,  \\n this column should have a mean value of this  \\n and this column should have a mean value of this,\\\"  \\n and it knows how to shrink and move those means around.  \\n And then the transform actually does that transform for you.  \\n So here we're going to call fit_transform  \\n on the training data.  \\n This gives us a new X_train.  \\n And then on the testing data, we have to be careful here.  \\n We don't want to call fit again on the testing data,  \\n we just want to call transform on the testing data.  \\n So, once we've made a model,  \\n we want to evaluate it on data that it hasn't seen before.  \\n If we retrain the model,  \\n call fit on data that it hasn't seen before,  \\n we're kind of cheating.  \\n So we want to make sure that we only call transform  \\n on that testing data.  \\n Let's run that and make sure that it works.  \\n It looks like it did.  \\n Let's run our model now  \\n with our new data that's been standardized.  \\n And it looks like in this case, we get the same score.  \\n So our score did not particularly change by doing that.  \\n Let's look at our coefficients.  \\n And it looks like our coefficients  \\n are actually different now.  \\n I'm going to sort the values of our coefficients.  \\n You can see that we have some coefficients  \\n that are pretty negative  \\n and some other coefficients that are pretty positive.  \\n A couple of orders of magnitude above the others.  \\n Let's do a bar plot there with some filtering  \\n just to zoom in on those.  \\n And it looks like we have basement square footage,  \\n basement unfinished square footage,  \\n ground living area, basement square footage 2.  \\n It looks like a lot of the features that impact our model  \\n are square footage features, or how big the house is.  \\n And intuitively, it makes sense that square footage  \\n would be one factor that determines  \\n how much a house sells for.  \\n And if we want to pull those values off of the index,  \\n we can.  \\n In this, I'm looking at the union of the features  \\n from our model that we had not standardized  \\n and the data that we did standardize here below.  \\n Let's look at the correlations between those  \\n and just see if there happened to be some correlations  \\n between all of these features  \\n that tended to be important in these two models.  \\n Again, I'm going to set a background gradient  \\n to this diverging color map.  \\n Red going through white to blue.  \\n And I'm also going to pin that negative value to -1.  \\n So we can look at the redest values  \\n and the bluest values here.  \\n So we do find some blue values that are off diagonal.  \\n That's because I filtered the columns here.  \\n So the diagonal here is not necessarily  \\n going to be the values that are one.  \\n But we can see the overall quality  \\n has a pretty high correlation with sell price,  \\n as does year built, year remodeled.  \\n Here I'll just scroll this over  \\n and look at the correlations there.  \\n You can see the garage area, wooden deck square footage,  \\n open porch square footage  \\n have a slightly positive correlation with our sell price.  \\n In this lesson, we looked at standardizing our data.  \\n Generally, you will want to standardize your data  \\n when you're doing linear regression.  \\n We saw in our model that performing standardization  \\n did not impact this model, but that's not always the case.  \\n It is possible that standardizing your variables  \\n can have a significant impact  \\n on how your model performs.  \\n We did see that it actually changed the coefficients.  \\n And we had different coefficients emerging  \\n as more important when we standardized our data.  \\n In the next lesson, we'll look at using other models,  \\n and we'll see how other models perform  \\n to our linear regression model.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4509081\",\"duration\":522,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Regression with XGBoost\",\"fileName\":\"4433355_en_US_03_04_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"The goal of this video is to learn how to build and interpret a regression model using XGBoost, which is a popular algorithm for gradient boosting.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":19400016,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson,  \\n we're going to use a very popular library called XGBoost  \\n to make a regression model as well.  \\n We're going to compare and contrast the performance  \\n and the interpretability of XGBoost with linear regression.  \\n Let me quickly explain what XGBoost does.  \\n It makes a decision tree to make predictions  \\n and those predictions, in this case,  \\n the price of the house are probably going to be off  \\n from the actual values.  \\n So the boosting comes from making subsequent trees  \\n and the subsequent trees take that same input  \\n and try and fix the error.  \\n The error is called the residual.  \\n And you can add as many trees as you want.  \\n Each of those trees keeps fixing that error.  \\n I like to compare this to golfing.  \\n When you golf generally you don't just hit the ball once.  \\n You have multiple times to hit the ball  \\n and that's what this is doing.  \\n The first tree hits the ball, so to speak.  \\n It's not going to go in the hole probably.  \\n It'll be away from the hole by some amount,  \\n there'll be some residual  \\n and then the next tree will basically take a new club  \\n and hit the ball from there and try and fix the error,  \\n get it closer to the hole, so to speak.  \\n So this is like golfing and having multiple times  \\n to hit the ball to get it in the hole.  \\n That's a good analogy for XGBoost.  \\n Now, one of the nice things about XGBoost  \\n is that it uses the same interface,  \\n that scikit-learn interface.  \\n So if you have data that works in scikit-learn  \\n you can easily use XGBoost and make a model.  \\n One of the downsides of XGBoost  \\n is that it is not completely interpretable.  \\n That is to say with linear regression,  \\n we could look at the intercept  \\n and we could look at that coefficient  \\n and we could explain how the model is working.  \\n With XGBoost, it's a little bit more difficult.  \\n We have a bunch of decision trees  \\n and you could have hundreds of decision trees  \\n and going through each of those decision trees  \\n and looking at how they sum up at the end  \\n could be a little tedious.  \\n You could do it if you wanted to, but in practice  \\n no one does because it's too much work.  \\n Okay, one more thing that's useful about XGBoost  \\n is that you don't have to clean up missing values.  \\n In fact, it will work with columns that have missing values.  \\n In addition, XGBoost will also work with columns  \\n that are not numeric.  \\n So this gives it a lot of power.  \\n You can take your data and without doing a ton  \\n of pre-processing, you can throw it into an XGBoost model.  \\n It also doesn't even require your data to be standardized.  \\n So this makes XGBoost a nice model to try out  \\n and see how it performs.  \\n Here, I'm going to make x and y.  \\n Note that I am not filling in my missing values with zero,  \\n I'm just leaving those missing,  \\n and then I'm going to split my data.  \\n In this case, I will standardize it.  \\n It turns out that standardization does not  \\n impact XGBoost model one way or the other.  \\n It will perform the same because  \\n if you think about how a decision tree is working,  \\n it's looking at a single column,  \\n it's not comparing one column to another,  \\n and so that relative size of the columns  \\n is not really important for a tree based model.  \\n Let's run that.  \\n Okay, it looks like that worked  \\n and we're going to come down here and make our model.  \\n Now look at this.  \\n This looks almost identical to what we had above  \\n when we made our linear regression model.  \\n We made an instance of the model.  \\n In this case, we're making an XGBoost regressor  \\n and then we called our fit with the training data  \\n and we called score with the testing data.  \\n Again, one of the nice things  \\n about scikit-learn is that it has a common interface  \\n and there are many models that have that interface.  \\n Look at this.  \\n Our score here of our XGBoost model is 0.89.  \\n So this is a better model,  \\n or it performs better than our linear regression model.  \\n A question you might ask yourself  \\n is 0.89 a sufficiently good model?  \\n And that's a different answer.  \\n The answer again, is this unsatisfying, it depends.  \\n It is a better model than linear regression  \\n in that it performs better,  \\n but we don't know if that performance  \\n is sufficiently good enough  \\n to impact our business.  \\n That would require us diving into how far  \\n off the predictions are and if we would make  \\n or save money by leveraging that model.  \\n Note that XGBoost has an attribute called  \\n feature_importances_ that is learned by doing the fit here.  \\n This is like the coefficients  \\n but it's a little bit different.  \\n It doesn't have a direction, it only has a size.  \\n So in this case, it is saying that the feature  \\n that impacted our model the most was the overall quality.  \\n After that, it was the garage cars.  \\n And at a high level what's going on here,  \\n you can think we have a bunch of trees.  \\n The features that are at the top of the trees  \\n where it makes those decisions  \\n tend to be the most important features.  \\n So this is basically a way of measuring which features  \\n come at the top of the trees.  \\n You can see that there are some of these features  \\n at the bottom that have very low scores,  \\n meaning that those features don't really impact  \\n or drive the model too much.  \\n In fact, we could probably make a semi-decent model  \\n just by looking at the overall quality,  \\n how big the garage is,  \\n the number of baths, and the living area.  \\n In this example, I'm going to use categories  \\n in my XGBoost model.  \\n One of the things about our XGBoost model  \\n is that our XGBoost model doesn't like the pyarrow types.  \\n So I've got a chain here.  \\n I am selecting the numeric values.  \\n These are the pyarrow numbers  \\n and I'm converting these to N64s.  \\n These are the pandas values that XGBoost is okay with  \\n and I'm also dropping the sales price column.  \\n Note that I did not remove the categorical values,  \\n like I did with the other examples here.  \\n Then I'm going to split my data again  \\n and I'm going to say XGBoost Regressor.  \\n I'm going to say enable categorical is true,  \\n telling it I want categoricals to work in here.  \\n And then if I want categoricals to work  \\n I also have to say that the tree method  \\n which is the way that XGBoost makes the trees  \\n is this string hist.  \\n And let's just run that.  \\n When you run that calling fit and score  \\n we see that we got a model of 0.91.  \\n So remember we went from 0.84 with linear regression  \\n to 0.89 with XGBoost with the numbers  \\n to 0.91 with XGBoost with the categories.  \\n So we do get a boost from using those categories  \\n indicating that those categories might be important.  \\n So let's ask XGBoost  \\n what are the important features of the categorical model?  \\n And it looks like the first categorical model  \\n that I'm seeing is neighborhood.  \\n If you remember back in our scatter plot  \\n we had it looks like two clusters.  \\n The neighborhood might have explained that.  \\n It might have been a fancier neighborhood  \\n that costs more for the same size house.  \\n So we are probably seeing that there is value  \\n including that neighborhood categorical into our model.  \\n Further exploration would be useful  \\n in validating that theory.  \\n In this lesson, we looked at using XGBoost,  \\n a popular library, to make our regression model.  \\n We saw that it performs slightly better out of the box.  \\n We saw that if we add categoricals, it performs even better.  \\n Again, one of the downsides of this XGBoost model  \\n relative to a linear regression model,  \\n is that the explainability suffers a little bit.  \\n A linear regression model is completely explainable.  \\n An XGBoost model is kind of explainable  \\n but it's tedious to explain.  \\n That might be a trade-off.  \\n The performance versus the explainability  \\n might be a business decision that you need to consider  \\n whether you use a better performing model  \\n if you can't explain it.  \\n Think of a situation like a business loan.  \\n You might want to offer someone a loan,  \\n but if you can't explain why you're denying them a loan  \\n that might make the customer upset, causing them to churn.  \\n Finally, remember, because we're using  \\n that scikit-learn interface  \\n it makes it easy to try out these different models.  \\n I highly encourage you to not just try one model.  \\n Try out a few models and see how they perform.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4509080\",\"duration\":40,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Predict Ames\",\"fileName\":\"4433355_en_US_03_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1159627,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] In this challenge,  \\n you're going to predict the sales price  \\n of the Ames housing data.  \\n What I would like you to do is make  \\n a linear regression model,  \\n but I want you to only use the top five features  \\n from the XG Boost model that was not using categorical data.  \\n I want you to pull off those features.  \\n We saw how to do that in a previous lesson,  \\n and then I want you to train a linear regression model  \\n with just those features from the training set  \\n and then evaluate the model.  \\n What is the score or coefficient of determination  \\n or our squared value of that model?  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4503096\",\"duration\":235,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Predict Ames\",\"fileName\":\"4433355_en_US_03_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8494356,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] Let's explore a solution to this challenge.  \\n The first thing I want to do is inspect my XG boost model  \\n and see if I can get those features from that.  \\n So here's my XG boost model.  \\n Remember, we discussed that it has an attribute  \\n called feature_importances_ that ends in underscore,  \\n again that underscore meaning  \\n that attribute was learned when we fit the model.  \\n So here's our feature_importances_,  \\n this is a NumPy array of the importance of each feature.  \\n This corresponds with the training data.  \\n So we should be able to stick this into a Panda series  \\n and get the names of that.  \\n So I'm going to say  \\n let's stick those values into a Panda series.  \\n And for the index  \\n I'm going to use the columns from the training data.  \\n Let's look at what that looks like.  \\n That's looking pretty good.  \\n I'm going to stick this into a chain.  \\n Now I want to sort these values.  \\n Let's just look at what that looks like when we sort that.  \\n It looks like we're going to want to take the values  \\n at the bottom.  \\n Those have the highest score.  \\n So to take the values at the bottom,  \\n I'm going to pull off the index.  \\n Let's just evaluate that  \\n and make sure that that looks correct.  \\n Okay, yeah, we want those values at the end  \\n and we want the last five values at the end.  \\n So to get those, I'm going to use a slice syntax  \\n and I'm going to say minus five colon.  \\n If you use that negative indexing, it's going to go back five.  \\n And then the colon says go to,  \\n and because we didn't put anything on the right side  \\n of the colon, it's just going to go to the end.  \\n So it's going to take the last five values.  \\n Let's just run that and evaluate that.  \\n It looks like that did work.  \\n Okay, these are the features that we want to use.  \\n So I'm going to come up here  \\n and I'm going to store these features in a list.  \\n I'm going to say top five is equal to,  \\n and I'll stick those into a list.  \\n And then what I'm going to do is  \\n I'm going to make a new model down here.  \\n I'm going to call this the linear regression model.  \\n I'm going to say it's the top five features  \\n and then I'm going to use my linear model.  \\n And I'm going to say linear regression.  \\n We'll make an instance of that.  \\n And then I need to fit my model.  \\n So I'm going to say linear regression, top five.  \\n We're going to call fit.  \\n I'm going to call it with X_train.  \\n And I'm going to use loc here to specify a subset of this.  \\n Now remember, loc takes a row selector  \\n and a column selector.  \\n I'm going to specify just a colon here  \\n for the row selector, that's a slice,  \\n that means take all of the rows.  \\n And then for my column selector, I'm going to pass in top five.  \\n Let's just run this right here  \\n and make sure that that works.  \\n And I got an error.  \\n It says it is missing a positional argument, y,  \\n so it did not work.  \\n Why didn't it work?  \\n 'Cause I need to pass in y_train as well.  \\n Let's try it again.  \\n The challenge is asking us what is the score of this model?  \\n To get the score of this model  \\n we need to call the score method.  \\n This looks very similar to what we have above.  \\n I'm going to say lr top five score.  \\n I'm going to say X_test.  \\n And then again, I need to subset what I'm selecting.  \\n So I'm going to say take all of the rows  \\n but just the top five columns.  \\n And then we need to pass in the actual true values  \\n so it can evaluate how it did on its performance.  \\n And we got a score of 79.  \\n So our score dropped a little bit when we used a subset  \\n of these features, but we're only using five features.  \\n This might be a trade-off that you're willing to make  \\n to have a very simple model  \\n even if it performs slightly less.  \\n \\n\\n\"}],\"name\":\"3. Linear Regressions\",\"size\":73574467,\"urn\":\"urn:li:learningContentChapter:4509086\"},{\"duration\":1342,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4507089\",\"duration\":160,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Exploring data\",\"fileName\":\"4433355_en_US_04_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The goal of this video is to understand the data to perform statistical tests.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6301362,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We're going to start looking  \\n at doing some hypothesis testing using Python.  \\n In this lesson, we're going to look at the data  \\n that we're going to explore.  \\n Let's run this first cell here.  \\n We are going to use the stats module from the SciPi library.  \\n Let's make sure that we import that,  \\n and we're going to be looking at neighborhoods  \\n and comparing neighborhoods.  \\n Because neighborhood is a categorical value  \\n I'm going to use my favorite method on that,  \\n value counts, to look and see what we have in here.  \\n It looks like the two most popular neighborhoods are NAmes  \\n and it looks like probably college, CR College Creek,  \\n College something.  \\n So let's limit our analysis to those two neighborhoods.  \\n Another way to look at these categoricals  \\n is to use a group by,  \\n and then for our aggregation, do a describe.  \\n Look at what the output of this looks like.  \\n This is kind of cool.  \\n In the index, that because we grouped by neighborhood  \\n we have all the neighborhoods  \\n and in the columns, now we have hierarchical  \\n or multi-index in the columns,  \\n we actually have two levels of columns.  \\n For each numeric value, we have the outer column  \\n and then in the inner columns,  \\n under that, we have the summary statistics for those.  \\n Let's limit those to the two neighborhoods  \\n that I'm interested in looking at.  \\n I'm going to call one College Creek  \\n and the other one North Ames.  \\n So let's look at those two rows  \\n and let's just pull out the sale price.  \\n Here we can see the summary statistics  \\n for those two neighborhoods.  \\n College Creek looks like it has 267 entries.  \\n The mean sales price for College Creek is around $200,000,  \\n whereas North Ames has a mean sales price around $145,000.  \\n We might want to ask ourselves,  \\n is this data different or is it the same?  \\n It looks like it's somewhat different  \\n in that the mean is different, let's look at the median,  \\n the median actually looks different as well.  \\n The maximum values are different  \\n and the minimum values are different.  \\n It looks like from just looking  \\n at these summary statistics here  \\n that College Creek is a more expensive neighborhood  \\n than North Ames.  \\n Let me just show you an option that you can do  \\n sometimes when you do a describe that gets a little wide,  \\n if you want to often see a little bit more data  \\n you can use T there to transpose the data.  \\n Makes it a little bit more compact sometimes  \\n and fits in the screen a little better.  \\n We want to explore two neighborhoods, so we're going to look  \\n at this North Ames in this College Creek neighborhood.  \\n In this lesson, we did some summary statistics  \\n to compare the sales price of those two neighborhoods.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4504089\",\"duration\":363,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Visualizing distributions\",\"fileName\":\"4433355_en_US_04_02_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"The goal of this video is to visualize distributions of data before performing a statistical test.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12359122,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In the last lesson,  \\n we looked at summary statistics  \\n to understand these two neighborhoods.  \\n Let's use some visualization now to understand them as well.  \\n I'm going to pull out the North Ames  \\n and College Creek data into their own series  \\n so that we can look at them a little easier.  \\n I'll just use some pandas to do that.  \\n And the next thing I'm going to do  \\n is I'm going to make a histogram of both of those.  \\n So I want to plot these histograms on top of each other.  \\n What I'm going to do is call hist on our North Ames series.  \\n I'm going to give that a label as well,  \\n so a legend will appear in that,  \\n and that will return a map plot lib axis.  \\n I'm going to take that axis  \\n and pass it into the College Creek histogram call  \\n so that College Creek is plotted  \\n on the same axis or same plot as we have.  \\n I'm also giving that a label,  \\n and then after I do both of those histograms,  \\n I'm going to tell map plot lib to throw a legend on there  \\n with AX dot legend.  \\n This is the result of that.  \\n Now, note that both of these are fully opaque  \\n and because we plotted College Creek  \\n after we plotted North Ames, it is occluding some of that.  \\n It might be the case, probably isn't,  \\n but it might be the case  \\n that what College Creek is occluding,  \\n North Ames matches directly,  \\n but it's hard to tell because we don't know  \\n what's going on underneath College Creek there.  \\n To deal with this, I'm going to adjust the transparency,  \\n and we do that by changing the alpha parameter.  \\n So here I'm going to set the alpha to 0.7.  \\n Remember, alpha is how transparent something is.  \\n This should let us understand what's going on below that.  \\n Let's look at this.  \\n From a quick look at the histogram,  \\n these look like different distributions.  \\n We already looked at the summary statistics.  \\n We thought that they were different distributions as well.  \\n It looks like this histogram is confirming that.  \\n Let's look at one more plot  \\n that's useful for looking at distributions,  \\n that's continuous distribution function.  \\n I'm going to show how to do that with pandas.  \\n Let me just walk through this chain here  \\n because we have a few steps of that.  \\n So we have our North Ames series.  \\n I'm going to convert this to a data frame by saying two-frame.  \\n Now it's a data frame with a single column.  \\n That's fine.  \\n A data frame is two dimensions, but it is possible  \\n to have a data frame with a single column.  \\n Now that I have a data frame, I can add a new column to it.  \\n I'm going to make a column called CDF,  \\n and that is going to be taking these values  \\n and ranking them.  \\n And the CDF column is going to be the result  \\n of calling the rank method on our data  \\n and converting that into a percentage.  \\n So it looks like the first entry there  \\n is around the 96 percentile.  \\n The next entry is around the six percentile of entries.  \\n The next thing I'm going to do  \\n and we should see when we do this, the index should change.  \\n And indeed it does.  \\n The next thing that I'm going to do  \\n is I'm going to plot this.  \\n I've said multiple times in this course,  \\n one of the keys to plotting in pandas  \\n is understanding how pandas makes plots.  \\n In this case, I'm just going to call the plot method,  \\n which will make a line plot.  \\n Now with a line plot, I can specify X and Y.  \\n If I don't specify X, it will use the index for X.  \\n I don't want to use the index for X,  \\n what I want in the X axis is the cell price  \\n and in the Y axis I want that percentage or that CDF.  \\n Let's un-comment that and run that, see what it looks like.  \\n We get something that looks like this.  \\n So if we created a CDF of College Creek and North Ames,  \\n and they had the same distributions,  \\n we would expect these plots to overlap each other,  \\n to trace each other, essentially.  \\n Let's see if they do.  \\n I'm going to create a function called plot CDF  \\n and it's going to take a series as the input  \\n and an optional map plot lib axis and a label.  \\n It's going to do the logic that I just showed above,  \\n converting a series to a frame, making a CDF column,  \\n sorting it, and then doing the plot,  \\n but it's going to return the series as the output.  \\n Let's run that and see what happens,  \\n just make sure that it works.  \\n You can see that this returned the series.  \\n You can see at the bottom, there is a series there,  \\n and then below that  \\n it had a side effect of making that plot.  \\n With that function in hand,  \\n let's now call that on both of our data sets.  \\n I'm going to call that with North Ames and College Creek,  \\n passing in the same map plot lib axis for both,  \\n and it should plot them on the same plot.  \\n I got an error, it says map plot lib is not defined.  \\n I ran into this because I restarted my code space  \\n and my map plot lib library was not installed.  \\n So if I were to do this in the real world,  \\n I would come up here to the top,  \\n where I've put my imports here,  \\n and note that I don't have map plot lib here,  \\n I would come in here and say,  \\n import map plot lib dot py plot as PLT.  \\n That will make it so, in the future,  \\n when I run this, I'm not going to have that issue.  \\n Let's run this again.  \\n You can see that it prints out a series here  \\n because plot CDF returns a series.  \\n Below that we should see our plot,  \\n and we can see that these CDFs do not overlap,  \\n giving us further evidence  \\n that these do not have the same distribution.  \\n In this lesson,  \\n we looked at comparing distributions by looking at plots.  \\n We looked at histograms  \\n and continuous distribution functions.  \\n We saw that,  \\n for these two neighborhoods that we're looking at,  \\n these don't appear to overlap,  \\n suggesting that they are not the same distribution.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4507088\",\"duration\":264,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Running statistical tests\",\"fileName\":\"4433355_en_US_04_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"By performing statistical tests, you can understand if two data sets have the same distribution.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12107398,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson,  \\n we're going to use the scipy.stats module  \\n to run a statistical test to give us a numeric value  \\n as to whether these two distributions are the same.  \\n Imported that scipy.stats module up above.  \\n Scipy is a collection of different utilities  \\n for manipulating numerical data.  \\n One of those modules is the stats library.  \\n Let's just look and see what's in there.  \\n There are a bunch of things that you can do  \\n with this stats module.  \\n One of them is to run statistical tests,  \\n another one is to create distributions,  \\n there are also some plotting capabilities as well.  \\n In this case, we're going to run this ks_2samp function.  \\n Let's pull up the documentation for that.  \\n It says, it performs a two sample Kolmogorv-Smirnov test  \\n for goodness of fit.  \\n Basically what this is doing is it's testing  \\n whether these two distributions are the same.  \\n Let's look at what we need to pass into it.  \\n We need to pass in data1 and data2  \\n and we already have those two series,  \\n so we should be good with that.  \\n What does this return?  \\n This says it returns a p-value.  \\n I'm going to view as a scrollable element here  \\n and let's scroll this up.  \\n This says, it returns an object containing two attributes,  \\n the KS statistic and a p-value as a result.  \\n And if we scroll down a little bit,  \\n we should see some examples.  \\n One of the nice things  \\n about a lot of the Python numeric libraries  \\n such as Pandas, Matplotlib, Scikit-learn and Scipy  \\n is they have really good documentation.  \\n You can see an example of using it right here.  \\n We just create the two distributions  \\n and then we call ks_2samp with our two samples  \\n and this gives us this KstestResult.  \\n You can see that the first part here is a statistic  \\n and the next part is a p-value.  \\n In this case, we're mostly interested with the p-value.  \\n You can see that says, if the p-value is lower  \\n than a threshold of 0.05, we reject the null hypothesis  \\n in favor of the two-sided alternative,  \\n which is the data were not drawn from the same distribution.  \\n Here's another example.  \\n You can see that these two samples, the p-value is 0.5  \\n and so because the p-value is 0.5,  \\n it's not below that threshold.  \\n We cannot reject the null hypothesis  \\n or we fail to reject that.  \\n The null hypothesis in this case would be  \\n that the two samples were from the same distribution,  \\n so we cannot reject that,  \\n in essence saying that we cannot prove  \\n that these were not from the same distribution,  \\n i.e. we think they are from the same distribution.  \\n Let's do this with our data now.  \\n I'm just going to pass in n_ames and college_cr into that  \\n and I'll print out the results there.  \\n We have the statistic and the p-value.  \\n The p-value is very low.  \\n Down here I have an IF statement  \\n that lets us check the p-value.  \\n If the p-value is greater than 0.05,  \\n we fail to reject the null hypothesis,  \\n i.e. these two are from the same distribution.  \\n If it is less than 0.05, we reject the null hypothesis,  \\n meaning that they are not from the same distribution.  \\n In this case, this is a very small number,  \\n it is certainly less than 0.05  \\n and we are going to reject the null hypothesis  \\n that these two data sets are from a different distribution.  \\n This confirms what we saw  \\n with both our statistical summaries  \\n and our visualizations of these two distributions.  \\n In this lesson, we looked at using the scipy.stats library  \\n to do a statistical test to compare  \\n whether two samples were from the same distribution.  \\n The scipy.stats Library makes this really easy  \\n to run statistical tests such as these  \\n and you can leverage the scipy.stats library  \\n to confirm what you see when you do visualizations  \\n or summary statistics.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4508089\",\"duration\":268,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Testing for normality\",\"fileName\":\"4433355_en_US_04_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The goal of this video is to test whether a set of values has a normal distribution.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9502184,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lesson we're going to use  \\n the SciPi library to test  \\n whether a distribution is normal.  \\n We're also going to create a visualization  \\n to let us evaluate that visually as well.  \\n Typical test for testing for normality  \\n is called the Shapiro-Wilks Test,  \\n and it turns out that SciPi stats module  \\n has a function that will do that.  \\n And similar to the function  \\n that we looked at in the previous lesson,  \\n this will give us back a statistic and a P value.  \\n So let's see if northern aims is normal,  \\n We're going to run that  \\n and then we'll look at the P value there.  \\n It says that the distribution  \\n of the series is likely not normal,  \\n so presumably that P value was low enough,  \\n so we are going to reject the hypothesis  \\n which is that it is a normal distribution.  \\n Just print out that P value so you can see what it is,  \\n and it is indeed a small number.  \\n Another way to evaluate normality is to  \\n use a probability plot.  \\n It turns out that this module has that capability as well.  \\n You can pull up the documentation if you want to.  \\n The key thing here is that you pass in the data  \\n and I'm also going to pass in a parameter  \\n for this plot to tell us to use map plot lib  \\n to plot that.  \\n Here's my code.  \\n I am going to create a figure in an axis using map plot lib  \\n and then I'm going to call probplot and pass in the axes.  \\n Here's our probability plot.  \\n Let me explain how we interpret this.  \\n We don't have a hard numeric value to say  \\n whether or not something is normal.  \\n By looking at this, this is a visual interpretation.  \\n We would like to see the blue dots track that red line,  \\n and if they do track that red line,  \\n that would be a strong indication that this is normal.  \\n You can see that it looks like it's overlapping the red line  \\n at a few points,  \\n but it's a little bit above on the small end.  \\n Then it goes below the red line  \\n and then it goes back up above the red line.  \\n From looking at this probability plot,  \\n I would say that this is not normal.  \\n It's close to normal on the left hand side,  \\n but on the right hand side it is not.  \\n Let me just plot a histogram of this so we can see what  \\n that histogram looks like and understand what's going on  \\n with this probability plot.  \\n Again, we're going to look at the north aims blue histogram,  \\n and we said that the left hand side of this  \\n looks somewhat normal,  \\n but the right hand side does not.  \\n Indeed, the right hand side has a tail where it's dragging  \\n out a little bit, and you can see that that tail  \\n is represented by this going up and above.  \\n Now, on the left hand side, it's going above as well.  \\n That indicates that it's actually a little bit short here.  \\n We would like to see that drag out a little bit more,  \\n so if this had a long tail  \\n on the left hand side,  \\n we would actually see these blue lines  \\n go below that red line.  \\n So that's the interpretation there.  \\n Let's actually repeat this with the College Creek data.  \\n This doesn't look normal either.  \\n Let's look at what the probability plot looks like for that.  \\n So here's the probability plot for our College Creek.  \\n You can see that it's quite a bit above  \\n on the left-hand side.  \\n What that indicates is that it's not tailing off  \\n as much as we would like for it to be normal.  \\n You can see that it then goes below here.  \\n I am interpreting that as this bump right here.  \\n We would like that to go up a little bit more,  \\n but it's not, looks like along the middle there we're okay.  \\n Then we're going back down below,  \\n and then it's going back up above,  \\n indicating that this tail is a little bit too long.  \\n In this lesson,  \\n we looked at the ability to do a probability plot.  \\n A probability plot is a visualization that lets us  \\n understand whether our data looks normal.  \\n It does not have a numeric yes or no answer,  \\n but this is somewhat fuzzy.  \\n We want to see the blue dots tracking that red line,  \\n and I showed you how you can interpret when  \\n these values are off by comparing that to the histogram.  \\n This is a nice tool to have in your tool belt  \\n if you need to check if your data is normal.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4507087\",\"duration\":20,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Checking square footage distributions\",\"fileName\":\"4433355_en_US_04_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":601364,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat electronic music)  \\n - [Instructor] In this challenge,  \\n you're going to get a chance  \\n to play around with statistic tests.  \\n What I want you to do is get the first floor square footage  \\n from North Ames and College Creek  \\n and compare those distributions.  \\n Are they the same or not?  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4508088\",\"duration\":267,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Checking square footage distributions\",\"fileName\":\"4433355_en_US_04_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8992336,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] Let's look at a solution for this challenge.  \\n The first thing that I want to do  \\n is I want to get the square footage  \\n from both of these neighborhoods.  \\n Let's use our pandas code to do that.  \\n Say from housing, let's do a query  \\n and I'm going to say neighborhood is equal to,  \\n and I'll put in double quotes here  \\n because my string has a single quote and NAmes.  \\n Close my double quote there, close my single quote  \\n and then I need another parentheses at the end for my chain.  \\n Let's run that and just scroll down  \\n and look at how many rows.  \\n Okay, there's 400 rows, so it looks  \\n like this is getting the Northern Ames  \\n or North Ames neighborhood.  \\n Let's pull off the first floor square footage from that.  \\n I'm going to use .loc to do that.  \\n So remember, loc takes a row selector.  \\n I'm going to take all of the rows from this  \\n and then a column selector.  \\n Now, if I want to get a series from this,  \\n I need to just put in a scaler value from this.  \\n That should give me a series.  \\n Let's run that and make sure.  \\n Okay, there's my series.  \\n If I wanted to get a data frame  \\n with just one dimension in that, I could put in a list  \\n of the columns and just have a single column in there  \\n and that should give me a data frame.  \\n Okay, so there's my data frame.  \\n I don't want a data frame. I want a series.  \\n That looks like that's pretty good.  \\n Okay, so this is going to be my NAmes  \\n and then I'll call this _sf.  \\n Okay, now I'm going to just copy this  \\n and I'm going to leverage this  \\n for making the College Creek value here.  \\n Let's change this to college_cr,  \\n and I'm going to come down here and change NAmes to CollgCr.  \\n Let's run that and see if it works.  \\n It looks like it does work.  \\n Let's just look at the output of that.  \\n Okay, it looks like that did work as well.  \\n Okay, now I have my two datasets here.  \\n I want to see if these distributions are the same.  \\n So before I run my statistical test,  \\n I'm going to visualize these.  \\n So let's make a histogram to visualize these.  \\n I'm going to say ax is equal to n_ames_sf  \\n and then I'll do a hist here.  \\n There's the histogram  \\n of the square footage of the first floor.  \\n And let's plot on top of that  \\n my College Creek square footage.  \\n I'm going to say hist, and then I'm going to say ax is equal  \\n to that ax that I just created from North Ames.  \\n I'm going to get something that looks like this.  \\n In this case, I can see that I don't really need to play  \\n with the alpha here, but I can tweak it a little bit.  \\n I'll just change it to 0.7 just on College Creek.  \\n These do not look like the same distribution  \\n but let's quantify that using our summary statistics.  \\n Okay, so we're going to use the Kolmogorov-Smirnov test  \\n and we're going to get a statistic from that  \\n and we're going to get a P-value from that.  \\n And we're going to say stats.  \\n And this is the ks_2sample  \\n and we're going to pass in n_ames_sf  \\n and College Creek sf  \\n and we'll just print the P-value from this.  \\n Okay, remember, our null hypothesis  \\n is that the values have the same distribution.  \\n The P-value is less than 0.05, giving us an indication  \\n that these do not have the same distribution.  \\n In this lesson, we looked  \\n at how we can apply a Kolmogorov-Smirnov test  \\n to two samples.  \\n We also verified that by looking  \\n at the histogram and understanding  \\n that these two distributions graphically also did not look  \\n like they were the same distribution.  \\n \\n\\n\"}],\"name\":\"4. Hypothesis Tests\",\"size\":49863766,\"urn\":\"urn:li:learningContentChapter:4503103\"},{\"duration\":78,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4503095\",\"duration\":78,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"4433355_en_US_05_01_LA30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5259035,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Congratulations on completing  \\n the Statistics with Python course.  \\n Now that you've acquired a solid statistics foundation,  \\n you might wonder what are the next steps?  \\n I highly recommend practicing the concepts  \\n and techniques covered in this course.  \\n Like any skill, the more you practice,  \\n the more proficient you become.  \\n Consider working on improving your data manipulation skills.  \\n As we've seen, many libraries are easy to use  \\n if the data is in the appropriate format.  \\n One valuable resource for this is my book,  \\n \\\"Effective Pandas.\\\"  \\n This book provides comprehensive examples  \\n and snippets for data manipulation using Pandas.  \\n It offers real world examples as well  \\n as exercises to reinforce your learning.  \\n Finally, apply the knowledge and techniques you gained  \\n in this course to your own projects and data sets.  \\n Whether you're analyzing survey data,  \\n conducting AB testing,  \\n or exploring customer behavior,  \\n using statistics and Python will enable  \\n you to extract valuable insights  \\n and make data-driven decisions.  \\n Completing a project will impress your boss  \\n and is also helpful  \\n Thanks for completing this course  \\n and I wish you continued success  \\n in your statistical journey.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":5259035,\"urn\":\"urn:li:learningContentChapter:4503104\"}],\"size\":379622141,\"duration\":9565,\"zeroBased\":false},{\"course_title\":\"Machine Learning with Scikit-Learn\",\"course_admin_id\":2861087,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2861087,\"Project ID\":null,\"Course Name\":\"Machine Learning with Scikit-Learn\",\"Course Name EN\":\"Machine Learning with Scikit-Learn\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"The ability to apply machine learning algorithms is an important part of a data scientist\u00e2\u20ac\u2122s skill set. scikit-learn is a popular open-source Python library that offers user-friendly and efficient versions of common machine learning algorithms. In this course, data scientist Michael Galarnyk explains how to use scikit-learn for supervised and unsupervised machine learning. Michael reviews the benefits of this easy-to-use API and then quickly segues to practical techniques, starting with linear and logistic regression, decision trees, and random forest models. In chapter three, he covers unsupervised learning techniques such as K-means clustering and principal component analysis (PCA). Plus, learn how to create scikit-learn pipelines to make your code cleaner and more resilient to bugs. By the end of the course, you'll be able to understand the strengths and weaknesses of each scikit-learn algorithm and build better, more efficient machine learning models.&lt;br&gt;&lt;br&gt;This course was created by &lt;a href=http://www.onlymadecraft.com target=_blank&gt;Madecraft&lt;/a&gt;. We are pleased to host this content in our library.&lt;br&gt;&lt;br&gt;&lt;img src=https://media.licdn.com/media/AAYAAgCwAAoAAQAAAAAAAHppnBQxgeyWS2CsU3aDDPcMgw.jpg height=25% width=25%&gt;\",\"Course Short Description\":\"Learn to use scikit-learn, the popular open-source Python library, to build efficient machine learning models.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":\"21401000, 20517019\",\"Instructor Name\":\"Madecraft Licensor, Michael Galarnyk\",\"Instructor Transliterated Name\":\",\",\"Instructor Short Bio\":\"Full-Service Learning Content Company|Python Instructor and Blogger\",\"Author Payment Category\":\"LICENSED, NONE\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2020-10-15T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/machine-learning-with-scikit-learn\",\"Series\":\"Essential Training\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Advanced\",\"LI Level EN\":\"Advanced\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"scikit-learn\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":2637.0,\"Visible Video Count\":22.0,\"Contract Type\":\"LICENSED, NO_CONTRACT\"},\"sections\":[{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2366781\",\"duration\":55,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Get started with scikit-learn\",\"fileName\":\"2861087_04_01_XR30_GetstartedwithScikitLearn\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2337588,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Michael] Congratulations.  \\n I've hope you found this course useful  \\n in your machine learning journey.  \\n As you probably know, your learning doesn't stop here.  \\n Machine learning is an ever-expanding topic,  \\n and there are a lot of resources available  \\n that can help you keep learning.  \\n I'd like to offer a few resources on your journey.  \\n First, you can always check out Scikit-Learn's  \\n documentation to learn more about other algorithms.  \\n Next, if you want to learn about deep learning,  \\n you can check out deep learning frameworks  \\n like TensorFlow or PyTorch.  \\n Also, be sure to check out my blog on Medium.  \\n If you're looking for a data science job,  \\n I encourage you to check out my blog post titled  \\n \\\"How to Build a Data Science Portfolio\\\"  \\n to help you on your way.  \\n And finally, stay in touch.  \\n You can follow me on Twitter @GalarnykMichael  \\n and connect with me on LinkedIn.  \\n I'd love to hear from you.  \\n So that's it.  \\n Thanks again for watching this course.  \\n Now, get out there and take advantage of your data  \\n to create machine learning models.  \\n Good luck.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2353859\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2368043\",\"duration\":54,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Effective machine learning with scikit-learn\",\"fileName\":\"2861087_00_01_WX30_EffectivemachinelearningwithScikitLearn\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1786660,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Machine learning is transforming industries  \\n and it's an exciting time to be in the field.  \\n A large amount of machine learning programs are written  \\n using open source Python library, Scikit-learn.  \\n Scikit-learn provides an easy to use streamlined  \\n API that provides efficient versions  \\n of a large number of common algorithms.  \\n And it makes it easy to train models.  \\n My name is Michael Galarnyk.  \\n I'm a data scientist, a machine learning instructor,  \\n and a blogger about all things data science.  \\n I'm also a big fan of Scikit-learn.  \\n In this course, I'll show you how to use several  \\n machine learning algorithms and when they're appropriate.  \\n I'll share with you how you can tune your models  \\n to better predict unseen data.  \\n So not only make your models better,  \\n but also help you understand the strengths  \\n and weaknesses of each algorithm.  \\n By the end of the course, you'll feel confident  \\n and ready to build your own powerful machine learning models  \\n using Scikit-learn.  \\n So if you're ready to dive in, then let's go.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2367237\",\"duration\":34,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you should know before you start\",\"fileName\":\"2861087_00_02_XR30_Whatyoushouldknowbeforeyoustart\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Get the most out of this course. In this video, discover what background knowledge would be beneficial to have before starting this course. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":964736,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] There are a few things I'd like you  \\n to be aware of as we get started.  \\n First, you should understand basic Python data structures,  \\n such as lists, tuples, and dictionaries.  \\n Additionally, you should have knowledge of Python libraries  \\n such as pandas and matplotlib.  \\n If you'd like to know more about these libraries,  \\n you can check out my course, Python for Data Visualization.  \\n Don't worry if you feel your background knowledge  \\n could be better.  \\n Throughout the course,  \\n Regardless of your background,  \\n you'll still be able to follow the course  \\n and learn how to create machine learning algorithms  \\n with scikit-learn.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2367238\",\"duration\":21,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Using the exercise files\",\"fileName\":\"2861087_00_03_XR30_Usingtheexercisefiles\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"The course includes a folder called Exercise_Files. In this video, learn how to utilize the course files and code along with the videos. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":778209,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] To learn the most from this course  \\n and to help you follow along,  \\n I've included a ZIP file of the contents of this course.  \\n You can find these included  \\n as the exercise files for this course.  \\n Once you've unzipped it, you'll see this folder here.  \\n If you click here,  \\n you can see the contents  \\n of a particular chapter of the course.  \\n If this sounds great to you,  \\n you can open the different notebooks and follow along.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2366782\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2367239\",\"duration\":81,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What is machine learning?\",\"fileName\":\"2861087_01_01_XR30_Whatismachinelearning\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Machine learning is an exciting new technology. In this video, learn why machine learning is useful and how it can solve problems that are normally too difficult or tedious for humans to solve.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2220700,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] What is machine learning and why is it useful?  \\n You can think of machine learning  \\n as a field of study that gives computers the ability  \\n to learn from data without being explicitly programmed.  \\n Here's an example of why machine learning is useful.  \\n Say you have 150 flowers.  \\n You're interested in determining which flowers are  \\n which flower species based on a feature  \\n like their petal length.  \\n There are three different flower species:  \\n Iris Setosa, Iris Versicolor, and Iris Virginica.  \\n From analyzing the data, you can mainly write rules  \\n to separate out the flowers from each other.  \\n The first rule could separate  \\n out the Setosa from the other species.  \\n From there, you can make another rule to try  \\n and separate out the Versicolor from the Virginica.  \\n You're going to keep on writing rules  \\n until you completely separate  \\n out the flower species from each other.  \\n For something more complicated with more features,  \\n your program could have a very long list of complex rules.  \\n This manual writing of rules might even seem feasible  \\n for some applications like flower classification.  \\n What if your data changes faster  \\n than you can update the rules?  \\n Can this approach work for more complicated problems  \\n like image or speech recognition?  \\n It turns out that these are the sort of problems  \\n where humans don't necessarily have a good understanding  \\n of how to solve the problem with rule-based approaches.  \\n This is where machine learning approaches shine.  \\n Machine learning can extract structure from data  \\n and solve problems that are normally too difficult  \\n or tedious for humans to solve.  \\n So that's it.  \\n Machine learning is an efficient means  \\n of building models from data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2367240\",\"duration\":67,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Why use scikit-learn for machine learning?\",\"fileName\":\"2861087_01_02_XR30_WhyuseScikitLearnformachinelearning\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Scikit-learn is a free library software used by many data scientists. In this video, learn why the Python library scikit-learn is a great library for machine learning due to its large number of efficient machine learning algorithms and an easy to use API. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1800963,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] With a host of machine learning tools  \\n and frameworks out there why should you scikit-learn?  \\n Scikit-learn is a very popular  \\n open source machine learning project  \\n which is constantly being developed and improved.  \\n In this video, I'll share with you  \\n some of the major advantages of scikit-learn.  \\n First scikit-learn provides a large number  \\n of machine learning algorithms.  \\n This is important as programming machine learning algorithms  \\n from scratch is not easy task.  \\n Most models in scikit-learn  \\n also have reasonable default values for hyper-parameters.  \\n This means that a machine learning algorithm  \\n might work well with little tuning.  \\n Next, scikit-learn has a clean uniform, and streamlined API.  \\n Scikit-learn also works well with other Python libraries,  \\n such as NumPy, Pandas, and Mathplotlib.  \\n Also, once you understand the basic use in syntax  \\n of scikit-learn for one model,  \\n switching to another is very straightforward.  \\n Finally, the advantage of the library being popular  \\n cannot be overlooked.  \\n It's widely used in academia and industry.  \\n There are always more scikit-learn tutorials being written.  \\n This also means it's easier to get  \\n your questions answered on stack overflow.  \\n So that's it.  \\n Due to its easy to use and popularity,  \\n scikit-learn is a great library for machine learning.  \\n \\n\\n\"}],\"name\":\"1. Input and Loading Data\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2353858\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2367241\",\"duration\":54,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What is supervised learning?\",\"fileName\":\"2861087_02_01_XR30_Whatissupervisedlearning\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Supervised learning is a common type of machine learning. In this video, learn how to set an algorithm with a matrix and a target vector to make predictions. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1445274,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The most common form of machine learning  \\n is supervised learning.  \\n In Scikit-Learn, a supervised learning algorithm learns  \\n a relationship between your features matrix  \\n and your target factor.  \\n A feature is a measurable property.  \\n A target is typically what you want to make predictions for.  \\n Once a model learns a relationship between a features matrix  \\n and a target factor,  \\n it can make predictions for unseen or future data.  \\n Supervised learning can generally be thought of  \\n to solve two different types of tasks.  \\n The first is when you try to predict a continuous value.  \\n This is considered a regression problem.  \\n This means that your target factor contains  \\n continuous qualities like home prices.  \\n The second is when you're trying  \\n to predict a categorical value.  \\n This is considered a classification problem.  \\n This means that your target factor contains  \\n categorical values like different flower species.  \\n So that's it.  \\n Supervised learning is when an algorithm learns  \\n from a features matrix and target factor  \\n to make predictions.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2367242\",\"duration\":115,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How to format data for scikit-learn\",\"fileName\":\"2861087_02_02_XR30_HowtoformatdataforScikitLearn\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Formatting is extremely important when working with data. In this video, learn how to format your data so that it is recognizable input for the Python library scikit-learn.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3945761,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Scikit-learn is a great library for creating machine  \\n learning models from data.  \\n Before you fit a model using scikit-learn,  \\n your data has to be in a recognizable format.  \\n Scikit-learn works well with numeric data  \\n that's stored in numpy arrays.  \\n Additionally, you can convert your data from objects  \\n like pandas dataframes to numpy arrays.  \\n In this video, I'll show you how you can  \\n make your data a more acceptable input for scikit-learning.  \\n The first thing you have to understand is what scikit-learn  \\n expects for features matrices and target vectors.  \\n In scikit-learn, a features matrix is a  \\n two dimensional grid of data where rows  \\n represent samples and columns represent features.  \\n A target vector is usually one dimensional  \\n and in the case of supervised learning,  \\n what you want to predict from the data.  \\n Let's now see an example of this.  \\n The image is a pandas dataframe of the  \\n first five rows of the iris dataset.  \\n A single flower represents one row of the dataset  \\n and the flower measurements are the columns.  \\n In this dataset, the species column  \\n is what you're trying to predict.  \\n Let's now go over an example of how to make your data  \\n a more acceptable format.  \\n The first thing you have to do is import the libraries.  \\n In this case, you'll import matplotlib,  \\n pandas, as well as the Iris dataset.  \\n This code loads the Iris dataset into a pandas dataframe.  \\n From here, you can try to arrange your data  \\n into a features matrix and target vector.  \\n This is a multiple column panda's dataframe,  \\n which will then be converted into a numpy array.  \\n You can do this by using the values attribute.  \\n One important thing to do is to make sure your  \\n numpy array is two dimensional.  \\n This is the first dimension,  \\n and this is the second dimension.  \\n This piece of code is a panda series  \\n that you'll then convert to a numpy array.  \\n You can do this by using the values attribute.  \\n Notice that this is one dimensional.  \\n This is okay, as target vectors can be one dimensional.  \\n So that's it.  \\n Scikit-learn expects data in a particular format.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2367243\",\"duration\":272,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Linear regression using scikit-learn\",\"fileName\":\"2861087_02_03_XR30_LinearregressionusingScikitLearn\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Linear regressions are common models in data science. In this video, learn how to build and tune a linear regression model using the Python library scikit-learn. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10740831,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] How do you create a complex model  \\n using scikit-learn?  \\n An easy solution is to start with a simple model  \\n like linear regression and go from there.  \\n In this image,  \\n we see a best fit line for a bunch of points.  \\n In this video,  \\n I'll show you how you can create a linear regression model  \\n using scikit-learn.  \\n So that more complex models will be easier to create.  \\n The first thing you have to do is import the libraries  \\n that you want to use.  \\n In this case Matplotlib, Pandas,  \\n train_test_split,  \\n as well as the model LinearRegression.  \\n From there, you need to load a dataset.  \\n This particular data set  \\n shows that scikit-learn requires data  \\n to be free of missing values.  \\n The goal of this dataset  \\n is to use the feature column X  \\n to predict the target column Y.  \\n Notice it looks like we have a missing value here.  \\n This is really important.  \\n As in scikit-learn,  \\n you can't have missing values input into a model.  \\n The next step is to remove or impute values.  \\n If you want to build models with your data,  \\n null values are almost never allowed.  \\n It's important to always see how many samples  \\n have missing values,  \\n and for which columns.  \\n Let's start by looking at the shape of the data frame.  \\n There are 102 rows and two columns.  \\n The next thing is to see how many missing values  \\n there are in each column.  \\n Notice that there's eight missing values  \\n for the column Y.  \\n You can either remove rows where there's a missing value,  \\n or you can fill in missing values.  \\n The option used in this notebook  \\n is to remove rows with missing values.  \\n To do this,  \\n And look, there's no more missing values.  \\n Notice though,  \\n that the shape of the dataframe is different.  \\n Before we have 102 samples.  \\n And now we only have 94.  \\n From here,  \\n you can arrange your data into a features matrix  \\n and target vector.  \\n This code converts the X column to a Numpy array.  \\n Notice that this features matrix is two dimensional.  \\n You have dimension one,  \\n and dimension two.  \\n This is really important  \\n as to input something into scikit-learn,  \\n your features matrix needs to be two-dimensional.  \\n What this code is doing is,  \\n is it's create a target vector.  \\n Notice that this target vector is one-dimensional.  \\n Dimension one, and there's no dimension two.  \\n Let's now create a linear regression model  \\n using scikit-learn.  \\n The first step is to import the model  \\n that you want to use.  \\n In this case,  \\n it was already imported earlier in the notebook.  \\n So this is not necessary.  \\n From here,  \\n This is a place we tune the hyperparameters of a model.  \\n In the case of linear regression,  \\n you can set fit_intercept to true or false.  \\n This is a really important concept.  \\n As more complex models have a lot more you can tune.  \\n In the case of linear regression,  \\n this is about it.  \\n On the left,  \\n you have an image of a model where fit_intercept  \\n was equal to true.  \\n On the right,  \\n you have an image of a model  \\n where fit_intercept was equal to false.  \\n Here's the code to make a instance of the model.  \\n Note that fit_intercept in this case is equal to true.  \\n From here,  \\n you can use the fit method to train the model on the data.  \\n What's happening the model's learning the relationship  \\n between X and Y.  \\n From here,  \\n you can predict values of new data.  \\n The code here is predicting for one observation.  \\n The code here is predicting for multiple.  \\n With any model it's important  \\n to try to measure model performance.  \\n For regression tasks,  \\n one metric is R squared.  \\n Which is implemented by the score method.  \\n This model had a score of roughly .98.  \\n Which is actually pretty good.  \\n Scikit-learn also allows you  \\n to find the equation of the line.  \\n You can do this after you'd make an instance of a model,  \\n and then fit it on your data.  \\n The attribute coaf is essentially your slope.  \\n The intercept is your intercept.  \\n And here's the equation of the line.  \\n This next graph is plotting  \\n the best fit linear regression line.  \\n This next section is just showing  \\n how changing a single hyperparameter value  \\n can have a drastic impact on your model performance.  \\n By looking at these graphs,  \\n it's clear that fit_intercept equal to true  \\n makes a much better model.  \\n As the R squared is 0.98.  \\n Whereas where fit_intercept is equal to false,  \\n the R squared is 0.86.  \\n So that's it.  \\n I encourage you to create a linear regression model  \\n using scikit-learn.  \\n I hope you have a better understanding of how it works.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2366777\",\"duration\":113,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Train test split\",\"fileName\":\"2861087_02_04_XR30_Traintestsplit\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"A train test split is critical in testing your models. In this video, learn how to perform the train test split procedure using the Python library scikit-learn so you can simulate how well your model performs on new data. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4555737,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The goal of machine learning  \\n is it build a model that performs well on new data.  \\n If you have new data,  \\n you can see how well your model performs on it.  \\n The problem is that you may not have new data,  \\n but you can simulate this experience  \\n with Scikit Learn's train test split.  \\n In this video, I'll show you how train test split works  \\n in Scikit Learn.  \\n The first thing that you need to know  \\n is what is train test split?  \\n Here's how that procedure works.  \\n The first step is to split your data into two pieces,  \\n a training set and a testing set.  \\n Typically, about 75% of the data goes to your training set  \\n and about 25% of your data goes to the test set.  \\n The second step of the process  \\n is to train the model on the training set.  \\n The final step is to test the model on the testing set  \\n and evaluate the performance.  \\n To do this in Scikit Learn,  \\n you first have to import libraries.  \\n The next step is to load a dataset.  \\n The dataset using this notebook  \\n is the Boston House Price dataset.  \\n The goal of this dataset is predict house prices  \\n based on features like number of rooms.  \\n The next step is to create a features matrix,  \\n as well as the target vector.  \\n From here, you can create a train test split.  \\n The colors in the image indicate which variable,  \\n X_train, X_test, Y_train, and Y_test,  \\n the data from the data frame derive from two  \\n for a particular train test split.  \\n Notice that roughly 75% of the data went to the training set  \\n and roughly 25% went to the test set.  \\n From here, you can utilize a machine learning model.  \\n In this case, it's linear regression.  \\n The final part is to measure model performance.  \\n By measuring model performance on the test set,  \\n you can estimate how well your model is likely to perform  \\n on new data.  \\n To do this, you can use a score method,  \\n just make sure that your inputs are your test set.  \\n So that's it.  \\n Train test split helps you simulate  \\n how well a model would perform on new data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2367244\",\"duration\":235,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Logistic regression using scikit-learn\",\"fileName\":\"2861087_02_05_XR30_LogisticregressionusingScikitLearn\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"You can create logistic regression models in a number of ways. In this video, learn how to create a logistic regression model using the Python library scikit-learn and learn how to visualize the predictions for your model using Matplotlib.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8590508,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] How do you create a logistic regression model  \\n using scikit-learn?  \\n The first thing that you need to know  \\n is that despite the name logistic regression  \\n contain the word regression,  \\n logistic regression is actually a model user classification.  \\n Classification models can be used for tasks  \\n like classifying flower species or image recognition.  \\n All of this of course depends on the availability  \\n and quality of your data.  \\n Logistic regression has some advantages,  \\n model training and predictions are relatively fast,  \\n additionally, no tuning is usually needed for the model.  \\n Finally, it can perform well  \\n with a small number of observations.  \\n In this video, I'll share with you  \\n how you can create a logistic regression model  \\n for binary classification.  \\n The first thing that you need to do  \\n is import the libraries that you want to use.  \\n In this notebook, it's Matplotlib, numpy, seaborn, pandas,  \\n as well as train_test_split,  \\n StandardScaler, and LogisticRegression.  \\n While it may seem like a lot of libraries,  \\n a lot of model building involves oftentimes data processing,  \\n splitting your data up into training and test sets,  \\n and actually applying the model itself.  \\n The code below loads, a modified version  \\n of the Iris dataset, which has two classes,  \\n a one in the dataset is a virginica flower  \\n and a zero is a versicolor flower.  \\n From here, you can split the data  \\n into training and test sets.  \\n A really important part of this process  \\n is to standardize your data.  \\n Logistic regression is affected by scale,  \\n so you need to scale your features onto unit scale  \\n for optimal performance.  \\n Unit scale means having a mean of zero  \\n and a variance of one for your features.  \\n You can utilize scikit-learn's  \\n standard scaler to accomplish this.  \\n Note that you fit on the training set  \\n and transform on the training and test sets.  \\n From here, you could import and use the model.  \\n Logistic regression was already imported  \\n at top of the notebook, so this step is commented out.  \\n from here, you can make an instance of the model.  \\n This is normally a place  \\n where you can tune the hyperparameters of a model.  \\n From here, You can train the model on the data.  \\n What this means is the models learn the relationship  \\n between your X, in other words,  \\n your sepal width, sepal height, et cetera,  \\n and your Y, which are the flower species.  \\n Finally, you can predict labels of new data.  \\n What this code is showing is a prediction  \\n for one flower sample.  \\n Their prediction was zero.  \\n The reason why it was zero and not one  \\n is by looking at the line below.  \\n The probability of a zero, according to the model was 0.52,  \\n the probability of one was 0.47.  \\n If it happened to be greater than or equal to 0.5,  \\n it would have predicted a one.  \\n If this is unclear, let's visualize how logistic regression  \\n makes predictions by looking at our test data.  \\n If you don't know what this code is doing, don't worry,  \\n it's all about the visualization.  \\n What you can see in the graph  \\n is the probability of virginica  \\n given different petal lengths.  \\n When the probability is greater than or equal to 0.5,  \\n everything in this area is classified as virginica  \\n even when it may not be.  \\n If you look at these two blue points here,  \\n even though they're classified as virginica,  \\n they're misclassified, they're actually versicolor flowers.  \\n Everything below this threshold is classified as versicolor.  \\n An important part of a machine learning model  \\n is measuring its model performance.  \\n The code here utilizes accuracy as a metric,  \\n which is simply the fraction of correct predictions.  \\n Accuracy is one metric,  \\n but it doesn't give much say into what went wrong.  \\n Let's take a look at a confusion matrix.  \\n There are a couple of things to notice  \\n in this confusion matrix,  \\n the first is that it correctly predicted versicolor  \\n 10 times when it was actually versicolor,  \\n additionally, it correctly predicted virginica  \\n when was actually virginica,  \\n however, it incorrectly predicted virginica,  \\n when it was actually versicolor,  \\n these points were misclassified.  \\n So that's it.  \\n I encourage you to create a logistic regression model.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2367245\",\"duration\":216,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Logistic regression for multiclass classification\",\"fileName\":\"2861087_02_06_XR30_Logisticregressionformulticlassclassification\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Modeling multiclass classifications are common in data science. In this video, learn how to create a logistic regression model for multiclass classification using the Python library scikit-learn. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7754717,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] A lot of classification models  \\n like logistic regression  \\n were originally designed for binary classification.  \\n That's predicting whether something's one thing or another.  \\n For datasets with more than two classes,  \\n what do you do?  \\n For multi-class classification problems,  \\n one approach is to split the task  \\n into multiple binary classification datasets,  \\n and fit a binary classification model on each.  \\n In this video, we'll explore the one-vs-rest strategy  \\n and how you can apply it  \\n to logistic regression using scikit-learn.  \\n One-vs-rest, which is also sometimes called one-vs-all  \\n is a technique that extends binary classifiers  \\n to multi-class problems.  \\n Here's how it works.  \\n You train one classifier per class  \\n where one class is treated as the positive class.  \\n And the other classes are considered negative classes.  \\n For example, say you have an image recognition task.  \\n Your dataset has four classes  \\n the digits zero, one, two, and three.  \\n Your goal is to classify them.  \\n Using the one-vs-rest approach, you break down the task  \\n into four binary classification problems.  \\n Classification problem one is digit zero  \\n versus digits one, two, and three.  \\n Prom two is digit one versus digits, zero, two and three.  \\n And so on.  \\n From there, if you want to classify a new sample  \\n you'd use each of the classifiers.  \\n The model that predicts the highest class probability  \\n is the predicted class.  \\n Let's now see an example of this.  \\n The first thing you have to do is import the libraries  \\n that you want to use.  \\n In this case this notebook uses Matplotlib, pandas  \\n train-test-split, StandardScaler  \\n and of course, logistic regression.  \\n The dataset used in this notebook is a modified version  \\n of the digits dataset  \\n which is arranged into a CSV file for your convenience.  \\n The data consists of pixel intensity values  \\n for 720 images that are Eight by Eight pixels.  \\n Each image is labeled the number from zero to four.  \\n This code here loads into a pandas DataFrame.  \\n Before you create a machine learning model  \\n it's often a good idea to try  \\n to understand your data better.  \\n A great way to do this is to visualize your data.  \\n This code shows a sample of each individual digit  \\n as you can see, the images are rather low resolution.  \\n They're Eight by Eight pixels.  \\n From here, you can split your data  \\n into training and test sets.  \\n Logistic regressions are affected by scale.  \\n So you need to scale your features before using it.  \\n You can transform a data onto unit scale  \\n by utilizing scikit-learn's StandardScaler.  \\n This code creates an instance  \\n of multi-class logistic regression.  \\n Once you try to model,  \\n I encourage you to look at the attributes of a model.  \\n In particular for this model,  \\n I encourage you to look at the intercept and the shape.  \\n One thing to notice here  \\n is that we have four intercepts here.  \\n This is because we had a multi-class problem.  \\n We had binary classifier one, two, three, and four.  \\n The last thing I want you to look  \\n at is how the predictions are made.  \\n If you look at the predictive probabilities  \\n for this one simple digit,  \\n you notice that we have four different probabilities.  \\n We have the first one, the second, the third and the fourth.  \\n This is for class zero, class one, two and three.  \\n Notice that the predicted probability for class one is .98.  \\n What's going to happen here  \\n is it's going to predict class one  \\n because it has the highest probability.  \\n So that's it.  \\n I encourage you to use a logistic regression  \\n for multi-class classification.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2368044\",\"duration\":189,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Decision trees using scikit-learn\",\"fileName\":\"2861087_02_07_XR30_DecisiontreesusingScikitLearn\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Decision trees are a great way to visualize your findings. In this video, learn how to create and tune a decision tree model using the Python library scikit-learn.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7559006,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor ] One of the most important considerations  \\n when choosing a machine learning algorithm  \\n is how interpretable it is.  \\n The ability to explain how an algorithm makes predictions  \\n is useful not only to you,  \\n but also to potential stakeholders.  \\n A very interpretable machine learning algorithm  \\n is a decision tree.  \\n You can think of it as a series of questions,  \\n designed to assign a class or predict a continuous value  \\n depending on the task.  \\n Example image is a decision tree,  \\n designed for classification.  \\n So you have a flower with the following feature,  \\n petal length of 4.5 centimeters.  \\n The way decision trees work  \\n is you start at the top of the tree  \\n and ask questions until you reach these leafy green nodes.  \\n You first has the question is 4.5 centimeters less than  \\n or equal to 2.45?  \\n This is false, so going this other node.  \\n Is 4.5 centimeters less than or equal to 4.95?  \\n This is true, so you'll end up with a leaf node.  \\n Leaf nodes our predictions are assigned.  \\n In this leaf node, there were 38 versicolor and virginica.  \\n Their prediction for this leaf node is versicolor,  \\n as is the majority class.  \\n In this video, I'll share with you  \\n how you can create intuitive decision tree  \\n using Scikit-learn.  \\n The first thing you have to do  \\n is import the libraries that you're going to use.  \\n In this case, you'll import Matplotlib, pandas,  \\n the Iris data set, as well as train-test split,  \\n and decision tree classifier.  \\n This next piece of code loads the Iris data set.  \\n From here, you can split your data  \\n into training and test sets.  \\n What this image shows,  \\n is which variable the data from the day from df one, two  \\n for particular train test split.  \\n This is a really important step  \\n as oftentimes this decision trees overfit the training set.  \\n Train test split will help you avoid that.  \\n It's also important to note  \\n that another benefit of decision trees  \\n is that you don't have to standardize your features.  \\n This is different from other algorithms  \\n like logistic regression, and K nearest neighbors.  \\n From here, you can create a decision tree model.  \\n This model is already imported earlier in notebook  \\n so it's commented out.  \\n The next step is to make an instance of your model.  \\n This is normally a place  \\n where you can tune the hyper parameters of the model.  \\n The code below constraints the model  \\n to have at most a depth of two.  \\n Tree depth is a measure of how many splits it makes  \\n before coming to a prediction.  \\n It's important to note that max_depth  \\n is not always equal to depth.  \\n Max_depth is simply something that pre-prunes a tree  \\n to only grow at most discerned depth.  \\n From here, you can train your model.  \\n I can also make predictions.  \\n You can also measure your model performance.  \\n This notebook uses accuracy as the metric,  \\n which is a fraction of correct predictions.  \\n This section shows how to tune max_depth.  \\n If you look at the graph,  \\n you'll see a couple of things.  \\n The first is that accuracy increases  \\n up to a certain max depth.  \\n There could be a couple reasons for this.  \\n One potential reason  \\n is that max_depth is not necessarily equal to depth.  \\n It's possible that trees  \\n with max_depth four and five have the same depth.  \\n It could also be that after a certain point,  \\n the models not getting any more useful information  \\n after a certain depth.  \\n So that's it,  \\n I encourage you to create a decision tree of your own.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2366778\",\"duration\":125,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How to visualize decision trees using Matplotlib\",\"fileName\":\"2861087_02_08_XR30_HowtovisualizedecisiontreesusingMatplotlib\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are a number of ways to model a decision tree. In this video, learn how to make a visualization based on a decision tree model using the Python libraries scikit-learn and Matplotlib. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4763789,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] How do you understand  \\n how decision tree makes predictions?  \\n One of the strengths of decision trees,  \\n are they're relatively easy to interpret,  \\n as you can make a visualization based on your model.  \\n This is not only a powerful way to understand your model,  \\n but also to communicate how a model works as stakeholders.  \\n In this video, I'll show you how decision trees,  \\n can be plotted with Matplotlid .  \\n The first thing you have to do, is import libraries.  \\n Take note that you're also importing tree.  \\n This is what actually plots to the decision tree.  \\n The next step is a loaded dataset,  \\n in this case is the Iris dataset.  \\n From there, you can split  \\n your data into training and test sets.  \\n This is really important for decision trees, as they tend  \\n to be a high variance algorithm.  \\n What this means, is they tend to overfit  \\n on the training set.  \\n The next step is to create a decision tree model.  \\n Before you can make a visualization based  \\n on a decision tree, you need to make a decision tree first.  \\n So you make an instance of your model,  \\n you train the model on the data,  \\n you can also make predictions and measure model performance.  \\n After you fit a decision tree, you can make a visualization,  \\n based on the model, to do this,  \\n you can utilize tree.plot_tree, with the instance  \\n of a fit model.  \\n This is not a perfect visualization,  \\n there're a couple of reasons why.  \\n The first, it seems a bit small, so let's try to fix that.  \\n This code makes the figure size a bit bigger,  \\n as well as the DPI.  \\n The problem with this image,  \\n is even though the visualization is bigger,  \\n it's still hard to understand what's going on.  \\n The next step is to make the tree more interpretable.  \\n There're a couple of ways to do this,  \\n what you can do, is utilize the feature name parameter,  \\n as well as the class name parameter.  \\n This tree is more interpretable,  \\n there're a couple of reasons why.  \\n First, it's easier to understand the leaf node predictions,  \\n this leaf node predicts the setosa, this one versicolor,  \\n and this one virginica, additionally,  \\n this visualization is more visually appealing, so that's it,  \\n you can visualize decision trees using Matplotlid.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2368045\",\"duration\":120,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Bagged trees using scikit-learn\",\"fileName\":\"2861087_02_09_XR30_BaggedtreesusingScikitLearn\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Bagged trees, or a bagging regressor, are common models in data science. In this video, learn how to create and tune a bagging regressor model using the Python library scikit-learn.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4739896,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Each machine learning algorithm  \\n has strengths and weaknesses.  \\n A weakness of decision trees is that they're prone  \\n over fitting on the training set.  \\n A way to mitigate this problem,  \\n is to constraint how large a tree can grow.  \\n Bagged trees try to overcome this weakness  \\n by using bootstrapped data,  \\n to grow multiple deep decision trees.  \\n The idea is that matrix protect each other  \\n from individual weaknesses.  \\n What this image shows is that multiple decision trees  \\n come together to make a combined prediction.  \\n In this video,  \\n I'll share with you how you can build a Bagged Tree Model.  \\n The first step is to Import Libraries.  \\n The Dataset used in this notebook  \\n is a housing prices for King County.  \\n The code below loads the dataset.  \\n The goal of this dataset is to predict house prices  \\n based on features like number of bedrooms and bathrooms.  \\n This notebook only selects a small subset  \\n of the features for simplicity.  \\n However, if you have time I encourage you to play  \\n with this notebook,  \\n and add and subtract features.  \\n This code is just arranging the dataset  \\n into a features matrix,  \\n and target vector.  \\n From here you can Split the Data into  \\n Training and Test Sets.  \\n The next step is to build a Bagged Trees model.  \\n You import the model that you want to use.  \\n This is actually commented out because it was  \\n used earlier in the notebook.  \\n From here you can make an instance of the Model.  \\n Note that n_estimators is how many  \\n decision trees are coming together  \\n to make a prediction.  \\n Next you can train the model on the data,  \\n as well as make predictions.  \\n You can also measure model performance.  \\n For a Bagged Trees Regressor.  \\n You can use a metric R squared.  \\n The code below tunes and estimators,  \\n which in this case is the number of decision trees.  \\n This code can take some time to run.  \\n As you have multiple estimators coming together  \\n to make a prediction.  \\n In the graph notice that their score starts improving  \\n after a certain number of estimators.  \\n There could be a couple reasons for this.  \\n One potential way to get a better score,  \\n would be to include more features  \\n in the features matrix.  \\n So that's it.  \\n I encourage you to try building up Bagged Trees model.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2368046\",\"duration\":161,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Random forests using scikit-learn\",\"fileName\":\"2861087_02_10_XR30_RandomforestsusingScikitLearn\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The random forest models are the construction of a multitude of decision trees. In this video, learn how to create a random forest model using the Python library scikit-learn as well as visualize individual trees from random forest models.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6695222,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Each machine learning algorithm  \\n has strengths and weaknesses.  \\n Bagged tree models use many trees  \\n to protect individual decision trees from overfitting.  \\n However, bagged tree models are not without weaknesses.  \\n Suppose you have one very strong feature in a data set,  \\n most of the trees will use that feature as the top split.  \\n This will result in many similar trees.  \\n You can think of random forest  \\n as a variant of a bagged tree model.  \\n The difference is that each time a split's considered,  \\n only a portion of the total number of features  \\n are split candidates.  \\n In short, random forests make the individual decision trees  \\n less correlated  \\n In this video, I'll share with you  \\n how you can build a random forest model using Scikit-Learn.  \\n The first step is to import libraries.  \\n The next step is to load a dataset.  \\n This dataset contains house sale prices for King County.  \\n The code below loads the dataset.  \\n The goal of this dataset is to predict house prices  \\n based on features like number of bedrooms and bathrooms.  \\n The code in this notebook only selects five features  \\n to make a prediction.  \\n This notebook only selects a couple of features  \\n for simplicity.  \\n However, I encourage you to play with adding  \\n and subtracting features.  \\n You can now create a features matrix and a target factor.  \\n The next step is to split your data  \\n into training and test sets.  \\n From here, you can build a random forest model.  \\n After importing the model,  \\n you can make an instance of the model.  \\n This is a place where you can tune hyperparameters.  \\n In the case of random forest, you have N_estimators.  \\n What N_estimators is, is how many decision trees you have  \\n coming together to make a prediction.  \\n From here, you can train your model and make predictions.  \\n It's important to note,  \\n that the training of a random forest model  \\n can take some time.  \\n In this case you have 100 estimators  \\n that need to be trained  \\n and come together to make a prediction.  \\n The next step is to measure your model's performance.  \\n In this case, the score method uses R squared as a metric.  \\n Since bagged tree and random forest models  \\n are ensemble models,  \\n you can visualize individual decision trees  \\n comprising those models.  \\n Here's the first decision tree  \\n of 100-estimator bagged tree model.  \\n You can also visualize individual decision trees  \\n for a random forest model.  \\n One of the benefits of using a random forest model  \\n is that they can give you a feature importance metric.  \\n Feature importance metrics can give you an idea  \\n of what features were important  \\n in making predictions for your model.  \\n In this example, the random forest is suggesting  \\n that pedal length was the most important feature.  \\n So that's it.  \\n I encourage you to build a random forest model.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2367246\",\"duration\":83,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Which machine learning model should you use?\",\"fileName\":\"2861087_02_11_XR30_WhichmachinelearningmodelshouldIuse\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are tons of machine learning models that you can use to visualize your data. In this video, learn how to determine which method is best used for which desired outcome. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3252642,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] With so many machine learning  \\n algorithms available from scikit-learn,  \\n which algorithm should you choose?  \\n Selecting a good enough model from among a large number  \\n of possible machine learning models is one  \\n of the hardest parts of machine learning.  \\n Some algorithms are better suited  \\n to different types of data and problems.  \\n Luckily, a quick answer to model selection  \\n with scikit-learn is, use the algorithm cheat sheet.  \\n It's meant to give you a rough guide  \\n in how to choose an algorithm.  \\n From the start point,  \\n you first ask, do you have more than 50 samples?  \\n From there, you keep on answering questions  \\n until you get an idea of what you should try.  \\n If you don't use the cheat sheet,  \\n here are a few things to consider when choosing a model.  \\n The first thing is a problem you're trying to solve.  \\n For example, if you have a supervised learning problem,  \\n figuring out if you're trying to predict a continuous  \\n or categorical value can be an important first step.  \\n Next, always consider the size,  \\n quality, and structure of your data.  \\n There's no machine learning without data.  \\n You should also consider the strengths and weaknesses  \\n of each algorithm you're considering.  \\n It's especially important,  \\n as some algorithms take longer to make predictions.  \\n Also, more complex models  \\n are often more difficult to maintain.  \\n Finally, consider the urgency of a task.  \\n Some models take longer to train and tune.  \\n Now, if you're feeling a little shaky,  \\n you're not quite sure which model to choose,  \\n don't worry, you've got this.  \\n I now encourage you to try a couple models  \\n and learn from the process.  \\n \\n\\n\"}],\"name\":\"2. Supervised Learning\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2368049\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2353857\",\"duration\":75,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What is unsupervised learning?\",\"fileName\":\"2861087_03_01_XR30_Whatisunsupervisedlearning\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Unsupervised learning relies more on artificial intelligence and less on human intelligence. In this video, learn how to determine when unsupervised learning is most useful. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1992763,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In machine learning,  \\n you aren't always tryna predict the value.  \\n Sometimes your goal is to find some structure  \\n in your dataset.  \\n Unsupervised learning is when you train an algorithm  \\n without giving it the answers for examples in your dataset.  \\n In the context of psychic learn,  \\n this means that you only provide a features matrix  \\n when you fit your algorithm.  \\n A features matrix is a two-dimensional grid of data  \\n where rows represent samples and columns represent features.  \\n Unlike supervised learning, there's no target factor.  \\n It's important to emphasize that unsupervised algorithms  \\n don't make predictions from the data.  \\n There are two common types  \\n of unsupervised learning algorithms.  \\n The first is clustering.  \\n Clustering is often used to discover natural groupings  \\n in a dataset, when common use is for market segmentation.  \\n Companies often have large amounts of customer information.  \\n By clustering customers into different segments,  \\n they can more efficiently sell  \\n or market to their customers.  \\n Another common type of unsupervised learning  \\n is dimensionality reduction.  \\n You can think of dimensionality reduction techniques  \\n as data compression algorithms.  \\n They can make your data take up less space on your computer.  \\n Having less features in your data can make visualizing  \\n your data easier as well speed up the fitting  \\n of your machine learning algorithms.  \\n So that's it.  \\n Unsupervised learning helps  \\n you discover structure in your data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2366779\",\"duration\":148,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"K-means clustering\",\"fileName\":\"2861087_03_02_XR30_Kmeansclustering\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"K-means clustering is a method of vector quantization. In this video, learn how to create a K-Means model using the Python library scikit-learn to find some structure in your data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5560618,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Clustering algorithms  \\n have identified this thing groups of data.  \\n One example is who's clustering the group customers  \\n based on their behavior.  \\n There are so many clustering algorithms.  \\n But the most commonly used algorithm is K-Means.  \\n In this video, I'll show you how to use K-Means Clustering  \\n to find some underlying structure in your data.  \\n The first step is to import libraries.  \\n The next step is to load a dataset.  \\n This notebook uses the Iris data set.  \\n From there, you can arrange your data  \\n into a features matrix.  \\n It's important to note that K-Means  \\n is considered unsupervised learning algorithm.  \\n This means that you only need a features matrix.  \\n In the Iris data set, there are four features.  \\n In this notebook, the features matrix  \\n will only be two features,  \\n as it's easier to visualize clusters in two dimensions.  \\n It's important to mention  \\n that you do not eat a target factor,  \\n as this is an unsupervised learning algorithm.  \\n Like a lot of different algorithms,  \\n K-Means is sensitive to the scale of your data.  \\n To standardize your data,  \\n you can use Scikit-Learns StandardScaler  \\n to help standardize your features.  \\n Before you cluster your data, it's often a good idea  \\n to try to understand your data better.  \\n If your data is two or three dimensional,  \\n it's a good idea to at least try to visualize your data.  \\n Hopefully you can see if there's a natural looking clusters.  \\n From this graph,  \\n it looks like there's at least two clusters.  \\n You can now apply K-Means Clustering.  \\n In K-Means clustering,  \\n you can specify the number of clusters you want.  \\n In Scikit-Learn, this parameter is called N-Clusters.  \\n In the case of the code below,  \\n the number of clusters is at three,  \\n because most people who use this data set  \\n happen to know that there are three species.  \\n After you fit your model on the features matrix,  \\n you can get the cluster labels  \\n as well as the cluster centroids.  \\n Let's now visually evaluate the clusters.  \\n Here are your three clusters.  \\n You have cluster one, cluster two and cluster three.  \\n Let's now see how well instead,  \\n compared to the Iris data sets labels.  \\n There are a couple things you notice  \\n when you look at the two graphs.  \\n On the left, you have the K-Means clustering graph,  \\n on the right you have the flower species.  \\n They actually look pretty similar.  \\n It looks at K-Means picked up some flower differences  \\n with only two features and not the labels.  \\n The colors are different in the two graphs,  \\n simply because K-Means is on arbitrary cluster number,  \\n and the Iris data set said has an arbitrary number  \\n in the target column.  \\n So that's it.  \\n K-Means is a clustering algorithm  \\n that you can use to find some structure in your data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2366780\",\"duration\":133,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Principal component analysis (PCA) for data visualization\",\"fileName\":\"2861087_03_03_XR30_PCAfordatavisualization\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Principal component analysis, PCA, is a critical tool for dimensionality reduction and visualization. In this video, learn how to perform PCA for data visualization using the Python library scikit-learn.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5022077,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Are all the features in our dataset needed?  \\n Say you have some flowers  \\n and you measure their petal length.  \\n If you have a column of that measurement in centimeters,  \\n and another column with measurement in inches  \\n do you need both columns?  \\n In that circumstance,  \\n you could probably drop either column  \\n without losing information.  \\n In other cases dropping a column could lead to issues.  \\n Principal Component Analysis  \\n better known as PCA.  \\n Is a technique that you can use  \\n to smartly reduce the dimensionality of your dataset  \\n while losing the least amount of information possible.  \\n One use of PCA, is for data visualization.  \\n In this video,  \\n I'll share with you how you can use PCA  \\n to help visualize your data.  \\n The first step is to import libraries.  \\n From there, you can load your dataset.  \\n The dataset used in this notebook is the hours dataset.  \\n The next step is to standardize your data  \\n PCA like a lot of different algorithms is affected by scale.  \\n You can transform your data onto unit scale  \\n by using scikit-learn standard scaler.  \\n Note,  \\n that PCA is an unsupervised learning algorithm.  \\n What this means is that when you use the fit step,  \\n you only fit it on your features matrix.  \\n From here, you can apply PCA  \\n the code below projects the original data  \\n which is four dimensional into two dimensions.  \\n Note that after you applied dimensionality reduction,  \\n there usually isn't a particular meaning assigned  \\n to each principal component.  \\n The new components  \\n are just the two main dimensions of variation.  \\n The next step creates a visualization  \\n of the first two principle components.  \\n One thing to note from the graph  \\n is that the Setosa class  \\n is well separated out from the other classes.  \\n One thing to look after PCA  \\n is the explained variance.  \\n What this shows is how much variance can be attributed  \\n to each of the principal components.  \\n This is important.  \\n As well, you can convert  \\n four dimensional space to two dimensional space.  \\n You lose some of the information when you do this.  \\n You can look at how much information  \\n is attributed to each of the principle components  \\n by using the explained variance ratio.  \\n These two principle components contain roughly  \\n 96% of the information in the dataset.  \\n The first component contains roughly 73%  \\n and the second one contains roughly 23%.  \\n So that's it.PCA can be used to help visualize your data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2368047\",\"duration\":161,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"PCA to speed up machine learning algorithms\",\"fileName\":\"2861087_03_04_XR30_PCAtospeedupmachinelearningalgorithms\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Unsupervised learning can benefit greatly from PCA. In this video, learn how to perform PCA using the Python library scikit-learn to speed up machine learning algorithms.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6220579,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Do you want to speed up the fitting  \\n of your machine learning algorithm?  \\n Second learn offers quite a few ways to do this.  \\n One way is to train your model in parallel using n_jobs  \\n parameter, which exists for many psychic learn models.  \\n A really simple way is to reduce the number of columns or  \\n rows in your data.  \\n The problem with this approach is it's hard to know which  \\n rows and especially which columns to remove.  \\n Principle Component Analysis,  \\n commonly known as PCA is a technique that you can use to  \\n smartly reduce the dimensionality  \\n in your data while losing the  \\n least amount of information possible.  \\n In this video,  \\n I'll share with you the process of how you can use PCA to  \\n split the fitting of a logistic regression model.  \\n The first step is to import libraries.  \\n The next step is loaded dataset.  \\n The dataset is a modified version of the MNIST dataset  \\n that contains 2000 labeled images  \\n of each digit zero and one,  \\n the images are 28 pixels by 28 pixels. For your convenience,  \\n it's been arranged into a CSV file  \\n before you apply PCA or a machine learning model.  \\n It's often a good idea to try to visualize your data.  \\n The Coppola shows a sample image of each digit zero and one.  \\n The next step, it says, put your data  \\n into training and test sets  \\n before continuing it's important to standardize your data.  \\n PCA and logistic regression  \\n are sensitive to the scale of your features.  \\n You can standardize your data onto unit scale by using a  \\n psychic learns standard scaler.  \\n This next piece of code applies PCA and logistic regression.  \\n For the code here, note that n components equals 0.9.  \\n It means it's psychic learn  \\n we'll choose a minimum number of principal components such  \\n that 90% of the variance is retained  \\n From here, you fit PCA in the training set  \\n After that, you apply the mapping to  \\n both the train set and the test set.  \\n The final step is to create a logistic regression model.  \\n When you run this code,  \\n First, the number of dimensions before PCA is 784.  \\n This is because the original images  \\n were 28 pixels by 28 pixels and 28 times 28 is 784.  \\n The number of dimensions after PCA was 104.  \\n Additionally, the classification accuracy  \\n with this model was very high.  \\n So even after removing a lot dimensions going from 784  \\n dimensions to 104, the model still worked pretty well  \\n for this particular dataset.  \\n You can look at the relationship between cumulative  \\n explained variance and number of principal components.  \\n One thing to notice in this graph is that after roughly 150  \\n to 200 dimensions, there wasn't a lot of explained variance  \\n in the remaining principal components.  \\n So that's it.  \\n PCA can be used to speed up the fitting of your algorithm.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2368048\",\"duration\":125,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"scikit-learn pipelines\",\"fileName\":\"2861087_03_05_XR30_ScikitLearnpipelines\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Pipelines can reduce the chances of error in your code. In this video, learn how to create pipelines using the Python library scikit-learn to make your code cleaner and more resilient to bugs.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4262686,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Machine learning  \\n is not always about applying  \\n a single machine learning algorithm.  \\n For a lot of machine learning applications,  \\n you'll need to apply various data processing steps,  \\n data transformations,  \\n and potentially multiple machine learning algorithms.  \\n This can lead to a lot of code.  \\n The question becomes, how do you keep your code organized  \\n and as bug free as possible?  \\n In this video, I'll share with you how you can use  \\n Pipelines in Scikit Learn to make your code cleaner  \\n and more resilient to bugs.  \\n To demonstrate the utility of Pipelines,  \\n this notebook shows how much less code you need  \\n to chain together PCA and logistic regression  \\n for image classification.  \\n Before getting to that though,  \\n you need to import the libraries that you're going to use.  \\n The dataset using this notebook  \\n is a modified version of the MNIST dataset  \\n that contains 2000 labeled images  \\n of each digit, zero and one.  \\n The images are 28 pixels by 28 pixels.  \\n For convenience, I arranged the data into a CSV file.  \\n This code loads the data into a panda's DataFrame.  \\n This code is a chaining together  \\n of PCA and logistic regression.  \\n It's quite a bit of code.  \\n The first step is a train_test_split.  \\n From there, there's a standardization step.  \\n Notice that there's a fit step here,  \\n as well as when you apply PCA and logistic regression.  \\n There's quite a few places where an error can occur  \\n as there's quite a bit of code.  \\n Let's now try to do this with Pipelines.  \\n The first step as before is a train_test_split.  \\n The next step is creating a Pipeline.  \\n You still data scalar, PCA and logistic regression.  \\n You can also name the steps,  \\n you have scalar, PCA and logistic.  \\n Note, you still have fit step,  \\n but unlike before you don't have three of them.  \\n Another advantage of using Pipelines  \\n is you can visualize your Pipeline.  \\n You can see all the steps your machine learning model took  \\n to get to the end.  \\n So you have a Standard Scalar,  \\n you have PCA and logistic regression.  \\n So that's it.  \\n Pipelines can make our code more organized  \\n and easier to understand.  \\n \\n\\n\"}],\"name\":\"3. Unsupervised Learning\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2367247\"}],\"size\":0,\"duration\":2637,\"zeroBased\":false},{\"course_title\":\"Applied Machine Learning: Algorithms\",\"course_admin_id\":3806104,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3806104,\"Project ID\":null,\"Course Name\":\"Applied Machine Learning: Algorithms\",\"Course Name EN\":\"Applied Machine Learning: Algorithms\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;With the growing importance of machine learning in almost every sector, professionals need a deeper understanding and practical approach to implementing ML algorithms effectively. &lt;/p&gt;&lt;p&gt;This course covers commonly used machine learning algorithms. Instructor Matt Harrison focuses on non-deep learning algorithms, covering PCA, clustering, linear and logistic regression, decision trees, random forests, and gradient boosting. &lt;/p&gt;&lt;p&gt;Join Matt in this course to understand common ML algorithms, learn their pros and cons, and develop hands-on skills to leverage them by following along with challenges and solutions in GitHub Codespaces.\",\"Course Short Description\":\"Learn about common machine learning algorithms, their pros and cons, and develop hands-on skills to leverage them.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":9254436,\"Instructor Name\":\"Matt Harrison\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Python and Data Science Corporate Trainer, Author, Speaker, Consultant\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-04-15T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/applied-machine-learning-algorithms-23750732,https://www.linkedin.com/learning/applied-machine-learning-algorithms-revision-2024-q2\",\"Series\":\"Deep Dive (X:Y)\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":7083.0,\"Visible Video Count\":32.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":113,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5903617\",\"duration\":49,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Applied machine learning: Algorithms\",\"fileName\":\"3806104_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Editors, this is a workspace cam video\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":117,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3806205,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Do you have data that you want to make sense of?\\nMaybe you want to make predictions,\\nthen you've come to the right place.\\nMachine learning allows us to cluster data, derive insights,\\nand make predictions,\\nand it isn't just for PhDs and tech giants.\\nIn this course, you'll get hands-on practice\\nusing powerful libraries and tools like Pandas,\\nScikit-Learn, XGBoost, and Jupyter.\\nWe'll introduce the algorithms, show how to use them,\\nand then let you try them out.\\nWe'll explore clustering principle component analysis,\\nand making predictions\\nwith both classification and regression.\\n\\nI'm Matt Harrison, a corporate trainer and author.\\nI've written multiple books on Python and data science\\nand helped thousands learn these topics.\\nNow you get to learn these algorithms with me.\\nLet's get going.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5905599\",\"duration\":64,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you should know\",\"fileName\":\"3806104_en_US_00_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Editors, this is a workspace cam video. Please add lower third in the following timecodes.\\n1) 00:33 (Fundational understanding of Python)\\n2) 00:46 (Jupyter Notebook)\\n3) 01:12 (Basic statistics and algebra).\\nNo need for additional visuals, some punch in would be sufficient if necessary.\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":93,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4074438,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Before embarking on this journey,\\nthere's a few prerequisites\\nthat will help maximize your learning experience.\\nFirst, a foundational understanding of Python is important.\\nWhile you don't need to be an expert,\\nfamiliarity with basic programming constructs like\\nvariables, loops, and functions,\\nis really important for this course.\\nSecond, experience with Jupyter Notebooks\\nis really beneficial.\\nJupyter provides a web-based, interactive computing platform\\nthat enables you to write code, visualize data,\\nand share insights in a single document.\\n\\nIt's invaluable for data science\\nand machine learning projects.\\nLastly, a basic grasp of statistics\\nand linear algebra will aid your comprehension of\\nhow machine learning algorithms work under the hood.\\nUnderstanding concepts like mean, standard deviation,\\nmatrix multiplication will equip you\\nwith the skills you need\\nto grasp complex machine learning concepts.\\nWith these skills in your arsenal, you're ready\\nto dive into the world of machine learning algorithms\\nand solve real world problems.\\n\\n\"}],\"name\":\"Introduction\",\"size\":7880643,\"urn\":\"urn:li:learningContentChapter:5905603\"},{\"duration\":2097,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5904635\",\"duration\":466,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"K-means\",\"fileName\":\"3806104_en_US_01_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":591,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn about the fundamental workings of the KNN algorithm and its application in classification and regression tasks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17297610,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this video, we're going to talk\\nabout clustering.\\nSpecifically, we're going to talk about K-means clustering.\\nAnd K-means clustering is what we call\\nan unsupervised machine learning algorithm\\nto make clusters from data.\\nThe unsupervised portion means that we are going\\nto feed data in, we're not going to provide any labels,\\nand the algorithm,\\nbased on the data that we passed in,\\nwill do some processing.\\nIn this case, it will give us cluster labels.\\nThere are other machine learning algorithms\\nthat are unsupervised,\\nwe'll look at another one called PCA.\\n\\nPCA is also unsupervised,\\nthat means it doesn't have labels that come in with it,\\nit just has the data,\\nand PCA will do dimension reduction.\\nSo the algorithm for K-means clustering is as followed.\\nWe're going to choose a k where k is the number of clusters,\\nand then what happens is the algorithm\\nwill choose three points from the data that we passed in\\nand it will go through and label the points\\nthat are closest to each of those clusters,\\nit calls the clusters centroids.\\n\\nAfter it's gone through labeling those,\\nit will recenter the centroids.\\nIt will go through everything\\nthat's labeled in cluster one.\\nIt will move the centroid to the middle of that cluster.\\nEverything for cluster two,\\nsame thing, will move the centroid.\\nAnd then after it's moved the centroid,\\nit repeats the algorithm,\\nmeaning it goes and finds the points\\nthat are closest to each centroid.\\nAnd it does that, and eventually\\nthe centroids come to a common state.\\nI'll show you an example right here.\\nSo here we're using the scikit-learn library,\\nand it has clustering in it.\\n\\nLet me walk through the code.\\nAt the top we have our imports.\\nWe're going to be using the KMeans library.\\nWe're also importing the datasets library\\nto load the Iris dataset,\\nand we're going to be using Matplotlib to do some plotting.\\nWe'll load the Iris dataset\\nand make a variable called dataset.\\nAnd then I'm going to make a variable called \\\"X\\\".\\nCapital X is a common convention\\nthat you'll see used throughout the scikit-learn library.\\nIn linear algebra,\\na capital variable is used to describe a matrix\\nor a two-dimensional group of data with rows and columns.\\n\\nAnd that's a common convention\\nthat you'll see in scikit-learn.\\nWhen we're passing our data into scikit-learn,\\nit's generally in two dimensions, rows and columns.\\nSo each row represents a sample,\\nand then you can have columns of features\\nthat describe what is in the data.\\nYou can also have a Y dataset.\\nY is used for supervised learning.\\nIn this case, the dataset that we have,\\nwhich is the Iris dataset,\\nis a classic dataset for machine learning.\\nIt's got 150 rows,\\neach row represents a different flower\\nfrom the Iris family,\\nand there are three different types of flowers:\\nVirginica, setosa, and versicolour.\\n\\nAnd there are a few features in the X variable\\nthat describe the shape and dimensions\\nof the petals and the sepals\\nof each of those 150 flowers.\\nThe next thing I'm going to do\\nis I'm going to make a list of my centroids,\\nand then I'm just going to loop over 10 times.\\nI'm going to run this algorithm I just talked about\\n10 times in this little for loop down here.\\nSo you can see at the top, I am making a model,\\nand I'm saying I want to have three clusters in here,\\nand I'm initializing the KMeans algorithm.\\n\\nThen I'm going to call model.fit.\\nOne of the nice things about scikit-learn,\\nand we'll be using it throughout this course,\\nis that it has a consistent interface.\\nSo once you learn that interface,\\nit's really easy to use.\\nUnsupervised learning algorithms will use fit,\\nand you'll just pass in X along with that.\\nFor supervised learning algorithms,\\nwhich we'll see later,\\nyou will call fit with both X and Y.\\nThe next thing we're going to do\\nis we're going to predict our labels.\\nAnd because this is a prediction algorithm,\\nit can make predictions,\\nwe're going to pass in our X,\\nand it will give us out a label for each row.\\n\\nAgain, scikit-learn uses the same interface\\nall over the place.\\nWe'll see when we do classification of regression models,\\nthey will also have a predict method.\\nThis is really nice because when you understand\\nthe basics of scikit-learn,\\nit uses a consistent interface all over the place\\nand it will make your life a lot easier.\\nThe next line, we're going to create\\na Matplotlib figure and axis,\\nand then I'm going to plot,\\non top of that, a scatter plot.\\n\\nI'll also pull out the cluster centers.\\nYou can see that I'm saying model.cluster_centers_.\\nOne thing to note in scikit-learn\\nis that attributes ending in underscore\\nare learned when we call fit.\\nSo when we call fit up above,\\nit determined where those cluster centers are.\\nI'm also going to plot those as a star on my plot.\\nAnd I'm going to make a title for my plot,\\nit's called \\\"iteration\\\", what iteration I'm on.\\nAnd then I'm also going to,\\nif my i, if my round is greater than zero,\\nI'm going to plot the previous centroids.\\n\\nAnd then at the end of my for loop,\\nI'll just keep track of my centroids.\\nSo what this is going to show us\\nis that as we move through the algorithm,\\nthe centroids will move along as well.\\nAnd then at the end, outside of the for loop,\\nI will just plot the original data,\\nso you can see that compared to what's going on here.\\nLet's run this.\\nIf you're not familiar with using VS Code and Notebooks,\\nall you have to do to run this\\nis you can hit this little triangle up here.\\n\\nI like to just hold down Control and hit Enter.\\nYou can see at the top\\nthat we've got a little bar indicating that it is running,\\nand then we'll scroll down here.\\nOkay, so it looks like it just ran.\\nAnd here's our plots.\\nWe should have a series of plots.\\nHere's the first iteration.\\nYou can see that I have three stars here\\nand we have green labels, we have purple labels,\\nand then we have yellow labels.\\nSo this is the first iteration.\\nAfter we've done this iteration,\\nwhat's going to happen is the star will move,\\nit will center inside of the labels.\\n\\nAnd so you can see that in the next iteration,\\nyou can see that the stars have migrated a little bit,\\nand you can also see that the boundaries\\nbetween those different clusters have moved as well.\\nHere's another iteration.\\nYou can see that we're just slowly shifting\\nthose centroids a little bit.\\nAnd I'll just scroll down to the bottom here.\\nYou can run this on your own\\nand look at what's happening at the individual levels.\\nBut here is the original data.\\nAnd in the original data,\\nthis is colored by the target.\\n\\nNote that I did not include the target in my data\\nthat I passed into the algorithm,\\nI just passed in the dimensions.\\nBut here I have the dimensions,\\nand I'm labeling these\\nby the type of Iris that it is,\\nremember there's three different types there.\\nAnd you can see on the upper left, there's one type,\\nin the middle, we have that green type,\\nand there's some overlap there\\nwith the yellow type on the right.\\nHowever, if you look up above here,\\nour clustering algorithm did a decent job.\\nIt's not perfect, but it did seem\\nto do a decent job getting the upper left group classified.\\n\\nAnd it's not able to do\\nthe overlapping that we see at the bottom,\\nbut it does a decent job.\\nOkay, and this video I gave an introduction\\nto the K-means clustering algorithm.\\nThis is a unsupervised algorithm\\nthat you can pass in data in.\\nYou can tell how many clusters you want,\\nand it will return labels for pieces of data\\nthat are in the same cluster.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5904636\",\"duration\":490,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"K evaluation\",\"fileName\":\"3806104_en_US_01_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":626,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to master the technique of selecting the optimal number of neighbors (K) for improved model performance.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16929638,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In the previous video,\\nwe introduced the K-means Clustering Algorithm.\\nAnd one of the things we said, when you run this algorithm,\\nyou need to provide a K or a number of clusters.\\nYou might wonder, \\\"How do I get those clusters?\\nWhat is the number of clusters?\\\"\\nSo in this video, I'm going to show you a few mechanisms\\nfor determining what might be a good value for K.\\nOftentimes, we don't know that ahead of time,\\nso we want to determine that.\\nHere's the basic thing that we're going to do.\\nWe're going to try different values of K\\nand keep track of some metric and see which value of K\\ngives us the best clustering for given metric.\\n\\nAnd specifically, I'm going to show you two mechanisms here.\\nOne is called the Elbow Method,\\nwe're going to track what's called the Inertia,\\nand the other one is called the Silhouette Coefficient.\\nBoth of these are a little bit different.\\nLet's walk through the Elbow Method first.\\nSo the Elbow Method, the idea here is when we run K-means,\\nK-means has an attribute called Inertia_\\nyou can see in my little FOR LOOP here,\\nI'm keeping track of the Inertias,\\nand I'm pulling it off of km.inertia_.\\n\\nRemember that underscore,\\nany attribute ending in underscore,\\nis learned by doing fit.\\nSo we're looping over different values of K here,\\nand we're keeping track of those Inertias.\\nAnd then what I'm going to do is I'm just\\ngoing to plot those.\\nSo we'll let those run.\\nAnd while that's running, I'll explain what the Inertia is.\\nSo the Inertia Score is the sum of the square\\nof the distances from the centroid to each point.\\nSo if each point is very close to the center,\\nthose squared distances will be small.\\n\\nAs they get bigger,\\nthat means that your clusters are more spread about.\\nSo here's our plot here.\\nYou can see along the bottom,\\nwe have the number of clusters,\\nand on the left hand side we have the Inertia.\\nNow, there's kind of an art and science\\nto interpreting this.\\nWe call this the Elbow Method,\\nbecause oftentimes, these plots kind of look like a bent arm\\nwith the elbow in the lower left.\\nThe idea here is as you're going along,\\nif you're losing a lot of Inertia, that's great.\\n\\nBasically that means that your clusters are getting tighter.\\nAt some point, you don't have as many gains\\nwhen you add more clusters.\\nAnd so what you want to do is when you stop getting\\na lot of gains, you choose to stop adding more clusters.\\nI think of this as we want to make our model\\nas simple as possible.\\nSo if I can have a model with fewer clusters,\\nthat's a little bit simpler than a model\\nwith a lot of clusters.\\nAlternatively, you would take an angled ruler\\nand move it along\\ntowards the right.\\n\\nAnd when you tap the corner or the elbow,\\nthat's kind of a good spot to stop.\\nIn this case, we might think that somewhere,\\nif this ruler or shape is going along in this direction\\nand we shift it to the right,\\nit's going to tap probably somewhere here,\\naround three or four.\\nYou can see that as we go from one cluster to two clusters,\\nwe have a lot tighter clustering.\\nEven as we go to three, it gets better,\\nand then it starts to give diminishing returns.\\n\\nI'm going to show now the Silhouette Visualizer.\\nThis comes from a library called, Yellow Brick.\\nIf you've installed the requirements\\nthat are included in the Repository, you should have that.\\nOne thing to be aware of is if you're inside of Jupyter,\\nyou can put a question mark out or something,\\nand pull up the documentation.\\nIt turns out that most of these libraries\\nwe're going to look at have pretty good documentation.\\nSo this visualization will create a visualization\\nof the Silhouette Coefficient.\\nThis is a score between negative one and one.\\n\\nPoints that have a score of one\\nindicate that they are very close\\nto the center of the cluster.\\nPoints that are negative one are samples that are far away.\\nLet me show you an example and it might make more sense.\\nI'm also going to tell matplotlib about some plots,\\nso it doesn't complain so much here.\\nSo that's what these cells are doing.\\nOkay, so we're going to, in this case, just loop over up\\nto zero to five clusters\\nand we're going to make these Silhouette Plots here.\\n\\nThis plot takes a little bit of explanation\\nto understand what's going on here.\\nAlong the bottom, we have that Silhouette Score.\\nAgain, that goes from negative one to one.\\nThe closer it is to one, the better it is.\\nAnd why are these kind of shaped like knives?\\nWell, what's going on here is on the left\\nit says Cluster Label, but we actually have,\\nyou can think of this as a slice,\\nand each individual point here is a slice in the cluster.\\n\\nSo at the top of this green one, there's a thin slice,\\na thin horizontal slice,\\nand that would be the point that's probably closest\\nto the center of the cluster.\\nAnd then we're going to put each individual point\\nas a slice below that,\\nas they're getting further away from the center.\\nWhat you want to see with these clusters\\nis that they are closer to one\\nand that they sort of bulge out.\\nIf the cluster was a rectangle that came straight down\\nand over and the score was at one, these would be points\\nthat all overlapped in the middle of the cluster.\\n\\nThis is a pretty good clustering.\\nIt looks like we're having a pretty good shape.\\nGenerally, you'll see a shape that looks kind of like this.\\nIt looks kind of like a knife or a butter knife, maybe.\\nWe also see this red dashed line in the middle.\\nThat's the Average Silhouette Score.\\nSo that's another way to interpret this.\\nGenerally, the school of thought is you want these knives\\nor plots to be poking through that average.\\nIf a cluster is not coming up to the average,\\nthat might indicate that it's bad clustering.\\n\\nOkay, so that is with two clusters.\\nLet's look at three.\\nAnd you can see when we go to three,\\nour average score goes down a little bit.\\nAnd you can also see that the shape of our clusters\\nare more pointy.\\nWe actually don't want them to be more pointy.\\nWe actually like them\\nto bulge out like they do in the two clusters up here.\\nAnd if you think about it from our previous plot\\nthat we did in the last video, there's really a strong case\\nto be made for two clusters,\\nbecause there's that cluster in the upper left\\nand then there's the overlapping cluster in the bottom.\\n\\nLet's look at four points.\\nAnd we can see that the average for four points,\\nthe average score goes down.\\nYou can also see that these are getting more pointy,\\nand again, we really don't want them to be pointy.\\nWe want them to be more bulgy.\\nHere's with five points, again, the average is going down.\\nYou can see at the bottom left of this blue one,\\nwe've got some negative scores.\\nMistake, that would indicate that we have outliers\\nor points that are far away from the center of the cluster.\\n\\nAnd then you can see as we add six,\\nit actually goes back up a little bit, the average score.\\nAnd here's seven, it goes back up a little bit for that.\\nSo one of the hard things with clustering\\nis that there aren't any hard answers.\\nIt's a little bit fuzzy.\\nIf I were looking at the Silhouette Plot,\\nI would choose two clusters for this.\\nIf I was looking at our Inertia Score,\\nI would probably choose three or four clusters.\\nIn this video, we discussed how we can determine the number\\nof K to choose for clustering.\\n\\nAnd again, this is a little fuzzy.\\nSo one of the things I like to tell Data Scientists\\nis that you need to be able to explain and justify\\nyour reasonings for choosing what you did.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5903618\",\"duration\":479,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understanding clusters\",\"fileName\":\"3806104_en_US_01_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":527,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Gain insight into how KNN clusters data points and the underlying patterns in the dataset.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":18009512,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this video,\\nwe're going to look at understanding our cluster results.\\nOne of the key things for someone who's working with data\\nis to be able to communicate their results,\\nand clustering is great that we can make clusters,\\nbut often what's even more important is to explain\\nwhat those clusters represent.\\nSo there's a couple mechanisms that we can use.\\nSome of the more popular ones would be\\nto create what's called a surrogate model.\\nThat's a model that can predict things,\\nand so what we'll do is we'll take our data\\nand we'll have it predict our labels\\nor train it to predict labels\\nand then explain why it predicted those labels.\\n\\nAnother thing that you can do is you can summarize\\nthe clusters just using some Pandas code.\\nYou can also visualize the clustering results\\nin two or three dimensions.\\nI'm not going to be doing the visualization here\\nbecause the dataset that we're going to be using\\nhas a few more than two dimensions.\\nBut when we talk about PCA,\\nyou could use PCA to reduce your dimensions\\ndown to two or 3D,\\nand that would be a great way to explain or visualize that.\\nNow I'm going to be using this datasets library.\\nMake sure you install that if you haven't already.\\n\\nWe're going to load some electricity usage data from Australia\\nusing that datasets library.\\nOnce we've done that,\\nyou can see we have this electricity object.\\nThis looks kind of like a dictionary,\\nso we'll pull off the train value from that\\nand I'll just look at what's in there.\\nI'm not super familiar with the interface here\\nbecause it's not a common one,\\nbut if you look in here,\\nyou can see that we can say to_pandas here.\\nSo I'm going to say let's make a Pandas data frame from that.\\nOkay, now we're in a good place,\\ngenerally when we're using the Scikit-learn library,\\nwe like to use Pandas.\\n\\nNow on the right hand side,\\nwe can see that there is a class.\\nIf you're trying to predict things with this,\\nyou might want to predict whether that goes up or down.\\nIn this case, we're not doing that prediction,\\nso I'm actually going to drop that class\\nand I'm going to make my X without that.\\nOkay, so again, I'm going to make some clusters\\nand try and explain what's going on.\\nI don't even know how many clusters to make.\\nSo I'm going to go through my process here.\\nI'll just loop over from zero to 19\\nand see what that looks like with my inertias.\\n\\nAnd if I'm going to use this mechanism again,\\nremember I'm going to have like a angled line here\\nand I'm going to move it over probably somewhere\\naround five is the number\\nof clusters I would choose for this.\\nLet's do our silhouette plot visualization here,\\nand I'll kick that off.\\nOne thing to realize is that I'm sampling the data here.\\nI'm not using all of it.\\nIf I used all of the data,\\nit would take a little bit longer to run\\nto create these plots.\\nSo let's look at this. Okay, here's two clusters.\\n\\nI'm just going to come through\\nand look at my average scores here and the shape of these,\\nthat looks okay.\\nIf I do three, you can see my average goes up,\\nso that looks better.\\nFour, my average goes up a little bit more.\\nFive, my average goes up.\\nWell, it's probably a little bit less than four.\\nAnd then six and seven,\\nit looks like it's starting to go back down.\\nOkay, so from this I'd probably choose four,\\nbut based on my other one, I'd probably choose five.\\nSo I'm going to just say five here.\\n\\nIf you've got multiple clusters\\nthat look like they're similar,\\ngenerally I will take the smaller one.\\nIn this case, I'm feeling pretty good about five.\\nSo let's make a model with five clusters.\\nSo we're going to start N clusters or a K to five.\\nWe're going to call fit with that,\\nand then I'll get my labels here.\\nI'm going to explain this clustering\\nusing some Pandas code down here.\\nSo I'm just summarizing this.\\nLet me kind of walk through this\\nif you're not familiar with the Pandas code.\\nI'm going to assume that you have\\nsome basic familiarity with Pandas.\\n\\nIf not, my recommendation is\\nto check out my book, \\\"Effective Pandas,\\\"\\nbut there are other resources for Pandas as well.\\nSo here's my data frame, elec,\\nand I'm going to say let's stick on a new column\\ncalled cluster.\\nThis is the predictions,\\nand then I'm going to group by that and aggregate.\\nI'm going to take the mean of the numeric columns\\nfor each cluster.\\nSo you can see over here in the index we have\\neach cluster label and then we have the mean values.\\nSo this is pretty good right here.\\nI just want to add some style to it\\nto make it a little bit easier to understand.\\n\\nSo I'm going to transpose it first of all,\\nso that T does a transpose,\\nit flips the rows and the columns,\\nand then I'm going to use the style background gradient\\nto color each row from red to blue.\\nRed things will be negative, blue things will be positive.\\nThis makes it pretty clear that cluster four\\ntends to be the positive things,\\nthis is a blue cluster,\\nand probably cluster two and zero\\ntend to be negative things.\\nCluster one and three are probably\\nsomewhere in between them.\\nSo if I knew what each of these features was like period,\\nnswprice, nswdemand, et cetera,\\nI could say that cluster zero is low values for that,\\ncluster four is high values for that\\nand come up with a description for that.\\n\\nAnother thing I can do is make a surrogate model.\\nSo I'm going to use Scikit-learn to do that.\\nHere I'm going to use a decision tree classifier.\\nWe'll talk about decision trees later on,\\nbut one of the nice things about decision trees\\nis that they can give an explanation\\nof why they made their predictions.\\nWhat I'm going to do is train my decision tree,\\nand you can see I'm calling fit here.\\nRemember that Scikit-learn has a consistent interface.\\nA decision tree is a supervised learning algorithm,\\nso we need to pass in in addition to X\\na label or Y generally.\\n\\nIn this case, I'm just going to pass in my predictions\\nfrom my clustering algorithm,\\nand then I'm going to use the mechanisms from Scikit-learn\\nto plot what's going on there.\\nWe're going to plot the decision tree, and here we go.\\nSo this is a decision tree that explains our clustering.\\nLet me walk through what's going on here.\\nThe first thing that we're going to do\\nis we're going to look at our date\\nand it's going to say, okay, if your date is less than 0.6,\\nwe're going to go down to this side.\\n\\nIf it's greater than that value,\\nwe're going to go down this right side.\\nSo date is pretty important\\nfor determining which label a given row has,\\nand we're going to look at period.\\nAnd if period is less than some value,\\nwe're going to go down here.\\nIf it's greater than, we're going to go down here,\\nand you can keep going down this recursively on each side.\\nYou can see over here,\\nclass four is things that have high dates, high periods,\\nand high demand, and that makes sense.\\n\\nClass four was that one that was really high.\\nAnd so that is the explanation from this decision tree\\nof how it got there based on the date, the period,\\nand the demand.\\nYou can also look at these ones down here.\\nIt's a little bit hard to see,\\nif we maybe made this a little bit wider.\\nSo maybe I'll come over here and see if making this wider\\nactually helps us look at the labels.\\nOkay, now you can see the labels here.\\nHere is class two. Class two has low values here.\\n\\nYou can see class one has low values for these two,\\nbut not for the demand.\\nYou can see that this class three here has low values\\nfor these and has low values for date, not for period,\\nand date is super low.\\nYou can see that it's visiting date again.\\nSo this is a nice feature of a decision tree\\nis that you can walk through this\\nand you can explain what's going on here.\\nThis is a useful tool for explaining your clustering.\\nIn this video, we looked at mechanisms\\nto understand what's going on with clustering.\\n\\nAgain, really important thing is to be able to explain\\nto people why you chose the clustering\\nand what the clusters represent.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5907647\",\"duration\":164,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Other algorithms\",\"fileName\":\"3806104_en_US_01_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":200,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Explore alternative algorithms to KNN and understand their comparative advantages and disadvantages.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5562153,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- In this video, I want to briefly discuss\\nother clustering algorithms.\\nSo we've just looked at one clustering algorithm\\ncalled K-means, which is relatively simple,\\nbut there are a bunch of other clustering algorithms.\\nOne of the nice things about the site kit learn library\\nis that it follows the same interface.\\nSo once you can run K-means you can probably\\nuse your data and run it in other algorithms\\nand see how they perform.\\nThe process is probably similar to what we've just seen.\\n\\nYou're going to choose an algorithm to run.\\nYou might not know the number of K,\\nsome algorithms do give you the number of K,\\nbut some might not, and you have to evaluate the algorithm\\nand see what K works for it.\\nAgain, it's not hard to try these other algorithms\\nbecause you just swap out the class,\\nbut the rest of the code, the fit,\\nand the label is the same.\\nNow let me just talk\\nabout two clustering algorithms that might be useful.\\nOne is hierarchical clustering,\\nand what's unique about hierarchical clustering\\nis that it starts with every point as its own cluster,\\nand then it looks for the two points that are closest\\nto each other and quote clusters them into a cluster,\\nand it recursively repeats this keeping track\\nof how far apart each point was is added to the cluster.\\n\\nOnce you've done this, you can create a visualization called\\na dendrogram, which gives you some good insight\\ninto what is the appropriate size of your cluster there?\\nOne of the downsides of hierarchical clustering\\nis that it's relatively slow to run\\nbecause for every point it will make a cluster,\\nso that can take a long time to run.\\nAnother popular clustering algorithm is DBSCAN.\\nThis clustering algorithm creates clusters based on density,\\nand so you can think of it as sort\\nof moving a flashlight around your data,\\nand if things are close to each other, it keeps looking\\naround for other things that are close to that.\\n\\nAnd when there are things that aren't close to that,\\nthen it's kind of done with that cluster.\\nThat can be a nice one to find points that are close\\nto each other based on density,\\nand oftentimes you might have shapes\\nthat are around other shapes but not touching them.\\nThis has the ability to sort of tease that apart,\\nwhereas K-means might not be able to do that.\\nI recommend you try different clustering algorithms\\nand find out which ones might work for you.\\n\\nAgain, one of the main things that I think is important\\nwith doing these experiments is being able\\nto explain why you chose what you did.\\nSo it makes sense to explore some of these other algorithms\\nand understand their pros and cons\\nand why you might want to use them.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5906613\",\"duration\":54,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Apply KNN\",\"fileName\":\"3806104_en_US_01_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":105,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to apply KNN and associated techniques to a real-world problem, testing comprehension, and application.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1487462,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Now we're at the point\\nwhere you get to run clustering on your own.\\nSo what I want you to do\\nis using a dataset called the Titanic dataset,\\nload that into a Pandas DataFrame,\\ndrop missing values, drop any non-numeric values,\\nand then I want you to scale the features,\\nbringing them down so they're all on the same scale.\\nScikit-learn has a standardizer that will do that for you,\\nand then run K-means clustering\\nand use the elbow method to find the best value.\\n\\nI highly recommend you try out these exercises.\\nPracticing these, rather than just listening to me,\\nis going to be one of the best ways that you can learn this.\\nIf you find this challenging, what I would recommend\\nis try it out, see where you get stuck,\\nand then follow along with me\\nas you watch the solution video.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5909019\",\"duration\":444,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Apply KNN\",\"fileName\":\"3806104_en_US_01_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":572,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Review and learn how to assess the optimal approach to the challenge, solidifying understanding and filling gaps.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14945965,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(cheerful music)\\n- [Presenter] Okay, let's look at\\nhow I would probably do this.\\nNote that I do have GitHub copilot turned on,\\nso I'll probably take advantage of that.\\nWe do live in a world of AI\\nand I think you should start getting used to being able\\nto leverage that if you can.\\nIf you can, that's okay too.\\nYou can type this out.\\nThis is just going to save me a little bit of time typing this.\\nSo I need to load the Titanic data set.\\n\\nI have this stored on my GitHub,\\nso I'm going to just use the URL from my GitHub for that,\\nand it is as a Excel spreadsheet.\\nI'm also going to need to import pandas.\\nSo let's import pandas\\nand then we'll say, I'm just going to call this raw.\\nI'm going to say raw is equal to pd.read_excel,\\nand then we'll look at what the raw is when we've done that.\\nOkay, so it looks like that worked.\\nThere is our data, if you're not familiar with this,\\nthis is passengers on the Titanic.\\n\\nThis survived columns, whether they survived,\\nthey lived or they died.\\nThis is a common machine learning library used\\nfor making predictive models.\\nOkay, the next thing I want to do is drop\\nthe missing values.\\nSo let's just look at what values are missing here.\\nI'll play around with this a little bit.\\nSo in order to do that, I like to say is an A,\\nthis gives me a data frame, a true false values.\\nAnd then I like to sum that up.\\nThis is going to sum up each column in Python.\\nFalse is zero, true is one.\\nSo this will gimme the counts there.\\n\\nSo age is missing, a few cabins missing.\\nAlmost every one embarked as missing a, you know,\\ntwo fair is missing one.\\nA lot of boat and body are missing\\nand home destinations are missing.\\nSo I think what I'm going to do is I'm going\\nto drop the age column\\nthat are missing the fair and the embarked.\\nBut before I do that, I'm going to get rid\\nof the other columns that are not numeric.\\nSo let's see if we can look at that.\\nI'm going to see raw.dtypes\\nand it looks like anything\\nthat's an object here, I'm going to get rid of.\\n\\nSo I'll get rid of names.\\nSex, ticket, fare.\\nSo I am going to pull off the column names from this\\nso I can make my life a little bit easier.\\nAnd I'm going to make a little function here.\\nI'm going to call it tweak_titanic.\\nAnd it's going to take a data frame and say return.\\nAnd I want to return my data frame.\\nIt's having problems completing there.\\nOkay, so I'm going to say, let's pull off certain columns here.\\nSo the columns that I want are,\\nI'll just copy this whole thing here\\nand then delete what I want rather than typing that out.\\n\\nOkay. And some people use drop.\\nMy preference is actually not to drop things,\\nbut rather be positive about what we do want.\\nSo name and sex, we're going to get rid a ticket,\\nwe're going to get rid of cabin.\\nJust all of these we're going to get rid of as well, okay?\\nSo let's just try this out.\\nI'm going to say tweaked Titanic raw, see if it works.\\nOkay, that's looking pretty good.\\nAnd then we do have some missing valleys\\nin this probably, right?\\nWe can do, this is na, and then sum that up\\nand see what that looks like.\\n\\nSo age is missing and fair is missing.\\nSo I'm just going to do a dropna right here\\nand we'll run that.\\nThat looks pretty good. And we'll do,\\nthis is na and sum that up.\\nOkay, this is looking, okay, so now what I want to do\\nis I want to standardize this data.\\nWhy do I want to standardize this?\\nWell, if you think about clustering, it is doing distance\\nof how far apart things are.\\nAnd you can see that like fair looks like it goes up\\nto like 150 and age goes up to maybe 80,\\nbut some of these are ones and zeros and twos and threes.\\n\\nSo we want to get them all on the same scale.\\nSo I'm going to standardize the data using psychic learn.\\nSo because I'm using copilot here,\\nthis is probably pretty easy.\\nI'm going to say standardize the data here and look at that.\\nIt's kind of doing what I want.\\nHere's a scaler and I'm just going to say, oh, there we go.\\nSo we're going to use a scaler.\\nIt's from psychic learn,\\nand we're going to call fit Transform again,\\nbecause it's psychic learn, it has these common methods.\\nThis is what's called a transformer.\\n\\nSo you can pass in data\\nand it will transform it into a new form.\\nLet's run this and look at what X is when we do this,\\nand this should be the same data that we had before,\\nbut it's going to be standardized.\\nSo what does standardization mean?\\nIt means that every column has a mean value\\nof zero in a standard deviation of one.\\nNow this is returning a NumPy data frame.\\nI actually don't want a NumPy data frame.\\nI don't know if copilot will complete this.\\nHave sklearn output pandas.\\n\\nYeah, that's not what's going to do it.\\nSo I believe there is a set config function in sklearn.\\nSo I'm going to say from sklearn import set config,\\nthere we go.\\nAnd we'll say set config\\nand it's not display is equal to diagram here.\\nI believe it's transform output, that's what it is.\\nTransform output is equal to pandas.\\nOkay, let's try this again here.\\nI'm just going to put exit the bottom here to print that out.\\nOkay, so that looks better in that this is now coming out\\nas a pandas data frame instead of a NumPy array.\\n\\nJust makes it a little bit easier\\nto understand what's going on.\\nYou see these values are the same, negative 1.4,\\nbut if you look at the summary statistics here,\\nthe mean value is very close to zero, like one times 10\\nto minus 16, and the standard deviation\\nis very close to one.\\nSo that makes clustering not pay attention to the size\\nof the data, but rather the relative position of them.\\nOkay, so the next thing we're going to do is I'm going\\nto track the inertias here.\\nSo I think because I am using copilot\\nand it's seen this code, I should be able\\nto get this pretty easy for I in range.\\n\\nLet's just do 20 and let's see if it will complete for me.\\nOkay, so there's my inertias.\\nAwesome.\\nAnd then we'll plot the results.\\nOkay, I think this is pretty good.\\nOkay, yeah, that worked.\\nSo again, I did use AI to complete a lot of this for me,\\nbut one thing you'll note is that a lot of\\nwhat I do in this class is looking at patterns\\nlike these are patterns of code\\nand basically, a lot of these things you can take them\\nand just stick your data into them.\\n\\nSo this code looks very similar to what we saw up above.\\nLet's look at the results here.\\nSo how many clusters would I cluster\\nthe Titanic data set into?\\nAgain, I'm going to sort of take my imaginary ruler here,\\nstick it at an angle and bring it over here, maybe five.\\nAgain, if I've got it touching in multiple places,\\nI might want to do the simpler one.\\nSo I would probably start off with five\\nand start exploring that.\\nOkay, so hopefully, this was useful to give you a chance\\nto play around with the site kit learn library\\na little bit more,\\nand understand how to start making clustering models.\\n\\n\"}],\"name\":\"1. Clustering\",\"size\":74232340,\"urn\":\"urn:li:learningContentChapter:5903620\"},{\"duration\":1465,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5905600\",\"duration\":218,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"PCA\",\"fileName\":\"3806104_en_US_02_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":278,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Grasp the concept and mechanics of PCA for dimensionality reduction.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7728508,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay We're going to look at\\nprinciple component analysis or PCA.\\nPCA is an unsupervised machine learning technique,\\nmeaning that we are just going to pass in the data\\nto the algorithm and the algorithm will do something to it.\\nIn the case of PCA, what it does,\\nis it reduces the dimensions.\\nI like to use this for visualizing\\nand understanding my data,\\nbut oftentimes people will use this\\nwhen they have many columns\\nand they want to reduce the number of columns.\\nLet's load in our dataset here\\nand let's look at our dataset.\\n\\nSo X is going to be sepal length and sepal width\\nfrom our iris dataset.\\nThe first two columns there,\\nwe're going to run PCA on the first two columns.\\nAgain, this is using scikit-learn,\\nso we'll import the class and we'll call fit.\\nThis is a transformer,\\nso we're going to call transform after that.\\nThis will give us what I'm going to call XPCA\\nand then I'm going to plot XPCA.\\nSo let's do that.\\nAnd I got an error here.\\nAnd the error\\nis because this code is expecting NumPy as an output.\\n\\nIf we look at XPCA,\\nI believe XPCA is now panned as output\\nbecause of the solution that I did up above.\\nSo let's change this a little bit.\\nThis is what it wanted in pandas,\\nand I'm going to say PCA zero here as the column.\\nThe code is a little bit different and PCA one,\\nso just depending on if you're using\\nNumPy as an output or pandas,\\nyou will have different code here.\\nSo we'll make this work with pandas, I believe.\\nAnd it's not PC, it is PCA, the column name.\\n\\nOkay, there we go.\\nSo this is principle component one,\\nand principle component two of the first two components.\\nAnd this looks pretty similar to what we saw before,\\nwith just the first two columns of the data.\\nSo it, it doesn't look like there's\\na lot different going on here.\\nLet's try and see if we can make sense of what's going on.\\nHere is sepal length and sepal width,\\nand we've got PC1 and PC2.\\nWhat principle component analysis does\\nis it finds the linear combinations of these two columns\\nthat maximizes the variance.\\n\\nAnd so these are linear combinations\\nof these columns down here below.\\nThat might not make sense right now.\\nHopefully I can help you understand it\\na little bit more.\\nHere I'm going to do principle component analysis\\non all of the data.\\nAgain, this is expecting NumPy down here,\\nso I'm going to fix this so it works with panda as the output.\\nAnd here's a scatter plot\\nof the first two principle components.\\nOne of the things I don't like about scikit-learn\\nis that it labels the first component, PCA0.\\n\\nGenerally in the literature,\\npeople will call that principle component one not PCA,\\nPCA is short for principle component analysis.\\nSo I'm not sure why the scikit-learn developers\\nchose that nomenclature there,\\nbut I'm just going to label it PC1 and PC2.\\nBut the column names that scikit-learn gives us in pandas\\nis PCA zero and PCA one.\\nSo what is this?\\nThis is the linear combinations of all of those columns\\nthat add up to principle component one\\nand principle component two scatter plotted out there.\\n\\nOkay, in this video I showed you how to\\nrun principle component analysis.\\nI told you that it was the linear combinations.\\nIn subsequent videos,\\nhopefully I will give you the intuition to understand\\nwhat's going on under the scenes and why this is important.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5907648\",\"duration\":248,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Structure of components\",\"fileName\":\"3806104_en_US_02_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":266,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to delve into the principal components derived from PCA, understanding their significance and structure.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8493889,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, so when we run\\nprinciple component analysis, we got back out\\nthe principle components again.\\nLike I said, these are the linear combinations\\nof the features.\\nWe also get some other artifacts as well,\\nwhich these artifacts are going to help us\\nunderstand what's going on.\\nOne is what's called the explained variance ratio.\\nThis tells us how much information,\\nand in principle component analysis,\\ninformation is the variance.\\nSo how much variance is in the first column,\\nrelative to the second, relative to the third, et cetera.\\n\\nAnd these are in descending, monotonic decreasing order.\\nSo the first principle component\\nwill have the most information,\\nthe second, the second most, et cetera.\\nAnd then we also have what are called the feature weights.\\nYou can think of the feature weights as coefficients\\nthat we multiply the original columns or features by,\\nand then we sum those up to get the principle components.\\nBasically what this is telling us\\nis how important a feature is to the component.\\n\\nOkay, so in this case, I am setting the output here\\nfor scikit-learn to be Pandas,\\nand you can see that here's the output.\\nWhen we run this with all of our data, we get a data frame\\nwith PCA zero, one, two, and three.\\nSo we have four principle components with 150 rows.\\nAgain, I don't like those names,\\nso I would probably do something like this.\\nThis is just pandas code to fix those names here.\\nOkay, so what I'm going to do here is I'm going to make\\nwhat's called a scree plot,\\nand this is going to show us the explained variance ratio.\\n\\nNow, if you look in this code, inside of it,\\nyou can see that it says PCA period\\nexplained variance ratio_.\\nAgain, those attributes ending in underscore\\nare attributes that are learned by fitting the data.\\nWhen we fit the data, it calculated\\nwhat the explained variance ratio is.\\nAnd I am going to plot what that looks like.\\nOkay, there we go.\\nSo this is telling me that the first principle component\\nof this data has 80 plus percent\\nof the information of all of the four columns.\\n\\nAnd the second principle component\\nhas probably around 8% of the information.\\nThe third one, a little bit less.\\nWe can actually pull that off and look at it here.\\nAnd I misspoke, it's not even 80, it's 92%.\\nSo 92% in the first principle component,\\nfive in the second, 1% or almost two in the third,\\nand a half percent in the last.\\nSo what is this saying?\\nIt's saying that if we wanted to reduce\\nthe dimensions of our data, we could use\\njust that first principle component.\\n\\nAnd it has about 92% of the information\\nin the other four columns, seems pretty cool.\\nWe can also do a cumulative sum of that,\\nand we can go the opposite direction.\\nSometimes you might want to say,\\nokay, I want to be able to capture 90%,\\n80%, some amount of percent of the information,\\nand I'm good with losing the rest.\\nIf you do a cumulative sum, you can say,\\nokay, if we want 95%, we have to take\\nthe first two principle components\\nand then we'll have 97% of the information.\\n\\nIt can give you a cutoff to determine\\nwhere you want to drop additional columns if you want to.\\nWhy might you want to drop columns?\\nWell, a lot of machine learning libraries or algorithms\\nwill run a lot quicker with less features.\\nSo if you can preserve the information,\\nbut have them run quicker, that might be something\\nthat is useful to your business.\\nIn this video, we talked about the amount of information\\nstored in the principle components.\\n\\nIn subsequent videos, I'll explain\\nhow we get those principle components.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5904637\",\"duration\":323,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Components\",\"fileName\":\"3806104_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":368,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11329176,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Lecturer] In this video, I'm going to talk about\\nhow we get the components.\\nThis is the crux of principle components in my opinion.\\nOkay, so here, I'm making a data frame\\nfrom this components underscore attribute.\\nAnd if you just look at components underscore,\\nit's just going to be a NumPy array.\\nSo, I'm actually sticking into a Pandas DataFrame.\\nI hope this will help you understand\\nwhat's going on a little bit better.\\nIn the columns here, we have the original columns\\nthat we fed into our data,\\nand in the row we have each of the principle components.\\n\\nSo, what is this saying?\\nThis is saying that for principle component one,\\nto get principle component one,\\nyou take the sepal length and you multiply it by 0.36.\\nYou add that to the sepal width times negative 0.08.\\nYou add that to the pedal length times 0.85.\\nAnd you add that to the pedal width times 0.35.\\nAnd that gives you one number,\\nwhich represents principle component one.\\nNow, if you think about this,\\nthese weights have some magnitude, how big they are, right?\\nThey might be very big negative or very big positive.\\n\\nBut if your data is on the same scale,\\nand in this case, our Iris data is on the same scale,\\nit's all like numbers between like one and seven.\\nIf your data wasn't on the same scale,\\nwe could use something like standardization,\\nwhich is what we use with a Titanic dataset.\\nIf your data's all on the same scale,\\nthen basically what these weights are,\\nare they are saying how important a feature is\\nfor impacting that principle component, right?\\nBecause sepal width is a very small magnitude,\\nit's pretty close to zero.\\n\\nIf you change sepal width, it's really not going\\nto impact principle component one a lot.\\nHowever, if you change pedal length because it is 0.85,\\nthat will have a big impact on principle component one.\\nSo it's a little bit fuzzy,\\nbut you can think of these as feature importance.\\nThat principle component one is mostly made up\\nof pedal length, but also pedal width and sepal length.\\nIf you look at principle component two,\\nprinciple component two is mostly made up\\nof sepal width and sepal length.\\n\\nAgain, we don't have a bunch of features here,\\nbut in other data sets where you have 80 columns,\\nthis can tell you which columns have the most information\\nor the most variance in them.\\nOkay, so I'm just going to manually show you how to do that.\\nYou need to center your data\\nto get these numbers to pop out.\\nAnd if I center my data, you can see\\nthat like sepal length is negative 0.74.\\nSo, I'm going to multiply that by this, 0.36,\\nand I take the 0.44 and multiply that by negative 0.08.\\n\\nThe negative 2.35, multiply that by this number\\nand the negative 0.99 by this number.\\nIf we do all of that, we get this value right here.\\nAnd that value should be this value here,\\nprinciple component one for row one.\\nSo, that's where those values are coming from.\\nIt's a way to reduce all of those columns to a single value.\\nNow, one thing to note is that how the math works out\\nfor this principle component one is in one direction,\\nand principle component two is going to be orthogonal to\\nthat in ever how many dimensions this is.\\n\\nSo, this is four dimensions.\\nSo, this principle component one would be in one dimension,\\nprinciple component two would be orthogonal,\\nmeaning it's at a right angle.\\nAnd principle component three would be orthogonal\\nto both of those.\\nSo, this would be the third dimension,\\nand then principle component four would be orthogonal\\nto those which is orthogonal in the fourth dimension.\\nThe math works out such that is the case.\\nSo, that might be something that's useful to know is\\nthat all of these are mutually orthogonal to each other.\\n\\nFor those who are curious,\\nyou can manually calculate PCA using NumPy here,\\nand that's what's going on in this cell.\\nSo, you center the data, you take the eigenvalues\\nof the covariance of the data,\\nand you sort those in the order of descending strength.\\nAnd if you look at that,\\nthat will give you the explained variance ratio,\\nthose values there.\\nAnd if you do the dot product of the centered data\\nwith the components, those vectors that came out of there,\\nyou will get the principle components.\\n\\nSo, you can do this by hand if you want to,\\na few lines of code,\\nbut you can also just call fit_transform with scikit-learn,\\nand it gives you this,\\nalbeit I don't like those label names,\\nI wish they changed them to PC instead of PCA zero.\\nOkay, this video hopefully was super useful\\nto you in understanding what is going on with the weights.\\nWhat are principle components?\\nReally, you can think of them as a single number\\nthat represents the importance of the information\\nor variance that is in the original data.\\n\\nSo, it's a great way to collapse multiple pieces\\nof information into a single value\\nor into smaller dimensions.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5906614\",\"duration\":138,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Scatter plot\",\"fileName\":\"3806104_en_US_02_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":150,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to visualize high-dimensional data in lower dimensions using scatter plots of principal components.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4077728,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, in this video,\\nI only have one cell of code but I think it's really cool.\\nWhat I'm going to do is I'm going to scatter plot\\nthe principal components.\\nAnd I'm going to use the plotly library to do this.\\nYou can use matplotlib as well.\\nBut I like the plotly library\\nbecause it works well in Jupyter,\\nbut it also gives us interactivity.\\nLet's just play around with this\\nbecause I'm going to plot this in three dimensions.\\nAlso, I do like to plot scatter plots\\nof the first two dimensions,\\nbut we're going to do three dimensions here.\\n\\nI've imported the plotly library and I just say,\\nlet's do a scatter_3d on this pcas dataframe here.\\nAnd in the x dimension, I want PC1, y, PC2 and z, PC3.\\nAnd I'm going to color this by y.\\nLet's plot that.\\nOkay, and this is the result of that.\\nThis is a plotly scatter plot.\\nThe nice thing about this is you can hover over this,\\nyou can see what's going on here.\\nSo these colorings\\nare based on the variety of the iris flower here.\\n\\nAnd if I click and drag, I can view what's going on.\\nSo remember, we said PC1 has 90 plus percent\\nof the information here, so I might want to come down\\nand sort of rotate this like this.\\nYou can see, as we're going from the left to right,\\nwe're going through PC1 from negative to positive values.\\nAnd this has a lot of the information.\\nAnd maybe I'll zoom in here a little bit if I can.\\nLet's see if I can get this to zoom in.\\n\\nOkay, with with my mouse, I can sort of scroll in\\nand zoom in a little bit.\\nAs we're going from left to right,\\nyou can see a pretty clear delineation here\\nof like, one variety of flower, another one and another one.\\nAgain, I did not train the data on the variety.\\nI only trained it on the shape of that,\\nbut it's kind of clustering the data in the varieties.\\nTo me, this is pretty cool.\\nI can use this principal component analysis as a technique\\nto view multiple dimensions in two or three dimensions,\\nand see what's going on with my data.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5904638\",\"duration\":240,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Other algorithms\",\"fileName\":\"3806104_en_US_02_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":272,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Investigate other dimensionality reduction techniques beyond PCA.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7278208,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this video, I want to briefly touch\\non some other dimensionality reduction techniques\\nthat might be interesting that you might hear about.\\nOne is t-SNE,\\nor t-distributed stochastic neighbor embedding.\\nThis tries to preserve the local structure of the data.\\nAnother common one that you'll hear about\\nis uniform manifold approximation and projection, or UMAP.\\nAnd this tries to preserve the local\\nand the global structure of the data.\\n\\nNow, these both follow the scikit-learn interface.\\nSo if you can run PCA on something,\\nyou can probably run these others as well.\\nOne of the things I like about PCA\\nis it's relatively simple,\\nwe have those weights that explain what's going on with it.\\nBoth of these, t-SNE and UMAP,\\nare a little bit more complicated.\\nAnd so, while you can use them, oftentimes,\\nyou have to nurse them along a little bit more.\\nBecause, for example, they might behave differently\\nif you run them multiple times,\\nor you might need to tune some of the behavior of it.\\n\\nBut if you look at this, this is from scikit-learn,\\nit's in there and you can call fit transform.\\nAnd when we look at the output here,\\nwe get these embeddings, I would call these embeddings,\\nthat are similar to the principle components,\\nbut these are the t-SNE embeddings for that.\\nAnd you can throw these into Plotly just like we did before,\\nand you'll get something that looks like this.\\nSimilarly, we can use UMAP.\\nThis is not part of scikit-learn,\\nbut it follows the scikit-learn interface.\\n\\nSo if you install that, pip install UMAP learn,\\nwe can make a UMAP class,\\nand then we can call fit transform with that.\\nI'm going to stick that result back into a Pandas data frame\\nbecause for me, it's easier to work with Pandas.\\nAnd let's plot that.\\nAnd here is the result of UMAP.\\nWhich one of these is best?\\nThe answer is, an unsatisfying, it depends.\\nOne of the things that principle component analysis\\nmakes an assumption of is that\\nthere is a linear relationship with your data.\\n\\nAnd if you don't have that, doesn't mean you can't run\\nprinciple component analysis, but you might see\\nweird artifacts from running\\nprinciple component analysis on your data.\\nSo there's no guarantee, like in our example,\\nwe saw that the first principle component\\nhad 90% of the information.\\nThere's no guarantee, in your dataset,\\nthat that will be the case.\\nBut I like to have this in a tool for me,\\nbecause my brain can't go much beyond three dimensions\\nto understand or to visualize\\nwhat's going on at high dimensions.\\n\\nRemember when we looked at the clustering previously,\\none of the things I like to do is I like to cluster my data,\\nand it might be high dimensions that I'm clustering it on,\\nbut then how do I visualize those clusters?\\nWell, I'll often do principle component analysis\\non the data, on the original data.\\nAnd then color the plot of the principle components\\nby the labels of the clusters.\\nAnd that lets me kind of get a feel\\nfor what's going on in there.\\n\\nI can also look at the weights of the principle components,\\nand understand the clusters if they are related\\nwith the principle components that way as well.\\nSo for me, it's a good tool to explore data\\nand try and understand it.\\nThe nice thing about these unsupervised algorithms\\nis that they're just telling me what's in the data.\\nThey don't encode my bias,\\nor what I am trying to encode.\\nThey are just what's in the data.\\nSo the data might be biased, but it's going to just show\\nwhat is in the data, which is good for me\\nto look at the data in a fresh way.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5906615\",\"duration\":34,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Utilize PCA\",\"fileName\":\"3806104_en_US_02_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":37,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to utilize PCA on a provided dataset, emphasizing interpretation and application.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":888909,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Okay, it's challenge time again.\\nYour challenge is to run PCA on the numeric columns\\nof the \\\"Titanic\\\" data set.\\nOne thing to be aware of is that PCA will not work\\nwith missing data, and it requires numeric data.\\nSo you might need to play around with the data a little bit\\nbefore you can run PCA on it.\\nAnd then after you've done that,\\nI want you to plot the results in plotly\\nof the first three components.\\n\\nGood luck.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5905601\",\"duration\":264,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Utilize PCA\",\"fileName\":\"3806104_en_US_02_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":339,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to analyze the optimal PCA application and understand potential areas for improvement.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10261542,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Okay, let's look\\nat the Titanic data set here.\\nI believe I have it loaded as raw\\nand I believe I have that tweak Titanic function\\nas well around.\\nSo let's just run that\\nand see if that helps us get our data\\npaired down a little bit.\\nOkay, so here is our numeric data,\\nand we're going to run PCA on this.\\nAgain, note that we probably want to standardize the data.\\n\\nSo let's do that here.\\nWe're going to use scikit-learn's standard scaler to do that.\\nWe'll make a scaler, and we'll call fit transform\\nto get that scale data here.\\nLet's look at what that looks like.\\nOkay, here is our scale data. That's looking pretty good.\\nOkay, so we're going to now\\nrun principle component on the data.\\nSo we'll make a PCA object,\\nand we're going to call fit transform.\\n\\nThat should give us the transform data.\\nLet's look at what that looks like. Okay, here is the data.\\nAwesome. It is pca0, pca1, pca2. Cool.\\nSo we're going to plot this using Plotly now.\\nAgain, I keep coming back to this,\\nbut I want you to pay attention.\\nThis interface here, fit transform, fit transform,\\nit's the same interface.\\nSo once you get used to that, it makes it really easy.\\nPlot the first three columns in Plotly.\\n\\nLet's see if this works, okay?\\nI think that this should work.\\nOkay, it didn't show us anything\\nbecause we need to say fig.show at the end here.\\nLet's try it again.\\nOkay, so here are the first three components.\\nOne thing that might be cool here is\\nto color this based on whether they survived.\\nLet's do that.\\nAnd I got an error here, says\\nthat the arguments don't have the same length.\\nSo the issue here is that raw has all\\nthe data and I believe the X_pca doesn't.\\n\\nLet's look at X_pca.\\nSo if you look at the index here, the index goes up to 1308,\\nbut there's only 1045 rows.\\nSo what I can do is I should be able to come here\\nand say, let's take the raw data, but I'm going to use loc,\\nand I'm going to use the X_pca index,\\nand that should filter the rows.\\nLet's see if that works. There we go.\\nOkay, so there is our data, whether they survived or not.\\n\\nNow, note that this is including\\nthe survival column, I believe.\\nIf we look at the output of this X right here,\\nokay, so this is using survived.\\nLet's actually remove survived from this.\\nSo I'm going to come in here\\nand let's just run it one more time removing survived.\\nI'm going to say drop column survived here,\\nand I just want to see if there's still the separation\\nthat we get when we do that, so I'll run that again.\\n\\nWe'll run this again, and we'll plot this again.\\nOkay, so remember, I said there's no guarantee\\nthat your data will be like cleanly separated\\nlike our iris data is,\\nand you're kind of seeing that here, right?\\nIt was kind of nice that survived, sort of stuck out here.\\nI mean, it looks like we are seeing a little bit of like\\nthis blue edge down along this side here,\\nbut we also see like some outliers over here.\\n\\nSo what this is telling me is this relationship\\nbetween survived and not is not a linear relationship.\\nThere might be some sort of bathtub, curved-type effects\\nwhere if you're very young\\nor very old, you might've survived,\\nbut if you're middle age, maybe you didn't survive.\\nI think this is really cool\\nthat we can get insight into our data\\nand just by looking at this,\\nand I would encourage you to play around\\nwith this a little bit more.\\nLook at the weights, see what weights\\nare impacting those components.\\n\\nWhat original features are driving principle component one,\\nand principle component two, et cetera,\\nto kind of understand what's going on here?\\n\"}],\"name\":\"2. PCA\",\"size\":50057960,\"urn\":\"urn:li:learningContentChapter:5907651\"},{\"duration\":1431,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5906616\",\"duration\":274,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Linear regression algorithm\",\"fileName\":\"3806104_en_US_03_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":287,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn about the core principles of linear regression for modeling relationships between variables.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9129412,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this video,\\nwe're going to talk about linear regression.\\nAnd linear regression is one of a family\\nof machine learning algorithms\\ncalled supervised machine learning.\\nWe've been looking at unsupervised machine learning.\\nWith supervised machine learning,\\nwe're going to pass in this x data frame or matrix,\\nand we're going to also pass in a y.\\nSo if you think about what we've been looking at,\\nwe've been thinking at rows, which are samples,\\nindividuals with columns that are features\\nthat describe those samples.\\n\\nIn the case of supervised learning,\\nwe're also going to pass in some labels as y,\\nand that will be a one dimensional in our case,\\ngenerally a series that corresponds to each row.\\nSo each row will have a label.\\nWe're going to train our algorithm to be able to predict these.\\nIn the case of regression, these will be numeric values\\nand we're going to train the algorithm\\nto predict numeric values.\\nLinear regression is a common algorithm\\nand it's kind of the basic algorithm you might remember\\nfrom school where you learned a formula,\\ny is equal to mx plus b,\\ny is equal to the slope times sum x plus the intercept.\\n\\nAnd that is what linear regression is kind of doing it,\\nsolving that equation for us,\\ngiving us the slope and the intercept.\\nI've got a formula here\\nthat shows a generalized version of it,\\nbut you can think of this b0 here as the intercept.\\nAnd then for each x here,\\nyou can think of each of these x's as a column in our data.\\nWe're going to multiply it by some weight,\\nand we sum all of those up and that will give us a y value.\\nSo it's trying to solve this equation here.\\n\\nSo I'm going to load a dataset called Anscombe's Quartet.\\nThis is a popular dataset used for visualization.\\nGot it in our data frame here.\\nSo we've got x with y1 and y2 and y3,\\nand then this fourth dataset x4 goes with y4.\\nWe'll just plot x with y1 here and a scatter plot,\\nand it looks something like this.\\nOkay, so we're going to run the algorithm on this,\\nand here's the formula for doing this.\\n\\nIf you like the math, you can calculate the slope\\nand then you can calculate the intercept\\nand you'll get this equation right here.\\nSo let's do that right here.\\nWe're going to say that our x is the x column here\\nand y is this y column.\\nAnd then our slope, we're just plugging this in.\\nThis is using either Pandas or NumPy.\\nEither one of those will work.\\nAnd this should give us the slope for that.\\nIt's saying that the slope is 0.5.\\nAnd if you remember that, that's the rise over the run.\\nSo it looks like there's a positive slope there.\\n\\nThat's seems plausible.\\nAnd here's the intercept.\\nWe're just going to follow that calculation form.\\nThe intercept is our y bar, which is the mean,\\nminus the slope times x mean.\\nAnd we'll get 3 as the intercept.\\nAnd if we scroll up here to our graph,\\nit's not going to zero,\\nbut you can imagine zero would be over here.\\nAnd if you fit a line on this,\\nit looks like it would probably cross around 3,\\nwhich is what it's calculating there.\\n\\nOkay, let's plot this now.\\nI'm going to plot my original scattered plot,\\nbut now I'm going to plot my line as well.\\nAnd I'm just using NumPy to say,\\nlet's make a linear space here\\ngoing from 4 to 14 with 100 points.\\nAnd my y is going to be looks like math.\\nI'm going to say slope times my x, mx plus b,\\nplus my intercept, okay?\\nAnd we're going to plot that on the same plot here.\\nWe're going to say plot x1 and y1 there as well.\\n\\nAnd there we go.\\nThere is our formula for a line that fits these points.\\nNow note that this is a line,\\nit's not curve, it's a straight line.\\nBut what this would give us is,\\nyou could think about in the future\\nif someone said, \\\"Okay, I've got a value of x around 10.5,\\nwhat value of y would that be?\\\"\\nAnd you need just go over here to 10.5,\\ngo up and whatever is on that line,\\nthat's what this would predict.\\nThis is a quick introduction to linear regression.\\n\\nWe've done it in one dimension here.\\nWe just got a single value for x,\\nbut this generalizes to end dimension.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5903619\",\"duration\":258,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"scikit-learn\",\"fileName\":\"3806104_en_US_03_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":279,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to implement linear regression on a simple dataset, emphasizing foundational concepts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7704971,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, we just looked at the math\\nbehind linear regression,\\nand I know a lot of you probably like math,\\nbut I'm a lazy programmer,\\nand so I don't want to do the math.\\nAnd guess what?\\nAs long as we understand that Scikit-learn interface,\\nwhich is fit.\\nSo let's try this.\\nI'm going to say, okay, let's make an X1,\\nand I'm using some pandas code here.\\nGenerally, Scikit-learn wants X to be a data frame,\\nand if I just do this with a single square bracket,\\nthat X will be a column or a series, not a data frame.\\n\\nIf I do it with the double square brackets here,\\nthis is saying pass in a list of columns\\nthat you want in your data frame,\\nand I can do a list with just one thing in it.\\nSo X1 here is really a data frame,\\nand then Y1, this is going to be a series.\\nSo look at this.\\nI just import linear regression from Scikit-learn.\\nI make an instance of the linear regression class,\\nand I call fit.\\nWe've seen fit many times in this course already.\\n\\nIt's so easy once you understand how to use Scikit-learn,\\nwhen you have your data in the format\\nthat Scikit-learn likes,\\nyou generally just call fit with your data.\\nSo let's run that.\\nAnd this looks like it returns\\nthis linear regression object down here.\\nI'm going to now look at this thing called coef_.\\nWe talked about this already.\\nWhen things end in an underscore in Scikit-learn,\\nthose are things that are learned from fitting.\\n\\nSo they're not always the same.\\nSome models learn different things.\\nIn the case of linear regression, we learn a coefficient\\nand we learn an intercept.\\nSo here's our coefficient, which is 0.5.\\nThat should seem familiar.\\nWe actually saw that above.\\nAnd here's our intercept, which is 3,\\nwhich is what we also calculated above.\\nSo linear regression in Scikit-learn is giving us\\nthe same things that we saw above.\\nNow I'm going to do linear regression on Y2 and Y3,\\nwhich are two other parts of this\\nAnscombe's Quartet dataset,\\nand I'm just going to plot those here.\\n\\nSo now we have three plots.\\nIn the left plot is the first dataset.\\nThat's the one we saw before.\\nIn the second plot is the second dataset\\nfrom Anscombe's Quartet,\\nand you can see that the linear regression\\nis a straight line.\\nHowever, the dataset doesn't really look like it's straight.\\nIt actually looks like it's curved.\\nAnd in the third plot here,\\nyou can see the data looks like it's a straight line,\\nbut if you look carefully up above,\\nthere is an outlier up there.\\nSo this dataset, Anscombe's Quartet,\\nif you're not familiar with it,\\nwas a dataset created by a statistician\\nto drive home the importance of visualization.\\n\\nIf you look at the summary statistics of these data sets,\\nthey have the same summary statistics, same mean,\\nand same standard deviation.\\nBut if you visualize them, you can see\\nthat they are different data sets.\\nAnd people have actually taken this idea recently\\nand made fancier data sets that have like dinosaurs in them\\nand other shapes in them\\nthat have the same summary statistics.\\nBut when you visualize the data,\\nyou see that they are different.\\nSo you could think that for the first dataset on the left,\\nlinear regression might be an appropriate choice.\\n\\nFor the second one, it probably isn't.\\nIt just rubs me the wrong way to see\\nthat you've got these points\\nthat look like they're in a parabola,\\nand then you've got a line going through them.\\nAnd then in the third one, it makes me think,\\nokay, what's going on with that point up there above 12?\\nDo we need to figure out something to do with it?\\nIs it an outlier?\\nIs the data bad or is that really how it goes?\\nAnd our model needs to adapt to that somehow.\\n\\nHopefully, this combination of plotting is a great technique\\nthat you can use as well to start\\nto understand your models and diagnose them\\nand see if they make sense.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5906617\",\"duration\":374,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Real-world example\",\"fileName\":\"3806104_en_US_03_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":463,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to recognize and validate the core assumptions behind linear regression.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12535691,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Tutor] Okay with that, what I'd like to do\\nis move on to a real-world example,\\nrather than playing with these toy datasets.\\nAnd we're going to use from that datasets library a dataset\\nof F-16 aircraft elevator information.\\nSo I'm not an expert in aircraft, so to speak,\\nbut this dataset is used to predict,\\nif an action is taken on the aircraft, what happens to that.\\nSo let's load the dataset here.\\n\\nAnd again, we need to jump through a little bit of hoops.\\nWe need to say, okay, we want the train set,\\nand we want to convert that to pandas,\\nand it looks something like that.\\nOkay, at the end here, you can see this goal.\\nIt's a numeric value that we might want to try and predict.\\nSo let's see if we can predict it.\\nSo what do we do?\\nWe're going to make an X and a y.\\nSo our X is going to be all of the columns except for Goal.\\nOur y is going to be the goal column.\\n\\nAnd we'll make a linear regression model,\\nand we'll call fit with X and y.\\nThat looks like it worked.\\nAgain, you need to be aware that LinearRegression\\nis an algorithm that needs numeric data,\\nand it can't have missing data.\\nSo looks like this data is actually pre-processed\\nin a way such that we're not running into those issues.\\nNow, another thing to be aware of\\nis that you might want to standardize your data as well.\\nIn this case, we did not do that,\\nbut you can see that the climbRate column\\nlooks like it has a different magnitude\\nthan some of these Time columns at the end.\\n\\nSo you might get a different result\\nif you standardize that data.\\nLet's look at the coefficient here.\\nIn this case, the coefficient is not a single value,\\nit is a NumPy array.\\nWhat this corresponds to is,\\neach of the features that we passed in,\\neach of these columns that came in here,\\nthis is the corresponding coefficient for that column.\\nSo to calculate the result of the prediction here,\\nif you have a row, you would take the first column,\\nmultiply it by this weight, the second column by this one,\\nsum these up, and then add the intercept as well.\\n\\nSo here is the intercept, intercept_.\\nOne of the things that I like to do\\nis I like to plot this to see what's going on here.\\nBecause these are weights, the magnitude is important,\\nand it tells us, the larger the magnitude,\\nthe more impact it might have on the data.\\nNow, be aware that we did not standardize the data here.\\nSo by looking at this, it looks like these SaTime3, Sa,\\nand SaTime2 are the bars that have the biggest magnitude.\\n\\nAgain, I'm not super concerned about the direction.\\nThe direction is important.\\nLike, if SaTime3 goes up,\\nthat's going to push the result higher.\\nIf SaTime2 goes up,\\nit's going to push the result in a negative direction.\\nThat's super useful to have direction.\\nBut also note that, like,\\nthese values in the middle without any magnitude\\nlook like they're not going to impact the model very much.\\nWe can also ask the model what the score is,\\nand scikit-learn has a general method for that.\\n\\nIt's the score method.\\nIn the case of regression models,\\nit reports what's called the R2,\\nor the coefficient of determination.\\nThis is the amount of variance in the answer\\nthat is explained by the features in the data.\\nGenerally, this is a score that is between 0 and 1.\\nThe closer it is to 1\\ngenerally indicates that a model is better.\\nNow, let me just make a comment here.\\nFolks often ask me, \\\"What number represents a good model?\\\"\\nAnd the answer to that is an unsatisfying, \\\"It depends.\\\"\\nIt might be the case that you have a score of 0.99,\\nand the model isn't sufficiently good for your use.\\n\\nIt might be the case that you have a model\\nthat has a score of 0.2,\\nand it works for your business case.\\nSo oftentimes you need to go into further analysis\\nand see if a model makes sense for your business.\\nBut what we can say is that,\\non a given dataset, if you have two models,\\nand one has a higher R2 score,\\nthat should be a better model.\\nNot that a higher score is of itself sufficient\\nfor a model to be put into production.\\n\\nNow, there are other metrics as well.\\nI'm going to import some of those here.\\nCommon ones include the mean_absolute_error.\\nSo that is taking all the errors,\\nbasically, here's the predicted value,\\nhere's the true value, what's the difference between those,\\nand take the absolute difference and take the mean of those.\\nWhy the mean absolute instead of just the mean error?\\nWell, you might have some errors that are positive\\nand some that are negative,\\nso theoretically it's possible to get a mean error of 0,\\nbut you have numbers that are way off.\\n\\nSo we're taking the absolute there.\\nAlternatively, you can say the mean_squared_error,\\nsquare those values so they're always positive,\\nso you don't have negative values canceling them out.\\nThis is also going to penalize outliers\\nor values that have really bad errors.\\nSo in the case here, you can see that\\nour mean_absolute_error is this value, 0.0019,\\nand our mean squared_error_is 8.4 times 10 to -6.\\n\\nIs that good or bad? I'm not sure.\\nAgain, I'm not a aircraft expert.\\nBut again, if those values go down,\\npresumably you have a better model.\\nNow, we can also ask the model to predict\\nsomething given a row.\\nSo here I'm saying,\\ngiven the first row of my data, make a prediction.\\nIt says, \\\"I'm going to predict 0.03.\\\"\\nIf I look at the real value of that, it's 0.031.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5901671\",\"duration\":364,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Assumptions\",\"fileName\":\"3806104_en_US_03_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":405,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to apply linear regression to a complex dataset, drawing insights and making predictions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13543944,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, let's talk\\nabout some of the assumptions of linear regression.\\nIf you were to take a stats class, they would go over these.\\nI'm going to give a caveat,\\nand some statisticians might not like this,\\nbut my experience sample size one is that in the industry,\\na lot of people aren't covering these\\nbecause oftentimes they will use linear regression\\nas a base model and then use other models like XGBoost.\\nAnd if the XGBoost model performs better\\nor is good enough for their business,\\nor even if the linear regression model\\nworks in their business,\\nthey don't necessarily care\\nthat some of these assumptions are violated.\\n\\nSo let's talk about the assumptions here.\\nOne is that this assumes that there's a linear relationship\\nbetween the features and the target.\\nRemember the features are the columns\\nand the target is that label that we're trying to predict.\\nAnd we saw in the examples with the Anscombe's quartet,\\nwhere we had a non-linear relationship.\\nRemember that second model there?\\nI said it didn't sit well with me\\nbecause the scatter plot looked curved,\\nbut the model was square.\\n\\nThat second model didn't sit well with me\\nbecause the scatter plot looked like it was a parabola,\\nbut the model was a line.\\nNow, in practice, that model might be sufficiently good\\nfor someone to deploy in the real world,\\nprobably not, because that's pretty simplistic\\nand you probably wouldn't need a model for that.\\nBut again, you need to make sure\\nthat you evaluate a model from a business point of view\\nand see if it would make sense for your business\\nif it's going to save you money or make you money.\\n\\nOkay, another assumption is no multicollinearity.\\nThat means that the features,\\nthe columns are not correlated among themselves.\\nNow, in practice, they can be correlated,\\nbut what's going to happen is if you have two columns\\nthat are basically correlated\\nor highly correlated, they're the same thing.\\nThey're going to split the weights between them.\\nSo if you look at the weights\\nand you have multiple columns that are correlated,\\nit's going to screw up the interpretation of your model.\\n\\nSo you want to be careful with that.\\nHomoscedasticity, that's a big word,\\nbut basically what it says\\nis that when you look at the residuals,\\nwhich is the error of your prediction,\\nas you go through the values for that target,\\nare the errors constant or do they change?\\nIs the variance changing over time,\\nor is that variance constant\\nas you sweep through the various values?\\nSo this assumes that it will be constant over time,\\nbut if it's not, generally, that indicates\\nthat you might need to play around with your features\\nor use a better model\\nthat's better able to compensate for that.\\n\\nAlso, linear regression doesn't like outliers.\\nWe saw that with the third example in Anscombe's quartet.\\nIt kind of threw off the line\\nbecause of that outlier up there.\\nSo you might want to be aware of outliers in your data\\nbecause that might throw off your model.\\nAnd then again, I note here\\nthat you probably want to scale the features.\\nSo we didn't scale the features above.\\nLet's scale them now.\\nAgain, we've seen how to do this already.\\nWe're just going to use our standard scaler,\\nand now all of these columns should be on the same scale.\\n\\nIf we look at the summary statistics of those,\\nif you look at the mean,\\nthe mean should be close to zero.\\nAnd in this case, it's not zero\\nbecause of the impedance mismatch\\nbetween how computers represent numbers,\\nbut it's close enough for computers.\\nLike -1 x 10 to the -17\\nfor most people is pretty close to zero.\\nStandard deviation should be close to one as well.\\nAnd you can see that that looks like\\nthat is indeed the case.\\n\\nSo let's run our model now.\\nHere is our model.\\nIf we look at the scorer, the score is now 0.81.\\nLet's look at the score previously.\\nAnd the score previously was 0.8134.\\nSo it looks like the score didn't really change too much.\\nLet's look at our bar plot here of the features.\\nAnd you can see that the bar plot is different now.\\nSo before, SaTime was the most important,\\nand now we had diffRollRate\\nand absRoll bump up above that.\\n\\nSo I'm assuming\\nthat that is because we standardized the data\\nand that these were at a different scale before.\\nSo those weights were scaled differently,\\nbut now they're coming in as more important.\\nSo that is something to be aware of\\nif you want to understand what's going on with your model.\\nOkay, I'm going to now use what's called the XGBoost model.\\nThis is not part of scikit-learn,\\nbut it follows the scikit-learn interface.\\nThis is a super popular model\\nand it tends to do very well out of the box.\\n\\nYou can see that I call fit and score\\nso it has that same interface, but we got a 0.95 in there.\\nAgain, folks ask, so is 0.95 good enough?\\nI don't know if it's good enough,\\nbut what I do know is that this 0.95 score is a better model\\nthan a 0.81 score.\\nSo it's a better model.\\nIs it sufficiently good?\\nThat question needs a little bit more exploration to answer.\\n\\nOkay, in this video, we talked about some of the assumptions\\nof linear regression,\\nand we also saw that if we scaled the data,\\nin our case, the score did not change,\\nbut the interpretation of the weights did change.\\nWe also saw that we can use an XGBoost model\\nthat has the same interface,\\nand oftentimes we get a big performance\\nby using a model like XGBoost.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5906618\",\"duration\":34,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Develop a linear regression model\",\"fileName\":\"3806104_en_US_03_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":37,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to develop a linear regression model for a practical scenario, focusing on model tuning and interpretation.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":980931,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] It is challenge time again.\\nNow's your chance to make a model to predict\\nhow much Titanic passengers paid for their tickets\\nwith linear regression.\\nSome of the previous challenges might have been\\na little hard because we weren't aware of standardization\\nand other things that we can do with Scikit learn,\\nbut hopefully now we're getting a better feel for this.\\n\\nTry this out and see how your model does.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5906619\",\"duration\":127,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Develop a linear regression model\",\"fileName\":\"3806104_en_US_03_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":202,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Examine the best practices for the challenge's scenario, consolidating learning and refining techniques.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3984216,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Okay, let's look at the solution here.\\nI think we've got our Titanic data right here.\\nOkay. So we're going to make a model\\nthat predicts this column here, fare,\\nfrom all of the numeric columns.\\nLet's see if we can do that.\\n\\\"Predict fare from numeric columns.\\\"\\nOkay, so here is our X.\\n\\nWell, I think we want to call tweak_titanic on that too.\\nSo we're going to call tweak_titanic on that,\\nand then we'll drop that.\\nAnd our Y is equal to,\\nand that should be the fare column.\\nAnd let's make a linear model.\\nSo we're going to call fit with X and Y.\\nOkay, that looks like it worked.\\nLet's see what our score is.\\nAnd our score is 0.38.\\n\\nOkay.\\nSo, is that a good model? Again, we don't know.\\nWe can look at other metrics and see if that makes sense,\\nbut it's a little bit hard to tell.\\nJust for fun, let's compare this with an xgboost model\\nand see how that does.\\nSo it's an XGBRegressor.\\nAnd we're going to say xgb.fit.\\nIt's the same interface here.\\nAnd we're going to say X and Y,\\nand then we will see the what the score is.\\n\\nAnd it looks like this model performs better.\\nFull disclosure, I still haven't shown you one thing,\\nwe'll talk about this later, which is splitting your data.\\nWe're evaluating our model on data that it's seen,\\nso we're evaluating our scoring here with all of the X,\\nand we're fitting it with all of that.\\nSo you could imagine a model that just memorizes that\\nand returns the result.\\nWhat we really want to do is split the data\\ninto a training set and an evaluation set.\\nWe'll see that later on in the course.\\nSo keep your eye out for that.\\n\\n\"}],\"name\":\"3. Linear Regression\",\"size\":47879165,\"urn\":\"urn:li:learningContentChapter:5909022\"},{\"duration\":737,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5904639\",\"duration\":79,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Logistic regression algorithm\",\"fileName\":\"3806104_en_US_04_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":129,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Grasp the foundational knowledge of logistic regression for binary classification tasks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2579617,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Narrator] In this video,\\nwe're going to talk about logistic regression.\\nOne thing to be aware of,\\nlogistic regression has the term regression in the name,\\nbut it is used for what is called classification,\\nwhere regression is we are predicting a numeric value,\\nin classification, we are predicting a categorical value.\\nIn this case, either a one or a zero\\nfor a positive or a negative class.\\nAnd it's called logistic regression\\nbecause it actually does curve fitting on a logistic curve,\\nand when you fit that curve, you get probabilities.\\n\\nAnd so basically, when the probability is above 0.5,\\nit's going to predict the positive case,\\nand below 0.5, it is going to predict the negative case.\\nI've got the formula written out right here\\nfor this function.\\nLet's plot it and see what it looks like,\\nand hopefully, that helps you get an understanding\\nof what's going to happen here.\\nSo in our data, and I'll show this in the next video,\\nwe'll have ones and zeros,\\nand we are going to try and fit this curve to that.\\n\\nAnd above this 0.5 value,\\nanything that's to the right of that,\\nwe will predict that as a positive,\\nand below, we will predict that as a negative.\\nIn the next video, we'll see an example of doing this.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5906620\",\"duration\":109,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Basic example\",\"fileName\":\"3806104_en_US_04_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":125,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to execute logistic regression on a basic dataset, emphasizing core concepts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3453785,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's look at a basic example\\nof logistic regression.\\nI'm going to make some data points here.\\nAgain, I'm just doing this in one dimension here.\\nI've got some X values,\\nand we're going to predict some Y values from that.\\nSo here's our training data.\\nWhen I plot this, I get something that looks like this.\\nSo the question is, if I give you an X value,\\ncan you predict whether it is a one or a zero?\\nSo we're going to use scikit-learn to fit this data here.\\nAgain, I need to put that X, even though it's one dimension,\\nit needs to be two dimensional.\\n\\nSo I'm going to stick it into a data frame.\\nThe Y can be a series, that's fine,\\nand it looks like it fit.\\nAt this point we have coef underscore,\\nwhich is the coefficient, and we have the intercept.\\nWe can plug those into our formula here\\nand see what happens when we do this.\\nSo here is our fitted plot.\\nI've got the original points as scatter plots.\\nI've got the curve fit on there.\\nAnd again, anything above this 0.5 or to the right of it,\\nso it looks like somewhere around here below zero,\\nwe are going to say that it is positive.\\n\\nEven though this would misclassify this\\nand it might misclassify that.\\nThat's okay, it will capture the other points.\\nAnd once we have this, again,\\nthis follows the scikit-learn interface.\\nIf we want to predict a value,\\nwe can pass in the value here.\\nAnd this says, if you pass in a negative 0.3,\\nwe're going to predict one.\\nAnd we can play around with this if we want to.\\nWe can say, okay, what about negative 0.43?\\nThat's a zero, right?\\nSo somewhere around that 0.3 is where it decides\\nto go up into positive versus negative.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5909020\",\"duration\":247,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Assumptions\",\"fileName\":\"3806104_en_US_04_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":305,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to implement logistic regression on a real-world dataset, deriving actionable insights, and outcomes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9001186,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, we're going to use a dataset\\nfrom the datasets library.\\nAgain, this comes from openml.org,\\nand I've pasted a little bit from the website here,\\nbut this is tracking eye movements.\\nYou can see that features are in the columns.\\nEach assignment is a time sequence, 22 dimensions.\\nThe first column is the line number,\\nblah, blah, blah, blah, blah.\\nEach example represents a single word.\\nYou're asked to return the classification\\nof each read sentence.\\n\\nSo we're going to load that,\\nand once we've loaded that,\\nwe're going to stick that into Pandas\\nand see what it looks like.\\nOkay, so 7,000 rows, 21 columns,\\nand we have this label over here,\\nand that's what we are trying to predict which label.\\nSo let's set up our data.\\nI'm going to standardize our data.\\nAgain, this is a family of algorithms that fits this curve,\\nand generally with these curve type fitting algorithms,\\nwe want to have data that's on the same scale.\\n\\nSo I'm going to use the standard scaler, standardize that data.\\nAgain, that gives each column a mean value of zero\\nand a standard deviation of one.\\nWe're going to stick all of the columns except\\nfor label into X,\\nand we're going to stick the label column into the Y.\\nLet's standardize our data.\\nSo we'll use the standard scaler,\\nwe'll just call fit transform.\\nThat will give us our X scale data.\\nWe don't need to worry about scaling the Y data,\\nthat's fine.\\nLet's then call fit and score on that and see what happens.\\n\\nOkay, so we fit the data and we called score,\\nand we got a score of 0.56.\\nSo what does that 0.56 mean?\\nThis is not that R2 score that we saw in regression.\\nThis is the accuracy.\\nIt is the percent of classifications that is correct.\\nSo of all of those labels in there,\\nwe got 56% of them correct.\\nAgain, little rant about this.\\nIs 56 good or bad?\\nIt might be good, it might not be good.\\n\\nIt really depends on your business use case.\\nGenerally, a model that has a higher accuracy is better,\\nbut there are other metrics that might be important.\\nA simple example I like\\nto tell people about when we're talking about classification\\nis predicting fraud.\\nGenerally, instances of fraud are very rare,\\nso it's really trivial to make a model\\nthat gets high accuracy on fraud prediction.\\nYou can just predict not fraud\\nand you'll get 99.9% accurate.\\n\\nNow, is that model useful? Probably not.\\nIn fact, you probably don't even need a model to do that.\\nYou can just say nothing is fraud.\\nSo be aware of that accuracy number.\\nAgain, generally with these models,\\nthis gives us a baseline.\\nOur gut film allows us to compare models,\\nbut we want to dive in deeper\\nand often look at business metrics,\\ntie models to business metrics,\\nto see if they will work or not.\\nAnother nice thing about this model\\nis that it has those coefficients.\\n\\nI'm going to pull those out and stick those in a Panda series\\nand do a bar plot of them.\\nSimilar to the linear regression,\\nwe have both a direction and a magnitude.\\nThings that are positive are going to push things\\nto the positive prediction when those values go up.\\nSo this last sack, Lynn, if that goes up,\\nit's going to push more towards the positive.\\nWord no if that goes up,\\nthat's going to push us towards negative.\\nAnd you can see that word no and title no,\\nand regress dur tend to have\\na large impact on our model here.\\n\\nSo in this video I gave you a quick intro\\nto logistic regression with real world data.\\nMost of the concepts here shouldn't be new now\\nbecause we've been seeing the Scikit Learn interface a lot.\\nSo it's just pulling in the new model\\nand using our existing tools with the new model.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5906621\",\"duration\":12,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Construct a logistic regression model\",\"fileName\":\"3806104_en_US_04_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":20,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to construct a logistic regression model for a given real-world challenge, emphasizing predictive accuracy.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":341510,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] It's challenge time again.\\nYour challenge is to make a model\\nthat predicts whether...\\n\"},{\"urn\":\"urn:li:learningContentVideo:5909021\",\"duration\":290,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Construct a logistic regression model\",\"fileName\":\"3806104_en_US_04_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":470,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Review the optimal strategies for the challenge, reinforcing understanding, and pinpointing areas of enhancement.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10160093,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Okay, we're going to look at the solution\\nfor our logistic regression model here.\\nThe first thing that we need to do is load our data set.\\nSo I'm going to just find the Titanic code that I had up above,\\nand I'll just copy this whole cell.\\nLet's plop that in here\\nand make sure that that runs.\\nOkay, so here is our Titanic data set,\\nand what we're going to do is we're going to predict\\nthe survived column here from the other ones.\\n\\nSo we're going to import our logistic regression model,\\nand we'll drop any rows that have missing values.\\nSo let's actually explore that a little bit.\\nWe've seen this already, but I'll just review it here.\\nSo here's row I can say is NA,\\nthat's going to gimme this data frame of true false values.\\nI can sum that up to see the counts.\\nOkay, and so we do have missing values for age,\\nand we have a lot of missing values for cabin,\\nbut we're going to drop those.\\n\\nAnd we're going to drop these ones at the end here as well.\\nSo maybe I'll come down here\\nand I'll say that our Titanic_X is equal to,\\nwe'll take the raw.\\nAnd I'm going to select the columns that I want.\\nI'm going to do that using loc.\\nSo I'm going to say take all of the rows\\nand we'll take P class that looks good.\\nAge, siblings, and parents.\\nParents and children fair.\\nAnd we'll say drop NA after that.\\n\\nThat should get rid of the missing age ones.\\nAnd we'll do Titanic_X,\\nand we'll just look what that looks like after doing that.\\nOkay, that looks okay.\\nLet's standardize the data here.\\nSo we need to import our standard scaler,\\nand then we will make an instance of our standard scaler,\\nand then we're going to call fit transform on that.\\nOkay, let's look at X after we've done this.\\n\\nOkay, and that is a NumPy array.\\nIf I don't want a NumPy array,\\nI'm going to tell it to output a pandas data frame.\\nSo that is from sklearn.\\nI need to import the set config,\\nand we'll say transform output is pandas.\\nLet's run it again.\\nAnd I got to make sure I don't have a typo there.\\nLet's try it again.\\nOkay, so that's looking pretty good.\\n\\nLet's split our data.\\nI'll do this in the next cell here.\\nSo we're going to say we want survived\\nand we want to use the index\\nfrom X as the rows here.\\nAnd we'll we'll use loc, let's see if this works.\\nAnd let's just look at that after\\nwe've done that to validate it.\\nOkay, so I think we're pretty good.\\nIt says the length is 1045,\\nand it says the index is going to 1308.\\nThat looks like that's okay.\\n\\nSo let's split the data.\\nIt's going to be X_train and X_test,\\nand we will say train test split.\\nAnd it says that is not defined.\\nSo we got to load that.\\nSo you can see I'm relying pretty heavily\\non my AI to help me complete this.\\nDo I have to do that?\\nNo, I'm just kind of being lazy.\\nI have all this code up above,\\nbut I've just reloaded my notebook.\\nSo the existing environment was lost when I did that.\\nAnd can you use AI to do this? Possibly, right?\\nDepends on if you're in an environment\\nwhere AI is available.\\n\\nIf not, you can take the code above\\nand just adapt it so that it works.\\nI don't have problems with that.\\nSo let's see here.\\nWe need to make an instance of our logistic regression here.\\nSo let's do that.\\nI'm going to say LR is equal to logistic regression.\\nAnd then all we do is call fit\\nand we'll call lr.score.\\nLet's see what the score is.\\nThis is the percent accuracy.\\nOkay, it looks like we got 65% accurate after doing that.\\n\\nOkay, just for fun, I'm going to load the XG boost model\\nand let's do the same thing.\\nThis should be really easy.\\nAll we have to do is swap out this logistic regression\\nwith XG Boost Classifier, and the rest is the same\\nor call fit and we'll call score.\\nOkay, so in this case, it looks like our\\nlogistic regression model is actually\\ndoing better than our XG Boost Classifier.\\n\"}],\"name\":\"4. Logistic Regression\",\"size\":25536191,\"urn\":\"urn:li:learningContentChapter:5905604\"},{\"duration\":1154,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5906622\",\"duration\":252,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Decision tree algorithm\",\"fileName\":\"3806104_en_US_05_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":298,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to acquire foundational knowledge of decision trees for classification and regression tasks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8457824,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this video\\nwe're going to look at decision trees.\\nLet's talk about the decision tree algorithm.\\nDecision trees are a great way to make models.\\nI really like decision trees.\\nThey have a few advantages of them.\\nOne is that you don't need to scale the data\\nbecause a decision tree is looking at\\nan individual column at a time.\\nIt's not comparing one column to another\\nat the same scale, so that doesn't matter.\\nAlso, decision trees can be intelligent\\nin that an implementation can deal with missing values\\nor categorical data, that depends on the implementation.\\n\\nFor example, XG Boost does that for us.\\nDecision tree is also explainable.\\nSo I went to the doctor and the doctor gave me a diagnosis\\nand actually showed me a decision tree\\nthat helped them lead to that diagnosis.\\nThese are some of the few advantages of a decision tree.\\nSo how do they work?\\nWhat they do is they look through all of the features,\\nall of the columns,\\nand then they decide at some threshold\\nin the value in that column,\\nwhere the best place to split that column would be\\nsuch that it best divides the positive\\nfrom the negative values.\\n\\nAnd I'm going to show an example here.\\nI need to load my anscombes data up above.\\nSo let me do that really quickly here\\nsince I restarted my notebook.\\nOkay, and let's make a decision tree.\\nSo this is a decision stump\\nand what that does is it makes one decision.\\nAnd let me visualize that here.\\nWe'll use plot tree, this is from Psychic Learn,\\nand this is what our stump looks like.\\nSo you can see for this set, this anscombes data,\\nwhat it's doing is it's saying if X is less than 0.8,\\nthen we're going to say the value is 5.79,\\notherwise the value is 8.927.\\n\\nSo it's made a single decision here\\nto give us one of two values.\\nLet's actually visualize that.\\nI'm going to plot the data and the predictions from the data\\nin a visualization.\\nAnd it's asking for numpy, and again,\\nbecause I restarted my notebook,\\nI don't have numpy here, so let me just throw that in here.\\nImportant numpy as np and let's try this again.\\nOkay, here's our anscombes data set.\\nYou can see those black dots there.\\nAnd here, the red line is the decision tree.\\n\\nBasically what it said is it can make one decision\\nbecause it's a stump\\nand it's saying that if it's less than 8.5,\\nit's this value down here.\\nIf it's greater than, it's that value above.\\nNow that doesn't look like a great fit to this line,\\nbut guess what?\\nWe can go deeper.\\nSo here I'm going to say max depth of two,\\nand we'll just plot this again.\\nAnd you can see that it's still doing the initial split\\nright here, but also now it has on the right hand side,\\nit can do another split\\nand on the left hand side it can do another split.\\n\\nSo you can imagine if we keep doing this,\\nwe can go up to max depth none.\\nThat means keep splitting\\nuntil you have pure nodes at the end\\nand we get something that looks like this.\\nYou can see it's actually matching every point on here,\\nand if you are close to one of these points in X,\\nyou will get that Y value.\\nNow this also demonstrates another feature\\nor maybe problem of a decision tree.\\n\\nIn that case, this looks like it's a little,\\nwhat we would call over fit.\\nIt's too complicated.\\nIt's going up and down.\\nAnd if you think about what's going on here with these dots,\\nwe probably would want some sort of smoother line\\ngoing on between there.\\nAnd our decision tree, because we've let it grow\\nas deep as it could, basically memorized the data.\\nWe call this over fitting in machine learning.\\nSo that's something to be aware of.\\nGenerally we want to tune these hyper parameters.\\nNow contrast that with our stump up here.\\n\\nOur stump was probably too simple,\\nso we would call this an under fit model.\\nThis is an over fit model,\\nand something like this might be an okay model.\\nThat is a good balance between those two.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5907649\",\"duration\":388,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Real-world example\",\"fileName\":\"3806104_en_US_05_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":614,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Discover the underlying assumptions and characteristics of decision tree algorithms.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14515178,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, let's look at a realistic example.\\nWe're going to use the aircraft elevators dataset\\nthat we have up above.\\nLet me just load that again.\\nOkay.\\nAnd we're going to make our X and our Y.\\nLet me just load that again.\\nOkay.\\nI think I've loaded the data for elevator now.\\nLet's run this.\\nAnd it says I haven't.\\nLet's try and do that again.\\nOkay, I loaded the raw data,\\nbut I didn't pull off the pandas dataframe.\\n\\nI think that was my problem.\\nLet's go back down here and and run this now.\\nOkay, so what I've done is I've made a decision tree\\nand I've said it has a max depth of three.\\nSo max depth is a hyper parameter.\\nIt is a lever that controls the complexity of this model.\\nAnd I called fit with my X and my Y,\\nand I got my model that is trained.\\nNow, one of the nice things about a decision tree\\nis that we can look at the tree,\\nso let's look at this tree and see what's going on here.\\n\\nHere is three levels.\\nYou can see that the first thing that it's looking at\\nis this SA time one.\\nAnd then on the right hand side,\\nit's looking at SA time one again.\\nAnd then it's looking at it again.\\nThis is actually really cool if you think about it.\\nWhat it is doing is it can dive in on a single variable.\\nAnd this lets a decision tree capture non-linear behaviors.\\nIf you have a relationship with a column in X\\nthat is non-linear,\\ni.e., it might have like a bathtub curve shape,\\nor it might have like an elongated S or Z shape,\\na decision tree can capture that,\\nwhereas a linear model, like logistic regression\\nor linear regression, cannot capture that\\nunless you have encoded some non-linearity into the columns.\\n\\nSo this is actually a cool feature of decision trees.\\nLet's look at the score of our model.\\nIn this case, because this is a regressor,\\nthis is the R two score.\\nSo we are saying that 48% of the variance of the solution\\nis derived from the columns in there.\\nRemember, the R two, or coefficient of determination,\\nis generally a value between zero and one,\\nscores being close to one being better models.\\nAnd we had a linear regression model up above.\\n\\nBut again, because I've restarted my kernel,\\nI don't have it.\\nLet's just make that really quick here.\\nOkay, so it looks like I don't have that model around\\nbecause I restarted my kernel.\\nI'm going to, again, just find it here.\\nThis is the steps that you probably would have to do\\nif you came back to your kernel.\\nSo we just came back to our kernel\\nand we can see that we need this right here,\\nand we need to make this linear model down here,\\nwhich is this right here.\\nThe code is actually the same,\\nso it should be relatively easy to just throw that in here.\\n\\nLet's do that.\\nSo I'm going to say L-R-E-L-E-V is equal to linear regression.\\nAnd we're going to fit our model.\\nOkay, let's run that.\\nAnd our linear regression model is .81.\\nSo what is that telling us?\\nIt's telling us that our linear regression model\\nhas a higher coefficient of determination,\\nor it's a better model, than this decision tree.\\nNow, remember, up above here,\\nwe made a decision tree of depth three.\\n\\nMaybe that's not the appropriate depth.\\nAnd so, what I'm going to do is I'm going to loop over the depths\\nand I'm just going to make different depth trees.\\nI'll start from a stump and I'll go up to 19.\\nAnd I'll keep track of my score and plot my score over time.\\nOkay, so here we go.\\nWe can see that as I add more depth to this,\\nas I get closer to 19, my score gets better.\\nSo we might think,\\nokay, well why don't we just make the tree go to 19?\\nWell, if you look at this, we are fitting it\\nand we're scoring it on the same data,\\nso we're kind of cheating.\\n\\nAnd if you remember what we talked about\\njust in the previous video,\\na decision tree has the ability to memorize your data.\\nAnd so, what we want to do is we want to split our data\\ninto a training set and a testing set.\\nSo we're going to use train test split to do that\\nso that we evaluate it on data that it hasn't seen.\\nLet's do that and then we'll run this here.\\nWhat this is going to do is it's going to plot a visualization\\nof our score on the training data, which is this blue line,\\nand then a plot of our scores on the testing data,\\nwhich is the orange line.\\n\\nAnd this is pretty interesting.\\nWe call this a validation curve.\\nAs we're tweaking the values of a hyper parameter,\\nwe can look at how our model does.\\nAnd it is interesting\\nthat the blue line goes up close to one,\\nbut we're not really caring too much about that blue line,\\nwhat we're caring about is this orange line,\\nhow the model is doing on data that it hasn't seen before.\\nAnd it looks like somewhere around here, maybe 10 or 11,\\nit maxes out and then it starts going down.\\n\\nSo at this point, we could probably say,\\nto the left of this, the model is under fit,\\nand to the right of it, it is over-fitting.\\nWhat does that mean, over-fitting?\\nIt means that it's memorizing the noise basically\\nin the training data, such that when it sees data\\nthat it hasn't seen before,\\nit can't regularize or adapt to that,\\nand so it does poorly.\\nDown here on the left hand side, it is too simple,\\nso it's not able to explain very well\\ndata that it hasn't seen before.\\n\\nSo let's make a new model with depth 11\\nand look at what our score is,\\nand our score goes up to 70, or .7.\\nSo we can compare that\\nwith our model from linear regression\\nand we see that our linear regression model is .81.\\nSo really what we should do\\nis make a linear regression model\\nand evaluate it on data that it hasn't seen.\\nSo let's train it on the training data,\\nand then we'll evaluate it on data that it hasn't seen,\\nand this will give us\\na more apples to apples comparison here.\\n\\nAnd we're still seeing a score around .81.\\nSo in this case, it looks like linear regression\\nis doing a better job with this data than our decision tree.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5905602\",\"duration\":249,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Random Forest and XGBoost\",\"fileName\":\"3806104_en_US_05_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":401,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to implement a decision tree on a complex dataset, deriving insights, and predictions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7842487,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In this video,\\nI want to talk about Random Forests and XGBoost.\\nWe saw in the previous video\\nthat our decision trees have the ability\\nto overfit and also underfit.\\nWe can make a stump that's too simple,\\nwe can make a decision tree that can go as deep as it wants,\\nbut that's memorizing,\\nit's getting too complicated.\\nSo one of the ways that we can remove that complication\\nor that tendency to memorize and make it adapt better\\nis to use a few tricks.\\nAnd one of those tricks is what is called doing bagging.\\n\\nThe idea behind bagging with a decision tree\\nis we're going to take a subset of the columns,\\nand we're going to train a model on a subset,\\nand then we'll train another model on a different subset\\nand repeat that multiple times.\\nAnd then we'll let each of those different trees\\nthat's looking at different aspects of the data\\nbasically vote,\\nand we'll take the vote or the aggregation of those.\\nWe actually call that a Random Forest.\\nIt's randomly looking at different subsets of columns.\\n\\nYou can also make it\\nlook at different subsets of features as well.\\nLet's run this.\\nI'm going to say let's import a Random Forest regressor.\\nThis is from the ensemble module.\\nIn scikit-learn, ensemble means combining a bunch of models.\\nSo you can think of this as making a bunch of small trees\\nthat look at different parts and then combining them.\\nSo in this case,\\na hyperparameter is the number of estimators,\\nthat's the number of trees,\\nand we're limiting the depth of all of them to 3.\\nIf we look at the score of this,\\nwe can see that the score of this is 0.528.\\n\\nNow, we can do the same thing here.\\nWe can say, okay,\\nlet's leave the number of estimators at 100,\\nand let's change the depth here\\nand plot that and look what happens when we plot it.\\nThis takes a while to run\\nbecause it's making 20 different models.\\nOkay, here's the result.\\nLet's look at this plot.\\nAgain, we see the blue line that's creeping up towards 1.\\nWe're actually not super concerned with the blue line.\\nWhat we're more concerned with is the orange line,\\nand it's a little bit hard to see here,\\nbut it looks, again, somewhere around 10, 11, 12.\\n\\nIt's sort of flattening out.\\nSo a rule of thumb when I'm making models\\nis if I have multiple models that are basically the same,\\nI will take the simpler model.\\nIn this case, if I have a depth that is shallower,\\nthat is a simpler model.\\nSo I'm probably going to go around here,\\n11, 12, maybe 13 for my model.\\nLet's try a depth of 13,\\nand look what that score looks like.\\nAnd we get a score of 0.82.\\n\\nSo, again, remember previously we had a score of 0.81\\nwith our linear regression model,\\nand now with our decision tree,\\nwe're getting a score of 0.82.\\nOkay, I'm also going to make a XGBoost regressor.\\nSo this is using another ensembling technique.\\nRandom Forest used what we call bagging.\\nXGBoost uses what we call boosting.\\nThe idea with this is that you make a decision tree,\\nand then you make another decision tree\\nthat corrects the previous decision tree's error.\\n\\nI like to compare this to golf.\\nIf you're thinking about golfing,\\na decision tree is like being able to hit the ball once,\\nand you're so far away from the hole\\nafter you hit the ball once.\\nA Random Forest is like you and five of your best friends\\nor 40 of your best friends\\nall get a chance to hit the ball once,\\nand you take the average of where your ball lands\\ncompared to where the hole is.\\nThat's probably going to be better than a single hit,\\ndepending on who your friends are.\\nA XGBoost regressor is like,\\nI hit the ball once, then I hit it again,\\nthen I hit it again,\\nand I can change my swings each time.\\n\\nIf you think about that analogy,\\nwhich is kind of what's going on here,\\nXGBoost should be able to do a better job.\\nLet's try it out and see.\\nAnd it looks like indeed here it does.\\nIt gets 0.87 on this model.\\nAgain, the nice thing about this,\\nthese are all using the same interface.\\nSo once you've got your data in a place\\nwhere it can work with a decision tree or linear.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5907650\",\"duration\":25,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Design a decision tree model\",\"fileName\":\"3806104_en_US_05_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":29,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to design a decision tree model for a specific real-world problem, emphasizing depth, and feature selection.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":666605,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Okay, now it's time\\nfor you to try out decision trees.\\nAgain, this should be relatively easy.\\nAll you have to do is swap out the previous code\\nand use a decision tree instead.\\nI want you to see\\nif you can determine the optimal depth of the tree\\nusing a validation curve, like we did up.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5904640\",\"duration\":240,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Design a decision tree model\",\"fileName\":\"3806104_en_US_05_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":443,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to evaluate the best approach to the challenge, solidifying understanding, and improving modeling strategies.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8452753,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Instructor] Okay, we're going to make a decision\\ntree classifier.\\nLet's load that module here.\\nSo I'm going to say from SK learn\\nand it's tree import decision tree classifier.\\nAnd let's just look at our raw data here.\\nHere's our raw data.\\nWe want to predict the survived column from the other ones.\\nSo I'm going to say Titanic X is equal to raw\\nand I want to get certain columns in here.\\n\\nI want P class that looks good, age looks good,\\nsiblings, parents ticket.\\nI don't have ticket in there.\\nI believe ticket is actually not numeric.\\nSo I'm okay with that.\\nAnd let's drop the missing values from that\\nand we'll look at Titanic X after doing that.\\nOkay, that looks okay, again,\\nbecause this is a decision tree, we don't need to\\nstandardize the data.\\n\\nIf we wanted to compare it to logistic regression,\\nwe might want to do that,\\nbut in this case, I'm not going to.\\nSo I'm going to say for our Y, we're going\\nto take the survived column.\\nSo I'm going to come down here and say pull off survived.\\nAnd then if I do this\\nbecause I dropped A on the X, I need\\nto have corresponding rows here.\\nSo I'm going to say loc here,\\nand I'm going to Titanic X index here in loc\\nto get those so that they're corresponding here.\\n\\nOkay, so I think that's pretty good.\\nI'm going to say DT is equal to,\\nand I'm going to say decision tree.\\nActually, I'm going to split my data first.\\nSo let's split our data, so that should be good.\\nWe'll run that, let's just look at what our data looks like\\nafter we've done that.\\nOkay, so that's looking like it split.\\nI'm going to come up here and take this code up here\\nand I'll copy this and paste it down here.\\n\\nSo instead of a random forest here,\\nI'm going to say decision tree classifier.\\nAnd we don't have an estimator.\\nThat's not a hyper parameter there this says RF here.\\nSo maybe I'll just change that to DT\\nand let's run this.\\nOkay, and here we go.\\nIt looks like our depth at this is, I believe this is three,\\nis probably giving us our best model here.\\n\\nNow, one of the things you might be concerned about is like,\\nwhy is this going up and down?\\nWhy isn't it monotonically increasing and decreasing?\\nThat's probably our train test split has different subsets\\nin it that perform better at different model sizes.\\nSo you could change where we split on,\\nwe said random state 42.\\nIf you change this to 43\\nand we reran this, this might look a little bit different.\\nOkay? And it looks like it's still at three the best here.\\n\\nAnother thing you can do is you can do what's called k-fold\\ncross validation.\\nBasically what that is doing is instead\\nof just reserving some chunk for testing,\\nit splits up the data into some number of chunks,\\ntypically something like five.\\nAnd you loop over and hold out each of those chunks\\nand then aggregate those values to see overall on all\\nof your data, how is your model performing\\nwith given hyper parameters?\\nAnd that's looking probably\\nfor this model, this decision tree.\\n\\nI would do a depth of three for our Titanic model.\\n\"}],\"name\":\"5. Decision Trees\",\"size\":39934847,\"urn\":\"urn:li:learningContentChapter:5902655\"},{\"duration\":86,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5902654\",\"duration\":86,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"3806104_en_US_06_01_LA30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Editors, this is a workspace cam video. Please add URL overlay https://store.metasnake.com/xgboost at 00:51 and overlay https://www.linkedin.com/in/panela/ at 01:10. No need for additional visuals, some punch in would be sufficient if necessary.\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":105,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5452973,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Congratulations on completing the course.\\nYou might wonder about the next steps to solidify\\nand expand your newly acquired machine learning skills.\\nFirst and foremost, I can't emphasize enough\\nthe importance of practicing what you've learned.\\nMachine learning, like any skill,\\nrequires practice to deepen your understanding.\\nConsider working with data sets from your own projects,\\nor explore online repositories for data sets\\nto apply the algorithms we've discussed.\\nSecondly, for those looking to further their knowledge,\\nI recommend my book \\\"Effective XGBoost.\\\"\\nIt's designed to bridge the gap between theoretical concepts\\nand real-world application, offering advanced techniques,\\ncode examples, and practical exercises.\\n\\nThis book provides end-to-end coverage\\nof classification models with XGBoost.\\nAdditionally, I encourage you to connect with me\\non LinkedIn.\\nI regularly post updates, code snippets,\\nand insights on the latest in machine learning,\\nPython programming, and data science.\\nFinally, I urge you to apply these concepts and techniques\\nyou've learned to your own data projects.\\nHands-on application is crucial\\nfor mastering machine learning.\\nWhether it's predicting customer behavior,\\nanalyzing text data, forecasting trends,\\nthe skills you've gained in this course are valuable\\nand applicable across many domains.\\n\\nThanks for embarking on this journey with me.\\nI wish you all the best\\nin your future projects and endeavors.\\n\"}],\"name\":\"Conclusion\",\"size\":5452973,\"urn\":\"urn:li:learningContentChapter:5903621\"}],\"size\":250974119,\"duration\":7083,\"zeroBased\":false},{\"course_title\":\"How to Handle Poor Performers\",\"course_admin_id\":2884099,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2884099,\"Project ID\":null,\"Course Name\":\"How to Handle Poor Performers\",\"Course Name EN\":\"How to Handle Poor Performers\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Patience with poor performance too often becomes permission to perform poorly. Effective leaders know they need to address the problem of poor performance in their company and on their team, but the skills needed to do so don\u00e2\u20ac\u2122t come naturally to most of us. In this course, former corporate executive Ron Williams shows you a roadmap for tackling the tough conversations and hard decisions that come with responding to poor performers. Ron explains how to identify and respond to poor performance, as well as exactly how to do it. He covers strategies to recognize the difference between performance and potential and to take swifter, firmer action today with team members who are coming up short. &lt;br&gt;&lt;br&gt;This course was created by &lt;a href=http://www.onlymadecraft.com target=_blank&gt;Madecraft&lt;/a&gt;. We are pleased to host this training in our library.&lt;br&gt;&lt;br&gt;&lt;img src=https://media.licdn.com/media/AAYAAgCwAAoAAQAAAAAAAHppnBQxgeyWS2CsU3aDDPcMgw.jpg height=20% width=20%&gt;\",\"Course Short Description\":\"Become a stronger and more effective manager by learning to tackle the problem of poor performers with compassion and decisiveness.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":\"21401000, 20568001\",\"Instructor Name\":\"Madecraft Licensor, Ronald Williams\",\"Instructor Transliterated Name\":\",\",\"Instructor Short Bio\":\"Full-Service Learning Content Company|Management Professional and Entrepreneur\",\"Author Payment Category\":\"LICENSED, NONE\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2021-03-19T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/how-to-handle-poor-performers\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Beginner\",\"LI Level EN\":\"Beginner\",\"Sensitivity\":null,\"Internal Library\":\"Business\",\"Internal Subject\":\"Leadership and Management\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":2975.0,\"Visible Video Count\":16.0,\"Contract Type\":\"LICENSED, NO_CONTRACT\"},\"sections\":[{\"duration\":81,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2420012\",\"duration\":81,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"The importance of performance\",\"fileName\":\"2884099_00_01_WL24_Theimportanc\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15686338,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Here's the truth.  \\n Patience with poor performance  \\n eventually becomes permission to perform poorly.  \\n One of the things I've seen all too often  \\n over the course of my professional career  \\n is a manager who's afraid to handle the poor performer.  \\n But if that's you, then you're losing your rhythm  \\n and undermining your effectiveness by allowing  \\n a person's poor performance to continue unaddressed.  \\n My name is Ron Williams.  \\n I'm an entrepreneur, a coach,  \\n and a former corporate executive.  \\n I'm committed to and passionate about  \\n helping leaders become better managers  \\n and helping managers become better leaders.  \\n In this short course,  \\n I want to help you take swifter, firmer action  \\n to address poor performers.  \\n I'll share with you the environmental impact  \\n of poor performance.  \\n You'll learn strategies to have  \\n more effective crucial conversations,  \\n decide between performance and potential,  \\n and then learn the three T's of poor performance.  \\n Once you're done,  \\n you'll be prepared to handle poor performers  \\n by either managing them up or managing them out.  \\n The truth is, performance issues don't just happen.  \\n There's always an underlining cause.  \\n I want to help you lead change  \\n by changing the way you lead  \\n when it comes to poor performers.  \\n So are you ready?  \\n Let's go.  \\n\\n\"}],\"name\":\"Introduction\",\"size\":15686338,\"urn\":\"urn:li:learningContentChapter:2415018\"},{\"duration\":511,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2420013\",\"duration\":146,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Environmental impact\",\"fileName\":\"2884099_01_01_LA24_Environmenta\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"As a manager, you must understand that all your employees want to do well in their job. In this video, learn how to set expectations and accountability for your team.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":31366498,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - I used to believe that in order to be successful,  \\n you just had to be self-motivated,  \\n and while that's important, I've realized over the course  \\n of my career that even a self-motivated person can fail  \\n if their environment isn't conducive to their success.  \\n The truth is: people need the right conditions  \\n to fulfill their potential.  \\n No matter who you have on your team,  \\n whether they're high potential or low potential,  \\n they'll need a great environment to thrive.  \\n As a manager, it's your job to create the conditions  \\n under which your employees can avoid the trap  \\n of poor performance.  \\n In this lesson, I'll walk you through three ways  \\n to start creating an environment you can be sure  \\n will contribute to strong performance  \\n from all of your employees.  \\n First, you have to make sure people feel appreciated.  \\n Not only is feeling valued a key indicator  \\n of job satisfaction,  \\n it's also a key driver of performance.  \\n Start by looking for ways your team members are meeting  \\n or even exceeding expectations.  \\n When you find something, make a special effort  \\n to recognize it in your next one-on-one.  \\n And even if you don't,  \\n just a simple thanks for all of your hard work  \\n can go a long way  \\n to helping someone feel seen and valued.  \\n Second, regularly walk your employees  \\n through your expectations for them.  \\n Your team needs to know what their responsibilities are  \\n in order to take charge  \\n of their work and perform at their best.  \\n Have high, but attainable expectations  \\n and state them clearly.  \\n This makes it clear that you have confidence  \\n in your employees and helps build the sense  \\n of autonomy they need to succeed.  \\n And finally, compensate your employees fairly.  \\n You respect your employees when you pay them fairly  \\n and they'll return that respect.  \\n And while you're at it,  \\n develop proper incentives and rewards for excellent work.  \\n Incentives will vary by person.  \\n What feels like a reward to one, won't to another,  \\n so take the time to get  \\n to know what each employee will appreciate most.  \\n This will help motivate them to achieve your department  \\n or company's goals and avoid poor performance.  \\n As a manager, you're an environmentalist.  \\n You create an environment  \\n in your workplace based upon what you say  \\n and how you say it, what you reward, and what you penalize.  \\n Take that responsibility seriously and start today.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2414015\",\"duration\":195,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Performance and potential\",\"fileName\":\"2884099_01_02_LA24_Performancea\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"A critical task for a leader is to create a climate that enables employees to succeed. In this video, learn how to help employees reach their full potential.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":41746403,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - As every manager knows,  \\n performance and potential are not the same thing.  \\n Just because someone has succeeded in a role so far  \\n doesn't mean it will continue to be the best fit for them.  \\n And just because someone isn't a high performer  \\n at a particular time  \\n that doesn't mean they don't have potential.  \\n They might flourish under difficult circumstances  \\n or in a different position.  \\n As a manager, you should always stay open  \\n to an employee success.  \\n Don't write someone off,  \\n even if they aren't living up  \\n to what you thought they would be.  \\n But the reality is you do need to keep a sense  \\n of your employees.  \\n In this lesson, I'll give you a sense  \\n of four categories of employees  \\n through the lens of performance and potential.  \\n Along with steps to take  \\n to guide employees in each one.  \\n Scenario number one,  \\n is the high performing high potential employee.  \\n These are your superstars who rise to every challenge  \\n and who always are seeking out ways  \\n to advance their career.  \\n For these employees  \\n make sure you are regularly recognizing their performance  \\n and doing whatever you can do to reinforce it.  \\n You can also find ways to help them become a coach  \\n or a role model for others on your team.  \\n Scenario number two,  \\n is the high performing low potential employee.  \\n This is the satisfied employee,  \\n they like their current role, and probably aren't interested  \\n in leveling up their role or their responsibilities.  \\n Their job fits their lifestyle,  \\n it fits their interests.  \\n It's not that this person couldn't accomplish more  \\n but they are happy where they are.  \\n Focus your feedback for these employees  \\n on finding new ways to keep them engaged,  \\n ask them about their interests  \\n or goals and aspirations and seek out opportunities  \\n that may continue to be a strong fit for their skills.  \\n Scenario number three is,  \\n the low-performing high potential employee.  \\n This employee is stuck.  \\n They might have a big dream and even big talent  \\n but something is keeping them from reaching their potential.  \\n Have a genuine one-on-one with them  \\n where you can attempt to get  \\n to their heart of what's holding them back.  \\n Then develop a close coaching relationship with them  \\n and guide them through goals based upon what you learn.  \\n And finally, scenario number four is,  \\n the low performing low potential employee.  \\n These are your employees who are really slipping.  \\n They aren't doing well at work  \\n and they don't seem to care.  \\n Your feedback here needs to be focused closely  \\n on changing their results and behaviors.  \\n Even if they don't seem open to feedback  \\n still make the effort to have those hard conversations  \\n where you remind them of your expectations for them.  \\n Make sure they have a clear sense  \\n of what their responsibilities are  \\n and then create a plan with them with deadlines  \\n for improved performance.  \\n And of course, don't forget to follow up.  \\n Now understanding these four scenarios  \\n will help you coach your team members  \\n to realize their highest possible potential.  \\n Think of your team and ask yourself  \\n if there's anyone who may have slipped  \\n between these categories lately  \\n what steps could you take to reward them  \\n or get them back on track?  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2419007\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining poor performance\",\"fileName\":\"2884099_01_03_LA24_Definingpoor\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"It\u2019s important to assess employee performance and potential to see where there\u2019s room for improvement and additional training. In this video, learn how to recognize when an employee is underperforming.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":36293868,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - You may be hesitant to say  \\n that you have poor performers on your team,  \\n but just because your employees aren't behaving  \\n like the employees in \\\"Clerks,\\\"  \\n that doesn't mean you don't have any poor performers.  \\n Especially if you've built strong relationships  \\n with your team members,  \\n it can sometimes be difficult to recognize poor performance.  \\n But as you know,  \\n you can't leave poor performance unaddressed.  \\n Overlooking it can drain the morale  \\n of your other employees and tank your company's profits.  \\n In this lesson, I'll walk you through some qualities  \\n that regularly show up with poor performers  \\n so you'll be quick to recognize  \\n and respond to them right away.  \\n Now, as to be expected,  \\n a poor performer consistently fails to produce the results  \\n you expect from them.  \\n They miss deadlines, they don't hit their numbers,  \\n and they do these things on a regular basis.  \\n In the same vein,  \\n poor performers make more mistakes than others on your team.  \\n In other words, the quality of their work is poor.  \\n Presentations are sloppily done.  \\n Reports are thrown together last minute,  \\n and even important projects are riddled with errors.  \\n Some markers of poor performance,  \\n however, can fly under the radar.  \\n For example, is there an employee  \\n you just find yourself talking to all the time?  \\n You seem to spend much more time handling them  \\n than you do anyone else.  \\n That's a sign they're struggling  \\n to develop autonomy in their role.  \\n Similarly, poor performers will rely too heavily on others  \\n to meet their goals.  \\n And of course, if an employee consistently struggles  \\n to maintain good relationships with you  \\n or with their coworkers, they're performing poorly  \\n even if they're producing seemingly great work.  \\n Ultimately, their inability to get along  \\n with their team members will have an effect  \\n on the work they have to produce collaboratively,  \\n and their bad attitude will affect everyone near them.  \\n If you're seeing these signs in an employee, ask yourself,  \\n \\\"Knowing what I know about them,  \\n if they had applied for the job today, would I hire them?\\\"  \\n If there are people working for you  \\n that you wouldn't rehire if given the opportunity,  \\n you have an unacceptable situation.  \\n You cannot allow mediocrity into the workplace.  \\n If you do, it will spread  \\n and ultimately infect the whole environment.  \\n When high performers see that you tolerate poor performers  \\n and the poor performance,  \\n you run the risk of them becoming less engaged.  \\n Your leadership will be questioned  \\n when you don't take action on poor performance  \\n or poor behavior.  \\n Being able to identify the characteristics  \\n of poor performers early  \\n will help you address the issues early  \\n and turn around the poor performance.  \\n \\n\\n\"}],\"name\":\"1. Understanding Performance\",\"size\":109406769,\"urn\":\"urn:li:learningContentChapter:2419009\"},{\"duration\":429,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2416008\",\"duration\":224,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating value\",\"fileName\":\"2884099_02_01_LA24_Creatingvalu\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"It\u2019s important to understand that everyone has equal value as human beings, but not everyone knows how to create equal value in the workplace. In this video, learn how to coach your team towards creating value.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":47658092,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - If you ask your employees what they thought  \\n their salary paid for, what do you think they would say?  \\n Many might provide responses  \\n associated with the time spent and or on work,  \\n but the reality is  \\n that employees are compensated based on the value  \\n they bring into an organization.  \\n In my first position as a manager  \\n I had an employee who was frequently combative  \\n towards my leadership style.  \\n He argued with me in team meetings,  \\n disagreed with customer strategies  \\n and disregarded my direction and advice.  \\n Ultimately, he was a challenge to work with  \\n and this led him down a path of poor performance.  \\n As a result of this the employee was terminated  \\n and out of anger he approached human resources  \\n upset with this outcome.  \\n In my conversations with human resources  \\n I was able to articulate that this person  \\n did not provide sufficient value to the organization.  \\n This individual unfortunately prioritized  \\n disagreement over progress and retaining them  \\n turned into more of a burden than it was worth.  \\n Although letting a member of your team go is never easy,  \\n revealing the value employees bring to the table  \\n is a key part of these decisions.  \\n When considering value production  \\n you should also reflect on if you've clearly communicated  \\n what that value should be for your team members.  \\n Most employees want to get a raise or a promotion  \\n but can't always answer this question  \\n with confidence and conviction.  \\n What value do I bring to the company?  \\n Additionally, a recent Gallup poll revealed  \\n that up to half of employees don't really understand  \\n what is expected of them at work.  \\n In this lesson, I'll provide you with a set of standards  \\n you can use to assess  \\n if an employee is contributing sufficient value  \\n to your organization,  \\n along with some suggestions you can employ  \\n if they're falling short in one of these areas.  \\n First, they need to meet expectations.  \\n Before an employee starts expecting raises and promotions  \\n they need to make sure that they are meeting  \\n the expectations of their role.  \\n If this is a struggle, set a meeting with your employee  \\n where you review the responsibilities of their position,  \\n then the two of you together can discuss  \\n and decide on a list of metrics you'll track  \\n to ensure they're meeting and exceeding expectations.  \\n Next, they need to be a team player.  \\n Someone who builds strong relationships with others  \\n and who always shows up with a positive attitude  \\n that creates a ripple effect through their organization.  \\n They inspire others to take initiative  \\n while also ensuring there's a strong foundation  \\n for collaboration.  \\n Not only does this increase productivity  \\n it also creates a positive environment  \\n that team members and customers alike will feel.  \\n Consider team building activities  \\n to foster this sense of community in your organization.  \\n Lastly, valuable team employees are big picture thinkers.  \\n They understand how their efforts  \\n will impact the organization  \\n and know how to prioritize their efforts appropriately.  \\n They recognize where there's room for innovation  \\n and they communicate their observations readily and clearly.  \\n Encourage creative thinking in your organization  \\n to demonstrate to your employees  \\n that this is an important skill to you  \\n and the company as a whole.  \\n To establish their value,  \\n employees must show up, step up and stand out.  \\n Creating values more than just being good at your job.  \\n Now, you have a better understanding of the characteristics  \\n and qualities that help employees create value  \\n in the workplace.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2420014\",\"duration\":205,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Assessing reality\",\"fileName\":\"2884099_02_02_LA24_Assessingrea\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"It's important to be honest with yourself as a leader about the talents, actions, and performance levels of members of your team. In this video, learn how to identify potential performance problems.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":44019050,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Do you know where you are right now?  \\n This might seem like a silly question.  \\n Sure, you might be enjoying this course from your office  \\n or in the comfort of your home, but knowing where you are  \\n goes beyond your physical location.  \\n It means you have a sense of where you are in your career.  \\n What are your goals,  \\n and where are you in relationship to them?  \\n This is an important step that routes the actions you take  \\n towards what you want to accomplish.  \\n The same rules apply  \\n for understanding your team and their performance.  \\n You need to know where you are  \\n and where you want to be in order to create a path forward.  \\n As Lewis Carroll famously stated,  \\n \\\"If you don't know where you're going,  \\n \\\"any road will take you there.\\\"  \\n In order to establish goals and work towards achieving them,  \\n you need to know your workforce reality.  \\n This means taking an objective view of your circumstances,  \\n particularly as they relate  \\n to your organization's ability to be successful.  \\n This includes looking at yourself, your unique workplace  \\n and your team, especially your poor performers.  \\n To assess your team, you need to look seriously  \\n at each employee.  \\n While the precise metrics or KPIs to track  \\n will differ based on your organization,  \\n here are three criteria to start with.  \\n First, effectiveness, how effective is this team member?  \\n Did they produce what they were supposed to produce?  \\n This will give you a chance to reflect on if this person  \\n successfully met the expectations set for them  \\n and to identify any patterns,  \\n such as a team member consistently  \\n under-delivering on a certain type of task.  \\n Second, efficiency, by asking questions  \\n like was the work delivered on time,  \\n How did this person allocate their resources,  \\n Were they self-sufficient at this task,  \\n you'll gain an idea of challenges the team member  \\n may have when completing tasks.  \\n This also allows you to better understand ways  \\n in which you might support this person differently.  \\n Maybe if they struggle with reaching goals on time,  \\n you need to help them lay out a more specific timeline  \\n with incremental deliverables.  \\n Third, progress, this is examining  \\n a team member's effectiveness and efficiency over time.  \\n People who are passionate about continuous improvement  \\n demonstrate an infectious, positivity and excitement,  \\n as well as increasingly great results.  \\n But a poor performer likely won't show progress,  \\n at least not in the right direction.  \\n They'll be more and more checked out,  \\n frequently late to work  \\n or frequently demonstrate negative attitudes.  \\n You might not notice this by just checking in occasionally,  \\n but if you take the time to consider performance  \\n in terms of long-term progress,  \\n new trends or concerns may appear.  \\n Once you perform this evaluation,  \\n you can leverage this sense of workforce reality  \\n to get a fuller picture of your team  \\n and how you can keep moving forward.  \\n At the end of the day,  \\n you're being held responsible in getting things done  \\n and delivering value for all stakeholders.  \\n So take a hard look at your team,  \\n where they're at and where they can grow  \\n in order to understand how you can ensure their success.  \\n You and your team are better than taking just any road.  \\n Help them find the right one.  \\n \\n\\n\"}],\"name\":\"2. All Workers Are Not Created Equal\",\"size\":91677142,\"urn\":\"urn:li:learningContentChapter:2418013\"},{\"duration\":708,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2417014\",\"duration\":239,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Employee engagement\",\"fileName\":\"2884099_03_01_LA24_Employeeenga\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"It\u2019s important to know the mental and emotional relationship between employees and the organization. In this video, learn how to respond to disengaged employees.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":51429803,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Many years ago, when chatting with a colleague of mine,  \\n they told me  \\n I'm just here to collect a paycheck, sound familiar?  \\n If so, you can probably already guess  \\n that my friend wasn't very happy in that job.  \\n But even if he was, maybe he was happy  \\n being able to do the bare minimum to get by  \\n that wouldn't have fixed the bigger problem.  \\n He wasn't engaged.  \\n Keeping your employees happy is important  \\n to keep attrition low and morale high,  \\n but it's nowhere near as important  \\n to performance as engagement.  \\n In this lesson, I want to share with you  \\n the three levels of engagement  \\n and some concrete steps you can take  \\n to increase your employee's level of engagement,  \\n so none of them just show up for a paycheck.  \\n To start, recognize that engagement  \\n is the emotional connection  \\n and commitment an employee has toward their responsibilities  \\n and their place of work.  \\n Engaged employees find a compelling purpose  \\n and meaning in their work,  \\n which means they'll be ready to go the extra mile  \\n to advance your organization's values  \\n and achieve your goals.  \\n Most research shows that engaged employees  \\n are more productive, more profitable, more customer-focused,  \\n and have longer tenure.  \\n So, it's usually easy to recognize  \\n a highly engaged aged employee,  \\n but let's look to two other levels of engagement.  \\n To start, the non-engaged employee  \\n is probably quite neutral about your organization.  \\n They take a backseat when it comes to task,  \\n won't go out of their way to take on additional work  \\n and avoid making commitments,  \\n but they're generally satisfied with their work.  \\n A 2018 Gallup study indicated that  \\n about half of all workers are in this category.  \\n At the far end of the spectrum  \\n are the actively disengaged employees.  \\n These employees aren't just checked out.  \\n They actively harbor some sort of frustration  \\n or grudge against their work or the company.  \\n They're the ones having a miserable work experience.  \\n If you're finding your team has a lot of employees  \\n who are not engaged or actively disengaged,  \\n try using these strategies to encourage them.  \\n First, set clear job expectations  \\n and give your team opportunities  \\n to ask questions or clarify.  \\n A good tactic here is  \\n to create a document with the expectations,  \\n so your team can review if they're ever unclear.  \\n Second, offered them career advancement opportunities  \\n that align with their interests.  \\n You can ask if they have ideas for specific projects,  \\n or if any projects are available  \\n that would help them get to their next opportunity,  \\n then get them to create individual development plans,  \\n where they outline goals over the next one to three years.  \\n Once you have these insights,  \\n you can help them keep a long-term career line of sight.  \\n Third, provide regular feedback and dialogue.  \\n You should always deliver feedback in private  \\n during one-on-ones  \\n and should focus on encouragement  \\n when working with disengaged employees.  \\n This feedback should include regular recognition  \\n of their contributions.  \\n Show praise for their efforts when they do a good job  \\n and approach them with empathy  \\n and respect when discussing challenging topics.  \\n Finally, do what you can to ensure  \\n they have good quality working relationships  \\n with their peers and managers.  \\n You can provide opportunities for the individual  \\n to build rapport with others by encouraging team members  \\n to host one-on-ones with each other periodically  \\n or by scheduling team lunches.  \\n Driving employee engagement  \\n is not a one-time project or initiative,  \\n it is something that you must pursue  \\n vigorously and consistently.  \\n Start today by picking one area of employee engagement  \\n you can improve on and brainstorm some ways to get going.  \\n The only way to go is up.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2420015\",\"duration\":252,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understanding morale\",\"fileName\":\"2884099_03_02_LA24_Understandin\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"You can't underestimate the effect team morale has on your company's success. In this video, learn how to identify areas of your workplace and team that may be damaging morale.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":53512042,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Think about a time when you shared with your boss  \\n that you were struggling with a task.  \\n Maybe you didn't have the skills to complete it,  \\n you were feeling discouraged  \\n or you didn't have enough time to get it done.  \\n Now think about how your supervisor or boss responded.  \\n Hopefully they were supportive  \\n and offered words of encouragement.  \\n That's because good managers understand  \\n that in order to improve performance  \\n employee morale has to be sustained.  \\n For employees or teams how they feel about their work  \\n influences their emotional and mental state  \\n when they're completing a specific project.  \\n If they feel positively towards the task  \\n and are excited to complete it  \\n they'll ultimately be more productive.  \\n Or if a poor performer has low morale  \\n or lacks excitement about their work,  \\n they're likely to be less productive.  \\n It's up to you as a manager to ensure that morale  \\n stays high amongst the members of your team.  \\n If you're unable or unwilling  \\n to deal with poor performing employees  \\n you'll likely notice the trickle down impact  \\n low morale can have.  \\n Instead stay proactive towards boosting morale  \\n by focusing closely on these key factors.  \\n First, the work.  \\n Employees today are looking  \\n for meaningful and fulfilling jobs.  \\n They want to work on things related  \\n to their personal interests  \\n what they're good at and what will make an impact.  \\n That means they'll prioritize what they're passionate about  \\n over money or other benefits when it comes to their work.  \\n Fulfilling this factor means  \\n you'll need to know your employees.  \\n Do what you can to set them on paths  \\n that matched their interests and commitments  \\n and be explicit about the ways  \\n in which you think a particular project may provide meaning  \\n or satisfaction for them.  \\n In addition, to helping employees find their niche,  \\n you should also be thinking about these basic factors  \\n that can boost or lower work morale.  \\n One, demands.  \\n Are you over or under-loading your employees?  \\n Number two, content.  \\n Is there never any variety in the kind of projects  \\n you ask your team to do?  \\n Are you putting them on tasks that don't use their skills  \\n or which don't have a meaningful context?  \\n Number three, control.  \\n Are you including your employees in discussions  \\n about how their work is done or how decisions are made?  \\n This goes, especially for times of change  \\n involve employees and change processes.  \\n Four, support.  \\n Are you regularly encouraging your team  \\n as well as ensuring they have all the resources  \\n they need to fulfill their obligations?  \\n Next, the workplace, whether your team is in an office,  \\n working remotely or a mixture of both,  \\n it's important that your team feels comfortable  \\n and like where they are working  \\n which hopefully is in a conducive environment.  \\n Factors that contribute to the work environment  \\n are lighting, ventilation, temperature,  \\n sanitation and cleanliness,  \\n interior, decoration, noise, and ergonomics.  \\n Your organization may have a human resources department  \\n that tackles ensuring employees have what they need  \\n but as a manager, a check-in from you  \\n is always a good place to start.  \\n And finally, the relationships at work.  \\n How people feel about their managers, coworkers  \\n and customers has a major effect on the employee experience.  \\n It's important that your team has the opportunity to bond  \\n around things outside of work  \\n to forge more meaningful relationships.  \\n A great way for you to aid in creating these relationships  \\n is to organize team or department outings.  \\n Set aside time each day for the team to catch up  \\n and to give opportunities for your team members  \\n to interact with customers.  \\n Creating a culture that constantly strives  \\n to have high morale is a win-win situation.  \\n You're a high performers stay happy and productive  \\n and your low performers have opportunities  \\n become more engaged with their work.  \\n The next time an employee isn't performing well  \\n try using these tactics to see if you can help them improve.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2415016\",\"duration\":217,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Cultural impact\",\"fileName\":\"2884099_03_03_LA24_Culturalimpa\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are several ways in which a poor performer can influence the rest of your team, but just as many ways you can mitigate their impact. In this video, learn how to build a great team culture using its six most important elements.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":46327617,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When I think about how a successful workplace is created,  \\n I often think of the Tracy Streckenbach quote  \\n culture is about making people feel good  \\n about how they contribute to the whole.  \\n Since culture relies on contributions,  \\n it's essential that each member of your team  \\n shares the values and ideals  \\n that will propel your organization forward.  \\n Poor performing employees can breed a negative culture  \\n and can quickly disintegrate a positive workplace.  \\n Workplace culture defines the way employees complete task  \\n and interact with each other in your organization.  \\n It binds your workforce together  \\n and reinforces that your organization  \\n is or isn't heading in the right direction.  \\n Now, think of your company culture as a pie  \\n where the organization's values and mission  \\n are the crust and the day-to-day operations  \\n and interactions are the filling.  \\n When married correctly,  \\n this culture pie comes out of the oven tasting deliciously.  \\n Much of an organization's culture  \\n is dependent upon the leadership and its management.  \\n As a leader, you set a culture tone  \\n based on how you communicate, motivate  \\n and build trust with those around you.  \\n To that end, it's crucial  \\n that you feel empowered to recognize  \\n how your day-to-day actions  \\n impact your organizational culture.  \\n In the OC Tanner Institute's annual culture report  \\n they focus on six key elements  \\n that make up and have the power  \\n to transform your workplace culture.  \\n First, purpose.  \\n Your employees want to feel excited  \\n about the reason the organization exists  \\n and should be able to connect their role at the company  \\n to set purpose.  \\n A great way to foster purpose  \\n is by creating a team or department mission statement.  \\n Next, opportunity.  \\n All employees want a chance to grow in their careers.  \\n It should be a priority of yours to align opportunities  \\n with the career development interests of your team.  \\n Now, success.  \\n Meeting or achieving a goal  \\n creates a feeling that's tough to beat.  \\n As such your role as a leader is to create and highlight  \\n wins and successes across all levels.  \\n Next, appreciation.  \\n Going back to purpose  \\n your team wants to feel like they're aided  \\n in delivering on things that serve the organization.  \\n There are many ways you can show appreciation to your team  \\n and a great place to start  \\n is by asking each team member how they like to receive it.  \\n Next, well-being.  \\n Your employees deserve to know that you care about them  \\n beyond the work that they do.  \\n Create an environment that reduces burnout  \\n and increases trust,  \\n allows room for your employees to feel safe  \\n and included in the workplace.  \\n Finally, leadership.  \\n It's your responsibility to inspire and support your team  \\n to achieve new goals  \\n and ultimately benefit the organization.  \\n That means both being a leader yourself  \\n as well as ensuring there are programs for mentorship  \\n at all levels of your organization.  \\n Culture is always a work in progress.  \\n It can and will change.  \\n It's too significant to ignore and shaping it  \\n is one of your most important responsibilities you have  \\n as a leader.  \\n If you follow through on improving these six  \\n culture shaping principles,  \\n you'll have started making people feel better  \\n about their work and started building a root system  \\n from which your organization can flourish.  \\n \\n\\n\"}],\"name\":\"3. Understanding Your Team\",\"size\":151269462,\"urn\":\"urn:li:learningContentChapter:2414017\"},{\"duration\":1152,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2418012\",\"duration\":199,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The three Ts\",\"fileName\":\"2884099_04_01_LA24_ThethreeTs\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"If you have someone working for you who fits the profile of a poor performer, you must execute one of the three Ts: train, transfer, or terminate. In this video, learn how to leverage the right T when appropriate.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":42641400,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Before you wrote them up, did you coach them up?  \\n An expected part of any leader's role  \\n is to give constructive feedback to an employee  \\n when something isn't going the way you want it to go.  \\n If you have an employee who isn't motivated,  \\n doesn't follow directions, or doesn't work well  \\n in a team environment, what are you expected to do?  \\n I remember my first managerial position.  \\n I had five sales reps working for me.  \\n I had four outstanding performers and one poor one.  \\n Can you imagine what I was thinking about concerning  \\n that one poor performer?  \\n Was I the problem or were they the problem?  \\n As the manager, it's your job to get positive results  \\n and meet organizational goals,  \\n but how well people work is up to them.  \\n My experience has taught me  \\n that most people don't plan to fail,  \\n they just fail to plan.  \\n In this lesson, I will walk you through the three T's.  \\n These will help you determine the actionable possibilities  \\n that you may have with your poor performer.  \\n The first T is train them.  \\n If for some reason a person isn't meeting  \\n your performance expectations, you must determine  \\n if their failure is a performance problem or training need.  \\n I hired Tammy, who said she knew Microsoft Office programs,  \\n but her proficiency in Excel and PowerPoint were lacking.  \\n I immediately enrolled her  \\n in a Microsoft Office training class  \\n to enhance her skillset.  \\n Many people perform poorly because they don't know how  \\n or what to do.  \\n The second T is transfer them.  \\n After Tammy completed the Microsoft training,  \\n I was still not satisfied with her performance  \\n but I did notice she was extremely effective  \\n in talking to customers.  \\n I spoke with our CSR manager to see if she had an opening.  \\n She did.  \\n And I asked Tammy if she would be interested in interviewing  \\n for the vacant position.  \\n She got the job  \\n and has been a consistently high performer in her new role.  \\n As a manager, you must be able to assess  \\n if a poor performer has other skillsets  \\n that are transferable to another position or department  \\n in the organization.  \\n The third T is terminate them.  \\n If you've provided training for a poor performer  \\n and their performance has not changed  \\n and if you've assessed their talent or skillsets  \\n and identify there was nothing transferable,  \\n then you must terminate them.  \\n Now, there is a fourth T I was introduced to  \\n after working with the federal government,  \\n and that was tolerating them.  \\n Tolerating a poor performer shows a lack  \\n of managerial courage.  \\n Instead of doing the work to get them up to speed,  \\n toleraters are afraid to push poor performers.  \\n But tolerating isn't really managing.  \\n Now, look at your current team.  \\n Do you have anyone who is not meeting  \\n your performance expectations?  \\n Do they need training or do they have a talent better suited  \\n for another task and they can be transferred?  \\n Or maybe you just need to terminate them.  \\n Now that you have the three T's,  \\n you can determine which plan of action to tackle  \\n with any poor performer.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2415017\",\"duration\":194,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Confronting poor performers\",\"fileName\":\"2884099_04_02_LA24_Confrontingp\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"When faced with a poor performer, you know not to tolerate them. In this video, learn how to confront employees directly when they aren't performing as they should be.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":41186582,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - None of us love difficult conversations,  \\n and that includes managers.  \\n You're probably not excited to confront a poor performer  \\n to talk about what's gone wrong  \\n and what needs to change next.  \\n And yet you cannot avoid these conversations.  \\n I once had a manager on my staff  \\n that avoided having difficult conversations with employees.  \\n He was fearful that the conversation  \\n would just create bad feelings or even more conflict.  \\n I had to remind him that the situation,  \\n as with any poor performer, wasn't going to resolve itself.  \\n Putting it off would only allow it to continue  \\n and potentially get even worse.  \\n In this lesson, I'll walk you through the rules  \\n you should follow whenever you need to confront an employee  \\n about their performance.  \\n You'll need to do this if you have someone  \\n regularly missing deliverables or submitting subpar work,  \\n or if your employee frequently acts in any way  \\n that doesn't reflect your organization's values.  \\n To start, while an annual performance review  \\n may seem to be the perfect time  \\n to bring up performance concerns,  \\n it's essential that you confront poor work  \\n sooner rather than later.  \\n If an employee doesn't know you're unhappy with their work,  \\n they may never realize they need to change.  \\n Give them the best chance at success  \\n by letting them know  \\n as soon as you notice the concerning behavior.  \\n Next, never confront in anger.  \\n It's very hard to get critical feedback,  \\n so your employee is likely to be dealing  \\n with their own emotions during the conversation.  \\n Make sure you've prepared with a calm, respectful demeanor.  \\n It's up to you to keep the situation under control.  \\n Then be sure to have the conversation in private.  \\n Don't do it within earshot of other staff.  \\n That doesn't mean, however,  \\n that you need to turn it into a big event.  \\n If you're just offering quick, immediate feedback,  \\n you don't necessarily need to make a production  \\n of going to your office and shutting the door.  \\n And next, be specific and use data.  \\n Telling someone that they just need to do better  \\n only leaves your employees feeling bad about themselves  \\n and probably feeling upset with you,  \\n with no idea of how to improve.  \\n Make your cause factual information  \\n to show there are serious concerns with their behavior.  \\n Providing them with these details  \\n means they'll be able to talk with their manager  \\n about where exactly to start improving.  \\n Finally, be clear.  \\n Don't confuse people by watering down the fact  \\n that this is a reprimand.  \\n Don't give them so much sugar  \\n that they can't taste the medicine.  \\n The last thing you want is an employee  \\n who's confused as to what you think of their behavior.  \\n While it's tough to give critical feedback,  \\n it serves you both and your organization  \\n much better in the long run.  \\n Dealing with poor performance immediately  \\n curves the widespread effect  \\n it would have if left unattended.  \\n Follow these guidelines to react appropriately  \\n to poor performance the next time it appears.  \\n As with any hard conversation,  \\n you'll eventually be glad you did.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2419008\",\"duration\":157,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Making a transfer\",\"fileName\":\"2884099_04_03_LA24_Makingatrans\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Most people have seen people who are hired for the wrong role. In this video, learn how to identify when a transfer may be the right fit.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":33397698,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - I'm sure you heard the saying,  \\n \\\"When one door closes, another one opens.\\\"  \\n This is true in management as well.  \\n If you've ever had a good employee  \\n who was performing poorly, you face down that closed door,  \\n but you've had an open one at the ready for you.  \\n That's the possibility of a transfer.  \\n If you hire someone who turns out to not be flourishing  \\n in the role that you brought them on for,  \\n then you have a fiduciary responsibility  \\n to not automatically write them off.  \\n They might seem like a poor performer,  \\n but that doesn't mean they're destined to be one  \\n in all situations.  \\n In this lesson, I'll walk you through  \\n when it's appropriate to consider a transfer,  \\n as well as how to make the case for one.  \\n When should you transfer an employee  \\n who isn't doing well?  \\n The first thing to consider is if they have a good attitude  \\n and are good company fit.  \\n This is a feature that bodes well for any position.  \\n A team player who supports your organization  \\n and believes in its mission is likely to be motivated  \\n to make a new position work.  \\n Another reason a transfer may be the right decision  \\n is if the employee has a particular talent or skill  \\n that would benefit another department.  \\n In this case, transferring them would  \\n both benefit your organization  \\n and would likely increase their engagement.  \\n Employees flourish when they feel  \\n they're making a unique contribution.  \\n Finally, a transfer might be the best move  \\n if an employee isn't succeeding  \\n because of something circumstantial.  \\n Do they have a long commute that could be solved  \\n by moving to a remote-only department?  \\n Are they competent, but just bored by repetitive task.  \\n Maybe there's a team building a new product  \\n where they could make the most of their energy  \\n and desire to grow.  \\n A transfer can also benefit the organization at large.  \\n Transferring a poor performer to another department  \\n may re-invigorate their interest in work,  \\n while also reducing the amount of workload carried  \\n by the members of an understaffed department.  \\n A good worker in the wrong job  \\n can be disastrous for them and you.  \\n As a leader, you want to ensure everyone  \\n is in a position where they're upskilling,  \\n gaining experience and benefiting the organization.  \\n Keep these justifications in mind.  \\n The next time you're looking at what seems like  \\n a closed door, you may find a new opportunity  \\n for someone around the next corner.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2416009\",\"duration\":206,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating a performance plan\",\"fileName\":\"2884099_04_04_LA24_Creatingaper\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"When an employee isn't performing well, you need to set a clear path forward for them to improve. In this video, learn how to develop a performance improvement plan with your employee.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":43793430,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The performance improvement plan,  \\n it's well known and widely feared.  \\n It's a formal document given to employees  \\n who are seriously underperforming  \\n and it outlines their mistakes  \\n as well as a plan for them to course correct.  \\n For plenty of people a PIP is a hint  \\n that they're practically out the door already  \\n and indeed a PIP should be assigned to your employee  \\n that their situation is serious.  \\n It's something you only use  \\n when you're coaching and training  \\n have failed to produce improved performance.  \\n But at the same time, a PIP though, it has this reputation  \\n shouldn't just be a way to document poor performance  \\n on the way to firing someone.  \\n For example, the first time I used the PIP  \\n the employee was very upset  \\n and felt I was trying to get rid of them.  \\n I was trying to show the employee  \\n that I understood their current challenges  \\n and long-term goals  \\n and I was taking an active role in supporting them.  \\n You should approach the PIP through the lens  \\n of trying to create a genuine opportunity  \\n for your employee to get back on track.  \\n You don't want employ turnover,  \\n you want to give them a chance to recover  \\n and ultimately stick around.  \\n In this lesson,  \\n I'll walk you through the essential components of a PIP  \\n or a process improvement plan  \\n so that you'll be able to put one together effectively  \\n should the need arise.  \\n First, your PIP should include a clear presentation  \\n of their job performance.  \\n What are the problems they have led to you  \\n to decide the PIP is necessary?  \\n Are they new problems  \\n or have they persisted for many months?  \\n What strategies have already been tried  \\n and how did they feel?  \\n Back all of this information up  \\n with clear data and factual evidence.  \\n Next, your PIP should present a robust  \\n plan of action going forward.  \\n What exactly needs to improve  \\n in order for the employee to fulfill the PIP?  \\n What steps should they take to get there  \\n and what goals can they aim for along the way?  \\n These should of course be attainable and realistic goals,  \\n don't set them up for failure.  \\n You should also provide resources  \\n that can help them meet these goals.  \\n If a first time manager has been struggling  \\n with their communication style, for example  \\n provide with books or articles on communication.  \\n This plan of action should also include concrete deadlines  \\n by when does their performance have to improve  \\n and what will the consequences be  \\n if they fail to meet these standards?  \\n Will they be terminated, suspended  \\n or receive an additional reprimand?  \\n Make the stakes very clear.  \\n Finally, a key part of the PIP is an honest conversation  \\n with the employee.  \\n Make sure you understand where they're coming from.  \\n Are there any factors affecting their performance  \\n they haven't shared with you yet?  \\n Are there any resources they need  \\n that might keep them from meeting these goals?  \\n And is there any way the PIP can align  \\n with their personal career goals?  \\n While they need to meet expectations,  \\n this can also be an opportunity to refine their fit  \\n with the organization.  \\n It's essential that following this meeting,  \\n you and the employee are on the same page  \\n about how they must improve their performance.  \\n While you may hope to never reach this stage,  \\n the best way to recover from it  \\n is with clear expectations and a path forward.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2420016\",\"duration\":153,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Considering termination\",\"fileName\":\"2884099_04_05_LA24_Consideringt\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"It\u2019s important to understand that removing a poor performer from the team is every bit as important as finding and keeping a good one. In this video, learn how to terminate a poor performer legally and with compassion.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":32600940,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The worst case scenario has come true.  \\n You've attempted training an employee,  \\n considered a transfer,  \\n and even laid out a performance improvement plan,  \\n but there just hasn't been any improvement on their part.  \\n Now, you have to seriously consider termination.  \\n This is one of the most difficult things I've ever had to do  \\n in the corporate world.  \\n Even though I had tried to follow procedure,  \\n creating progressive discipline procedures,  \\n and keeping HR involved,  \\n it still cause me many sleepless nights  \\n and much emotional stress.  \\n Termination is emotional for you and for the employees.  \\n Remember to keep this conversation  \\n as compassionate and professional as possible.  \\n Then, before you even have the termination conversation,  \\n you need to follow these steps.  \\n First, have thorough documentation.  \\n If you've been invested in their success,  \\n you should have a clear record of performance reviews,  \\n data or samples of their subpar work,  \\n and a PIP that highlights just where they've fallen short.  \\n This should also be a chance for you  \\n to make clear to yourself  \\n that this is the right decision for the business.  \\n Second, consult with your HR department and legal team.  \\n Be sure you're in the legal clear  \\n in terminating this employee  \\n and that all of the paperwork is prepared appropriately.  \\n Ensure you have the right people present in the meeting  \\n and if there is any language you need to get just right.  \\n This is also when you get  \\n all the practical details just right.  \\n Then, when you have the conversation,  \\n be straightforward and specific.  \\n Don't leave any room for them to wonder about  \\n why they were let go, and don't give them false hope.  \\n It's tempting to attempt to soften the blow,  \\n but the reality is  \\n this is a tough moment for them and for you.  \\n Being transparent and realistic is the best thing  \\n for both of you.  \\n Afterwards, don't forget to inform the rest of your team  \\n and let them know what implications there may be  \\n for their role or responsibilities.  \\n Again, lead with compassion and professionalism.  \\n Termination is emotionally charged for everyone involved.  \\n Letting someone go is probably the most difficult task  \\n for a manager,  \\n and it's never going to be a pleasant experience.  \\n But taking the steps in this lesson  \\n will help you act appropriately  \\n when you have to terminate an employee for poor performance  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2416010\",\"duration\":243,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Moving forward\",\"fileName\":\"2884099_04_06_LA24_Movingforwar\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Letting a team member go can have lasting impacts on your team culture and how you're perceived as a leader. In this video, learn how to ensure you and your team move forward after a team member has been terminated.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":51612997,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - I want you to take a moment  \\n and think about the culture your team has.  \\n As a strong leader, you've likely done a great job  \\n building a culture you're proud of.  \\n Your employees are happy and productive,  \\n they work well together,  \\n and they demonstrate a sense of appreciation and respect  \\n towards each other.  \\n Everything is seemingly going well.  \\n But then the time comes to fire one of your own.  \\n Because you've worked so hard to build your team's culture,  \\n letting someone go can have a tough impact.  \\n If your team is close, termination of one member  \\n can lead to hostility or picking sides.  \\n You may also have team members  \\n who feel scared for their own job security  \\n or who are angry at needing to handle extra work.  \\n Even if your team members feel relieved by the termination,  \\n they still could feel unclear  \\n about the direction of the team  \\n or the importance of their role.  \\n The good news is that you can alleviate much of this worry,  \\n rally your team, and collectively get back on track.  \\n After all, as Henry Ford once shared,  \\n \\\"If everyone is moving forward together,  \\n then success takes care of itself.\\\"  \\n In this lesson,  \\n I'm going to share some of the steps you can take  \\n to aid your team collectively move on  \\n after an employee has been fired.  \\n First, be transparent.  \\n Keeping in line with your local employment laws  \\n and company policies,  \\n you should explain to your team  \\n what actions this person took that led to their termination.  \\n While respecting this employee's privacy  \\n should be paramount,  \\n many employees become fearful for their own employment  \\n when someone gets fired,  \\n and identifying actions that this specific person took  \\n can put your remaining team members' minds at ease.  \\n Next, communicate the information to your team all at once  \\n and give them opportunities to ask questions.  \\n When possible, you should let the team know in a meeting  \\n that an individual has been let go.  \\n Otherwise, it's best to share the news over a phone call.  \\n This is also a chance for you  \\n to reaffirm the company's direction and goals  \\n and to share next steps  \\n for how your team will proceed with task.  \\n Then check in with your team.  \\n It's natural for your team members to feel uneasy  \\n or to have concerns.  \\n It's important that you praise and spend time with your team  \\n and that you acknowledge their feelings.  \\n Focusing on their contributions  \\n to the team and the organization  \\n will give these team members a strong affirmation  \\n of the value that they bring to the company.  \\n Be sure to also take accountability for your role  \\n as the leader of your team.  \\n Ultimately, if someone was failing to perform,  \\n this is your responsibility.  \\n Consider what lessons you can take away  \\n from this experience.  \\n Write out two or three things you'll do differently  \\n the next time you have a poor performer  \\n or things you did  \\n that you felt worked well this time around.  \\n Next, have some fun.  \\n After the dust has settled,  \\n it's time for you to lighten the mood  \\n and give your team a thank you for all of their hard work.  \\n Going for a group lunch, bringing in donuts one morning,  \\n or heading out early for a group activity  \\n can be an easy means of lifting spirits.  \\n Finally, it's important to remember  \\n that your team is collectively grieving a loss.  \\n You should leave space for the emotions and stress  \\n that can come along with firing a team member.  \\n This could translate to setting up office hours  \\n or offering to step in  \\n and ease the workload for your team members  \\n during the days following the termination.  \\n You know your team best, and I trust you'll recognize  \\n how you can demonstrate compassion towards them.  \\n While my hope is that you're not faced with a decision  \\n to terminate a team member often,  \\n I'm confident that if and when the time comes,  \\n you'll be able to use these tips  \\n to move forward with grace and appreciation.  \\n You've got this.  \\n \\n\\n\"}],\"name\":\"4. Taking Action\",\"size\":245233047,\"urn\":\"urn:li:learningContentChapter:2417015\"},{\"duration\":94,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2414016\",\"duration\":94,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Thanks for joining\",\"fileName\":\"2884099_05_01_LA24_Thanksforjoi\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":19990890,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Congratulations!  \\n You've reached the end of this course,  \\n but this is not the end of your managerial journey.  \\n The truth is, the journey to be a great leader  \\n and manager is never-ending.  \\n I want to thank you for your time  \\n and I know that now you'll have the managerial courage  \\n to swiftly handle poor performers.  \\n By embracing the three T's,  \\n you'll be able to decide what to do  \\n with any poor performer you encounter.  \\n And remember, you must not, under any circumstances,  \\n tolerate the poor performer.  \\n As you continue on your managerial journey,  \\n I recommend you check out my book, \\\"Rhythmic Leadership,\\\"  \\n available at PersonalServicesPlusLLC.com.  \\n That's PersonalServicesPlusLLC.com.  \\n If you want to become a better manager  \\n of poor performers, in particular,  \\n I'd recommend \\\"Lost Cause: Managing Poor Performers\\\"  \\n by Xavier Zinn.  \\n And if you're looking for a book on management  \\n which takes a wider perspective,  \\n I'd recommend \\\"The Drama-Free Workplace:  \\n How You Can Prevent Unconscious Bias, Sexual Harassment,  \\n Ethics Lapses, and Inspire a Healthy Culture\\\"  \\n by Patti Perez.  \\n Stay in touch.  \\n I would love to hear from you.  \\n Connect with me on LinkedIn.  \\n Thanks for watching, and remember,  \\n patience with poor performance  \\n eventually becomes permission to perform poorly.  \\n After taking this course,  \\n I'm sure you won't forget it.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":19990890,\"urn\":\"urn:li:learningContentChapter:2414018\"}],\"size\":633263648,\"duration\":2975,\"zeroBased\":false},{\"course_title\":\"Letting an Employee Go\",\"course_admin_id\":2817013,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2817013,\"Project ID\":null,\"Course Name\":\"Letting an Employee Go\",\"Course Name EN\":\"Letting an Employee Go\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Discover how thoughtful preparation and following established best practices are not only important when letting an employee go, but can also reduce stress and negativity. Instructor Todd Dewett begins with an overview of the termination process, and covers things to consider before a termination, including options for dealing with serious offenses. He moves on to explore the process of determining if termination is appropriate, preparing documentation, and conducting the termination meeting.\",\"Course Short Description\":\"Learn best practices for letting an employee go in a thoughtful, fair, and considerate way that can minimize your stress.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":1516963,\"Instructor Name\":\"Todd  Dewett\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Authenticity Expert, Educator, Author, Speaker\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2019-11-13T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/letting-an-employee-go-2019,https://www.linkedin.com/learning/letting-an-employee-go-2\",\"Series\":\"Deep Dive (X:Y)\",\"Limited Series\":null,\"Manager Level\":\"Manager\",\"LI Level\":\"General\",\"LI Level EN\":\"General\",\"Sensitivity\":null,\"Internal Library\":\"Business\",\"Internal Subject\":\"Leadership and Management\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":3088.0,\"Visible Video Count\":17.0,\"Contract Type\":\"STANDARD\"},\"sections\":[{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2935442\",\"duration\":42,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"The correct way to terminate an employee\",\"fileName\":\"2817013_00_01_WL30_Correct\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Terminating an employee can be a highly stressful but critical action. In this video, learn how to recognize the steps you need to take to do it well.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8445440,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - As a decision maker in professional life,  \\n it's important to get things right.  \\n But all decisions are not equally important.  \\n A few are so important and delicate  \\n that being thoughtful and thorough is vital.  \\n The decision to let someone go is one such decision.  \\n While it can be stressful,  \\n if you're thoughtful and follow well-known best practices,  \\n you can be successful.  \\n That means knowing when and how to make the decision  \\n and how to follow through effectively.  \\n Hi, I'm Todd Dewett, educator, author, and coach.  \\n I'm excited to help you move forward  \\n with this challenging topic,  \\n because this is a skill you can learn.  \\n Let's get started.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2934679\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2935443\",\"duration\":207,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Termination in context\",\"fileName\":\"2817013_01_01_MM30_Context\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers need to understand that termination is not an isolated event but occurs in relation to other parts of the organization. In this video, learn about the context within which termination exists, the major effects on the terminated employee, and discover a useful philosophy to guide termination.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12937356,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - This course is full of practical tips and tools  \\n that will help you understand when  \\n and how it might be appropriate to let an employee go.  \\n It's not meant to be a replacement  \\n for proper professional advice  \\n from your Human Resources department,  \\n or from a proper legal representative.  \\n In fact, it's best used as a quality companion  \\n to the advice you should receive from those professionals.  \\n Don't forget, every situation is different.  \\n While this course presents some scenarios to consider,  \\n your specific case may vary, so, once again,  \\n be sure to seek sound professional advice.  \\n For many managers, the hardest thing you'll ever do  \\n is let someone go.  \\n Firing an employee is difficult and poses risks.  \\n However, when done correctly, it can be a useful tool  \\n that can help make your team  \\n and your organization stronger.  \\n Unfortunately, the emotional nature of termination  \\n often leads people to take extreme positions.  \\n Some managers use the option way too quickly  \\n while others choose to never fire anyone no matter what.  \\n Both of these positions are of course unacceptable.  \\n Now, in the face of extreme employee behavior,  \\n for example, violence or embezzling,  \\n an immediate firing could be justified.  \\n However, being too rash is generally a problem.  \\n Aside from possible legal troubles,  \\n you will unnecessarily scar the person being let go  \\n by creating anger and confusion.  \\n Even if your decision is sound,  \\n you're smart to be kind and supportive and helpful.  \\n They're going to experience a range  \\n of strong difficult emotions and you don't want to be seen  \\n as cold or lacking in compassion in the eyes of your peers,  \\n human resources, or your leadership team.  \\n And it's even possible to harm your own team  \\n by creating an atmosphere of fear  \\n that can erode trust, not good.  \\n Having said that, you can also move too slow  \\n and the results can be just as bad.  \\n If you're in the group that never wants to fire anyone,  \\n you're harming the group  \\n by allowing and validating poor performance.  \\n You're also unintentionally creating resentment  \\n among your strong performers.  \\n Okay, instead of these two extreme positions,  \\n check your emotions and use the termination process  \\n thoughtfully and respectfully.  \\n Also, view the situation as a process  \\n to be engaged over time instead of a single discrete event.  \\n In fact, when you follow all of the steps  \\n in the process correctly, the termination process  \\n can help you realize two huge benefits.  \\n The first is a genuine chance to help your team improve.  \\n New talent can be rare and it's a chance  \\n to improve chemistry and culture.  \\n The second benefit concerns the person being let go.  \\n When handled correctly, being let go provides a person  \\n a much needed wake-up call.  \\n They learn that continued employment must be earned  \\n and that their behaviors do have consequences.  \\n Those are very useful insights they can use moving forward.  \\n So I'll admit that firing someone is never fun  \\n but it happens and eventually  \\n it will be your responsibility.  \\n Get started now by studying the process  \\n and the relevant policies and know your HR contacts.  \\n That way, you'll be prepared  \\n and you can be confident you're helping improve the team.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2934678\",\"duration\":182,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Overview of the termination process\",\"fileName\":\"2817013_01_02_MM30_Process\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Managers need an overarching understanding of the different parts of the termination process to ensure success. In this video, explore a quick summary of all major steps prior to initial termination decision, most importantly the process of escalating feedback.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9098496,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Letting an employee go is a process, not a discrete event.  \\n While the actual act of letting someone go  \\n is just one step, before that meeting,  \\n there's a lot to be done.  \\n Here are the steps you need to go through  \\n before an eventual termination meeting.  \\n First is the delivery of escalating feedback.  \\n Long before considering termination, your role  \\n is to use feedback to assist the employee  \\n in getting their work done correctly.  \\n If performance issues persist,  \\n then the process may escalate  \\n to more formal conversations or warnings,  \\n or some form of an improvement plan.  \\n Without clear improvement,  \\n it's then time to start completing the documentation  \\n required by human resources  \\n concerning the person's performance.  \\n Depending on where you work,  \\n you might submit your work to some form of review board  \\n who makes the final decision.  \\n Or it's just on you.  \\n In either case, you're wise to first seek the counsel  \\n of more experienced managers  \\n before making your final decision.  \\n When the decision is actually made to terminate,  \\n you next create a termination agreement.  \\n This document states that employment ends  \\n on a particular date, the cause for termination,  \\n information about wages or severance,  \\n and all relevant facts about employee benefits.  \\n It's also a good time to consider  \\n any security concerns you might have.  \\n Violence is rare,  \\n but it's smart to consider the possibility.  \\n When in doubt, plan to have another person present  \\n with you for the actual meeting.  \\n One of your last tasks is to prepare yourself mentally  \\n for the actual meeting.  \\n You and your employee will feel a great deal of stress.  \\n You know you're impacting this person's life.  \\n So stay focused on the fact that you've done  \\n all you can do to help the person.  \\n And now you're really just trying to help the team.  \\n Then it's time for the meeting.  \\n You've done your homework in terms  \\n of needed conversations and documentation.  \\n If you're well prepared,  \\n the meeting itself will be very short,  \\n usually only lasting a few minutes.  \\n After talking with the person  \\n and hopefully obtaining a signed termination agreement,  \\n you'll collect company property from them  \\n and escort them from the building.  \\n But you're still not done.  \\n You still need to appropriately follow up with your team.  \\n They might be experiencing abnormal emotions just like you.  \\n Your job is to reduce their ambiguity  \\n by proactively addressing the issue  \\n with the team soon after the event.  \\n If you've not had to let someone go recently,  \\n it might be time to speak to someone who has  \\n and your colleagues in HR to be sure you know specifically  \\n how your organization addresses this issue.  \\n When you carefully engage each of these steps  \\n in the process, your decision will be effective.  \\n When you also show respect to your team  \\n by using an appropriate explanation,  \\n you're turning this challenging situation  \\n into an opportunity for the team to improve.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2935444\",\"duration\":182,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Knowing when termination is appropriate\",\"fileName\":\"2817013_01_03_MM30_When\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers need a practical understanding of how to determine if and when a termination decision is needed. In this video, learn how to identify when to stop coaching, explore a checklist of things you should have done before making the decision, and discover the importance of reviewing relevant legal issues where you are located.  \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10954819,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Here's a tough question,  \\n How do you know when to stop giving more  \\n chances, advice, and reprimands  \\n and actually decide to let an employee go?  \\n The truth is it's not a perfect science.  \\n But if you're paying attention  \\n and know what to look for,  \\n you can make the right call.  \\n Let's start with extreme behaviors as an obvious case.  \\n For example, any kind of violence,  \\n sexual infractions or drug and alcohol use at work.  \\n These may provide grounds for immediate dismissal.  \\n Your first call is for security if it's needed, then HR.  \\n Someone in those groups will make the decision  \\n about including anyone else.  \\n For example, the police.  \\n Of course most employee performance  \\n or behavior problems are not extreme.  \\n Which actually make your job more difficult.  \\n You have to be vigilant in making observations  \\n and documenting behavior.  \\n Typically a diligent effort will correct  \\n the performance issue.  \\n But, if not, then it's time to consider letting them go.  \\n Assuming you've progressed through feedback,  \\n tough conversations, performance improvement plans,  \\n and possibly reprimands,  \\n I now want you to think through these three questions.  \\n First, do you have a well-documented  \\n and prolonged performance trend?  \\n That includes job tasks, any interpersonal issues  \\n or issues related to integrity.  \\n Generally speaking, you're looking for a clear pattern,  \\n not just one mild incident.  \\n Next, are others on the team aware of  \\n and upset about this person?  \\n It's one thing for a person to underperform  \\n and thus show up on your radar.  \\n It's another thing all together  \\n for someone's performance or behavior  \\n to threaten team comradery and productivity.  \\n Then ask, are outsiders reacting negatively to this person?  \\n I'm referring to people in other parts of the company,  \\n customers, vendors, or any other stakeholders,  \\n with whom the person regularly interacts.  \\n If so, that's a major indicator that you need to act.  \\n Okay, if you answered affirmatively to these questions  \\n your case is clear and it's time to escalate  \\n by speaking to human resources.  \\n There isn't a simple formula  \\n that tells you when it's time to let someone go.  \\n However, if you pay attention to the performance trend  \\n and document it well, and listen carefully  \\n to your team and any relevant outsiders,  \\n you'll know when it's time.  \\n Then, HR, typically with assistance  \\n from your company's lawyer or legal team,  \\n can tell you more technically whether you're ready  \\n to implement the decision.  \\n Letting someone go is difficult but sometimes necessary.  \\n When you make this type of decision  \\n you want to be confident that you're doing the right thing.  \\n You can begin acting on the advice we covered  \\n by simply asking a few employees and outsiders  \\n how things are going.  \\n Inquire about any challenges they're experiencing  \\n that you can help address.  \\n Their feedback, your observations, and good documentation,  \\n will help you feel confident about making a decision.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2935445\",\"duration\":206,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Dealing with serious offenses\",\"fileName\":\"2817013_01_04_MM30_Serious\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Not all infractions are the same, thus managers need to understand how to differentiate key types of issues to respond appropriately. In this video, learn how to differentiate standard performance issues from more serious misconduct requiring stronger responses.  \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12625204,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - One important way to categorize terminations  \\n is to differentiate between terminations  \\n due to poor performance versus terminations  \\n due to employee misconduct.  \\n Generally speaking, things  \\n like making many mistakes  \\n or not completing tasks on time are not misconduct.  \\n I'm referring here only to serious offenses that immediately  \\n or over time might be cause for termination.  \\n For example, theft, fraud,  \\n intoxication or drug use,  \\n intentional damage to property or assets,  \\n violence, creating a hostile work environment,  \\n or repeated gross insubordination.  \\n Even though some of these seem clear cut,  \\n you must think about the issue of severity.  \\n Behaviors that are less objectionable could lead  \\n to a termination when they're repeated,  \\n whereas behaviors that are highly objectionable often lead  \\n to immediate termination.  \\n Please note that depending on where you work  \\n and where you live, the rules vary  \\n as to what is a minor offense,  \\n a more severe offense, or  \\n an actionable series of minor events.  \\n So, do you give someone a warning  \\n or do you start the termination process?  \\n The best answer is to reach out  \\n to your HR team to make sure your answer follows  \\n all applicable rules and laws.  \\n One special case we have to mention  \\n involves certain extreme behaviors.  \\n Most importantly, violence  \\n or the immediate threat of violence.  \\n In these cases, security should be called immediately,  \\n and typically, they will call the police if needed.  \\n Ideally, you do not intervene with the person who's engaging  \\n some form of violent behavior,  \\n even if it were a simple fight.  \\n Don't intervene.  \\n You can speak up, but don't get involved physically.  \\n That puts you in danger and creates liabilities.  \\n Your job is to seek safety if needed or to just observe  \\n and wait for security or the police.  \\n These situations are quite clear  \\n and a termination process begins immediately.  \\n The majority of cases, however,  \\n consists of smaller infractions,  \\n which means you have to collect data  \\n and try to make a decision when the time is right.  \\n Just do two things.  \\n First, consider the proof you have.  \\n If someone has been habitually late  \\n and your workplace uses time clocks or employee badges,  \\n documenting the infraction is easy.  \\n In contrast, if you're talking about  \\n a disruptive attitude,  \\n and the proof is basically an eyewitness other than you,  \\n that's not really actionable proof.  \\n So next, consider the person's performance history.  \\n If the infraction is small,  \\n such as being late, and the proof is strong,  \\n but it's the first time they've ever been late,  \\n there is no misconduct justifying termination.  \\n But if they are late, it's well-documented,  \\n this is say their fifth instance,  \\n and they've been properly warned numerous times,  \\n termination then becomes far more defensible.  \\n No manager looks for to reprimanding or firing employees,  \\n but sometimes it's necessary.  \\n So are you prepared?  \\n Start thinking now about exactly who to call for advice  \\n and how well you're documenting the situation as it evolves.  \\n Thinking about these things now means that you are  \\n likely to make termination decisions that stick later.  \\n \\n\\n\"}],\"name\":\"1. Overview of Employee Termination\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2934680\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2932635\",\"duration\":184,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Preparing your documentation\",\"fileName\":\"2817013_02_01_MM30_Preparing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Mangers need to understand the documentation required by relevant organizational systems to successfully terminate an employee. In this video, learn how to identify and collect relevant documentary evidence to support a termination decision, including past performance evaluations, your ongoing performance notes, work samples, customer data, and any other performance relevant data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11932144,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Just because someone exhibits poor behavior at work,  \\n doesn't mean that you as the manager  \\n will be able to let them go,  \\n not unless things are properly documented.  \\n One of the tasks you pick up  \\n when you join the leadership team  \\n is documenting performance.  \\n You have to do it to support decisions you'll make  \\n when employees deserve praise and promotions  \\n or other awards, and you have to do it  \\n to support more difficult decisions, such as terminations.  \\n Believe it or not,  \\n even in the face of very difficult behaviors,  \\n it's common for managers to neglect  \\n documenting problematic behavior.  \\n Sometimes they think they are simply too busy  \\n to immediately address the issue.  \\n Assuming the behavior in question is not extreme,  \\n they say to themselves,  \\n I see that's an issue but I'm busy, or I'll get to it later.  \\n And then they lose interest and forget to follow-up.  \\n Another very common explanation for poor documentation  \\n is simple conflict avoidance, people don't like conflict,  \\n so we choose to look the other way.  \\n They see some example of misconduct and they think,  \\n it's not that bad.  \\n Or maybe they think, the team will take care of that.  \\n Just remember, when you avoid conflict,  \\n it almost always gets worse.  \\n To properly document the situation, at a minimum,  \\n means that after you address the person  \\n to correct the unexpected behavior,  \\n you then capture all relevant information.  \\n That means you need to make  \\n an entry in your performance diary,  \\n that's a notebook or computer file  \\n you use to continually document your observations  \\n about the performance of each of your direct reports,  \\n whether documenting misconduct  \\n or more positive aspects of performance.  \\n You want to write down the employee's name,  \\n the names of others involved, the names of other witnesses,  \\n the location and time of the incident,  \\n and any other relevant information.  \\n In addition, you might collect or take pictures  \\n of any relevant work samples or work areas,  \\n get client input, and check on potential video  \\n of the incident.  \\n This all might sound excessive,  \\n but in the case of particularly bad behaviors,  \\n which might be the precursors of a termination,  \\n you have to go the extra mile.  \\n For example, if you observe someone being hostile  \\n to another person, you should document what you saw,  \\n and you should speak to whoever else was involved.  \\n You're not really investigating,  \\n just documenting in order to protect the team  \\n and the company.  \\n If you have any doubts  \\n about the sufficiency of your documentation,  \\n write down exactly what you did and take those notes  \\n to your human resource department.  \\n Dealing with issues like this  \\n is a core part of their expertise.  \\n Let them help you be sure  \\n you're correctly documenting the situation  \\n without overlooking any little detail  \\n that could stop a future termination process.  \\n Start now by auditing how well  \\n you've been documenting their work.  \\n Then moving forward,  \\n follow the suggestions we just discussed,  \\n and you'll have the data you need  \\n to make effective decisions.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2935446\",\"duration\":173,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Managing internal communication\",\"fileName\":\"2817013_02_02_MM30_Internal\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers must know that termination requires understanding how the target person interacts with others in the organization and that those connections must be proactively managed. In this video, learn how to articulate which members of the HR team, the leadership team, the person's immediate team, and possibly relevant customers, need to be addressed.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10278997,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The informal beginning of the termination process  \\n has a lot to do with documenting the person's performance.  \\n But, it also requires you to think about the other players  \\n who matter as well.  \\n Specifically, your supervisor and the leadership team,  \\n the human resources department  \\n and the rest of the team you lead.  \\n However, your very first task is  \\n to understand your companies policy  \\n surrounding reprimands and terminations.  \\n Know them very well.  \\n Even in the face of poor performance or bad behavior,  \\n if you don't follow procedures correctly,  \\n terminating someone might be more difficult  \\n than you imagine.  \\n It's best to start by obtaining this information online  \\n without going to your HR department.  \\n We'll consider that in a minute.  \\n Your first people related task  \\n is to think about the leadership team.  \\n You need to know how your actions on this matter  \\n will be talked about and can have a big impact  \\n on your reputation.  \\n That's why it's smart to talk to your direct supervisor  \\n to share your plans for dealing with the situation  \\n and their advice about the matter,  \\n given their knowledge of company policies and precedence.  \\n Now, how you approach them matters a lot.  \\n Don't say your need their help  \\n or that you don't know what to do.  \\n Instead, show some confidence and say  \\n that you're considering a particular course of action  \\n and would like to hear their thoughts given their expertise.  \\n This way you're keeping them in the loop  \\n and your eventual behaviors will not surprise them.  \\n Of course, it's also wise to note  \\n that if you are to let the person go,  \\n you expect to have the budget to replace them.  \\n Also, if they ask you whether or not you've been to HR yet,  \\n tell them no because you wanted  \\n to touch base with them first.  \\n Assuming you weren't advised against it,  \\n your next stop is HR where you'll clarify  \\n what you've done so far, what you wish to do,  \\n and how that meshes with company policies  \\n and other legal considerations.  \\n They are the team  \\n who will ultimately help you understand the bureaucracy  \\n surrounding this type of decision.  \\n Okay, let's think about your team for a moment  \\n and how to address this issue with them.  \\n It's simple.  \\n Prior to the decision,  \\n you don't share with anyone on the team  \\n your personal judgment about the person.  \\n You don't say they're in trouble or need to improve  \\n or anything critical.  \\n If anyone else says something critical,  \\n you change the topic.  \\n Any discussion of this nature will cause you trouble later  \\n so keep it to yourself, your boss, and HR.  \\n A successful termination isn't so much  \\n about whether it's justified.  \\n That part is very important  \\n but the real task is first ensuring that the right people  \\n are included and that the correct process is followed.  \\n Start your homework early so you'll know  \\n who you need to talk to.  \\n That way, when the time comes,  \\n you're ready to meet all of of the expectations  \\n of the relevant parties  \\n while successfully letting someone go.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2935447\",\"duration\":185,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Anticipating common questions\",\"fileName\":\"2817013_02_03_MM30_Common\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"To be effective, managers can and should anticipate the most common issues a person will have when they learn they are being terminated. In this video, learn how to identify the common questions and responses including, \\\"Why am I being let go?\\\", \\\"Who made this decision?\\\", and other relevant questions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11010739,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When someone finds out they're being let go,  \\n they're going to have a few predictable questions.  \\n So, try to predict the common ones and be ready  \\n to address them effectively.  \\n Let's start with one of the most common.  \\n Why am I being let go?  \\n Be respectful and brief, but be clear about the reality.  \\n For example, Jason, your performance has been judged,  \\n it's not acceptable and your skills no longer fit  \\n with the company's needs.  \\n No discussion of performance is proper right now.  \\n That discussion has ended.  \\n Next, they might ask, who made this decision.  \\n As their supervisor you have to own this,  \\n because blaming anyone else  \\n will be seen as a sign of disrespect.  \\n So, something like this, I made this decision and it's been  \\n approved by human resources.  \\n If they feel the need to comment,  \\n reiterate that the decision has been made  \\n and you need to move on a discuss a few important issues.  \\n They might follow by asking  \\n what can I do to change this situation?  \\n This means they want another chance,  \\n even though the decision has already been made.  \\n So, politely, but immediately say, the decision is final,  \\n now there are several pieces of information  \\n I need to share with you.  \\n Then get started, no discussion, no negotiation.  \\n It's also not uncommon for them to ask,  \\n who else knows about this?  \\n What they really want to know, is whether or not their  \\n colleagues know they're being let go.  \\n Tell them no one knows a thing,  \\n and they won't until after you've wrapped the meeting.  \\n Another question you might hear is when does this  \\n decision take effect?  \\n Usually it's immediately.  \\n That could prompt them to ask about uncompleted work  \\n or possibly their clients.  \\n Of course before this conversation ever began,  \\n you created a plan to have all relevant work  \\n and clients addressed as needed.  \\n So, just say thanks for asking but that's all being handled.  \\n Believe it or not, it's not uncommon to receive questions  \\n about using you for a job reference and using the company's  \\n resources for job counseling and a job search.  \\n Whatever your company's position is on these matters,  \\n just know them and be ready to share them.  \\n Finally, you can also expect them to ask  \\n when is my last paycheck?  \\n In fact, they might have several questions  \\n about pay and benefits.  \\n For pay, this includes when the last check will be issued,  \\n the discussion of severance if applicable,  \\n and any other financial benefits the person is owed.  \\n In terms of benefits, the most important issue  \\n to communicate is when they lose health benefits,  \\n so the person knows when they must enroll in a new  \\n temporary solution, such as COBRA in the United States  \\n or purchase something in the market,  \\n or maybe join their spouse's policy.  \\n Letting someone go is a stressful situation  \\n for all involved, but you can manage it effectively.  \\n So spend time mentally rehearsing before the actual event.  \\n Be ready to answer the questions we covered,  \\n and you'll help everyone feel a little more at ease  \\n and the person being let go can take comfort  \\n in knowing the answers to the questions that matter.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2932636\",\"duration\":185,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"When the employee is not at fault\",\"fileName\":\"2817013_02_04_MM30_Fault\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers must understand the procedural difference between termination due to personal performance issues versus termination due to circumstances beyond the employee's control. In this video, discover how to identify what to say and do in different special circumstances driven by organizational performance needs, including downsizing, RIFs, and restructurings.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10777344,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Sometimes a person is let go,  \\n not because of their performance,  \\n but due to other circumstances at the organizational level  \\n or in the industry.  \\n These decisions have to be made with care  \\n and with heavy involvement of human resources  \\n and your legal team.  \\n As you get started, remember these basics.  \\n Your primary concern is how to select employees  \\n who will be let go.  \\n There are many perspectives and your choice will be impacted  \\n by what the leadership team values,  \\n applicable laws, and the desires and rights  \\n of any labor unions affected.  \\n Often the method used is based on tenure or seniority,  \\n whereby the recently hired people  \\n are the first to be let go.  \\n Similarly, sometimes organizations use employee status,  \\n such that full-time employees are protected  \\n and part-time or contract employees  \\n are the first to be affected.  \\n Merit approaches are also popular,  \\n which focus on retaining top talent.  \\n Managers like this approach but to be safe,  \\n you do have to have a high quality,  \\n well-documented performance evaluation system.  \\n In addition, you see point-based systems  \\n that allow you to combine aspects  \\n of each of these other methods.  \\n Next, think about what makes a fair warning.  \\n For example, in the US, a federal law called  \\n the Worker Adjustment and Retraining Notification Act,  \\n requires some employers to offer  \\n a certain amount of advanced notice.  \\n Otherwise, they might owe employees many days  \\n of additional pay.  \\n Again, laws vary based on where you are.  \\n Another analysis to consider focuses on discrimination.  \\n For example, in the US, it's illegal to discriminate  \\n based on age, sex, race, disability, and so on.  \\n However, it's possible that your decision could  \\n unintentionally disproportionately affect certain groups,  \\n so think carefully.  \\n You also have to think about severance.  \\n That starts by understanding the relevant laws  \\n and any applicable labor contracts.  \\n Sometimes, you don't have to pay severance  \\n but it's wise to try and be generous.  \\n Remember, how separated employees feel about you  \\n and what they say in the community  \\n affects your ability to find talent in the future.  \\n Concerning unemployment benefits,  \\n your goal is to simply inform them of their rights  \\n and provide them with the information  \\n they need to get started  \\n and make sure they know who to call with questions.  \\n Finally, make sure they know whether or not  \\n they can use you as a reference,  \\n and let them know about any related job search resources  \\n your organization might provide.  \\n Letting people go under any circumstances is difficult,  \\n particularly when it's not their fault.  \\n Long before you dive into the selection process,  \\n huddle with your colleagues and HR  \\n so that you know their thoughts on the options  \\n and any precedents from your recent past.  \\n Doing so will position you to be thoughtful and prepared  \\n when it's time to navigate these types of circumstances.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2932637\",\"duration\":173,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Thinking through the logistics\",\"fileName\":\"2817013_02_05_MM30_Thinking\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers will be successful with termination when they attend to all smaller details correctly, such as selecting the right time and place and knowing how to schedule the actual termination meeting. In this video, learn how to recognize how to decide the right time of day and week, the location for the meeting, and other relevant points for termination.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9183916,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - You've made the decision.  \\n You have a strong case,  \\n and your decision has been approved.  \\n Now, it's time to choose the right time and place  \\n for the actual meeting.  \\n There are two different types of cases here.  \\n The first is when a person has done something so extreme  \\n that it warrants immediate dismissal.  \\n For example, maybe there was violence  \\n or threats or stealing.  \\n In these cases, first consider whether or not  \\n law enforcement or company security is needed  \\n based on the nature of the offense.  \\n Assuming it's safe, then find an appropriate witness,  \\n ideally someone above your rank or from HR.  \\n Together, you'll go and address the person,  \\n calmly and politely.  \\n Let them know they're terminated.  \\n Secure all company property.  \\n Allow them to collect personal belongings,  \\n and escort them from the building.  \\n Any other matters can be addressed later  \\n via phone or email or regular mail.  \\n If you have any concerns at all,  \\n it's wise to have security join you  \\n in addition to your witness.  \\n The second case is far more common.  \\n Here, the person is being let go for performance reasons,  \\n but the issue isn't extreme,  \\n and thus scheduling a more thoughtful process  \\n to be executed in the coming days will be preferable.  \\n Exactly when to act on this decision  \\n is something of a debate.  \\n I suggest you avoid major holidays or birthdays,  \\n and in general, avoid embarrassing the person unnecessarily.  \\n But after that, there's less agreement.  \\n There are different options.  \\n You can do it early in the week  \\n or in the middle or late in the week.  \\n The right answer will depend on the circumstances,  \\n and there are pros and cons to each of these options.  \\n Allow me to give you my best advice.  \\n You let someone go as soon as the decision has been made  \\n and properly approved.  \\n This way you minimize suspicions and rumors  \\n and the threat of continued  \\n or worsened performance problems.  \\n The best bet is to just err on being very prompt.  \\n Next is the decision about where to hold the conversation.  \\n You really have two main choices:  \\n your office or in the office  \\n of the appropriate human resource representative.  \\n Your office might be fine,  \\n particularly when you do not expect any problems.  \\n However, if you think that conflict is possible,  \\n it's smart to have the meeting in HR.  \\n This increases the likelihood that the employee  \\n understands that this decision is final,  \\n and that the company is backing your position.  \\n And it has the added benefit of moving  \\n the person physically away  \\n from their workspace and colleagues for added privacy.  \\n Here's your call to action.  \\n Think about the suggestions we just covered,  \\n and if you have any doubts,  \\n reach out to your mentor or a colleague in HR  \\n and seek their counsel about your plan.  \\n Based on company history or precedence,  \\n they might have a suggestion  \\n that can help the process flow more smoothly.  \\n So, remember to seek counsel before acting.  \\n \\n\\n\"}],\"name\":\"2. Preparing for Termination\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2934681\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2935448\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understanding meeting participant roles\",\"fileName\":\"2817013_03_01_MM30_Roles\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers need to be aware of the specific roles and responsibilities associated with each role in a termination meeting. In this video, learn how to identify your specific duties, the responsibilites of the target employee, and the role of additional potential participants.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9824428,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - One of the keys to having an effective termination meeting  \\n is to make sure that you know everyone's role.  \\n With few exceptions, there are only a few main players:  \\n You, the person who's being let go,  \\n someone from human resources, or your legal team,  \\n and possibly security.  \\n Okay, let's start with you.  \\n Long before now, you took all of the correct steps  \\n to help the person.  \\n You documented everything.  \\n You made the decision to let them go,  \\n followed procedure, and gained approval,  \\n and then, finally, you scheduled the actual meeting,  \\n and now here you are.  \\n Your main role at the meeting  \\n is to be an information provider.  \\n You first deliver the news that they're being terminated,  \\n then walk them through all of the issues  \\n related to benefits and compensation,  \\n then share the process that is about to happen  \\n that will allow them to gather their belongings  \\n before being escorted from the building.  \\n Please note that part of your role  \\n is not to be an emotional sympathizer or negotiator,  \\n or a person who engages in any negativity.  \\n Your goal here is clear:  \\n To correctly provide information, to remain unemotional,  \\n and to facilitate the removal from the premises.  \\n Yes, you do wish to thank them for their contributions,  \\n possibly wish them luck,  \\n but that is the extent of supportiveness  \\n allowed in this type of meeting.  \\n Next is the role of the person who's being let go.  \\n Simple enough, they need to receive and understand  \\n certain bits of information.  \\n Because of the situation, they might find listening hard.  \\n So you want to read their words and gestures  \\n to gauge their understanding so you can clarify as needed.  \\n You're letting them go, but you do want them  \\n to understand their rights and what they're owed.  \\n Next is your HR partner or lawyer.  \\n Their role is to be a witness and serve as expert backup.  \\n You're in charge, so they generally only speak up  \\n for one of two reasons:  \\n When you ask for their help in clarifying an issue,  \\n or when they feel you need help  \\n or have forgotten to mention a key issue.  \\n Otherwise, they are just being a witness.  \\n Finally, we have security.  \\n Their role is also to observe and to ensure order  \\n should any tensions erupt in the conflict.  \\n This is fairly rare, and their presence  \\n is one key reason why.  \\n You know, few meetings in your life will be as stressful  \\n as the meeting where you're letting someone go.  \\n It can, however, run smoothly  \\n if you know the roles everyone should fill.  \\n If you're facing a decision about letting someone go,  \\n start thinking proactively now  \\n about who should be in the room and why.  \\n Follow the advice we just covered  \\n and you'll increase the odds that your employee  \\n will leave with a clear understanding of their rights,  \\n obligations, and benefits,  \\n and that you conducted a productive, conflict-free meeting.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2932638\",\"duration\":172,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understanding the langauge of termination\",\"fileName\":\"2817013_03_02_MM30_Language\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In such a delicate situation, managers must understand the ideal language characteristics that provide both clarity and respect. In this video, learn how to plan how to phrase your ideas while being direct, appropriately unemotional, while owning your words and striving to be concise and to the point.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9039464,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Finding the right language in a termination  \\n is vital for reducing stress and increasing understanding.  \\n So, let's think about the characteristics  \\n of effective language in this situation.  \\n First, use direct language, not evasive language.  \\n Say what you want to say without beating around the bush.  \\n Don't start by asking about their week  \\n or by commenting on an email everyone just received.  \\n Get to the point of the meeting immediately.  \\n Next, deliver information unemotionally, not emotionally.  \\n While emotions are useful in many situations,  \\n they are not here.  \\n The more neutral and unemotional you are,  \\n the less likely you evoke negative emotions  \\n from the employee.  \\n Also, use language that is owned, not disowned.  \\n Show that you made this decision,  \\n not someone else like a committee or some other executive.  \\n You made the call  \\n and your language should reflect that reality.  \\n That can be tough, but it's the best way to ensure  \\n they hear you and respect the decision.  \\n Finally, be simple, not complex.  \\n For example, saying I've decided to let you go.  \\n Is much better than saying upon deep reflection,  \\n I have determined that your permanent separation  \\n from the team is appropriate.  \\n Don't do that.  \\n Use simple language that's easily understood.  \\n Okay, consider these examples that demonstrate  \\n how to address this issue correctly.  \\n Hi, Jack, come in.  \\n Please have a seat.  \\n You know Sarah from Human Resources.  \\n Jack, we're meeting today  \\n because I've decided to let you go.  \\n After several conversations with you over the last year,  \\n I've decided your performance isn't acceptable.  \\n I need to share that with you,  \\n and also inform you of your rights and obligations  \\n concerning things such as benefits and compensation.  \\n Then we'll also have time for you  \\n to collect your personal belongings  \\n before leaving the building today.  \\n Now, you'll notice I began by introducing  \\n the other person in the room,  \\n and then I immediately stated the reason for the meeting.  \\n No hesitation or ambiguity.  \\n Then I followed by concisely stating the remaining agenda.  \\n Here's another example.  \\n Hey, Jerry.  \\n Would you please shut the door?  \\n Jerry, you and I have been discussing your performance  \\n for some time, and we even tried  \\n a performance improvement plan.  \\n I've made a judgment that it's not working,  \\n and I've decided to let you go.  \\n Today, I wanted to share this with you,  \\n answer any questions you might have,  \\n and make sure you're aware  \\n of how this affects your benefits and compensation.  \\n When we're done, you'll, of course, have an opportunity  \\n to gather your personal belongings  \\n before being escorted out of the building.  \\n Again, the deliver is straight to the point,  \\n completely owned, and direct,  \\n but also polite and basically unemotional.  \\n Get ahead of the game  \\n if you have a meeting like this on the horizon.  \\n Actually spend a few minutes imagining the conversation  \\n and the language you'll use.  \\n Follow the guidelines noted here  \\n and your message is likely to be heard and understood.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2932639\",\"duration\":294,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Delivering the news\",\"fileName\":\"2817013_03_03_MM30_News\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"To be successful in the actual meeting, managers must know what to say and when to both cover their bases and to control the conversation. In this video, learn how to identify which pieces of information to share, in what order, and a process for effectively controlling the flow of the conversation.  \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17795121,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Letting someone go can be stressful and risky,  \\n so attention to the little details matters.  \\n For instance, let's take a closer look  \\n at the specific information that you'll need to share  \\n with an employee in the meeting  \\n when you're delivering the news.  \\n You'll be sharing with them, the decision that's been made,  \\n information about benefits, and so on.  \\n But before reviewing the specific bits  \\n of information to be shared,  \\n please remember this simple process.  \\n Deliver, confirm, and take questions.  \\n First, calmly and clearly deliver your message.  \\n Be clear, unemotional, and concise.  \\n Next, through their words, body language,  \\n or by using questions, be sure they actually heard you.  \\n With this type of stress, it's sometimes hard  \\n for people to focus and hear you.  \\n If they ask about why they're being let go,  \\n redirect them back to the conversation at hand.  \\n But if they have questions about benefits or pay,  \\n for example, you'll want to help them understand  \\n the situation as clearly as possible.  \\n Finally, following each issue you deliver, observe them,  \\n and if they look particularly confused or worried,  \\n you can ask them if they have a question.  \\n Okay, here are the major chunks  \\n of information to be delivered:  \\n the decision that has been made to let them go,  \\n information about health and other benefits,  \\n information about compensation,  \\n job search assistance that might be available,  \\n procedures for gathering personal belongings,  \\n returning company property, and leaving the workplace.  \\n Let's watch as Jarred, a manager,  \\n speaks to his employee, Sheila.  \\n - So, Sheila, I've decided to let you go.  \\n Now, this is effective immediately,  \\n but I have some important information  \\n I want to share with you.  \\n - What, wait, can't we discuss this?  \\n Is this final?  \\n - Yes, the final decision has been made.  \\n It's been approved, and it's irreversible.  \\n - I don't understand, why?  \\n - Well, this is performance related,  \\n and we've talked about this in the past  \\n on several occasions.  \\n Right now, I have some important details  \\n I want to share with you regarding your benefits.  \\n So, as you can see here, you'll be covered  \\n through the end of next month  \\n with your current health insurance plan,  \\n but between now and then you'll need to decide  \\n where you want to purchase health insurance moving forward.  \\n - Okay, when will I get my last check?  \\n - Your last check will be issued  \\n on the last day of next month,  \\n and it's also our policy that we pay  \\n any unused holiday, vacation, and sick pay.  \\n It will be electronically deposited,  \\n or we can mail a check to your home address.  \\n Which would you prefer?  \\n - Electronically is fine. - Okay.  \\n Now, I also want you to know  \\n that if a future employer contacts us,  \\n we'll verify your dates of employment, but nothing else.  \\n - Yes, I get it.  \\n - So, let's talk about some resources  \\n that are available for you.  \\n Until the end of next month,  \\n you'll have access to some job search resources  \\n that are available online, 24/7.  \\n Do you have any questions about that?  \\n - Okay, what about my customers and all my work?  \\n - Good question, everything's been taken care of,  \\n and all your work will be covered.  \\n - So, what now, I'm just supposed to go  \\n and walk out in front of everyone?  \\n - Well, it's the start of the lunch hour,  \\n so most of the employees will be in the cafeteria.  \\n Now, we'll go to your desk  \\n and you can get your personal belongings.  \\n I'll take your employee badge and your laptop,  \\n and then I'll walk you out.  \\n Do you have any questions for me?  \\n Are you ready? - Yeah.  \\n - Jarred did a good job delivering this information.  \\n He followed the pattern of delivering,  \\n confirming the messages were delivered,  \\n and soliciting questions as needed.  \\n It's also important to note what he didn't say.  \\n He did not say, I feel so bad about this,  \\n I'm sorry this has to happen, or I know how you feel.  \\n In this situation, don't get personal or emotional,  \\n the time to be supportive and show empathy  \\n has unfortunately passed.  \\n Your goal is to educate them about their new reality,  \\n and help them get started.  \\n If you're facing a meeting like this,  \\n remember, you want to nail the content and the delivery.  \\n Do yourself a favor  \\n and watch the video example one more time.  \\n Start to visualize yourself adopting Jarred's demeanor.  \\n You can do this, and don't forget,  \\n you'll be serving the needs of your team  \\n and your organization.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2935449\",\"duration\":213,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Responding to negativity\",\"fileName\":\"2817013_03_04_MM30_Negativity\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers must be prepared to properly respond to unproductive statements or behaviors during the termination meeting. In this video, learn how to recognize common negative reactions and how to respond, including how to show respect, redirect, and others.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13723931,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When you're about to have meeting  \\n where you intend to let someone go,  \\n if you wish to remain safe and professional,  \\n you need to be ready for potentially negative reactions.  \\n To be clear, hard to deal with or violent responses  \\n are incredibly rare.  \\n The lesser forms of negativity shouldn't be too surprising.  \\n Your goal is not to respond to negativity with negativity,  \\n but to respond in a way  \\n that dampens the negativity witnessed  \\n while helping move the conversation along.  \\n With that in mind, let's consider  \\n a few fairly common forms of negativity you might encounter.  \\n Here's Jared and his employee, Sheila.  \\n Jared has just told her that she is being let go.  \\n Let's watch a case where she reacts negatively  \\n and see how Jared handles things.  \\n - Look, I just don't understand what you're saying.  \\n This makes no sense to me.  \\n - Sheila, the decision's been made.  \\n Right now, I need you to focus on this  \\n conversation with me, because I have a lot of information  \\n I want to share with you.  \\n - You mentioned that I needed to improve, okay,  \\n but you never said anything about just letting me go.  \\n - Sheila, we've discussed your performance  \\n on several occasions.  \\n Right now, I have some important information  \\n I want to share with you.  \\n Now, as you can see here, we have several resources  \\n to help you through this transition.  \\n - I can't believe this.  \\n I don't know what I'm going to do.  \\n - I'll give you a second.  \\n So let's talk about what's going to happen  \\n with your health insurance next, okay.  \\n As you can see here, you'll be covered  \\n through the end of next month on your current plan.  \\n But between now and then, you'll need to decide  \\n where you want to put your self-insurance moving forward.  \\n - You know what?  \\n I could totally take you to court.  \\n - Sheila, I'm going to ask you to take a deep breath  \\n and refrain from making any type of legal threats.  \\n Let's talk about your last paycheck.  \\n It'll be issued--  \\n - Why isn't anyone from HR here?  \\n - HR already knows.  \\n We have a process and HR is part of that process.  \\n You and I need to have this conversation right now, okay?  \\n - No.  \\n I'd feel much more comfortable if someone from HR were here.  \\n - Look, I can call someone from HR  \\n but it's not going to change the decision.  \\n So if you choose not to continue with this meeting,  \\n I'm going to have to call security,  \\n but I'd really like to share  \\n some important information with you.  \\n - Security?  \\n Are you kidding me?  \\n This is ridiculous, I'm done talking to you.  \\n - Okay, Sheila, then this meeting is over.  \\n You have an opportunity to gather your personal belongings  \\n and then I'll escort you out.  \\n You'll receive a call from us  \\n to talk about important information  \\n regarding a separation from the company, okay?  \\n Let's go.  \\n - I sincerely hope you never have to deal  \\n with these types of issues.  \\n However, if you do, try and remember what Jared did well.  \\n He acted respectfully, politely and calmly  \\n and didn't inflame the situation.  \\n He also didn't engage  \\n in any unnecessary debate or conversation,  \\n and he quickly redirected Sheila in an attempt  \\n to restart the conversation he needed to have.  \\n When dealing with tough situations like these,  \\n you won't always get the reaction you want  \\n but you can follow the advice we just discussed  \\n to increase your odds of making the conversation productive.  \\n Use the example video as a reference,  \\n something you might want to watch right before your meeting.  \\n Then, take a deep breath,  \\n walk in and conduct the meeting successfully.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2935450\",\"duration\":181,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Avoiding common pitfalls\",\"fileName\":\"2817013_03_05_MM30_Pitfalls\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers should be aware of common challenges faced during termination discussions and how to handle them. In this video, learn how to identify proper process pacing, documentation, the need to show ownership, and additional best practices.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10125491,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When you're thinking about how  \\n to let someone go correctly,  \\n there are several things you don't want to do  \\n and a few common pitfalls to watch for.  \\n Let's start by talking about the pace of the process.  \\n Very often, some managers go too fast,  \\n while others move way too slow.  \\n To move too rapidly can send bad signals  \\n and lead to errors in terms of properly  \\n following procedure, which could stall  \\n or stop the process.  \\n Much more common is the manager who waits too long.  \\n They don't like conflict, so they avoid the issue,  \\n allowing the issue to fester and grow.  \\n To be honest, there is no perfect pace.  \\n It depends on where you work,  \\n the nature of the workforce,  \\n and any existing precedents.  \\n The same is true for documentation.  \\n How much do you really need to document  \\n in order to have an airtight case  \\n when letting someone go?  \\n It depends on whether or not  \\n you have well-crafted policies,  \\n whether or not the workforce is unionized,  \\n past company precedents, and so on.  \\n So the real answer for both pacing and documentation  \\n is to find folks in your organization  \\n with more experience than you and learn from them.  \\n Okay, now let's shift and consider  \\n several things to avoid saying or doing in the meeting.  \\n First, don't give false hope.  \\n So don't say things like,  \\n \\\"Everything will be okay.\\\"  \\n You can wish them the best when wrapping up,  \\n but don't address their future prospects in any way,  \\n since you don't know what their future holds.  \\n It's also important to not console  \\n or show strong empathy.  \\n Be respectful and polite, but don't say  \\n that you're sorry or that you know  \\n how tough this is.  \\n Statements like these, believe it or not,  \\n can provoke emotions and could make them  \\n think the decision really isn't final.  \\n Next idea, take proper ownership.  \\n You're holding this meeting.  \\n You are having this conversation, own it,  \\n and never blame the team, management,  \\n organizational performance, or any other factor.  \\n Owning your words is a sign of respect,  \\n so be kind and show it.  \\n Here's another one to avoid, debating.  \\n The data's been collected and the decision  \\n has been made.  \\n There's no reason to enter into a debate  \\n and if they try, you simply redirect them immediately  \\n to focus on the points you need to make.  \\n Further, remember that you can't be angry  \\n or defensive in any way during this meeting.  \\n Do not react to negativity they might show you  \\n and never instigate negativity.  \\n Always stay calm, positive, and polite.  \\n Finally, don't offer advice.  \\n I'm confident you have some, but don't bring it.  \\n Discussing anything like that at this point  \\n can be viewed as demeaning, so no coaching.  \\n In some situations, such as termination meetings,  \\n success has a lot to do with what you don't say or do.  \\n Before you go into that meeting, find a minute alone  \\n and commit to yourself that you'll stay on point,  \\n positive and helpful, no matter how you feel  \\n or which behaviors they show you.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2935451\",\"duration\":169,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Closing the meeting\",\"fileName\":\"2817013_03_06_MM30_Meeting\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers should know the key things that must be completed before ending a termination meeting. In this video, learn how to prepare for summarizing, taking questions, redirecting off-topic issues, and other productive tips.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10015831,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - After navigating through your agenda  \\n there are a few specific things to do  \\n at the end of a termination meeting  \\n to keep the process moving smoothly.  \\n First, offer a quick summary of points  \\n you feel they need to hear.  \\n Everyone reacts to this type of situation differently.  \\n So, for example, if they were concerned about an issue  \\n try explaining again and also remind them  \\n who they can contact with further questions.  \\n Next, ask for any final questions.  \\n Answer if you can, otherwise, write it down  \\n and tell them you'll get back to them  \\n and be sure you have their preferred phone number.  \\n If they ask about their performance or their job  \\n immediately redirect to the task at hand.  \\n Now let's think about escorting the person  \\n to their workspace and eventually out of the building.  \\n Some companies are leisurely about this  \\n while other have very strict protocols  \\n that rely on close supervision.  \\n Sometimes employees are simply handed a box  \\n full of their personal items and escorted out.  \\n This does minimize security risks,  \\n but it can be demeaning.  \\n In terms of walking them out,  \\n if you see no risk of violence or theft  \\n or anything like that  \\n the simple respectful path is to talk with them in private  \\n at the end of the meeting about what needs to be turned in  \\n and who will be accompanying them to their workspace.  \\n That would be you, HR, or another manager  \\n as dictated by policy.  \\n Try to reserve the use of security  \\n to when it's really necessary.  \\n Before leaving the meeting you can ask  \\n for their company badge and cell phone if they have one  \\n and then it's on to their workspace.  \\n It's useful to tell them how to deal with questions  \\n they might receive from colleagues in the office  \\n during this time.  \\n Just suggest they reply to anyone who talks to them  \\n by saying, \\\"I'll speak with you later, okay?\\\"  \\n The goal is to help them retrieve what is theirs  \\n and exit the building quickly  \\n without allowing others to become involved.  \\n No matter how you time this, you might see people,  \\n but don't engage conversation.  \\n If needed, you too can just say  \\n that you'll get back to them.  \\n After wrapping up in just a few minutes at their workspace  \\n escort them immediately out of the building.  \\n At the door, remind them of the contact information  \\n you provided for further questions.  \\n Thank them, wish them well, then go back inside.  \\n In many ways, success here is about  \\n not causing unnecessary problems.  \\n For termination meetings remember,  \\n no irrelevant conversation and no inflamed emotions.  \\n You deliver the information they need  \\n and you help them gather what's theirs  \\n and leave the building.  \\n Be ready by making yourself an agenda  \\n or checklist before you begin.  \\n Then remember the advice covered here  \\n and you will successfully minimize problems  \\n while giving the employee information they need.  \\n \\n\\n\"}],\"name\":\"3. Conducting the Termination\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2933578\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2935452\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Moving forward after a termination\",\"fileName\":\"2817013_04_01_MM30_Foreward\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers need to understand the necessary next steps following the completion of the termination meeting. In this video, learn how to clarify why and how you must inform the terminated person's team, and steps you must take to begin the process of backfilling the role.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10618880,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - After you let someone go,  \\n it's time to address your team.  \\n The first issue is deciding how to talk about  \\n what just happened.  \\n Unfortunately, managers often avoid this task.  \\n They don't like conflict,  \\n or maybe they just think it's not appropriate.  \\n Not so.  \\n It's avoiding that issue that causes problems.  \\n It makes the team draw assumptions about why this happened.  \\n This ambiguity results in fear.  \\n Some people will wonder if they're next.  \\n So now productivity suffers.  \\n You can also hurt your reputation.  \\n You can be seen as too secretive, cold  \\n or disconnected from the team.  \\n Instead, be proactive.  \\n Gather everyone and be direct.  \\n For example, you might say,  \\n \\\"Guys, by now I'm sure you know that Marcus was let go.  \\n \\\"These situations are tough.  \\n \\\"I want you to know  \\n \\\"that I believe I made the right decision.  \\n \\\"There were performance and fit issues  \\n \\\"that needed to be dealt with.  \\n \\\"After a lot of helping and coaching,  \\n \\\"I felt the need to make the call to put the team first.  \\n \\\"I do believe in second chances,  \\n \\\"but there comes a time to let someone go.  \\n \\\"I don't like it at all,  \\n \\\"but it's the best thing for this team.  \\n \\\"So please know that the decision was fair  \\n \\\"and executed with respect.\\\"  \\n Next, ask if anyone has a comment or a question.  \\n If they ask about the decision,  \\n just say it was a thoughtful and well documented process  \\n approved by all the right players.  \\n Don't discuss any details about why he was let go.  \\n Instead, use this time as an opportunity  \\n to make sure they know there's nothing strange going on  \\n in terms of strategic direction,  \\n further layoffs coming down the road and so on.  \\n Be as transparent as you can,  \\n and you'll help all of them breathe a sigh of relief.  \\n It's also time for you to speak to them  \\n about how this person's role is to be covered.  \\n Before you initiated this whole process,  \\n you knew it was not a given  \\n that you would receive a new resource.  \\n That depends on budgets and many other spending priorities.  \\n You might get a new employee,  \\n or you might be asked to simply absorb the role  \\n without a new resource.  \\n Try to find the answer to this question  \\n as early as you can  \\n so that you can think through the implications,  \\n make a decision and feel confident  \\n you know how to explain this to the team.  \\n Just know that being asked to absorb the role is common,  \\n and can be difficult.  \\n But it does come with benefits.  \\n For example, you avoid a lot of time and money  \\n associated with recruiting, hiring, and training someone.  \\n And you have the opportunity to use this situation  \\n as a development opportunity for the employees affected.  \\n In any case,  \\n when you endeavor to educate yourself on this matter,  \\n then prepare for the event,  \\n and follow up appropriately with your team,  \\n you'll be making a decision that will stick,  \\n and one that overall, will help the team.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2935453\"}],\"size\":0,\"duration\":3088,\"zeroBased\":false},{\"course_title\":\"Bad Boss: Dealing with a Difficult Manager\",\"course_admin_id\":779743,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":779743,\"Project ID\":null,\"Course Name\":\"Bad Boss: Dealing with a Difficult Manager\",\"Course Name EN\":\"Bad Boss: Dealing with a Difficult Manager\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Bad bosses are everywhere. In every industry, at every level. Dealing with a difficult manager is frustrating and impacts anyone's job performance. This course describes all sixteen different types of bad bosses\u00e2\u20ac\u201dand their underlying issues\u00e2\u20ac\u201dand gives you a playbook of responses for dealing sanely with these obstacles to your career. Chris Croft provides tips for dealing with abusive, demanding, and incompetent managers, and getting the credit, payment, and respect you deserve.\",\"Course Short Description\":\"Learn how to deal with a bad boss. Find out how to handle 16 types of difficult managers: the boss that doesn't listen, that plays favorites, or that engages in other bad behaviors.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":3308631,\"Instructor Name\":\"Chris Croft\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Lecturer, Thought Leader, Project Management, Leadership\",\"Author Payment Category\":\"LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2018-10-10T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/bad-boss-dealing-with-a-difficult-manager\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"General\",\"LI Level EN\":\"General\",\"Sensitivity\":null,\"Internal Library\":\"Business\",\"Internal Subject\":\"General Skills\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":4746.0,\"Visible Video Count\":24.0,\"Contract Type\":\"LICENSED\"},\"sections\":[{\"duration\":114,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:794609\",\"duration\":114,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Exploring management issues\",\"fileName\":\"779743_00_01_WL30_Overcoming_Management_Issues\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":21865427,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Welcome to this course on how to deal with\\nbad or difficult bosses.\\nAnd this is an important area,\\nbecause people join companies, but they leave bosses.\\nBad bosses are the biggest reason\\nwhy people leave their work.\\nAnd I think they might be the biggest reason\\nwhy people are unhappy in their work, as well.\\nThe bad boss can ruin your life,\\nor at least they can ruin five days out of seven,\\nand that affects the weekend, as well.\\nIt's amazing how they can get under your skin,\\nand they can slowly destroy you,\\nhowever strong you think you are.\\n\\nAnd I should know, I've had a few bosses.\\nMy name is Chris Croft.\\nI've spent about 15 years working in industry as a manager,\\nmostly manufacturing, running factories, that kind of thing.\\nAnd then, for about 20 years,\\nI've been running training courses,\\nusually in how to be a good boss.\\nBut it's ironic that, really,\\nthe problems are the people that haven't been on my course.\\nAnd actually, most bosses haven't had any training.\\nThey're not necessarily evil,\\nthey're just making it up as they go along.\\nSo when you think about it, it's not really surprising\\nthat quite a few bosses are not very good.\\n\\nAnd of course, whatever you do, you've got a boss.\\nSo I've had quite a few bosses,\\nand about 50% of them have been bad in one way or another.\\nSo I've been thinking about this a lot.\\nIt's about time this course was made.\\nAnd what I'm gonna do, I'm gonna list the 16 things\\nthat bosses do that are bad.\\nAnd then I'm gonna give you practical strategies,\\nthings you can actually do,\\nto deal with all of those 16 types of bad boss.\\nYou can keep this course forever,\\nand then you can refer back to it.\\nPerhaps in 10 years' time, you'll have a problem boss.\\n\\nYou can dip back into this course and get the answers.\\nSo I really hope that you decide to\\nsubscribe to this course.\\nBut before you decide, why not have a look at some of the\\nfree sample videos, give you an idea of the style of it,\\nand if you like them, get the course.\\nAnd then, let's do it.\\n\\n\"}],\"name\":\"Introduction\",\"size\":21865427,\"urn\":\"urn:li:learningContentChapter:794608\"},{\"duration\":116,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:794611\",\"duration\":58,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Bad boss basics\",\"fileName\":\"779743_01_01_LA25_Bad_Boss_Basics\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12775254,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- So welcome to my training course\\non how to deal with a bad or difficult boss.\\nIt's a really important subject this.\\nBosses can make your life a misery,\\nand it's not your fault,\\nand a difficult boss can ruin things for you\\nfor all kinds of weird reasons,\\nsometimes they're genuinely evil people,\\nbut quite often they're just incompetent.\\nNo one's ever told them how to be a good boss,\\nfor example, they might think that criticizing you\\nis going to improve your behavior, so that's what they do.\\nAnd it is amazing how bosses can get under your skin,\\nand they can slowly undermine you\\nand destroy you in the end.\\n\\nSo, we need answers.\\nSo what I've done is I've listed what I think\\nare the top 16 things that bad bosses do,\\nand for each one I'm gonna give you tactics\\nof how you can deal with it.\\nI've got different tactics for each one.\\nSome tactics work for several types of problem boss\\nbut I'll explain that as we go along.\\nSo, let's get started.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794612\",\"duration\":58,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What type of boss is yours?\",\"fileName\":\"779743_01_02_LA25_Guide_to_the_Course\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12927990,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Now I know that you're probably here\\nfor one particular type of boss,\\nand I've been thinking about the best way\\nto film these videos.\\nBecause each problem type,\\nthere's 16 problem types of boss,\\nand for each one there's probably\\nfive or six different tactics.\\nAnd some of those tactics work on\\na number of different bosses.\\nSo I could go through all six for each boss,\\nbut if we do that, it's a lot of repeating,\\nand if you watch the whole course\\nit'd be too much repeating.\\nBut on the other hand, if you delve into just one type\\nof boss you might miss some of the tactics\\nas they might be referring to other types of boss.\\n\\nSo what I've done is I've made a little matrix here\\nso that you can see.\\nSo what it shows you is you can look up\\nthe type of boss that you want to deal with,\\nand it'll show you which tactics you can use,\\nand it'll show you which video\\nthose tactics are described in.\\nSo hopefully that'll be useful,\\nand then you can get all the information you need\\nto deal with that horrible boss of yours.\\n\\n\"}],\"name\":\"1. Bad Bosses\",\"size\":25703244,\"urn\":\"urn:li:learningContentChapter:794610\"},{\"duration\":4349,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:794614\",\"duration\":108,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"My boss never listens to me\",\"fileName\":\"779743_02_01_LA25_Boss_Lone_Wolf\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":23367625,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The first bad boss behavior, and these\\nare not in any specific order, they're just 16 bad things.\\nThe first one I've picked is bosses who don't listen to you.\\nAnd linked to that is bosses who don't involve you\\nin their decisions, they just do their thing,\\nand you're just a minion who works for them.\\nThey don't appear to value your opinion.\\nSo what can you do about that?\\nAnd I've got two tactics.\\nThe first tactic is to compare\\nhow they treat you with how they treat everyone else.\\nSo talk to your colleagues and find out\\nwhether your boss listens to them.\\n\\nIf you can find people with the same boss,\\nask how that boss treats them.\\nDo they listen to them, do they involve them?\\nBecause if it's just you, that's a specific problem.\\nThe chances are it applies to everyone.\\nSo at least that's a bit of progress,\\n'cause you know that it's nothing personal.\\nIt's just that that's how they\\nthink they should manage people.\\nSo compare with how they treat other people,\\nand that applies pretty much to every single boss problem.\\nCompare notes with colleagues\\nand find out whether it's only you.\\nAnd then the second thing is to ask for a specific change.\\n\\nDon't ask for a general change.\\nJust don't say, oh, you're bad at listening,\\nor I want you to listen to me more,\\nor I want you to involve me more, 'cause that's just moaning\\nand it's too vague and too negative.\\nSo say to the boss, when you\\nselect a new supplier I would really like to be involved.\\nOr when you create the agenda for the meeting,\\nI would really like to be in on the creating\\nof the agenda 'cause I think I can add some things.\\nPick a specific change and ask.\\n\\nAnd by doing that, you can gradually train the boss\\ninto listening to you and getting your opinion\\nbefore they do things.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794615\",\"duration\":291,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"My boss is making terrible choices\",\"fileName\":\"779743_02_02_LA25_They_are_wrong\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":61504853,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The second problem you can get with bosses\\nis when you disagree with them.\\nYou just don't agree with the way they're doing the job.\\nMaybe they're trying to reduce quality\\nin order to get prices down,\\nor maybe they're rude to customers,\\nor they don't want to invest money on something,\\nand you just don't agree with them.\\nWhat can you do?\\nWell, the first thing you should\\nSay to yourself is it me, or is it partly me?\\nAnd this applies to all\\nof the following boss problems, as well, is it me?\\nSo it could just be that you disagree\\nwith your boss because you're wrong.\\n\\nOr maybe it's a matter of opinion,\\nand you're both equally right.\\nSo that's the first thing to ask yourself.\\nBut if you are really reasonably sure\\nthat you're right and the boss is wrong,\\nthen the second thing to do is to get better\\nat persuading your boss, influencing your boss.\\nAnd the thing to know about this\\nis that there are different types of boss\\nwho are susceptible to different types of influencing.\\nI think you can divide the bosses down into four types,\\nand you can see them on this diagram here.\\n\\nYou can look at how quiet versus outgoing they are.\\nYou can look at how logical versus emotional they are.\\nSo if they're quiet and logical,\\nand often accountants and engineers are like this,\\nthen they're probably an analytical type of boss.\\nSo if you want to persuade them,\\nyou need to give them lots of facts and reasons,\\nlots of information.\\nAnd if you can give them a logical case,\\nthen they should be open to being persuaded.\\nThe other thing with them is to, they're quite risk-averse,\\nso if you say to them my worry is that if we don't do this,\\nthere might be a problem, there's a risk\\nof something going wrong, then they're quite likely\\nto do what you want.\\n\\nThe second type of boss, top right corner in my diagram,\\nis the more outgoing logical person,\\nand I call them the controller.\\nAnd these are the people who are in a hurry,\\nand they're just tough, decisive,\\nand they make decisions quickly\\nbased on a short number of, small number of facts.\\nSo with this type of boss,\\nthe thing is to give them a very quick summary.\\nI think we should do this, and this is why.\\nI think we should do this, it'll cost X,\\nthese will be the benefits.\\nMake it really easy for them.\\nIn the ideal world you will have already found a supplier,\\nchosen the best product, filled out all the form,\\nall they have to do is sign it.\\n\\nSo you can say to them I think we should do this.\\nWe need to buy one of these.\\nHere's the form, if you could sign it,\\nI will sort all the details.\\nAnd that's the best way to persuade that type of boss.\\nThe other option is to give them just two choices.\\nDo you think we should do this or this,\\nbecause they are quite macho decision makers,\\nso they'll probably just say well, I think I'll do that one.\\nAnd then you've got what you wanted.\\nYou probably don't mind which of the two versions,\\ndo you wanna get the red or the blue one,\\ndo you wanna get it this week or next week,\\nsomething like that.\\n\\nSo get them to choose between the two.\\nThey have the illusion of control,\\nand their brain is occupied choosing\\nbetween your two options.\\nIt doesn't enter their mind that there's a third option,\\nwhich is to say no to you.\\nThe third of my four types of boss\\nis what I call enthusiast,\\nthe outgoing emotional type of boss.\\nAnd these ones are exciting, visionary, inspirational,\\nbut they're pretty disorganized and scatty.\\nThey change their mind,\\nthey have a different flavor of the month every month.\\nAnd so how do we persuade this boss\\nto do something if we disagree with them?\\nLogic is pointless.\\n\\nYou can give them a big long report,\\nthey're never gonna read it.\\nSo the thing is to be as quick as you can,\\nbut to paint them a picture of how great it will be.\\nSay I've had this amazing idea, it's really new,\\nit's different, everybody's gonna love it, shall I do it?\\nI'll organize it for you,\\nyou can have a look at it when it's done.\\nSo make it easy for them, and make it exciting sounding,\\nbecause that's what turns them on.\\nDon't expect them to do any work at all,\\nand definitely don't expect them to read a long report,\\nor to fill in any forms for you or anything like that.\\nYou have to do all the details for them.\\n\\nAnd then the final type of boss is the amiable boss,\\nthe people person who's a bit quieter than the enthusiast.\\nAnd these are the nice bosses,\\nthe cuddly, caring people-type bosses.\\nThey're not usually so difficult,\\nbut if you are trying to persuade one of these people,\\nthe main thing is security and happiness of people.\\nIf we do this, everything will be safe,\\nand everyone will be happy, nothing will go wrong.\\nThe other argument that works well with them\\nis that other people are doing it, and it's fine.\\nIf you say that every other company's doing it,\\nor somebody they know is doing it and it works really well,\\nthat's the best way to persuade them to do what you want.\\n\\nSo to sum this up, then, if you do disagree with your boss,\\nthe first thing is, is it you, could you be wrong?\\nAnd secondly, use some influencing methods\\ndepending on the type of boss that they are.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794616\",\"duration\":240,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"I'm bored\",\"fileName\":\"779743_02_03_LA25_Being_Bored\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":50883927,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- My next type of problem boss is when you're bored.\\nIt is your bosses fault they're not giving\\nyou enough to do, not giving you a meaty enough challenge\\nto get your teeth into it.\\nAnd you're just getting bored in your job, really.\\nWhat could be done?\\nWell, I've got a number of suggestions.\\nMy first one is to ask for just\\na small chance to prove yourself.\\nSay to the boss, can I go and see\\nthe customer on my own next time, or,\\ncan I go and do the presentation\\nto that conference next time?\\nJust think of something that would be a challenge for you,\\nbut which you could definitely do,\\nand ask the boss if you can have a go at that.\\n\\nSo that's the first thing you can do.\\nThey'd probably be fine with that.\\nI'd be surprised if they don't want to let you do that.\\nAnd then that will keep yourself entertained.\\nDon't expect your boss to come up with ideas\\nto keep you occupied.\\nThink of what you would like to do\\nas your next level of challenge\\nand then ask your boss for it.\\nThe next thing is to always be positive in your requests.\\nDon't just say to the boss, I'm bored,\\nor I don't like doing this.\\nBut say to them, I'd like to do X instead,\\nor I'd like to do X, as well.\\nCould I do that please?\\nThird is to gradually move your circle of accountability\\nso that your job evolves in the way that you want it to go.\\n\\nAnd what I mean by this is that if you do a circle\\nof everything that you are accountable for,\\nand then you also draw a circle of what\\nyou would ideally like to do,\\nthese two circles might not be quite the same,\\nin fact, they could be really different.\\nSo you've got a nice bit in the middle.\\nThe overlap is where you want to do it\\nand it is part of your job and it's great.\\nBut there's gonna be part of your job you're bored with\\nand there's also gonna be part of your ideal job\\nthat you haven't yet got.\\nAnd the game is to slowly try to move this circle.\\n\\nAnd you can do that just during the year\\nby saying to your boss, can I do this as well?\\nWould you like me to look after that area for you, as well?\\nBut you can also do it at your appraisal.\\nAnd at your appraisal you could say,\\nI'd like to learn more about this in the coming year.\\nI'd like to get experience of this.\\nAnd you can suggest moving it and gradually keep\\nyour circle moving in the direction you want it to go.\\nAnd it's a slow process.\\nYou might only be able to move it 10% a year,\\nbut the main thing is to be proactive about it\\nand decide what you want your job to consist of\\nso that you could start to lobby for that.\\n\\nIdea number four, if you're bored,\\nis consider moving internally within the company.\\nSo you'd be working for a different boss.\\nIn fact, this applies to almost all of the types\\nof bad boss, consider an internal move.\\nMuch less risky than leaving the company\\nand you don't lose your history if you've got\\na good track record of working for that company.\\nSo, is there another department?\\nThe other thing about moving sideways within a company\\nis that it makes you much more employable\\nfor going up later.\\n\\nIf you've got somebody technical who also knows about sales\\nor somebody technical who knows about production,\\n'cause they've moved sideways, they're much more suitable\\nto be put in charge of both.\\nBecause if you think about it, the managing director needs\\nto know a bit about everything, ideally.\\nSo you could consider moving sideways\\nand it might be diagonally upwards, of course,\\nsideways and upwards.\\nSo that's always an option.\\nMy fifth thought, if you're bored,\\nis don't wait for redundancy or early retirement\\nunless it's gonna happen very soon.\\n\\nIf you know it's happening in the next couple of weeks,\\nthen of course don't leave, but wait for it.\\nBut if you think there's gonna be redundancies\\ncoming up in six months time\\nor you've got retirement in two years, don't wait.\\nLife's too short to waste time waiting for things like that.\\nAnd there is a risk, of course,\\nthat it doesn't come after all\\nand you suddenly find after two years\\nthat you're not able to retire\\nor the redundancy doesn't happen.\\nAnd again, this applies to all of the bad boss situations.\\nDon't wait for redundancy or retirement,\\nunless it's very soon.\\n\\nYou've gotta do something instead.\\nSo those are my suggestions for a boss\\nwho's allowed you to get bored.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794617\",\"duration\":332,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"I don't have the authority or tools I need\",\"fileName\":\"779743_02_04_LA25_Tools_I_Need\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":70043477,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- My next boss problem is when you're not given\\nthe tools to do the job.\\nI don't necessarily mean physical tools,\\nbut you're just not given,\\nI don't know,\\nor you're not given the authority to do the job,\\nor you're not given enough time to do the job\\nthat they're asking you to do.\\nWhich his really unfair.\\nMainly,\\nI think it's authority though,\\nwon't let you get on and do the things you want to do.\\nAnd I personally like a lot of freedom,\\nI like to just get on and do the job,\\nI want to work,\\nand I hate it when bosses say,\\nno, no you've gotta check with me first.\\nSo what we're really looking at here is,\\nto negotiate where you are on something\\ncalled the freedom ladder.\\n\\nSo, if you have a look at this diagram,\\nyou'll see that there are five levels\\non the freedom ladder.\\nSo, the bottom level is wait until told.\\nThat's where you just sit there\\nand you wait for your boss to tell you what to do next.\\nNow, some people want to be here,\\nbecause they have an easy life and\\nPersonally I would hate to be there,\\njust to sit and wait to be told by my boss.\\nThe level above that is where you\\nask what next.\\nYou say to your boss,\\nwell I've done that,\\nAnd again,\\nI would rather be there than the bottom one\\nbut I don't really want to be at the\\nasking for what to do.\\n\\nI'd rather just be getting on with things,\\nbut there are people at that point.\\nSo that's the ask what next.\\nThe level above that on the freedom ladder,\\nyou have a bit more freedom now,\\nis where you actually go to your boss\\nand you suggest things,\\ninstead of just saying,\\nwhat should I do now?\\nYou say shall I do this,\\ndo you want that area tidied up,\\nshall I phone the customer and get a better price,\\nor should we sort out quality problem,\\nwould you like me to do that for you?\\nSo you actually suggest things.\\nNow, if you're at the suggesting level,\\nyou have to actually get permission,\\nyou can only suggest,\\nyou can't actually do it.\\n\\nSo, you could call it check before acting.\\nAnd some bosses like to keep people\\nat the check before acting point on the ladder,\\nbecause then there's not risk,\\nyou know they just go running off and do something\\nlike ask a customer for a price increase,\\nor something like that,\\nwhich could be quiet awkward and could cause trouble.\\nSo, some bosses like to keep you there,\\nbut personally I would feel that I haven't been given\\nthe authorities to do the job,\\nif I have to check with my boss every time.\\n\\nFor example, imagine if you have to check with your boss\\nevery time before you can work overtime,\\nit'd be pretty annoying.\\nSo, I would rather be at the next level up,\\nwhich is report afterwords.\\nSo, this is where we would just do the overtime\\nif we needed to,\\nwe worked overtime at the weekend,\\nthis is what it cost and this is why we did it.\\nAnd, if I have to buy a new part for a machine,\\nI would just do it but I would tell the boss afterwords.\\nSo that's report afterwords.\\nIt's still not that risky for the boss,\\nbecause they know after every time you do it.\\n\\nSo, if you do something you shouldn't have done,\\nyou can only do it wrong once,\\nbecause they're going to know,\\nand then they can say,\\nnext time don't do that.\\nDon't buy that part or don't work that overtime,\\nbecause you didn't need to.\\nAnd then the final level of the freedom ladder,\\nis free to act. Where you can just get on with it.\\nSometimes there's routine reporting,\\nthere's a budget or something like that,\\nbut you're basically free to act.\\nThat's where I want to be on the freedom ladder.\\nSo, in terms of managing your boss,\\nhow do you get to the top of the freedom ladder?\\nAnd the answer is one step at a time.\\n\\nSo, if they've got you down at\\nwait 'til told,\\nwhat you can do is come to them and suggest things.\\nwell you can come to them first of all and just ask,\\nwhat next? And say shall I do this,\\nshall I do this?\\nShall I sort that?\\nWould you like me to do that for you?\\nTo get from the third to the fourth level\\nis a bit harder,\\nbut you can say to them,\\ninstead of checking with you every time,\\nwhich does use up a lot of your time,\\nand sometimes I can't get a hold of you,\\nwhy don't I just do it,\\nbut always report afterwards,\\nso you always know what I've done.\\n\\nAnd I think any reasonable boss would say,\\nyeah, good idea.\\nAnd then, instead of reporting every time,\\nyou could say, instead of me coming to you every time\\nI do this,\\nwhy don't I give you a list at the end of the week,\\nor why don't I give you a monthly report\\nwhere you can just see all of the things that I have bought.\\nAnd I won't go above the budget,\\nor I will check with you before\\nI go above the budget,\\nbut within my budget why don't\\nI just do the things I have to do,\\nand just give you a summary every week or month.\\nAnd again, any reasonable boss would agree to that,\\nI think.\\nAnd then finally,\\nto get to free to act,\\nthat's a bit more difficult,\\nbut you could say to them,\\nevery time I send you this list,\\nit's always fine,\\nso why don't I just do it.\\n\\nYou can always ask me,\\nif you want to know anything just ask me.\\nRather than me giving you the list every time,\\nwhy don't I just get on with the job.\\nSave time,\\nget on with it.\\nif I don't have to give you a report\\nwhich you then have to read,\\nor pretend to read.\\nSo, that's the freedom ladder, and the idea is to try to go\\na level up and a level up until\\nyou get to the top if you can do it.\\nAnd as you go up those stages,\\nas I mentioned on one of the other videos,\\nask for specific changes.\\nSo, rather than just,\\ngive me the freedom to act,\\nsay to them,\\nI'd like to be able to just work over time\\nif I need to.\\n\\nOr I'd like to be able to just order parts\\nwithin a certain price range if I need to.\\nSo, make sure that your suggestions\\nabout how you got the level,\\nas specific as possible.\\nSo there we are.\\nThat's what to do if your boss\\ndoesn't give you the tools or the authority to do the job.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794618\",\"duration\":143,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"They always want me to stay late\",\"fileName\":\"779743_02_05_LA25_Working_Late\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":30567766,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The next boss problem is quite a common one, I think,\\nwhich is when they put pressure on you\\nto work really long hours.\\nAnd you've probably got a personal life.\\nI mean you don't have to spend all the time at work.\\nBosses think if they can get you to work longer hours,\\nthey'll get more out of you,\\nwhich of course, is probably not true.\\nSure, you can stay on late once and do some extra work.\\nBut if you regularly work longer hours,\\nit's been shown, there's been lots of research into this,\\nthat people don't produce any more\\nif they regularly work long hours.\\nAll they do is pace themselves.\\n\\nThey go a little bit more slowly,\\nbecause they know they've got a longer day.\\nSo it is stupid for bosses to put pressure on us\\nto work longer hours, but nevertheless,\\nthat's what they do.\\nSo what can be done?\\nWell, three thoughts really.\\nFirst of all, find out from your coworkers\\nhow they handle it.\\nWhat do they do when the boss puts pressure on them?\\nParticularly the ones who are really good\\nat keeping their hours down.\\nHow are they doing it?\\nSo learn from them.\\nMaybe even talk to them about it.\\n\\nMy second thought is make your results more measurable,\\nbecause quite often bosses are asking for long hours\\nbecause they don't know what you do.\\nBut if you can show that this is your target\\nand that you're achieving it,\\nthen the hours you work don't really matter.\\nSales people are a classic example of this.\\nSales people quite often do work longer hours,\\nbut they don't always,\\nand their boss doesn't really care what hours they work\\nas long as they're getting in the deals.\\nSo with any job, if you can make it measurable,\\nthen the focus will move away from the hours.\\n\\nAnd then my third and final thought\\nis to make yourself harder to monitor.\\nSo if you can work at two different sites,\\nthen your boss won't know which hours your working.\\nIf you can work from home some of the time,\\nI used to leave my jacket on the chair at my desk\\nwhen I went home so my boss would never really\\nknow whether I was around,\\nbecause I was down in the factory a lot\\nand my jacket would be on my chair.\\nSo I used to leave my jacket on my chair when I went home.\\nIt probably didn't fool the boss.\\nAnd of course they can look at when your car's there.\\nIf you park your car in different places as well,\\njust make yourself harder to monitor.\\n\\nIt's a bit naughty, but if they want to be that useless,\\nand they look at your hours, then I think it's okay\\nto play games back.\\nBut the big one there, I think really,\\nis make your results more measurable if you possibly can.\\nSo there are some suggestions for what to do\\nwhen your boss is putting pressure on you\\nto work longer hours.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794619\",\"duration\":304,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"My boss has favorites\",\"fileName\":\"779743_02_06_LA25_Favourites\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":64158038,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The next type of bad behavior by a boss is\\nwhen they have favorites.\\nMaybe you're a favorite, maybe you're not a favorite,\\nbut bosses who have favorites are basically unfair\\nand that's bad.\\nThe first thing to think about is what's the real problem?\\nAre they just an incompetent boss?\\nAre they actually evil?\\nAre they deliberately trying to make you unhappy?\\nDo they get a kick out of making you unhappy\\nby having other people who are favorites?\\nOr are they just different to you?\\nWith all different, with all difficult people,\\nyou've got these options.\\n\\nAre they incompetent?\\nAre they actually evil?\\nOr are they just different to you?\\nLet's just take a moment to think about that.\\nFor example, suppose you've got somebody\\nwho's really annoying because they always turn up late\\nto meetings.\\nAre they incompetent?\\nAre they just bad at time management?\\nAre they actually evil,\\nthey just don't care about you?\\nThey think they're more important.\\nOr are they just different to you?\\nMaybe they're just pretty laid back about time.\\nMaybe in their world plus\\nor minus 10 minutes is absolutely fine.\\nIt could be any of those three and the boss\\nwho has favorites could be just an incompetent manager.\\n\\nThey could actually be nasty\\nor they might just be different to you\\nin the way that they interact with people.\\nSo, you may interpret it as favoritism\\nand really there's no harm intended at all.\\nWhat could we do about it?\\nThe first thing is,\\nif you're not one of the boss's favorites,\\nis to get better.\\nMaybe, maybe you do your job well,\\nbut you aren't very good at PR for yourself.\\nYou don't tell the boss enough about how good you are\\nor maybe there are certain things\\nthat the boss really values that you don't do.\\n\\nYou're really good at everything else.\\nFor example, maybe you don't send your monthly report\\nin on time.\\nMaybe the boss thinks that you're rubbish,\\nwhen everything else you do is absolutely brilliant.\\nJust get better, send your monthly report in on time.\\nIf that's what the boss values, do that.\\nSome bosses are really obsessive about time keeping,\\nfor example, so why would you not always be on time\\nwhen that boss is involved?\\nIt could be that the boss finds you hard to deal with\\nand you remember I was talking about the four types\\nof people earlier.\\n\\nIt could be, for example, that you're an analytical person\\nand your boss is enthusiast,\\nand they just find you really picky and detailed.\\nIn which case, get better at influencing your boss.\\nDon't bore them with lots of detail.\\nSimilarly, if you are an enthusiast\\nand your boss is an analytical,\\nget better at dealing with them.\\nMake an effort to give them plenty of information,\\n'cause that's what they want\\nand just looking at the other diagonal\\nwhile we're on the four types of people,\\nif you're a controller and your boss is an amiable,\\nit's a bit of a weird combination,\\nbut that means your boss is really, really nice\\nand you're a cut to the point, no nonsense person.\\n\\nWhat it means is you've gotta take your time a bit.\\nBe nicer to the boss,\\nspend a bit of time chatting to them\\nand talk to them about the people side.\\nWhat's more likely is that your boss will be a controller\\nand you're an amiable, and that will be a problem,\\nbecause you'll find the boss scary and ruthless.\\nIf you find that happening,\\nthen it's really important to use the language,\\nget better at using the language that your boss uses.\\nJust give them a very quick summary, cut to the point,\\ndon't be waffling, prepare what you're gonna say,\\nget in there, and just give them a few bullet points.\\n\\nInfluencing the type of boss.\\nNext, if your boss has got favorites,\\nis never accuse them of being a bad person.\\nIt's the behavior change that you want,\\nso be very specific and clear.\\nIn what way are they favoritizing the other people?\\nFor example, suppose that they, I don't know.\\nSuppose they always invite somebody else\\nto their important meeting,\\nbut they don't invite you.\\nRather than saying, you're not fair,\\nyou've got a favorite.\\nJust say to them, I'd like to come to the meeting\\nor suppose that they spend more money\\non one person's department than they do on your department.\\n\\nSay to them, I've noticed you've spent this\\non their department and I really, really need some money\\nspent on my department and here's the case.\\nThis is what I'd like to spend it on.\\nCould I do that?\\nAlways make sure that the proposed behavior change\\nis specific and clear.\\nFinally, if you are a favorite, that's great,\\nbut be careful.\\nDon't hitch yourself to just one star.\\nEven if you've got a good boss,\\ndon't rely on that one good boss looking after you,\\nbecause you never know what's around the corner.\\n\\nWhat if they leave?\\nWhat if they get fired or they get promoted,\\ngo to some other company?\\nYou'll be stuffed, so don't rely on one boss.\\nIt's great if they like you, but be careful.\\nMake sure that you're also doing a really good job.\\nMake sure that you can prove that you're doing a good job\\nand make sure that you're known to be good\\nby the other people in the organization.\\nDon't rely on just one boss.\\nThere we are, that's bosses and favorites.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794620\",\"duration\":141,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Example: Is your boss evil?\",\"fileName\":\"779743_02_07_LA25_Example_No_Hope\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":30228624,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- An example of a bad boss that I had\\na few years ago, was a guy called Harry,\\nand I remember he rang me up and he said,\\n\\\"Come and see me, would you?\\\"\\nAnd I thought oh, you always know it's bad\\nwhen he just says come and see me in my office.\\nSo I went to see him and he said,\\n\\\"Chris, I don't think you're worth the money.\\\"\\nHe said, I'm paying you all this money\\n\\\"and the factory keeps on making mistakes\\n\\\"and I just don't think you're worth the money.\\\"\\nAnd mistakes do happen, in factories all the time.\\nThat's kind of how they are.\\nSo, what would you say if your boss just said,\\nI don't think you're worth the money?\\nSo I thought, right, I will prove, with logic,\\nthat I'm worth the money.\\n\\nSo I said to him, well, I will show you that I'm worth it.\\nI'll come back tomorrow with a list.\\nSo, I came back the next day with a list\\nof all the things I'd done that had saved him money\\nand, in fact, it added up\\nto 400,000 pounds I'd saved him, .4 of a million.\\nSo we were feeding the edge trim back into the machines,\\nwe were buying other people's secondhand waste\\nand we were feeding that in,\\nand we did all these really clever, difficult things.\\nAnd I'd saved him 400 grand.\\nAnd I only was being paid 40 grand.\\n\\nSo, basically, I'd saved him 10 times my pay.\\nAnd I showed him that list and I thought, that should do it.\\nGuess what he said.\\n'cause I thought he might say something like,\\nyeah, maybe you're right, or, that's not enough.\\nBut what he actually said was,\\n\\\"All those things would probably have happened anyway.\\\"\\nAnd you just think, what are you gonna do\\nwith a boss like that?\\nThat's an example of a boss who just\\nisn't supporting you at all.\\n\\nHe's got it in for you really.\\nAnd I think, when you get a boss who's that evil,\\nHe wasn't incompetent or different to me,\\nhe was actively evil.\\nAnd I think if you've got a boss\\nwho's either getting his kicks from giving you a hard time\\nor deliberately trying to get you out,\\nthe best thing you can do\\nis probably start looking for another job.\\nJust start looking.\\nGet some irons in the fire.\\nDon't feel disloyal.\\nJust ring up some employment agencies.\\nI wouldn't bother with answering adverts.\\nIt's too difficult.\\nContact some employment agencies\\nand find out what they've got.\\nJust get out.\\n\\nAnd that's what I did and it took a little bit of time.\\nBut that's what I did\\nand I think it was the right thing to do.\\nThere is a point where you've just got to leave.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794621\",\"duration\":251,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"I never get praised\",\"fileName\":\"779743_02_08_LA25_Over_critical\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":53244008,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The next type of problem boss\\nis the one who criticizes you all the time.\\nI read somewhere that you have to praise people 10 times\\nto cancel out just one criticism.\\nSo, if you've got a boss who criticizes and praises 50/50,\\nthat's still gonna feel as if\\nyou're mostly being criticized\\nAnd there are lots of bosses out there who never praise.\\nIt's always criticism.\\nAnd criticism is really, it's really horrible.\\nLong-term it really undermines you.\\n\\nIf you've seen some of my other videos,\\nyou'll know about the management potato, I call it.\\nAnd it's a bit as if your performance is like this potato\\nand every time your boss criticizes,\\nthey just cut a little piece off the potato\\nand eventually you get nibbled away til you've just got,\\ninstead of the potato of performance,\\nyou've got the prune of performance.\\nAnd that's really quite horrible.\\nWhat can we do?\\nThe question really is, what can we do if we've got a boss\\nand we feel our potato being nibbled away by criticism.\\nWhat you must never do is just end up as a prune,\\njust ceasing to care and just doing the minimum.\\n\\nBut that will happen if you're not careful.\\nSo, what can we do?\\nAlthough before I get to the answer on that,\\nI just wanna say that there are bosses\\nwith a personality type\\ncalled the controlling perfectionist,\\nand they are impossible to please.\\nDon't be fooled into thinking that\\nif you try hard enough, you'll win their approval.\\nSome bosses will just never be satisfied.\\nSo, they are gonna criticize us.\\nAnd it's not our fault.\\nSo, what can we do?\\nWell first, does everyone else get the same?\\nI mentioned this on a previous video.\\n\\nFind out from your colleagues, from your teammates,\\ndo they also get criticized by the boss?\\n'cause if you're all being criticized,\\nthen at least that's some consolation.\\nYou know it's not just you.\\nAnd, in fact, you could all, perhaps, between you\\nwork out a plan of how to deal with it.\\nNext is to ask your boss for their help\\nto learn and to be better.\\nIt's quite cunning.\\nSo you could say, yes, you're right.\\nI am bad at that and I want to improve.\\nAnd you're obviously and expert on it.\\nSo, will you help me to get better?\\nNow if you think about that, what's gonna happen?\\nThe answer is, if it's really difficult\\nand there is no answer,\\nthey're gonna find that out, aren't they?\\nThey're gonna go, well, actually,\\nI don't know the answer either.\\n\\nOr they're gonna go, yes, this is harder than I thought.\\nBut, on the other hand, what may happen is,\\nthey may actually be great.\\nYou might get some really good coaching.\\nYou might learn and you might become better.\\nSo that would be a result.\\nYou win either way.\\nSo ask for their help.\\nAnd, the other thing is that, if you improve a small amount,\\nbut it's from their coaching,\\nthey're gonna say that the coaching was really successful\\nand you've improved massively\\nbecause they've got a vested interest\\nin seeing the coaching work.\\n\\nSo ask your boss for a bit of help, a bit of coaching.\\nI think that's quite a cunning way\\nto get around the criticism.\\nBut the big thing is, never cease to care.\\nAnd this applies, actually, to every bad boss behavior.\\nNever cease to care about your job anymore.\\nBecause if you do that, you're now wasting\\nfive days a week of your life and that's just awful.\\nOnly if you're definitely gonna leave,\\nand you're applying for other jobs,\\nthen, okay, you could cease to care.\\nBut even then, I would try to do a good job\\nright up until the day I leave\\nbecause you never know, you may end up not leaving.\\n\\nSomething might change.\\nYou might wanna come back.\\nSo, never cease to care.\\nIt's much better to try to change your boss's behavior,\\ntrying to get your boss to give you some praise\\ninstead of criticism.\\nAnd if that doesn't work, then leave.\\nBut never leave until you've tried to retrain your boss.\\nThe best way to do that is by\\nthis asking for help to learn.\\nThe only other option you've got, by the way,\\nis to point out their behavior\\nand say, have you noticed how you criticize me\\nmuch more than praise me?\\nAnd I would find it much more constructive\\nif you were to give me some encouragement.\\n\\nWill it be possible to do that?\\nIt's a fairly sticky conversation,\\nbut, you know, you could do that\\nand that's much better than ceasing to care\\nand it's much better than having to leave.\\nSo that's what to do if you've got a criticizing boss.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794622\",\"duration\":132,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"They change their mind constantly\",\"fileName\":\"779743_02_09_LA25_Hot_and_Cold\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":28333339,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- My next category of tricky boss is the boss\\nwho blows hot and cold, the boss who's really excited\\nby something one week\\nand then they're not interested the next.\\nOr they change from one flavor of the month to the next.\\nOr they really want to help you one month,\\nand then the next month they're just not interested.\\nfor all sorts of reasons.\\nThey may have perfectly good reasons to be like this,\\nbut it is quite confusing to have a boss like this.\\nSo what can we do?\\nAnd the first thing is to agree\\non job objectives really clearly with the boss.\\n\\nRather than just doing whatever they want\\nin a particular week or a particular month,\\nhave very clear objectives with what you're trying\\nto achieve and then you can work on that independently\\nof the boss and their mood and their focus.\\nSo agree the job objectives really clearly with them.\\nAnd that may require a bit of negotiating\\nbecause you may want to negotiate to have something\\nthat you want in your job objectives\\nrather than what's already in there.\\nSo that's the first thing.\\nThe second thing is to make everything\\nas measurable as you can.\\nI talked about this already.\\n\\nBut if you've got measurable outputs, measurable outcomes,\\nthen whatever the boss's opinion is doesn't matter so much\\n'cause you can say I've achieved what we agreed.\\nAnd my final point with the hot and cold boss\\nis to have better communication with them.\\nYou really don't wanna have a communication disconnect\\nwith this type of boss.\\nHow do they like to be communicated with?\\nDo they like to meet and chat once a day\\nor do they just want email updates sent?\\nOr do they want to have a weekly meeting?\\nWhen is a good time of day to talk to them?\\nIs it best to get them when they first arrive?\\nWhen they're walking around the factory,\\ncan you go with them and chat to them?\\nOr perhaps they don't wanna be disturbed for the first hour.\\n\\nThey're looking at their email,\\nor they're not a morning person anyway,\\nso maybe it's better to sort of bump into them\\nin the afternoon and give them an update\\nof what you're doing and check that they're happy.\\nSo find out what their preferred communication style is\\nand do whatever works best for them.\\nSo clear objectives, measurable, and the best communication\\nyou can have with them.\\nThat's really all you can do with the hot and cold\\ntype of boss.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794623\",\"duration\":305,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"My boss demands the impossible\",\"fileName\":\"779743_02_10_LA25_Find_a_Way\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":64452267,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The next type of bad boss is the one who says,\\n\\\"You'll just have to find a way.\\\"\\nYou know, \\\"You've gotta get that boat assembled\\n\\\"within six weeks, and it's gotta be ready,\\n\\\"'cause the customer is coming.\\\"\\nOr, \\\"You'll just have to find a way to make\\n\\\"5,000 shock absorbers by the end of the week.\\\"\\nThat was a job that I did.\\n\\\"And you'll just have to find a way.\\\"\\nAnd when you say, \\\"Well, how?\\\"\\n\\\"I don't know, that's your job, you do it.\\\"\\nAnd I've got four things to say, really,\\nabout this type of boss,\\nand the first one is, stand up to bullies.\\n\\nNo one's really sure whether bullies\\nlike to be stood up to or not.\\nI think some like it and some don't.\\nBut I think, I don't care whether they like it or not.\\nIf they like it, stand up to them.\\nIf they don't like it, stand up to them.\\nThey can't be allowed to bully you.\\nSo your first thought is, \\\"This boss is a bully,\\n\\\"and I'm not having it.\\\"\\nSo you gotta have that.\\nAlmost to the point where,\\nif you get fired for standing up to yourself, then fine.\\nThere's always a better job 'round the corner,\\nyou'll be fine.\\nSo we've got to stand up to them.\\nBy the way, don't resign right now\\nbecause I said there was a job 'round the corner!\\nAlways get another iron in the fire before you resign,\\njust in case.\\n\\nMy second thought is, you can say to them,\\n\\\"I can do it, but it's gonna be expensive.\\\"\\nYou know, \\\"I can do it, but it's gonna cost X.\\\"\\nAnd when they go, \\\"Oh, well, no, no,\\n\\\"we're not spending that,\\\" or they may say,\\n\\\"Yeah, that's fine, spend the money,\\\" which is great.\\nBut if they say, \\\"No, no, you can't spend that,\\\"\\nthen you can say, \\\"Well, how can I do it?\\\"\\nAnd expensive doesn't always mean money.\\nIt could mean missing out on something else.\\nSo, you can say, \\\"Well, I can do it,\\n\\\"but I won't be able to do those other two jobs\\n\\\"that you want, so I hope that's okay.\\\"\\nAnd when they say, \\\"Well, no, no, no, I want them all,\\\"\\nyou can say, \\\"Well, each of these is a full-time thing,\\n\\\"so I can't do them all,\\n\\\"which one of the three do you want?\\\"\\nSo making them choose from a list is a good tactic.\\n\\nMy third point is, it's never too late to go back.\\nSo, if in a big meeting, you're told you've got to do it,\\nand you can't really argue there and then,\\nyou can go and see them later.\\nOr, if they take you by surprise,\\nand just say, \\\"You will do it, won't you?\\\"\\nAnd you go, \\\"Oh, yes boss,\\\"\\nYou can always go and see them later and you can say,\\n\\\"I've done some planning, I've done a bit of research,\\n\\\"and I've worked out that it can't be done.\\\"\\nSo you can think of an answer, you can plan your answer,\\nand you can go back to them, maybe with a Gantt chart,\\nor any type of proof, and say to them,\\n\\\"Look, I don't think this can be done in the time,\\n\\\"unless you got a suggestion of how I can do it,\\n\\\"because I don't think it can could be done.\\\"\\nAnd if they say, \\\"Well, I don't care,\\n\\\"you'll just have to find a way,\\\"\\nthey're behaving like a big spoiled baby, really.\\n\\nBut if they say, \\\"Well, you'll just have to find a way,\\\"\\nI think, persist, and say,\\n\\\"Well, I can't see how to do this.\\n\\\"I need you to help me,\\n\\\"please, will you help me, to plan how to do this job,\\n\\\"and then I'll carry it out.\\\"\\nAnd if they go, \\\"Well, that's not my job,\\\"\\nyou can say, \\\"But it is your job to help me\\n\\\"when I can't do my job,\\n\\\"and I literally don't know how to do this.\\\"\\nYou could even be a bit more honest and say,\\n\\\"I don't think you know how to do it either, do you?\\n\\\"I mean, do you even know that it's possible?\\n\\\"What makes you think it's possible?\\\"\\nAnd I think you could ask them some questions like that.\\n\\nReally challenge them, stand up to bullies.\\nMy final thought when you've got bosses\\nwho say you'll just have to find a way\\nis to comment on the process.\\nAnd you could say, \\\"You're asking me, every month,\\n\\\"you're asking me to increase production,\\n\\\"or reduce lead times, or sell more,\\\" whatever it is,\\n\\\"and I think, I've got to a point now,\\n\\\"where it's not possible to keep improving like that.\\n\\\"And I think it's kind of unfair that every month,\\n\\\"you just tell me I've got to do better.\\n\\n\\\"But you don't tell me how,\\n\\\"or you don't give me equipment, tools, authority for how,\\n\\\"you just say, 'Find a way,' and I think it's impossible.\\\"\\nSo, you could actually comment, and if necessary,\\nyou could actually say, \\\"You know, I think you're just\\n\\\"putting loads of pressure on me to get better results,\\n\\\"but I don't think even you know how to do it.\\n\\\"And it's fine, I'll have a go at it,\\n\\\"but I don't think it's fair to effectively threaten me\\n\\\"and say, 'If you don't do it, there'll be trouble.'\\n\\\"Let me have a go at it, help me if you can,\\n\\\"but you don't need to put that kind of pressure on me,\\n\\\"to say, 'If you don't do it, you'll be in trouble,\\n\\\"'or you might get fired.'\\\"\\nSo you could actually tell them\\nthat you don't like the process,\\njust talk to them one-to-one in a grown-up way.\\n\\nDon't let them use parent-child on you.\\nBe adult-adult with how you respond.\\nI wouldn't actually use the word bullying, by the way.\\nI think if you say to them, \\\"You're bullying me,\\\"\\nthat's sort of a red button word, isn't it?\\nAnd they'll think you're gonna put in a grievance,\\nor something about that,\\nso I wouldn't accuse of them of bullying,\\nbut I think I would accuse them of\\nusing an unreasonably forceful process,\\nan unfair process, and a process that's not motivational.\\nAnd say to them, \\\"Do you think this is\\n\\\"the best way to work?\\\"\\nSo, commenting on the process.\\n\\nSo my four points, then, standing up to bullies,\\nsaying, \\\"I can do it, but there'll be a cost,\\\"\\nit's never too late to go back and challenge them,\\nand to comment on the process.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794624\",\"duration\":274,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Example: Stand up to bullies\",\"fileName\":\"779743_02_11_LA25_Example_Bullies\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":57916416,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- One really horrible boss that I had,\\nwe were in this factory, and we were making\\nplastic trays for food to go in,\\nlike chicken Kievs and things like that,\\nand we were running three shifts 'round the clock,\\n'cause we had extruders,\\nand they take a long time to get up to temperature,\\nso once you got them working on Monday morning,\\nyou don't wanna stop, you just run all week.\\nSo it was three shifts, and I had a shift manager\\non each of my three shifts.\\nAnd one of them was old, but miserable.\\n\\nHe was quite negative, \\\"Oh, no, we've tried that before,\\n\\\"that won't work.\\\"\\nBut he was experienced, very knowledgeable guy.\\nOne of them was young, but very positive, up and coming.\\nHe didn't really know much yet,\\nbut he was shaping up to be good in the future.\\nAnd then the third guy was in the middle, really.\\nHe was excellent, I mean, he was experienced,\\nhe was knowledgeable, he was enthusiastic, he was great.\\nSo I had my three, the old, the young, and the great one.\\nAnd one day, the boss, who was really a sadist,\\nhe was horrible, said to me,\\n\\\"Chris, we've got to cut costs,\\\"\\nwhich was not true, by the way,\\nwe were making loads of profit.\\n\\nHe said, \\\"Chris, we've got to cut costs.\\n\\\"I want you to get rid of one of the three shift managers.\\\"\\nThe actual wording he used was,\\n\\\"Pick one, and firk him off.\\\"\\n(laughing) \\\"Firk him off,\\\"\\nit must be a Dorset expression for \\\"fire him.\\\"\\nSo he said, \\\"Pick one, and get rid of him, firk him off.\\\"\\nAnd I just thought, \\\"Oh, what am I gonna do?\\\"\\nNow, the third one, the really good guy,\\nI've gotta keep him.\\nBut who would you have got rid of?\\nWould you have got rid of the old, miserable one?\\nOr the young, enthusiastic one?\\nNow, after a bit of thinking,\\nI decided to get rid of the old guy,\\neven though that was gonna be worse for him.\\n\\nI mean, he was 58, or something like that.\\nHe's probably not gonna get another job.\\nHe's gonna get about 30 grand redundancy money,\\nbut that's gonna be gone in a year or two,\\nbut after that, he's gonna be stuffed!\\nSo it was an awful thing to do, but I had to do it.\\nAnd I figured that the young guy\\nwould be a better long-term prospect,\\n'cause the old guy was holding us back.\\nAnd we had enough knowledge to cope without him.\\nHis attitude was a problem,\\nand I'd rather have attitude than aptitude, I think.\\n\\nSo, I got him in and said, \\\"Look, I'm really sorry,\\n\\\"but somebody's gotta go, and it's you.\\\"\\nAnd he was really shocked,\\nhe went this sort of ashen, gray color.\\nHe just couldn't believe it.\\nAnd I felt so awful about it.\\nI went home that evening and I said to my wife,\\n\\\"I can't believe I'm having to do this,\\\"\\nyou know, \\\"I've sold my soul to the devil,\\n\\\"working for this company, it's just awful.\\\"\\nBut what do you do, you know?\\nSo, anyway, I went back into work the next day,\\nand the boss was waiting for me when I got in.\\n\\nAnd he said, the first thing he said was,\\n\\\"I can't believe you fired Fred.\\n\\\"I wouldn't have got rid of Fred,\\n\\\"You should've got rid of Jim,\\\" he was the young one.\\n\\\"You should have got rid of him.\\n\\\"In fact, get rid of him, as well.\\\"\\nSo I had to fire the young one on the second day.\\nAnd then it was just me and the third guy,\\nand we ran the factory, 12-hour shifts each.\\nIt was impossible, really, to run it like that.\\nAnd there were all sorts of mistakes made,\\nwhich cost a lot more money than we saved\\nby getting rid of those two perfectly good guys.\\nIt was just utterly stupid.\\n\\nAnd I remember going home from work the second day,\\nsaying to my wife, \\\"I can't believe I'm having to do this.\\\"\\nYou know, \\\"This boss, he's making me as bad as he is now,\\n\\\"and this is ridiculous.\\\"\\nAnd I did leave that job, I left.\\nBut looking back, what I should've done,\\nI think, was stand up to him.\\nAnd I think I should've refused to do it.\\nI shoulda just said, \\\"No, I'm not doing it.\\n\\\"It's crazy, it's gonna cost us more money,\\n\\\"I'm not doing it.\\\"\\nAnd I think it woulda been interesting to see what happened,\\nbecause either he would've given in and said,\\n\\\"Alright, then, you can keep your three guys,\\\"\\nwhich woulda been great!\\nMaybe there's only a 10% chance that would've happened,\\nbut I think I should've tried for that.\\n\\nBut because he gave me the choice of who to get rid of,\\nI stupidly didn't think there was\\nthe option of just saying no.\\nAnd, I guess I was frightened that if I'd said no,\\nI'd have got fired.\\nBut I don't know whether he could've fired me for that.\\nAnd besides, I was going to leave, anyway.\\nSo I think you gotta stand up to bullies,\\nand I think I should've said to him, \\\"No, I'm not doing it.\\\"\\nAnd, if he'd said, \\\"Well, do it, or you'll be fired,\\\"\\nthen, I could still have done it,\\nbut I think I should've just argued with him a bit\\nbefore just going ahead and doing it.\\n\\nThat's what I learnt from that story.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794625\",\"duration\":185,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Their promises never come true (promotion, pay raise)\",\"fileName\":\"779743_02_12_LA25_Future_Promises\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":39192406,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The next problem that I've certainly had\\nwith bosses in the past is jam tomorrow.\\nThey keep saying, Oh, you'll get a pay increase next month.\\nOr next year you'll get your new office\\nor we will have some money to spend on machines.\\nIt's always just promises, promises.\\nAnd it just never seems to happen,\\nand it's really frustrating.\\nAnd of course, you can see why bosses do it\\n'cause it's dead easy just to promise\\nthey're gonna sort it out at some point in the future.\\nAnd maybe they will eventually.\\nSo what can we do about that?\\nI think the first thing to do is keep records.\\n\\nSo on the day when they say it's gonna happen,\\nmake a note.\\nJust keep a little book somewhere of the promises.\\nDon't tell your boss you're doing it.\\nJust start keeping records.\\nAnd you need to do that\\nfrom the first time they promise anything, really.\\nYou could use an email thank you\\nas an excuse to put it in writing, as well.\\nSo you could email and say, Oh by the way,\\nwhile I'm emailing about x, just to say it's great\\nthat we're gonna get some new machines next month.\\nI'm really looking forward to it,\\nor something like that.\\n'Cause then you've got some actual proof.\\n\\nYou can say, Well, I'm sure you said last month\\nyou said that this month we were gonna get the new machine.\\nOr I'm sure that you said last year that in January\\nI was gonna get my new office or my pay increase,\\nso where is it?\\nAnd if they deny it, you can say, well,\\nhere's the email I sent.\\nDo you remember?\\nSo put it in an email if you can,\\nbut if not, just keep records in a little book.\\nAnd then you can say that this is the fourth time now\\nthat you've put this off.\\nThis is the fourth time that you've said it's gonna be done\\nand then it hasn't happened.\\n\\nAnd the worst that'll happen is they'll say,\\nWell, are you keeping records?\\nAnd you can say, Well, I keep a record of everything, yeah.\\nThat's just how I am.\\nI'm just organized.\\nSo keep records.\\nStick it in an email if you can.\\nAnd then something we've mentioned on an earlier video\\nis comment on the process.\\nSo you can say to them, by the way, have you noticed?\\nIt's always good with have you noticed.\\nHave you noticed that quite often you promise things\\nand they don't happen?\\nAnd I know it's difficult and sometimes it's hard\\nto get HR to come up with the money or whatever,\\nand things change in the company,\\nbut it is quite frustrating because there's this process\\nwhere you promise and it's always jam tomorrow.\\n\\nAnd it keeps just being postponed and postponed,\\nand it's very depressing for me.\\nSo is there any way we can definitely\\nget it to happen this time?\\nWhat do you think?\\nCan you give me some commitment\\nthat you really will make it happen this time?\\nSo comment on the process.\\nI think that's particularly powerful\\nbecause often people don't realize that they're doing it.\\nBosses do it without even noticing.\\nThey just fob you off.\\nSo you can make them aware of the process,\\nand you can also make them aware of the fact\\nthat you are aware of what they're doing.\\nI'm on to you.\\n\\nI know that you just make these promises\\nwith no intention of doing them.\\nYou wouldn't say that, but that's effectively\\nwhat you're saying when you say,\\nHave you noticed how often things seem\\nto get postponed around here?\\nSo keep records, email if possible,\\nand comment on the process.\\nThat's the answer to jam tomorrow.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794626\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The top priority tasks keep changing\",\"fileName\":\"779743_02_13_LA25_Top_Priority\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":36285782,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The next type of problem boss\\nis a boss who moves the goalposts.\\nThey have different flavor of the month\\nand they keep changing what they want from you.\\nAnd there are several things you can do.\\nFirst of all, agree a jobs list with them.\\nThey may ask for a jobs list, but if they don't,\\nwrite one yourself and then you can say to them,\\nthese are the jobs I'm doing for you, is this right?\\nAnd I've put them in priority order.\\nAre you happy with the priority order?\\nAnd doing this gives you a bit of control, of course,\\n'cause you can choose the order.\\nAnd you could even sneak a couple of jobs in\\nthat you want to do that they haven't given you.\\n\\nAnd you can say, these are the things I'm working on,\\nare you happy with my list?\\nAnd if they say yes, you've got them.\\nThe worst they'll do is delete the ones you added.\\nYou're only back at square one.\\nSo write a jobs list, get them to approve it.\\nAnd then every time they put in an extra job\\nyou can say, well, I can do that one,\\nbut I've got these other jobs I'm doing for you\\nso where do you want the new one?\\nShall I put it in at number three maybe?\\nI think I should probably do it third,\\nbut that means that you'll have to wait till next Thursday\\nfor it 'cause I've got to finish these other two first?\\nAnd if they say, no, no, I want it first,\\nyou can say, okay, fine, as long as you know\\nthat the one that's gonna be second, you won't get that\\ntill Wednesday, you're okay with that.\\n\\nSo you can negotiate over changes to your jobs list.\\nSo that's the first thing.\\nThe second is something I've mentioned before.\\nIt's just to comment on the process.\\nAnd you can say, quite a lot of things\\nhave changed since last month.\\nAnd you can say, is this definitely a priority?\\nBecause last month it was something else and that's changed.\\nAnd the month before, it was something else,\\nand that's changed, so I'm fine with it but can you\\njust confirm this one definitely really is the top priority?\\nSo commenting on the process, and as I mentioned,\\nit shows your boss, first of all, it makes them aware\\nof what they're doing 'cause they may not realize\\nhow often they change your priorities.\\n\\nIt also shows them that you're onto them\\nand that you've noticed that it's happening.\\nAnother method, which we mentioned earlier,\\nis I can do it but it'll cost.\\nSo I can do it, but you won't get something else.\\nOr I can do it, but I'll need to spend a bit of money.\\nAre you sure you want me to do that?\\nAnd finally, keep records, perhaps using email thank yous.\\nSo when they change the goalposts, you could say,\\nno worries, just confirming that this\\nis the current priority order, and just send them the email.\\nAnd then, if you have to have a big debate later on\\nabout whether they keep changing things, you can say,\\nwell, look, here are the last four emails and you can see\\nyou changed it, you changed it, you changed it.\\n\\nParticularly if they keep changing it back,\\nemail to say, just to confirm this one\\nis now the top one again.\\nAnd then, when you're ready, when you've got enough emails,\\nyou can challenge them by showing them the whole list.\\nSo those are my suggestions for how to deal\\nwith a boss who keeps moving the goalposts,\\nkeeps changing the flavor of the month.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794627\",\"duration\":375,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Money issues: Lies, delays, and underpaying\",\"fileName\":\"779743_02_14_LA25_Money_Issues\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":79131235,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Now we come to the biggest crime, I think,\\nthat a boss can do, which is messing with your money.\\nI say to people, rule number one,\\nnever mess with people's money.\\nIf you promise somebody a pay rise\\nor overtime pay for working a weekend,\\nmake sure you pay it.\\nAnd don't, you know, fail to pay it and say,\\noh, yeah, sorry, payroll forgot.\\nPromise it next month, and then next month\\nyou let them down again.\\nI mean, that's just a really guaranteed way to upset people.\\nSo, I think if your boss is messing with your money,\\nthat's a really bad sign.\\n\\nThat shows they have no idea about management\\nand they really don't care about you.\\nSo, what can you do?\\nAnd I would recommend the four-step process.\\nNow, this four-step process, you could use this\\nfor any of these boss situations.\\nAny of these videos that you're viewing,\\nyou could use this for.\\nAnd the four-step process is a really good way\\nto be polite and careful when you talk to a boss\\n'cause, let's face it, bosses are important\\nand often scary, and they do have the power to fire you,\\nso you don't want to upset them.\\n\\nSo, these things I'm suggesting,\\nthey need to be done diplomatically,\\nand the four-step process is the way to do it.\\nSo, the four steps are, I understand,\\nI feel, I want, is that okay?\\nSo, let's just look at that a little bit.\\nLet's suppose that the boss has failed to pay you\\nfor working the weekend doing a stock check\\nor something like that and it was supposed\\nto be extra money for that.\\nSo, you would say, I understand.\\nYou'd say to them, look, you know,\\nobviously it's a bit difficult to,\\nmistakes happen in payroll.\\n\\nMaybe somebody just forgot it,\\nit's just one of those things,\\nbut I feel quite upset.\\nYou don't have to actually use the words I feel,\\nyou could just say, I'm quite, I'm a bit upset about it\\nbecause I'm worrying now about whether I'm gonna get paid\\nand I feel bad having to chase it up.\\nI feel bad having to come to you\\nand appear like I'm money-minded when, you know,\\nI just wanna do a good job.\\nBut I'm worried I'm not gonna get paid.\\nSo, step three, I want is, it will be really great\\nif you could go to payroll and get it sorted out.\\n\\nOr maybe you could get payroll to actually email me\\nto confirm I'm definitely gonna be paid\\nin Thursday's pay packet.\\nCould you do that for me?\\nStep four is just to say, could you do that for me?\\nNow, this is quite a carefully thought out process\\nbecause the strong bits are steps two and three,\\nI'm not happy, I want you to sort it out.\\nBut if you just went to your boss and said,\\nI'm not happy, I want you to sort it out,\\nthat would be quite aggressive.\\nI mean, you have got a right, but nevertheless,\\nyou don't wanna do that, so what we do is we put it\\nin this fluffy exterior of, I don't that it's difficult\\nto get stuff done and I'm really grateful\\nthat you're doing it, but I'm worried,\\nI'm not happy, I want you to sort it out.\\n\\nIs that okay, could you do that for me please?\\nSo, always make sure you do step one and four,\\nand step one has the extra benefit\\nthat it takes away their excuse\\n'cause if you say, I know payroll are quite inefficient\\nand difficult, but it would be great if you could do it,\\nyour boss can't say, but payroll are really inefficient\\nand difficult 'cause you've already covered that off.\\nSo, make sure you look nice, it's a nice, soft lead-in,\\nstep one, but also it takes away their excuse.\\nSo, use the four-step process when you confront your boss\\nwith any of these things, really,\\nbut particularly for messing with your money.\\n\\nYou've gotta go in and you've gotta say,\\nI'm unhappy and I want it sorted out.\\nTwo other thoughts about messing with your money.\\nI think one of them is, be prepared to leave.\\nIf they don't sort your pay out, you've gotta go.\\nAnd just say to them, look, I'm really worried about this,\\nI really want it to be paid.\\nAnd you've gotta give them a few chances\\nbecause sometimes, you know, HR or payroll are very slow.\\nI would personally just go straight to HR or payroll myself\\nand say, look, what's happening?\\nAnd I did this once, actually, in one job,\\nand when I went to HR, they said,\\nwell, we've not had the, it was actually for a pay rise\\nand my boss said he'd put the form in\\nand it was waiting HR.\\n\\nAnd when I went to HR, they said,\\nwell, we've not had the form, so I went back\\nto the boss and said, HR haven't had the form,\\nand he said, really?\\nSo, I said, well, shall I take it to them?\\nSo, I think if you've gotta get really involved, you should\\nbecause the worst that's gonna happen\\nis you're gonna end up leaving.\\nGot nothing to lose, really.\\nSo, be prepared to leave over it.\\nIf you never get the money that they promised you,\\nwhether it's a pay rise or overtime or whatever,\\nthen I would leave over that because that's a measure\\nof how little they actually value me.\\n\\nIt's not about the money itself,\\nbut it's a sign that they just don't care,\\nso I would leave over that.\\nI wouldn't leave till I got another job,\\nbut I would go to a recruitment agency,\\nI'd find out what else they've got.\\nI'd go to some interviews, and if I found a job I liked,\\nI would leave, that's what I would do.\\nBut my final thought is, you could put in a grievance\\nor you could go to your union,\\nif you're a member of a union.\\nBut I think grievances and unions are usually a bad idea,\\nand I think for any of the problems\\nthat we're talking about on this course,\\nI think it's a bad idea to put in a grievance.\\n\\nI mean, it can work, but even if it works,\\nyou're then branded as a troublemaker\\nand managers take a very dim view\\nof people who put in grievances.\\nAlthough you have to have a grievance system\\nand I think it would be really wrong\\nif people could be bullied and were not able\\nto do anything about it.\\nIf you've got the choice, don't put a grievance in\\nbecause it will be, amongst many managers,\\nit will be a black mark against your name.\\nSimilarly if you involve the unions.\\nIt kind of means that you can't stand up for yourself,\\nso I would avoid that.\\n\\nI'd rather leave than put in the grievance\\nbecause if the only way to get\\nwhat you want is to put in a grievance\\nor to involve the unions, then it just shows\\nthe company doesn't really care about you.\\nCertainly your boss doesn't really care about you,\\nand do you really wanna work for somebody like that?\\nSo, I wouldn't bother with grievances and unions,\\npersonally, I would rather leave.\\nSo, that's messing with your money.\\nFour-step process, I understand, I feel, I want,\\nis that okay?\\nAnd be prepared to leave.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794628\",\"duration\":264,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Micromanagement: I have no freedom\",\"fileName\":\"779743_02_15_LA25_Micromanaging\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":55777195,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The next boss problem, and it's a very\\ncommon one, is micromanagement.\\nThe boss wants to control the way you do\\nevery detail of your job.\\nThey want to know everything that you're doing.\\nAnd it's annoying.\\nI mean they're not necessarily a bad boss.\\nThey care, they want you to do the job right.\\nThey want the job to be done well.\\nAnd maybe they do know better than you.\\nPerhaps that's why they're the boss.\\nBut it is annoying.\\nAnd my suggestion for this really is to retrain your boss.\\n\\nGet your boss to be a better boss.\\nAnd that would mean that you would say to them,\\n\\\"I'll do it my way if I may.\\n\\\"Well that's okay, I know how to do this.\\n\\\"You know, just leave me to do it, it's fine.\\\"\\nThe think about retraining your boss is that\\nit may require repetition.\\nThey won't get it the first time.\\nIt's a bit like, imagine if you get a new puppy,\\nand you bring him home and you put him there\\nin the middle of your living room carpet.\\nWhat's he gonna do?\\nNow at that point you think (sighs) I've got a pee-er.\\n\\nI'm just gonna have to live with dog wee on my carpet\\nfor the next 10 years.\\nI'll just wear my Wellingtons and squelch around\\non my carpet.\\nBut you don't, do you?\\nYou think no I'm gonna change that.\\nAnd it's the same with your boss.\\nYou don't need to go (sighs) I've got a micro-manager.\\nI'll just have to live with it.\\nSo you shove the dog out of the house.\\nOut, out, out!\\nAnd then when the dog comes back in,\\nyou know will the dog do it again?\\nAnd the answer's yes, probably.\\nNow when the dog does it again a second time,\\ndo you think not only have I got a wee-er,\\nI've got a non-learning wee-er.\\n\\nI'm doomed.\\nNo, you think right, I'm gonna have to tell\\nthe dog more than once.\\nAnd how many times do you have to put a dog outside\\nbefore the dog learns?\\nIt's probably 20.\\nBy the way, a friend of mine, he tried to train his dog\\nby throwing it out of the window.\\nEvery time it peed on the carpet,\\nhe threw the dog out the window.\\nIt's only on the ground floor so it wasn't too bad.\\nBut he would throw the dog out of the window.\\nAnd the dog very quickly learned.\\nSo what it used to do, he used to pee on the carpet\\nand then jump out the window.\\n\\nBut any way, how many times will throw the dog,\\ngently put the dog out of the room?\\nAnd the answer is possibly 20.\\nNow imagine after 19 times you gave up\\nand you thought that's it, I'm gonna give up.\\nI'm just gonna live with this dog wee-ing on the floor.\\nYou were so nearly there.\\nAnd it's the same with bosses.\\nI think you have to keep saying,\\n\\\"You don't need to worry about this detail.\\n\\\"I've got it, I'm doing it.\\n\\\"I've never let you down before, have I?\\n\\\"So don't worry about it.\\\"\\nAnd you've just got to keep pushing them back.\\n\\nAnd remember the micromanager probably thinks\\nthat they're a great manager.\\nThey think they're helping.\\nSo if you could say to them, you know it doesn't help\\nif you check every, if you come back every five minutes\\nand ask me how I'm getting on.\\nWe already agreed and I'll give you a report\\nonce every week.\\nSo it'll be fine.\\nYou gotta keep doing it.\\nNow it's that bosses are stupid.\\nThe fact that you have to keep repeating it\\nto train them is not because they're stupid.\\nIt's because they're forgetful.\\nThey got loads of other things to worry about\\nand trying to manage you in the way\\nthat you want to be managed is way down\\non their list of priorities.\\n\\nSo you've just gotta keep nagging.\\nSo never live with it.\\nNever give up after only asking for a change to happen once.\\nYou've got to keep repeating the change\\nand you'll get there.\\nYou can retrain your boss because they want\\nto be a good boss.\\nAnd if you have to use it, you could use\\nthe four-step process.\\nSo if you need to, you could say diplomatically,\\n\\\"I totally understand how important this job is to you\\n\\\"and I can see why you want to make sure it's done right.\\\"\\nThat was step one.\\n\\nBut if feel a little bit demotivated.\\nI feel as if you don't entirely trust me to do this job.\\nI'd really like to be just left to get on with it.\\nStep three, maybe I could give you a report\\nat the end of each day on how I'm getting on.\\nI mean how would that be?\\nWould that be good?\\nAnd okay, should we do that?\\nWhat do you think?\\nThat would be step four.\\nSo you could use the four-step process\\nto politely try to retrain your boss.\\nSo that's the answer to micromanagement,\\nretraining your boss with the four-step process\\nif necessary.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794629\",\"duration\":167,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Example: Removing your own freedom\",\"fileName\":\"779743_02_16_LA25_Example_Downgrading_Freedom\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":35699846,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- I was visiting a friend of mine.\\nHe runs this large company in London\\nthat does refurbishing of offices.\\nAnd I was in his office, and it was actually quite hard\\nto have a conversation with him\\nbecause people kept knocking on the door\\nand interrupting with trivial questions.\\nAnd I remember, one guy came in with these two cushions,\\ntwo red cushions, and said, \\\"Which one should I use?\\\"\\nI'm missing his name out.\\nHe said, \\\"Which one should I use,\\n\\\"for the (mumbles) job?\\\"\\nAnd my friend said, \\\"Oh, I'd go for that one there.\\\"\\nAnd the bloke went, \\\"Oh, thanks,\\\" and off he went.\\n\\nAnd after he'd gone, I was thinking,\\nwhy is that guy bringing you cushions?\\nYou're the managing director, and people\\nare bringing you cushions to choose between.\\nI mean, that's just mad.\\nNow, my friend is a brilliant cushion color chooser.\\nHe's probably the best in the company.\\nBut nevertheless, he is now managing director,\\nand he's got to move on from what he used to do.\\nSo, what should he have done?\\nAnd I think he should have said to the guy,\\n\\\"Why are you bringing them to me?\\\"\\nAnd I was thinking, \\\"Why did that bloke\\n\\\"bring the cushions to the boss to choose the color?\\\"\\nAnd I suspect what had happened,\\nand this is where it becomes the boss's fault,\\nI suspect what had happened was that the boss had said,\\n\\\"Who chose that cushion there?\\n\\\"That's completely the wrong cushion!\\n\\\"That color is totally wrong!\\\"\\nAnd from then on, it was, \\\"Oh, always check with the boss.\\\"\\nSo I suspect he'd made that problem happen.\\n\\nAnd this is an example of the freedom ladder\\nbecause somebody was free to act,\\nand the boss saw something he didn't like\\nand said, \\\"That's not right!\\n\\\"Always check with me!\\\"\\nIn fact, he may not even have said, \\\"Always check with me.\\\"\\nHe probably just said, \\\"That's not right.\\\"\\nAnd everybody thought,\\nwe've got to always check with the boss from now on.\\nAnd then, they demoted themselves almost\\ndown to probably not until 'wait until told,'\\nprobably 'check before acting.'\\nIn fact, that's where they are, isn't it,\\n'check before acting'.\\nSo I'm thinking, if you get told you've done it wrongly,\\ndon't immediately go, \\\"Hmm, right.\\n\\n\\\"I'll go down to check before acting.\\\"\\nBecause if you do that, you're just gonna enjoy\\nyour job less.\\nSo I think I would ignore it and carry on\\ndoing it my way.\\nNow, if the boss says, \\\"Always check with me first,\\\"\\nI think I would check with him one or two\\nor three times, but then I would say,\\n\\\"Look every time I bring these to you,\\n\\\"they're always fine, aren't they?\\n\\\"So why don't I just go back to just doing this?\\n\\\"You don't want me to have to come\\n\\\"and interrupt you every time with trivia\\n\\\"like cushions, do you?\\\"\\nSo I would suggest to the boss\\nthat I get moved up the freedom ladder.\\n\\nYour objective is to get high up the ladder\\nif you can, and it's better for them as well.\\nEverybody wins if you can get higher up the ladder\\nbecause you get more motivation\\nand they get more time.\\nSo that's an example of the freedom ladder in practice.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794630\",\"duration\":130,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"They lie to me\",\"fileName\":\"779743_02_17_LA25_Lying\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":27893383,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- This next boss problem we've kind of dealt\\nwith a little bit before when we talked about messing\\nwith your money.\\nBecause this next problem is lying to you,\\nwhere the boss says, oh yeah I'm waiting HR.\\nAnd messing with your money is kind of one version\\nof lying to you isn't it,\\nbecause that's where they say you're gonna be paid\\nand you're not.\\nfor example I worked as a university lecturer for awhile\\nand I had a temporary contract\\nand they kept saying, yeah, yeah your permanent contracts\\ngonna come through soon, you'll be made permanent soon,\\nand it just went on and on.\\n\\nAnd it is the most annoying thing.\\nAnd similarly to messing with your money\\nI think being prepared to leave has to be the bottom line\\nbecause if you've got a boss who lies to you\\nor if you've got an organization who lies to you\\nthat's not the sort of place where I want to work.\\nBut the only way that you can find out whether\\nit's the organization or just a bad boss\\nis to ask to meet the other parties.\\nTo go to HR and say, look have you had the form\\nfrom my boss.\\nOf course if they're any good they won't tell you.\\nThey'll say, well that's between you and him.\\nBut they might tell you so I would go to HR.\\n\\nBut the other option is to say to your boss,\\nI want to have a meeting with you and HR\\nand can we both sit down and sort this out.\\nSo ask to have a meeting with all the parties.\\nNow it may not be HR, your boss may be saying\\nthat their boss has to approve it\\nand their boss hasn't signed the form yet.\\nIn which case you could say, well can I have a meeting\\nwith you and your boss.\\nCan the three of us sit down and talk about it?\\n'Cause then you can find out what's really going on.\\nIt's gonna be a bit scary\\nbut you have to get to the bottom of whether it's\\njust your boss who hasn't even passed the forms on\\nor whether it really is an organizational problem\\nand your boss is just failing to fight\\nto your corner for you.\\n\\nSo because we're prepared to leave over this\\nwe can have no fear and we mustn't,\\nwe have to get to the bottom of that one.\\nStill use the four step process of course.\\nYou can still say, you know it's difficult\\nbut you're upset and all the stuff that we did before.\\nSo if they're lying to you have a meeting\\nwith all of the parties.\\nIt's the only way.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794631\",\"duration\":260,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"They never say thank you\",\"fileName\":\"779743_02_18_LA25_Never_Thanks\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":54913800,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Now the next type of boss is the\\nboss who never thanks you.\\nNow this is not quite the same as the\\nboss who criticizes you all the time.\\nThey do go together quite often but I had a boss once\\nwho never thanked me he didn't criticize me either,\\nhe was great and he didn't ignore me.\\nI mean, we used to talk about all sorts of stuff\\nwe used to jointly plan big things together.\\nIt was great.\\nIt's just the one thing he never did was thank me.\\nThat was quite weird really and in fact I decided to\\nask him whether I was doing okay.\\n\\nI decided to retrain him and get him to thank me.\\nAnd we've already talked about retraining your boss.\\nSo what I did I said to him, \\\"By the way,\\nhow's it all going generally with me.\\nAre you happy with the job I'm doing?\\\"\\nAnd he said, \\\"Of course yeah.\\\"\\nAnd I said, \\\"Good, that's alright then.\\\"\\nAnd he said, \\\"Well, why'd you ask?\\\"\\nAnd I said, \\\"Well you know, I think I'm doing a good job\\nbut I don't know what you think. I mean, the numbers\\nseem fine but I don't know whether you're\\nhappy or not unless you tell me.\\\"\\nAnd he said, \\\"So I need to tell you that I'm\\nhappy with you. With your job. The job you're doing\\\"\\nAnd I said, \\\"Well yeah it would be nice\\nto know that you're happy.\\\"\\nAnd he said, \\\"But you don't seem like\\na sort of insecure person.\\\"\\nAnd I said, \\\"Well no I'm pretty sure I'm doing a good job\\nbut I don't know what you think and it would be nice to\\nhear it occasionally, that's all.\\\"\\nAnd he went, \\\"Well alright then.\\\"\\nSort of looked at me weirdly but it was fine we knew\\neach other well enough to say that a bit of feedback\\nwould be nice occasionally.\\n\\nAnd I remember then what happened about a week later\\nwe were at a meeting so I was the production guy but\\nwe had finance, marketing, and HR and sales I think\\nand we were looking at how the company was doing\\nand the boss went round and he said,\\n\\\"Sales are slightly up this month, that's good.\\nThe factory has had another good month.\\\"\\nAnd I went (clears throat)\\nAnd he went, \\\"Oh yeah. So well done Chris.\\\"\\nAnd everybody is going, \\\"Uhhh yeeee.\\\" And all that\\nAnd then the next month he said,\\n\\\"Th factory has done well, waste is down\\\"\\nAnd I was going (clears throat)\\nAnd he went, \\\"Oh yes, well done Chris.\\\"\\nAnd everyone else is all going (Gags) like that\\nBut the point was that after a while I didn't\\nhave to prompt it and he did actually say\\nwell done Chris. Another good week.\\n\\nActually the annoying thing was that he started\\nto thank everybody else as well.\\nIt wasn't just me that benefited from all the pain\\nand suffering that I had to go through\\nto train him to thank me.\\nNow was it worth the pain and suffering and the\\nembarrassment in front of everybody else to get my\\nboss to thank me? The answer is yes I think it was\\nbecause all I had to do was hassle him a few times\\nand after a while it became a habit and he thanked\\nme every time and that was fine.\\nSo I think it was worth it.\\nIf I was forcing him to say something he didn't\\nreally believe then that would be worthless.\\n\\nBut if I'm getting him to say what he does actually\\nthink which is that I'm doing a good job then I\\nthink that's quite valuable.\\nSo I think retraining your boss using repetition is\\nworth it and I think it can work really well\\neven for a boss who doesn't thank you.\\nBut the final last thought about the never getting\\nany thanks is that if you can make your job measurable,\\nif you can have facts like waste percentage or output,\\nor sales, or whatever, or lead time then you don't\\nneed thanks because you've got proof that you've\\nimproved and also it's easier to get thanks\\nbecause you say to the boss,\\n\\\"These figures are looking good, aren't they?\\\"\\nand the boss will go, \\\"Yeah. Yeah they\\nare good, aren't they? Yeah, well done.\\\"\\nSo if you can manage to make it measurable\\nit's much easier to get thanks.\\n\\nIf your job is just a sort of matter of opinion,\\nsuppose you're just a designer say.\\nI say just, I mean I've got loads of admiration\\nfor designers but suppose you're a designer and\\nyou can't really measure how good your designs are\\nthen I think it's much more difficult to get your\\nboss to thank you but you can still say,\\n\\\"I think it's worked out rather well. What do you think?\\\"\\nAnd hope they don't go, \\\"I don't like it.\\\" (laughs)\\nSo I think you can ask for thanks and you can train\\nyour boss and if you can make it measurable\\nthat makes it even easier.\\n\\nBut don't put up with a world of not being thanked\\nbecause it's quite soul destroying in the end, you know?\\nYou've got to do something about it.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794632\",\"duration\":128,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"My boss always takes the credit\",\"fileName\":\"779743_02_19_LA25_Glory_thief\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":27433181,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Finally I've got one of the most annoying boss behaviors\\nof all and it's quite common as well,\\nwhich is bosses who take all the credit for your work.\\nThey don't give you any of the credit for what you've done.\\nVery irritating.\\nYou could see why they would do it of course,\\nespecially if they feel a bit insecure.\\nBut it's an awful habit really\\nto try to take the credit for your people.\\nI do always wonder whether their bosses are\\nstupid enough to believe that that boss did all the work\\nbut they might be.\\nSo anyway, what do we do about this?\\nAnd I think the first thing is\\nto not give them all the information.\\n\\nSomebody says, how did you do it,\\nthey can go, well I don't quite know how I did it.\\nSo give them some but not all of the information.\\nSo they're informed, 'cause you know they've got\\nto be kept informed, but they can't claim\\nthat they actually did it.\\nAnd if they ask you for all of the information\\nabout how you did it, play for time.\\nJust say, oh it's all a bit complicated\\nor I just did a bit of stuff on the computer.\\nDon't give them all the information.\\nSo that's the first tactic you've got.\\nThe next tactic is to publicize the results\\nduring the job.\\n\\nSo that as each step is done you publicize\\nthat you've done it and you get the credit.\\nAnd then immediately afterwards make sure you immediately\\nget the credit.\\nOr we just managed to make this product perfectly\\nin a very short time or whatever it is.\\nSo during and immediately afterwards publicize it,\\nget in first basically,\\nso everybody can see that it's coming from you.\\nAnd then later on when the boss says look what I did\\neveryone's gonna think, I'm sure I remember Chris talking\\nabout that last week.\\n\\nSo that's the second idea really.\\nThe third one is something we've talked about before\\nwhich is to make things measurable and have facts.\\nBecause if you've got measurable proof for what you've done\\nthen it's very difficult for your boss\\nto take the credit from you.\\nSo those are my three tactics.\\nParticularly don't give them all of the information\\nand publicize your results during the project\\nand immediately after it finishes.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:794633\",\"duration\":149,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Example: No idea where to start\",\"fileName\":\"779743_02_20_LA25_Example_Just_Ask\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":31795371,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- When I worked for the business school\\nat Bournemouth University,\\nI was really enjoying the lecturing,\\nand that was all great.\\nAnd I had a boss, a very nice boss, actually,\\nwho asked me at my appraisal\\nif I would improve links with French universities.\\nAnd I remember thinking, \\\"I have no idea how you do that.\\\"\\nAnd I was sort of a bit anxious\\nabout the idea of phoning up French universities,\\nprobably trying to speak French.\\nAnd so I just thought, I said to him,\\n\\\"Yes, yes, I'll do that,\\\"\\nand then I just didn't do it.\\nAnd I just hoped he would forget.\\n\\nAnd I remember passing him in the corridor a few times,\\nand thinking, \\\"Oh, don't ask about the universities,\\\"\\nand he didn't, so that was great.\\nI thought I'd got away with it.\\nIn fact, my appraisal a year later came and went.\\nThere was no mention of improving links\\nwith French universities.\\nAnd then suddenly, after about a year and a half,\\nhe said to me, \\\"Did you ever do\\n\\\"the links with the French universities, Chris?\\\"\\nAnd I went, \\\"Oh, no, I didn't.\\\"\\nAnd he said, \\\"Oh, well, don't worry about it.\\\"\\nAnd it sort of got forgotten.\\nAnd I was thinking back about that\\nand what should I have done?\\nBy the way, I was also thinking that I should have done it.\\n\\n'Cause it woulda been great,\\nI coulda just gone to France and a whole load of jollies\\nand had meetings with various people,\\nand taken 'em out to lunch and said I was improving links.\\nAnd, looking back, I really shoulda done it.\\nBut, if you're given something that you\\ndon't know how to do, that's just too hard,\\nthe answer is, tell them.\\nDon't just hope it goes away, hope they forget.\\nI shoulda just said to him, \\\"I would love to do that,\\n\\\"but I don't know how.\\n\\\"Will you coach me, will you give me some help?\\\"\\nAnd he was a really nice boss.\\nObviously, to him, it was easy,\\nso he just assumed that anyone would know how to do it.\\n\\nSo, if I'd said to him, \\\"I need a bit of help,\\\"\\nhe'd have said, \\\"Yeah, no problem.\\n\\\"Here's the first thing to do,\\n\\\"come back when you've done that and we'll do the second,\\\"\\n\\\"or I'll come with you.\\\"\\nPerhaps we would have both gone over to France.\\nIt woulda been great.\\nSo I think, looking back,\\nI was really stupid about that one,\\nand, I mean, was he a bad boss, or was I just useless?\\nI think he was a bad boss, in a way,\\nbecause he didn't check that I understood it.\\nHe didn't say, \\\"So, you know what you'll do, do you?\\\"\\nOr, \\\"What's gonna be the first step of your plan?\\\"\\nIf he'd sniffed any slight hesitation in me,\\nhe should've probed a bit more and said,\\n\\\"Are you gonna do it?\\\"\\nBut, still, what I'm really saying is,\\nif you do get a boss who asks you to do something\\nthat you don't know how, you must say so.\\n\\nAsk for coaching.\\nBosses are quite happy to give you coaching.\\nIt will be fine, they won't judge you on that.\\n\\n\"}],\"name\":\"2. Sixteen Terrible Bosses and How to Handle Them\",\"size\":922822539,\"urn\":\"urn:li:learningContentChapter:794613\"},{\"duration\":167,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:794635\",\"duration\":167,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Wrap up\",\"fileName\":\"779743_03_01_LA25_Course_Wrap_Up\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":35657515,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- So that's it.\\nYou've finished my course\\non how to deal with a difficult boss.\\nI really hope that I managed to identify\\nyour boss's behavior as one of the 16 things\\nI've come up with, or a combination of the 16 perhaps.\\nI've had bosses who've done about 10 of those.\\nSo good luck with dealing with the bosses.\\nWe've got to fight back against bad bosses.\\nRemember that often it's not their fault.\\nThey've never been trained.\\nThey're just trying to be a boss.\\nThey don't really know.\\nAnd remember to be diplomatic,\\nbecause they do have the ability to fire you.\\n\\nSo if in doubt, use my four-step process of\\nI do understand how hard it is, but I feel a bit this.\\nIs there any chance you could change?\\nWould that be possible?\\nSo keep it kind of gentle.\\nAnd I would also say, plan how you're gonna say it.\\nSo before you confront the boss,\\njust have a little think of how you're gonna word it,\\nand then take the plunge and do it.\\nYou could even force yourself to do it by booking a meeting\\nand saying are you free today, I don't know, maybe two p.m.?\\nI wanna come and ask you about something.\\n\\nThat's what bosses always do to us, isn't it?\\nCome and see me at two p.m.\\nAnd then let you sweat.\\nSo why don't you book an appointment?\\nAnd then you've got to go through with it.\\nAnd you got all morning to plan it,\\nyou can even try it out on a colleague or something.\\nOr try it out on your dog or something.\\nYou don't involve me enough in your decisions,\\nyou can say.\\nSo practice the wording and then go in and do it.\\nTake the plunge and do it.\\nDo it today, because the longer you leave it,\\nthe worse it is.\\nYou're spending five days a week on your job,\\nand if you don't enjoy it because of a boss,\\nsomething's got to change.\\n\\nAnd finally, completely free,\\nwhy not sign up for my tip of the month?\\nI send out a free email to everyone on my list\\nonce a month.\\nSo I do spend quite a lot of effort writing it\\n'cause it goes to 20,000 people.\\nIf I discover anything good in the world of management,\\nI put it into my tips and I send them out.\\nYou can always unsubscribe if you don't like it,\\nbut people always seem to love it.\\nI get very few people unsubscribing.\\n\\nSo all you do, you just go to free-management-tips.co.uk\\nwith hyphens in, you can see the link.\\nFree-management-tips.co.uk.\\nPut in your email address and my management tips\\nwill come into your inbox every now and then.\\nPerhaps when you're having a dark day\\nand your boss is really on top of you,\\none of my little tips will come in to cheer you up.\\nIt's a way of keeping in contact.\\nAnd feel free to reply to the tips, as well.\\nIt's great to know that you're out there\\nand you're receiving them.\\nSo that's it really, the tip of the month.\\n\\nPlease do leave a review if you could.\\nI'd be most grateful.\\nAnd I hope to see you again\\non another one of my courses very soon.\\nBye for now.\\n\\n\"}],\"name\":\"Conclusion\",\"size\":35657515,\"urn\":\"urn:li:learningContentChapter:794634\"}],\"size\":0,\"duration\":4746,\"zeroBased\":false},{\"course_title\":\"Quick Scripts for Difficult Conversations\",\"course_admin_id\":4358388,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4358388,\"Project ID\":null,\"Course Name\":\"Quick Scripts for Difficult Conversations\",\"Course Name EN\":\"Quick Scripts for Difficult Conversations\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Professionals often want to have the hard conversations, but they may stumble over the actual words they should use. In this course, executive coach and leadership development expert Alisa Cohn presents scripts that you can use in the most common, most delicate, and most difficult workplace scenarios. Practice how to terminate someone, as well as the conversation to have before you terminate someone. Learn how to lay someone off with compassion. Explore scripts for positive feedback and for direct, diplomatic, difficult feedback. Rehearse ways to hold someone accountable without making them feel bad, then dive into scripts such as telling someone you\u00e2\u20ac\u2122re putting a new leader over them, handling it when an employee gets defensive or starts to cry, and telling someone they didn\u00e2\u20ac\u2122t get the promotion without demotivating them. Go into delicate conversations well-prepared to say exactly what you need to say, in the best ways possible.\",\"Course Short Description\":\"Learn clear scripts to help you communicate what you need to say in difficult workplace conversations.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20545001,\"Instructor Name\":\"Alisa Cohn\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Executive Coach and Leadership Development Expert\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2022-12-19T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/quick-scripts-for-difficult-conversations,https://www.linkedin.com/learning/quick-scripts-for-difficult-conversations-high-visibility\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"Manager\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Business\",\"Internal Subject\":\"General Skills\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":1038.0,\"Visible Video Count\":10.0,\"Contract Type\":\"STANDARD\"},\"sections\":[{\"duration\":48,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4378202\",\"duration\":49,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Scripts to make hard conversations easier\",\"fileName\":\"4358388_en_US_00_01_WL30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Professionals often want to have the hard conversations, but what gets in the way is uncertainty over the actual words they should use. This course covers scripts that you can use in the most common, most delicate, and most difficult workplace scenarios.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8736611,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Firing someone.  \\n Difficult feedback.  \\n Handling employees' tears.  \\n Your job as a manager can be pretty tough,  \\n and sometimes you wish you had a playbook of scripts  \\n so you'd know what to say.  \\n Well, here you go.  \\n My name is Alisa Cohn.  \\n I'm an executive coach,  \\n and the author of \\\"From Start-up to Grown-up,\\\"  \\n a book about growing as a leader.  \\n Part of your growth as a leader  \\n is learning how to have tough conversations with ease.  \\n These quick scripts will help you do just that.  \\n We're going to cover nine topics that can be hard to navigate,  \\n and that you'll definitely encounter  \\n in your role as a manager.  \\n You may not look forward to this part of your job,  \\n but at least you'll have a starting point.  \\n So hang on to your hat, and join me  \\n for some quick scripts for difficult conversations.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":9271641,\"urn\":\"urn:li:learningContentChapter:4382184\"},{\"duration\":328,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4380225\",\"duration\":93,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script to terminate someone\",\"fileName\":\"4358388_en_US_01_01_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Terminating someone is the mother of all difficult conversations, and the most requested by many clients. Learn a script to guide you through the process you should undertake before terminating someone, and the actual words to use.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4001483,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Okay, we're going to dive right  \\n into the deep end to start this course.  \\n How to terminate someone.  \\n This is the hardest thing to do for almost everyone.  \\n Most people get nervous.  \\n They don't say enough or they say too much,  \\n so it's the most important one  \\n to have a strong talk track for.  \\n Here we go.  \\n All right, Jeremiah, I need to tell you I'm terminating you  \\n and that today is your last day.  \\n We've had a number of conversations  \\n about the way I needed your work to improve,  \\n and I'm sorry I haven't seen the improvements  \\n we talked about.  \\n I've asked you to make sure I'm updated  \\n on all your projects proactively,  \\n and I regularly have to chase you down.  \\n I've asked you to clarify for your team their top goals  \\n and they still come to me for a direction,  \\n and your team hasn't achieved its goals  \\n for multiple quarters.  \\n I've decided to make a change.  \\n So after you say all this, someone,  \\n either you or your HR team, have to handle the details.  \\n When will his last day be?  \\n What will you give him  \\n in terms of severance or vesting of stock?  \\n What are the details of his insurance?  \\n How will you break the news to his coworkers?  \\n And will you be a reference for him in the future?  \\n Think through the logistics of this or find out  \\n how your HR team handles these details  \\n so you're ready to answer questions.  \\n You can end the conversation by simply saying,  \\n \\\"Thank you for the contributions you've made  \\n while you were here, and I wish you well.\\\"  \\n Let's face it, firing someone is really hard.  \\n Use this script to give you more confidence  \\n and comfort in what you sometimes have to do as a manager.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4379334\",\"duration\":115,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script of the conversation before you terminate someone\",\"fileName\":\"4358388_en_US_01_02_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Sometimes managers shy away from firing someone because they weren't sure they were clear about the improvements the employee needed to make. Explore the discussion you should have with your employees to make sure you're clearly understood.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4286195,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Okay, how that we have the termination conversation  \\n out of the way, let's move a step back in time.  \\n I want to talk about the conversation you should have  \\n before you terminate someone.  \\n Often managers are reluctant to fire someone  \\n since they're just not positive they were super clear  \\n with the gravity of the situation.  \\n To make sure that you're positive,  \\n that you're a hundred percent sure  \\n that you told your employee what you needed her change,  \\n here's the conversation to have before you terminate her.  \\n Simone, I want to have a serious conversation with you.  \\n I've given you some feedback a few times  \\n and I want to make sure we're both crystal clear  \\n about my concerns and about how you need to improve.  \\n Your key metrics have been down for the past few quarters,  \\n and I need to see this trend reversing.  \\n I need you to work with your team  \\n to make sure they're working on the right things  \\n to increase the key metrics across the board  \\n And I want to be super clear  \\n that you need to do this in a way  \\n that doesn't stress everyone out or burn everyone out.  \\n Working everyone harder  \\n is not the sustainable way to solve this problem.  \\n I also need to be much more responsive to your peers.  \\n They come to me to ask me the status of the projects  \\n they need you to complete  \\n and I need you to set expectations with your peers  \\n and then update them proactively  \\n so they can do their planning as well.  \\n I'm happy to brainstorm ways with you  \\n to fix all these things, and I want to help.  \\n But ultimately I need you to take full ownership  \\n of these areas and fix them in the next two months.  \\n If you don't do that, then I'm sorry,  \\n our next conversation will be about moving you  \\n out of the business.  \\n We can talk about this some more later,  \\n and I certainly want to know what help you need from me.  \\n This is super direct, right?  \\n I think you need to be direct  \\n to make sure you land your point  \\n and to make sure you have no doubt  \\n or even wiggle room for yourself.  \\n Make sure your tone is neutral and not aggressive,  \\n and be ready to answer questions and talk it through.  \\n That way you'll know you've done everything you can  \\n to let your employee know where they stand.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4380226\",\"duration\":120,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script to lay someone off with compassion\",\"fileName\":\"4358388_en_US_01_03_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Laying someone off may make perfect business sense, but it's very hard emotionally on the employee being laid off, and it can also be hard on you as  the manager. Learn a script to help you prepare for and navigate the layoff conversation in a compassionate and clear way. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4850292,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - What's worse than firing someone?  \\n Laying someone off.  \\n That person didn't do anything wrong,  \\n but the business conditions require some cuts  \\n and the employees you're laying off  \\n are the ones who are impacted.  \\n So when you're telling someone you're laying them off,  \\n you need to be clear and compassionate.  \\n You also need to get the details together.  \\n Before you get into the discussion,  \\n make sure you can explain the timeline  \\n be ready to explain what comes next,  \\n what kind of support they'll get,  \\n and how they'll continue with their insurance and so on.  \\n So here's how this should go.  \\n I'm sorry to let you know  \\n that your job is being eliminated and you're being laid off.  \\n I'm going to give you the details of what's going to happen next,  \\n but I want to start by saying you're terrific professional  \\n and this is not about your performance at all.  \\n The company has not performed as well  \\n as any of us wanted to and, as a result,  \\n every group has had to take a hard look at costs  \\n and make cuts to help us be sustainable as a company.  \\n We're cutting 5% of our group here,  \\n and I'm sorry that you are one  \\n of the people we have to say goodbye to.  \\n I want you to know that I appreciate very much all  \\n of the contributions you've made over the years,  \\n as well as getting to know you personally.  \\n I'll do anything I can to help you get a new job,  \\n and of course I'll serve as a reference for you.  \\n Now, let me tell you the details of severance  \\n and health insurance,  \\n and then we can talk some more after you've had time  \\n to process all this, if you want to.  \\n Oh, if you have an HR partner,  \\n have them sit in with you  \\n and rehearse the conversation with them beforehand.  \\n They may also take over the heavy lifting for you,  \\n or at least share the messaging responsibility.  \\n Remember, the goal is to be compassionate but also clear.  \\n Don't be so soft that you leave some wiggle room,  \\n like maybe you'll change your mind,  \\n and don't badmouth the company  \\n and the decisions that get made higher up in corporate.  \\n You may yourself be frustrated,  \\n but you have to really focus on what's going to be most helpful  \\n for the person you're laying off.  \\n The way to do that is to stick to the facts  \\n and reassure them that they'll be well treated.  \\n \\n\\n\"}],\"name\":\"1. Scripts for Parting Ways\",\"size\":15108075,\"urn\":\"urn:li:learningContentChapter:4380230\"},{\"duration\":334,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4377367\",\"duration\":120,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script for positive feedback\",\"fileName\":\"4358388_en_US_02_01_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"On the whole managers don't give a lot of positive feedback, and sometimes that's because they're embarrassed or don't know what to say. After watching this video, you'll know when to give positive feedback and the words to use to make it impactful.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4761099,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A long time ago,  \\n I was facilitating a manager training session,  \\n and one of the participants said,  \\n \\\"I prefer negative feedback to positive feedback.\\\"  \\n \\\"Why?\\\" I asked her.  \\n \\\"Because it's so much more helpful.  \\n When someone tells me, 'Good job.'  \\n I don't know what I did a good job at.\\\"  \\n Unfortunately, that's common.  \\n You want to be a great boss, you want to give positive feedback.  \\n This may sound strange,  \\n but a lot of people need to learn  \\n how to give positive feedback so it sticks.  \\n And if you're the kind of manager  \\n who forgets to give positive feedback  \\n because you're trying to put out fires,  \\n getting a few scripts for the task  \\n will help you remember to do it.  \\n So I'm going to do a few quick scripts for you.  \\n The first one is super simple.  \\n \\\"Hey Mariana, great job getting all the data cleaned up  \\n in our system.  \\n This was a project that took a combination  \\n of high level strategy  \\n and the ability to grind out some hard work,  \\n and you did both seamlessly and cheerfully.  \\n I appreciate the way you organized yourself,  \\n worked with your colleagues,  \\n and kept me updated and even cracked a joke or two.\\\"  \\n Here's another one.  \\n \\\"Hey, Todd, I know you've had delays  \\n on the project you're working on.  \\n I'm sure it's frustrating to you.  \\n But I want you to know I see you working  \\n and putting in all the fires that keep getting lit.  \\n You're doing a great job keeping calm in this crisis  \\n and keeping your team focused.  \\n Even though you're running into issues,  \\n I appreciate how much ownership you're taking.  \\n Keep it up and you'll get to the finish line.\\\"  \\n And this last one is more positive attention  \\n rather than positive feedback.  \\n Also an important skill for a manager.  \\n This one showcases that you see your employee,  \\n that they're important to you,  \\n and that you notice how they show up.  \\n \\\"Naomi, I've noticed you rather quiet in meetings  \\n in our one-on-ones lately.  \\n I thought maybe I'd just check in to see how you're doing  \\n and see if there's anything you want to talk about.  \\n My door is always open.\\\"  \\n All of these scripts help you signal to your employees  \\n that you notice their good qualities  \\n and help them see both that you care about them  \\n and appreciate their efforts.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4380227\",\"duration\":129,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script for direct, diplomatic, difficult feedback\",\"fileName\":\"4358388_en_US_02_02_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Giving difficult feedback is often challenging for managers, especially if they're frustrated with their employees and they don't really know what to say. Learn a script to handle your own emotions, plan for the conversation, and deliver the feedback in a way which is direct and diplomatic.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6453652,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When I meet with a leader  \\n and they're complaining about their employee,  \\n which does happen sometimes,  \\n I always ask, \\\"Have you told them this?\\\"  \\n Most often the answer is either,  \\n \\\"I'm going to tell 'em the next performance review,\\\"  \\n which you know, is like eight months away.  \\n Or they'll say, \\\"Well, sort of,\\\"  \\n and they make this hand motion.  \\n When I probe a bit,  \\n it turns out this typically means no.  \\n Giving difficult feedback is uncomfortable,  \\n but it's also part of your job as a manager.  \\n Let's try to make it easier by giving you a few scripts.  \\n Start by getting the goal of the conversation  \\n in your head to change behavior,  \\n not to vent your frustration,  \\n and not to make them feel bad.  \\n Then keep your tone under control.  \\n You can say, \\\"There's something I want to address with you.  \\n Is now a good time?\\\"  \\n Hopefully they'll say yes  \\n since you're all ready to go.  \\n This conversation will really go better  \\n if they're in a reasonably open mental space.  \\n So assuming now is a good time.  \\n I've been noticing that when you commit to a due date  \\n about a project, you end up delivering it late,  \\n and then you don't tell me and the rest of the team.  \\n That happened during Project X and Project Y and project Z,  \\n to name a few times.  \\n The impact is that we're all expecting you  \\n to deliver your part and then we have to scramble  \\n and we don't get your peace and time.  \\n What I'd like you to do is to make sure you're realistic  \\n with the dates you commit to  \\n and then organize yourself and your team to hit these dates.  \\n If there's some times when you can't hit these dates,  \\n and I'd like those to be rare,  \\n I need you to let everyone know  \\n with plenty of time to adjust.  \\n Now, I'd love to hear from you.  \\n Can you see what I'm talking about?  \\n So after that, there may be some discussion  \\n and your employee may need help.  \\n So figure out how to help,  \\n whether it's coaching from you or someone else,  \\n or training or something else.  \\n And it's super important  \\n to end with a very clear understanding of next steps.  \\n Remember to ask them specifically,  \\n \\\"So what are you going to do now?\\\"  \\n Remember, your job is to help them be successful,  \\n and giving them direct  \\n and diplomatic feedback helps you accomplish just that.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4380228\",\"duration\":85,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script to hold someone accountable\",\"fileName\":\"4358388_en_US_02_03_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Managers know they should hold their employees accountable but they often don't know what tools are available for them. After watching this video, you will know what to say and how to say it to hold your employees accountable without making them feel bad.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3532789,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When I talk with leaders  \\n about holding their employees accountable,  \\n what I often get is, \\\"What, I'm supposed to fire them  \\n for not getting their time sheets in on time?\\\"  \\n No, that is not what accountability is.  \\n Accountability is just having clear conversations  \\n when your employees miss expectations,  \\n and helping them increase their level of ownership.  \\n Remember that you're trying to hold them accountable  \\n without making them feel bad.  \\n So tone matters.  \\n Think even-keeled, not nasty.  \\n More curious than furious.  \\n So here's your script.  \\n I want to talk with you about what I'm seeing from your team.  \\n What I see from your metrics is that the productivity  \\n of your team overall is going down.  \\n I'm also hearing from a few of your peers  \\n that your team is being kind of grouchy with their team.  \\n So I want to check in with you to make sure you know this,.  \\n And I want to talk with you about what's going on,  \\n and how you're planning to fix it.  \\n I'm here to help you, but I want to make sure we're clear  \\n that you and your team own their performance.  \\n What are your thoughts about what's going on right now,  \\n and what ideas do you have to make progress?  \\n That's a good start.  \\n You'll certainly have a discussion,  \\n and hopefully, come to some agreements.  \\n Remember to make sure your employee tells you very clearly  \\n what their next steps are.  \\n You'll probably need to have a follow-up conversation  \\n to check in on their progress,  \\n and continue to showcase  \\n if they need to own their area, and be accountable for it.  \\n This structure will help you clarify that,  \\n and stay consistent.  \\n \\n\\n\"}],\"name\":\"2. Scripts to Give Feedback\",\"size\":16174349,\"urn\":\"urn:li:learningContentChapter:4375208\"},{\"duration\":327,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4378203\",\"duration\":97,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script to tell someone they'll have a new boss\",\"fileName\":\"4358388_en_US_03_01_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"When a department needs a new leader so that an existing employee will no longer report to you, it can feel awkward to have that discussion with your employee. After watching this video, you'll identify the words to use to explain to an employee why they're getting layered. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4052054,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - There's something in corporate America called layering.  \\n That means that you put a new manager  \\n on top of an existing employee,  \\n and that employee now reports to them instead of you.  \\n The reason you layer someone  \\n is often because they help the department  \\n get bigger or more successful.  \\n But they aren't equipped to handle  \\n the new responsibilities  \\n of a bigger, more complex department.  \\n So this should be a good thing.  \\n We're successful, and we have  \\n a more experienced leader coming in.  \\n But most often, the person getting layered  \\n feels upset and resentful.  \\n They feel they're getting demoted.  \\n So the way you frame this is important.  \\n Here's a script you can use.  \\n Gabriel, I wanted to let you know  \\n I'm bringing a new leader into this department  \\n that you'll start reporting to.  \\n I'm doing this because you've been a terrific leader  \\n who's gotten us to the stage.  \\n And, for the challenges ahead,  \\n we're going to need a leader who's seen these stages before  \\n and can guide us in the direction we need to move to.  \\n I want you to know that it's important to me  \\n that the person we hire is a strong people leader.  \\n I'll expect this person to help you build your skills  \\n so that you'll be able to grow  \\n and ultimately take a bigger role for yourself,  \\n either here or somewhere else.  \\n Now I want to know how you feel  \\n about this and what questions you have.  \\n Remember, on this one, your person  \\n probably did a great job for a while.  \\n And it's jarring to feel like you're losing ground  \\n in your career, whether it's true or not.  \\n So have some compassion.  \\n Also, at some point around this time period,  \\n have a heart to heart to share how  \\n you understand your employee's development needs.  \\n And help them put together a development plan.  \\n Good employees want to grow, and this is  \\n a great time to proactively coach them,  \\n to help them advance their career.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4376181\",\"duration\":147,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script for when an employee cries or gets defensive\",\"fileName\":\"4358388_en_US_03_02_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"When an employee gets defensive or starts to cry, managers may be taken aback and not know what to do. Discover how to handle these difficult employee reactions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7251044,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - You're doing the best you can  \\n to be a great manager, to give timely feedback,  \\n to help your employees grow.  \\n And you're rewarded with an employee  \\n who gets defensive, maybe even attacking,  \\n or an employee where you can't even a conversation  \\n because they get teary.  \\n It's hard to handle that because,  \\n soon as the other person starts getting defensive,  \\n you start getting defensive.  \\n So let me give you another way.  \\n First of all, once you figure out  \\n that someone has a tendency to get defensive  \\n or teary, prepare for it.  \\n Assume it's going to happen so you won't be surprised.  \\n And stay even keeled yourself.  \\n Don't start getting defensive yourself.  \\n For someone getting defensive,  \\n you can say, \\\"I can see you're getting upset.  \\n The last thing I want to do is upset you.  \\n That's not my intention at all.  \\n We do need to be able to have conversations  \\n about my expectations for you,  \\n including when I need you to make changes,  \\n and I'm hoping we can do that in a constructive way  \\n where we both exchange ideas.  \\n So first of all, can you articulate why you're upset?\\\"  \\n And then you listen to them, if they can articulate it.  \\n Then after you've talked it out a bit,  \\n you can say, \\\"Thanks for sharing that.  \\n What are your thoughts about how to make sure  \\n we're able to have constructive conversations  \\n without your getting so upset?  \\n What do you think it'll take from me?  \\n And what do you think it'll take from you?\\\"  \\n And then listen.  \\n Now, pro-tip on this.  \\n Remember, this may happen over a series of conversations.  \\n Sometimes when someone's defensive  \\n and flustered and hot and bothered,  \\n they may not be able to calm down.  \\n That's understandable.  \\n In that case, you can say,  \\n \\\"How about if we table this discussion for now  \\n and come back to it in a day or two  \\n There's nothing wrong with giving both of you a timeout.  \\n Now, if someone gets teary,  \\n not only are they emotional,  \\n but they're also probably embarrassed.  \\n But don't freak out.  \\n You can just say, \\\"I can see you're getting upset  \\n and it's not my intention to upset you.  \\n Do you need a minute?\\\"  \\n If they need a minute, give them a minute.  \\n You can sit together in silence  \\n or you can step out of the room for a moment.  \\n You can also suggest  \\n you pick up the conversation another time  \\n by saying, \\\"Listen, I really don't mean to upset you,  \\n and I can understand if you'd prefer  \\n to talk about this another day.  \\n We do need to talk about it at some point.  \\n Should we get together again tomorrow and pick it up then?\\\"  \\n Dealing with people's emotions at work  \\n is actually part of the job as a manager.  \\n I hope these scripts will help you  \\n handle these situations with grace.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4380229\",\"duration\":83,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Script for when someone didn't get the promotion\",\"fileName\":\"4358388_en_US_03_03_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are times when a good employee goes for a promotion they're just not ready for. After watching this video, you'll know what to say to this employee and how to help them with next steps so they continue to stay motivated.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3777975,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - I personally applaud employees  \\n who go for it when it comes to promotions.  \\n But if they don't get that promotion,  \\n you need to have a delicate conversation with 'em  \\n to break the news and help them continue  \\n to feel motivated despite this blow.  \\n Here's how to approach this.  \\n You could say, \\\"Tricia, I have some bad news for you.  \\n \\\"I'm sorry to tell you didn't get the promotion.  \\n \\\"Everyone you interviewed with thinks you're amazing,  \\n \\\"and we all loved your energy.  \\n \\\"You also had some great accomplishments  \\n \\\"since you were the driving force  \\n \\\"to get the X Project back on track.  \\n \\\"We all admire you and the work you do.  \\n \\\"Ultimately we felt we needed someone  \\n \\\"who had more experience managing people  \\n \\\"as well as specific expertise in social media marketing.  \\n \\\"You've done a great job with that in the past year,  \\n \\\"but there's nothing like a decade of experience.  \\n \\\"I know you're disappointed, but I want you to know  \\n \\\"that you have a terrific future in store for you here.  \\n \\\"I'd like to find some time in the next few weeks  \\n \\\"to have a career conversation with you  \\n \\\"and help you create a development plan  \\n \\\"so you can build your career in the direction you want to.\\\"  \\n Then make sure you do that.  \\n When employees go for promotions they're not ready for,  \\n it's important to acknowledge their ambition  \\n and also help nurture them.  \\n When they don't get the promotion,  \\n giving this positive reinforcement  \\n and tangible help will go a long way  \\n towards making sure they stay motivated and engaged.  \\n \\n\\n\"}],\"name\":\"3. Scripts for Delicate Conversations\",\"size\":15904098,\"urn\":\"urn:li:learningContentChapter:4380231\"}],\"size\":56458163,\"duration\":1037,\"zeroBased\":false},{\"course_title\":\"Managing Misconduct in the Workplace\",\"course_admin_id\":2823547,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2823547,\"Project ID\":null,\"Course Name\":\"Managing Misconduct in the Workplace\",\"Course Name EN\":\"Managing Misconduct in the Workplace\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Confronting misconduct in the workplace is challenging enough. Ensuring that the process for managing misconduct and disciplinary actions adheres to CIPD guidelines and UK employment law adds another level of complexity. In this course, instructor Andrea Vogel equips HR professionals with the skills they need to support line managers and their organization in addressing misconduct in a non-emotional, fair, and objective fashion. Andrea shares the informal actions you can take before moving to a more formal disciplinary process, including how to address misconduct during an employee's annual review. Then, she details how to deal with misconduct using a formal disciplinary process, explaining how to evaluate the allegations, set up a disciplinary hearing, and separate facts from emotion before taking action. Plus, learn how to set up and conduct a fair appeal hearing for employees who wish to revisit the disciplinary actions they received.\",\"Course Short Description\":\"Learn how to fairly and objectively address workplace misconduct by leveraging strategies that adhere to CIPD guidelines and UK employment law.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20516026,\"Instructor Name\":\"Andrea  Vogel\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Head of People and Chartered FCIPD\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2020-04-28T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/managing-misconduct-in-the-workplace,https://www.linkedin.com/learning/managing-misconduct-in-the-workplace-uk\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Business\",\"Internal Subject\":\"HR\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":1634.0,\"Visible Video Count\":11.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2304468\",\"duration\":84,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Managing misconduct\",\"fileName\":\"2823547_00_01_WL30_Welcome\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Defining misconduct for your organisation increases your ability to support line managers in addressing inappropriate behaviour. In this video, learn about how to articulate what constitutes misconduct in your organization.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16362330,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Most managers and HR professionals will try to avoid  \\n managing misconduct in the workplace  \\n because most of us don't like having difficult conversations  \\n with people that we have a relationship with.  \\n Misconduct in the workplace can have a negative impact  \\n on the company culture and employee well-being.  \\n Some of the impacts include poor morale,  \\n stress related absenteeism, and reduced productivity.  \\n You can simplify this challenge by looking at managing  \\n misconduct as a non-emotional process with clearly defined  \\n steps to follow.  \\n Hi, my name is Andrea Vogel,  \\n I'm a head of international HR,  \\n a chartered fellow of the CRPD and I have worked  \\n with a number of organizations internationally  \\n to create better workplaces.  \\n In this course, we'll explore how to address misconduct  \\n in the workplace in a non-emotional way.  \\n And what process you need to follow to achieve a fair  \\n and objective outcome.  \\n We will also look at the informal actions you can take  \\n before managing misconduct in a formal disciplinary process.  \\n Join me on this course to identify a process to manage  \\n misconduct in a fair and objective way.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2305295\",\"duration\":171,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Defining misconduct\",\"fileName\":\"2823547_00_02_LA30_Impact\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Facts about the impact of misconduct on organisations and employees will help you engage managers in the process. In this video, learn about how to identify the reasons why misconduct must be addressed promptly.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":36381014,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Misconduct is not about an employee's performance at work.  \\n An employee can do a brilliant job  \\n and still be displaying misconduct.  \\n It's about their behavior towards others or the company  \\n and whether or not it's considered to be inappropriate.  \\n What constitutes inappropriate behavior in your company  \\n should be clearly defined  \\n because you need to make reference to it  \\n when you manage a misconduct case.  \\n Your company should have a clear policy or a code  \\n that defines what inappropriate behavior looks like  \\n and the degree to which it's tolerated in the company.  \\n How you define misconduct depends on two factors.  \\n The first one is your local legislation.  \\n You may, for example, operate in a country  \\n where discrimination based on ethnic origin  \\n is unacceptable by law.  \\n In the UK that would be the Equality Act.  \\n So you need to make sure that your policies  \\n reflect any inappropriate behavior  \\n that is supported by law.  \\n Other legislation that you need to consult  \\n are, for example, health and safety regulations.  \\n I've recently managed a case where an employee  \\n attacked their driver on their way home from the office.  \\n The person opened the door while driving  \\n and verbally abused the driver.  \\n This case was managed under the health and safety regulation  \\n and the person was considered  \\n to have put others at risk of physical harm.  \\n The second factor is your company values.  \\n These should be captured extensively  \\n in your code of conduct.  \\n Your values can include tangible inappropriate behaviors,  \\n such as stealing money or destroying company property.  \\n They can also include intangible inappropriate behaviors  \\n such as belittling and intimidating.  \\n These cases are usually more difficult to manage  \\n because they're less visible.  \\n You will probably have different values  \\n depending on which industry you work in.  \\n If you work in the sports industry, for example,  \\n then being shouted at by your coach  \\n may be an acceptable behavior  \\n because it's considered to be motivating.  \\n However, if you work in the health sector  \\n then shouting at your patients is probably unacceptable.  \\n And this should be captured in your company policies  \\n and the code of conduct.  \\n I invite you to take the time to review your policies  \\n and ensure that you have clearly articulated  \\n what inappropriate behavior looks like.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2305301\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2303257\",\"duration\":151,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Address misconduct in your regular catch-ups\",\"fileName\":\"2823547_01_01_LA30_Regular\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Establishing clear criteria for misconduct allegations will help you identify whether or not there is a disciplinary case to answer. In this video, learn how to apply fair and objective criteria to allegations of misconduct.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":32378331,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Managing misconduct informally  \\n is the first step in resolving issues in the workplace.  \\n Often misconduct is minor, inappropriate behavior,  \\n or simply a misunderstanding  \\n that doesn't warrant a more formal process.  \\n Addressing issues promptly and directly with the employee  \\n is the best method to maintain positive relationships  \\n and to avoid having issues manifest.  \\n So when you first become aware of an issue,  \\n you need to evaluate the severity of the misconduct  \\n and determine if an informal one-to-one conversation  \\n will be appropriate.  \\n How severe misconduct is in your company  \\n is determined by your policies and the code of conduct.  \\n If you have a zero tolerance level  \\n for sexual harassment, for example,  \\n then an informal one-to-one chat will not be sufficient.  \\n However, if an employee is rude, or distracts others  \\n by behaving in an unprofessional manner,  \\n then you may well recommend  \\n having a one-to-one in the first instance.  \\n The one-to-one happens between the line manager  \\n and the employee.  \\n And often the HR professional  \\n will not take part in this conversation  \\n unless either of the two requests the support.  \\n There are three parts to having a one-to-one on misconduct.  \\n The first part is the preparation.  \\n The line manager also needs exact details  \\n of the displayed behavior.  \\n When did it happen?  \\n What was said or done?  \\n And who else was present?  \\n The second part is the one-to-one conversation.  \\n Here the line manager explains to the employee what happened  \\n and why others are concerned about the behavior.  \\n They point out the relevant policies  \\n that the employee must adhere to,  \\n and the behavior they need to stop.  \\n You need to make sure the employee understands  \\n what is expected of them.  \\n Part three is the follow up.  \\n The line manager should make a note  \\n of the conversation in their diary  \\n and have a follow up chat with the employee after one month  \\n to see if they have experienced any further issues.  \\n You should also follow up with the person  \\n who may have complained about that employee  \\n and let them know that the concern is being addressed.  \\n I encourage you to address issues promptly and directly  \\n to avoid misunderstandings  \\n and promote positive relationships.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2305296\",\"duration\":155,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Address misconduct in the annual review\",\"fileName\":\"2823547_01_02_LA30_Annual\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Conducting a fair disciplinary process for misconduct is crucial to avoid unfair dismissal litigation. In this video, learn about how to define who needs to get involved and what employee rights you must respect.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":33076909,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Most companies have a performance review  \\n or appraisal in place that is completed annually.  \\n Such a review is an excellent platform  \\n to informally address any issues with an employee  \\n in a more formal setting.  \\n Addressing misconduct issues in the annual review  \\n has the advantage that concerns are documented,  \\n and objectives can be set to improve behaviors.  \\n Let's use an example.  \\n One of your employees tends to get  \\n very passionate about their projects,  \\n and sometimes raises their voice in project meetings,  \\n which upsets the other colleagues.  \\n To address this, you can follow three simple steps.  \\n First, gather all the information in preparation  \\n of the review meeting.  \\n Prepare real examples of when the employee  \\n has raised their voice, dates,  \\n times and who else was present.  \\n Also take note of the impact that behavior  \\n had on other people.  \\n For example, has this made it difficult to form  \\n productive relationships with others in the company.  \\n Be clear on what behavior improvements you want to discuss  \\n with the employee before you go into the review meeting.  \\n The second step is conducting your review meeting.  \\n Because the main goal of the review  \\n is to discuss objectives, you need to make a link  \\n between the expected behavior and the employees objectives.  \\n For example, raising your voice probably doesn't enable  \\n the employee to collaborate  \\n with others in a constructive manner.  \\n And because of it, it's difficult to progress on a project.  \\n So you would expect to see a more calm  \\n and constructive communication style.  \\n Now this is a very clear area for improvement,  \\n which you need to agree on  \\n and record in the review document.  \\n It's also an opportunity to identify any support  \\n the employee may need to improve that behavior.  \\n For instance, you could offer them communication  \\n training or coaching.  \\n The last step in this process is to conduct  \\n regular follow-up sessions.  \\n You need to check if there's any improvement  \\n in the employees behavior after you've given them  \\n the opportunity to address the areas of concern.  \\n You should check in at least monthly  \\n and see if the employee needs any further support.  \\n Be sure to use the review process to address misconduct  \\n issues in an informal manner  \\n before you go into a more formal process.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2303258\",\"duration\":159,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Address misconduct with the support of a mediator\",\"fileName\":\"2823547_01_03_LA30_Mediator\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"A disciplinary process requires you to establish facts before any disciplinary action can be taken. In this video, learn about how to separate facts from opinion.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":34042797,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Sometimes, misconduct is the product  \\n of a dysfunctional relationship between two people.  \\n Especially when those two people  \\n are equally displaying inappropriate behavior  \\n targeted specifically towards the other person.  \\n In such a case, you need to address the concerns  \\n with both parties in a neutral setting.  \\n Having a mediator intervene in a conflict  \\n will ensure that the issues are discussed objectively,  \\n and solutions are put in place  \\n that can prevent further misconduct on both sides.  \\n And mediation is often the last option  \\n before going to a formal disciplinary process,  \\n and it demonstrates  \\n that your company is exhausting all options available  \\n to resolve the issue.  \\n This becomes really important  \\n should you ever have to face a tribunal  \\n for unfair dismissal.  \\n So how can you engage a mediator?  \\n There are two options.  \\n The first option  \\n is to get a professionally trained mediator.  \\n Often this person will be external to your company.  \\n The advantage of this option  \\n is that you know that the process  \\n is completed professionally and meets industry standards.  \\n You can also be sure that the mediator  \\n is not biased, or has a conflict of interest,  \\n as they won't know either party to the conflict  \\n and doesn't have prior knowledge of the case.  \\n This can also be seen as a disadvantage,  \\n because knowing the company and its culture  \\n would give the mediator a better perspective  \\n of what challenges both employees are facing at work.  \\n The other disadvantage is that a professional mediator  \\n always comes with a cost.  \\n So if this option is not feasible for you,  \\n then you would go for option two,  \\n which is engaging an internal mediator.  \\n This can be anyone in the company  \\n who has either been trained in mediation  \\n or has significant experience in conflict resolution  \\n in a leadership role.  \\n The person needs to demonstrate  \\n that they don't have a conflict of interest  \\n or bias towards either of the parties,  \\n and both employees must be comfortable  \\n with the chosen mediator.  \\n The actual mediation  \\n then involves both parties and the mediator.  \\n It's important that the mediation identifies  \\n expected behavior for both employees,  \\n and that objectives are being set  \\n with timelines to review the improvements made  \\n by both parties.  \\n If you haven't identified possible in-house mediators yet,  \\n I highly encourage you to do that,  \\n and train them in mediation practices.  \\n \\n\\n\"}],\"name\":\"1. Informal Misconduct Process\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2303260\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2303259\",\"duration\":157,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Evaluating allegations of misconduct\",\"fileName\":\"2823547_02_01_LA30_Allegation\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Establishing clear criteria for misconduct allegations will help you identify whether or not there is a disciplinary case to answer. In this video, learn how to apply fair and objective criteria to allegations of misconduct.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":33438208,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Managing a misconduct case  \\n can be very stressful for everybody involved.  \\n So it's really important  \\n to separate the emotions from the process  \\n because this will reduce the stress  \\n and it will ensure that you evaluate the case  \\n fairly and objectively.  \\n There are two criteria that will help you decide  \\n if you should take a case  \\n into a formal disciplinary process.  \\n The first one is the evidence that is provided  \\n to support the allegation.  \\n Evidence must be factual, relevant, and sufficient.  \\n You need to distinguish  \\n whether an allegation of misconduct  \\n is a personal opinion  \\n or if it is based on real examples  \\n and observations of behavior.  \\n When you receive an allegation  \\n of sexual harassment, for example,  \\n you would look at whether there are other people  \\n who have witnessed the sexual harassment behavior  \\n or if there's written evidence  \\n in the form of emails or text messages.  \\n Facts include details of a specific situation,  \\n including location, dates, and times.  \\n You also need to ensure that the evidence  \\n is relevant to the allegation.  \\n For example, if someone reports on sexual harassment  \\n and then provides evidence  \\n of the employee's under-performance at work,  \\n you won't be able to confirm the allegation.  \\n You also need sufficient evidence  \\n that allows you to make a reasonable judgment  \\n on whether or not someone has behaved  \\n in the way it is alleged.  \\n In some cases, for example, where behavior  \\n can be more subtle like belittling or intimidation,  \\n you need to evaluate  \\n if there are sufficient factual examples  \\n that would show a pattern of inappropriate behavior.  \\n Once you have established  \\n that there is evidence to support the allegations,  \\n you need to consider whether any policy,  \\n company value, or code was actually breached.  \\n For this, you need to make a comparison  \\n between the alleged behavior and the company policy.  \\n In this case, for example,  \\n it could be either the Code of Conduct  \\n that refers to a zero tolerance for sexual harassment  \\n or it could even be a legislative act  \\n outside of your company policies.  \\n The main question you need to ask yourself is:  \\n Would a reasonable person  \\n consider this behavior to be misconduct?  \\n I really encourage you  \\n to embrace allegations of misconduct  \\n by separating the process from the emotions involved  \\n and by sticking to factual evidence  \\n and referring to company policies.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2305297\",\"duration\":157,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting up a disciplinary hearing\",\"fileName\":\"2823547_02_02_LA30_Hearing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Conducting a fair disciplinary process for misconduct is crucial to avoid unfair dismissal litigation. In this video, learn how to define who needs to get involved and what employee rights you must respect.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":33497515,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When you move into a formal disciplinary process  \\n you need to start thinking about  \\n possible outcomes including dismissal.  \\n Respecting the rights of the employee  \\n when setting up a disciplinary hearing  \\n is the first step to a successful formal process.  \\n Conducting a fair and objective disciplinary process  \\n will reduce the risk of an unfair dismissal tribunal  \\n and possible claim for compensation.  \\n It will also ensure that you maintain  \\n a professional company image,  \\n which improves employee engagement.  \\n The disciplinary hearing is a fundamental  \\n right of the employee because it provides  \\n an opportunity to respond to the allegations.  \\n You need to appoint a hearing manager  \\n and an HR support person that are objective  \\n and not biased towards or against the employee.  \\n For example, if you are a witness to the allegations,  \\n you cannot also be hearing or supporting the process.  \\n There are a number of things you need to set up  \\n a successful hearing.  \\n You need to give sufficient notice  \\n to the employee in writing,  \\n and at least 48 hours before the hearing.  \\n This will give them enough time to prepare,  \\n and gather information they may want to present  \\n during the hearing.  \\n The notice must include the allegations  \\n made against the employee,  \\n and you should also make reference  \\n to the policies the employee has allegedly breached.  \\n In addition, you need to attach a summary of the evidence,  \\n covering the main facts and examples you have gathered.  \\n The employee needs to be notified  \\n that they have the right to accompanied to the hearing.  \\n Usually, this can be a work colleague  \\n or a union representative.  \\n Your notice letter should also be  \\n advising the employee of any possible outcomes.  \\n So if for example the allegedly misconduct is severe,  \\n then you need to mention that this process  \\n could lead to dismissal.  \\n If your company has any support services available,  \\n such as an employee assistance program,  \\n then the notice letter is a great place  \\n for you to offer this service as a support to the employee.  \\n Finally, you should remind the employee  \\n of the company's commitment to confidentiality.  \\n And ask that the employee equally  \\n keeps this process confidential.  \\n I encourage you to follow these simple steps  \\n and conduct a fair process to reduce the risk  \\n of unfair dismissal.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2305298\",\"duration\":165,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Establishing facts in a disciplinary process\",\"fileName\":\"2823547_02_03_LA30_Facts\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"A disciplinary process requires you to establish facts before any disciplinary action can be taken. In this video, learn about how to separate facts from opinion.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":35250435,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A disciplinary process is very stressful  \\n for everyone involved.  \\n And often, managers try to avoid it  \\n because nobody likes having difficult conversations.  \\n Removing the emotions from the process  \\n and distinguishing facts from personal opinion  \\n will make this process easier for you.  \\n Establishing facts in a disciplinary process  \\n requires you to do an investigation.  \\n This will enable you to make a fair and objective judgment  \\n on what or not disciplinary action  \\n should be taken against an employee.  \\n So what's the difference between facts and opinions?  \\n Facts are information based on evidence and observations.  \\n Opinions are subjective interpretations  \\n and perceptions and emotions towards  \\n a situation or a person.  \\n The way you can search for and identify factual information  \\n is by asking the right questions.  \\n When you conduct an investigation  \\n into a bullying and harassment case for example,  \\n you would first speak to the person who submitted  \\n the complaint or allegation.  \\n Often you will find that the person's distressed  \\n and emotional, and they will express that emotion  \\n in your discussion with them.  \\n While that is acceptable, and you should show empathy  \\n for the emotions of the person,  \\n it's your job to find out what actually happened rather  \\n than exploring how the person feels about it.  \\n So for example, if the person tells you  \\n that they feel bullied and undermined by their manager,  \\n and it makes them feel intimidated.  \\n You haven't actually heard any factual information yet.  \\n The kind of questions you want to ask here are,  \\n \\\"Can you tell me about a situation where your manager  \\n \\\"has made you feel like that?\\\"  \\n Or, \\\"What happened, when did it happen,  \\n \\\"and what did they do or say to you?\\\"  \\n You'll also want to find out  \\n if there is anyone else who can confirm what happened.  \\n Your goal is to get real examples of behavior  \\n displayed by the employee  \\n that demonstrate possible misconduct.  \\n So when the person then tells you for example,  \\n that they have been excluded from an important work activity  \\n without explanation, and which resulted in them  \\n not being able to deliver on their objectives,  \\n you suddenly have factual information.  \\n I highly encourage you to spend your investigative time  \\n on asking the right questions  \\n and finding factual information  \\n because this will reduce your emotional involvement,  \\n and ensure an objective judgment.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2305299\",\"duration\":159,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Disciplinary action for misconduct\",\"fileName\":\"2823547_02_04_LA30_Action\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Disciplinary outcomes must be fair and proportionate to hold up on appeal or litigation. In this video, learn how to make a reasonable judgment of disciplinary action.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":33973932,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Taking disciplinary action against an employee  \\n can be quite difficult and emotional.  \\n So applying objective principles  \\n will help you make fair and reasonable  \\n judgments about any action that needs to be taken.  \\n This will also reduce the risk of litigation  \\n or the decision being overturned in an appeal process.  \\n First of all, depending on the country  \\n your company operates in, there may be  \\n legislative frameworks, or codes of practice  \\n which determine the type of disciplinary action  \\n you can take.  \\n For example, in the U.K., you can issue a warning  \\n or go straight to dismissal in cases  \\n of gross misconduct.  \\n In other countries, you may have to issue  \\n three warnings before you can go to dismissal.  \\n I've also worked in countries  \\n where possible disciplinary action  \\n can include demoting the employee,  \\n or reducing their salary.  \\n So make sure you understand the local regulations  \\n before considering any disciplinary action.  \\n Secondly, you need to understand which policy  \\n or code was breached by the employee,  \\n and what level of importance that policy  \\n or code has within the company.  \\n For example, if someone has come to work intoxicated,  \\n and behaved very drunk, but hasn't caused  \\n anyone harm, you may apply a more lenient  \\n disciplinary action, such as a warning.  \\n However, if an employee has come to work intoxicated  \\n and put others at risk by driving a vehicle  \\n or operating heavy machinery,  \\n then this could warrant an immediate dismissal  \\n with, or even without, notice period.  \\n Have a look at your policies  \\n They may give you very specific guidance  \\n on what your company considers unacceptable behavior.  \\n A third factor to consider  \\n is whether the employee has any history of misconduct.  \\n In cases of minor misconduct, you may consider  \\n taking less severe disciplinary action  \\n if the employee has never displayed  \\n such behavior in the past, and the impact  \\n of the behavior is low.  \\n But if the behavior is repeated,  \\n and the employee already has a warning on record,  \\n for the same misconduct,  \\n you may need to go ahead and terminate the employment,  \\n because there appears to be little evidence  \\n that the behavior is improving.  \\n I encourage you to use these principles to guide you  \\n in making fair and reasonable judgments  \\n about disciplinary action.  \\n \\n\\n\"}],\"name\":\"2. Formal Disciplinary Process\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2305302\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2305300\",\"duration\":165,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Conducting an appeal hearing\",\"fileName\":\"2823547_03_01_LA30_Appeal\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Employees have the right to appeal a disciplinary action. In this video, learn about how to set up and support a fair appeal process.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":35242156,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The right to appeal disciplinary action should be embedded  \\n in your company policy as it demonstrates  \\n that the company's committed to an objective evaluation  \\n of a management decision.  \\n The first thing you need to do is appoint a hearing manager.  \\n This cannot be the same person  \\n who managed the disciplinary process.  \\n In fact, everyone involved in the appeal process  \\n must not have been part of the disciplinary process.  \\n This will ensure that the process  \\n and action is evaluated objectively  \\n and purely on the information documented  \\n throughout the process.  \\n Once you have a hearing manager,  \\n you need to advise the employee  \\n that they must clearly set out the grounds for the appeal  \\n and provide further information or evidence, if needed.  \\n The appeal must be submitted within a certain timeframe  \\n which should be specified in your company policy.  \\n The grounds for an appeal can include reasons such as  \\n the employee believes the process was flawed,  \\n or the employee believes there was additional evidence  \\n that was not previously available or was not considered,  \\n or the employee believes  \\n the disciplinary action was too severe.  \\n For example, if an employee was dismissed  \\n because of gross misconduct,  \\n but they believe their misconduct was only minor  \\n and, therefore, they should have only received a warning,  \\n they can request the disciplinary action to be reviewed.  \\n The hearing manager will review the grounds of appeal  \\n together with the documents from the disciplinary process  \\n before inviting the employee to the appeal hearing.  \\n The invitation must be in writing  \\n and set out the right of the employee to be accompanied.  \\n The employee can usually be accompanied  \\n by a work colleague or a union representative.  \\n During the hearing, the employee then has the opportunity  \\n to explain the grounds for the appeal,  \\n and the hearing manager  \\n may ask any questions for clarification.  \\n I have often sat in appeal hearings  \\n where the employee has submitted very vague grounds  \\n and very little additional evidence.  \\n However, the company really needs to demonstrate  \\n that they're committed  \\n to giving the employee every opportunity for a fair process.  \\n After the hearing,  \\n the hearing manager makes a final decision on whether  \\n or not the disciplinary action is upheld or overturned.  \\n I invite you to follow these simple steps to set up  \\n and conduct a fair appeal process.  \\n \\n\\n\"}],\"name\":\"3. The Appeal Process\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2303261\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2304469\",\"duration\":111,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Top tips to manage misconduct\",\"fileName\":\"2823547_04_01_LA30_Tips\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Addressing misconduct promptly and avoiding the traps of unfair dismissal are crucial to mitigate the risk of litigation. In this video, learn about the must-dos of managing misconduct in the workplace.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":24024066,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Managing misconduct in the workplace is absolutely crucial  \\n because if you don't you nurture a culture  \\n where inappropriate behavior is acceptable,  \\n and this will have a negative impact on employee engagement  \\n and trust in your leadership.  \\n Because managing misconduct  \\n can lead to the dismissal of an employee,  \\n you need to ensure that you follow a few procedural steps  \\n to avoid a possible unfair dismissal case.  \\n Here are my top three do's for managing misconduct.  \\n Ensure you have sufficient, relevant,  \\n and factual information  \\n that justifies conducting a disciplinary process.  \\n Give the employee an opportunity to prepare and respond  \\n to the allegations in a hearing.  \\n And inform the employee of the outcome in writing  \\n and give them the right to appeal the decision.  \\n There are also things you must absolutely avoid.  \\n Here are my top three don'ts.  \\n Don't intimidate or threaten the employee  \\n in any shape or form verbally or in writing.  \\n Don't ask the employee to resign as this could be seen  \\n as constructive dismissal.  \\n And don't make a judgment  \\n before you have evaluated all the evidence,  \\n there are always two sides to a story.  \\n The most important tip I can give you is,  \\n document, document, and document.  \\n Keep a diary or notes,  \\n but ensure that you start writing down the facts  \\n and do it early.  \\n I really encourage you to manage misconduct  \\n following this step process  \\n and leave your emotions out of it  \\n to ensure that you can provide a fair  \\n and objective perspective.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2305303\"}],\"size\":0,\"duration\":1634,\"zeroBased\":false},{\"course_title\":\"Nano Tips for Navigating Life After Layoff with Lorraine K. Lee\",\"course_admin_id\":4455105,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4455105,\"Project ID\":null,\"Course Name\":\"Nano Tips for Navigating Life After Layoff with Lorraine K. Lee\",\"Course Name EN\":\"Nano Tips for Navigating Life After Layoff with Lorraine K. Lee\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;Welcome to our Nano Tips series, where LinkedIn Learning creators deliver impactful lessons in literally seconds. Keynote speaker, founder, and author Lorraine K. Lee guides you through productive ways to handle life after a layoff. Lorraine explains the importance of feeling your emotions, staying positive, and putting time and thought into planning the next stage of your career. She encourages you to share your layoff story, leverage your network, and set up informational interviews. Lorraine shows you how to ask for recommendations, shares ways to avoid job application burnout, and highlights the importance of writing down your accomplishments. Plus, she goes over ways to leverage LinkedIn so that you can get found by more recruiters and hiring managers. With these concise videos, you can fit learning into even your busiest days!&lt;/p&gt;&lt;p&gt;This course was created by Lorraine K. Lee. We are pleased to host this training in our library.&lt;/p&gt;\",\"Course Short Description\":\"Lorraine K. Lee shares tips on productive steps you can take after a layoff.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20159018,\"Instructor Name\":\"Lorraine  Lee\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Keynote Speaker, Founder, Author\",\"Author Payment Category\":\"LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2023-07-10T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/nano-tips-for-navigating-life-after-layoff-with-lorraine-k-lee,https://www.linkedin.com/learning/nano-tips-for-navigating-life-after-layoff-with-lorraine-lee\",\"Series\":\"Nanolearning\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"General\",\"LI Level EN\":\"General\",\"Sensitivity\":\"Personal\",\"Internal Library\":\"Business\",\"Internal Subject\":\"Career Development\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":577.0,\"Visible Video Count\":10.0,\"Contract Type\":\"LICENSED\"},\"sections\":[{\"duration\":577,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4467265\",\"duration\":68,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Feel your emotions after a layoff\",\"fileName\":\"4455105_en_US_01_01_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Getting laid off is a traumatic event. These are the emotions you're likely to feel\u2014and how to handle them.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8387815,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"After getting laid off, you're likely to feel all\\nsorts of emotions, including shock,\\nanxiety, anger, isolation, and sadness.\\nI know I definitely felt a few of these.\\nLayoffs are a traumatic event, so much so that you may even\\nexperience the various stages of grief.\\nYou might feel denial where you think your previous employer\\nwill change their mind,\\nor perhaps you haven't yet accepted that you were laid off.\\nAnger.\\n\\nformer coworkers who didn't get laid off.\\nBargaining where you question what you could have done differently to\\navoid this outcome or what you could have done to have been\\nbetter prepared for it.\\nDepression where you don't feel like yourself and you feel down\\nand upset all the time and acceptance where you may still\\nfeel parts of the other stages, but ultimately you're ready to\\nleave the past in the past and move ahead.\\nAnd you may feel multiple of these at once,\\nand that's okay.\\nIt's important to take the time to feel any feelings you have,\\nand then once you've processed, you can start moving forward in\\na productive and positive way.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2702279\",\"duration\":55,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Stay positive after a layoff\",\"fileName\":\"4455105_en_US_01_02_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"It's natural to enter a negative self-talk spiral post-layoff. Follow these suggestions to shift your mindset.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6989888,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"It's important to not get stuck in a cycle of negative self-talk\\nduring this time,\\nand you will achieve that by shifting your mindset.\\nTry these three techniques.\\nFirst, reframe the situation.\\nI cannot tell you how many people I know who have gotten laid off\\nwho end up saying it was the best thing that ever happened to them.\\nOf course, it didn't seem like it at the time\\nbut they were able to take it as a chance to grow and pursue\\nopportunities they didn't have the time to look into and may\\nnever have considered.\\n\\nSecond, create a brag sheet, list out your strengths\\nand skills.\\nThis is a wonderful way to build up your confidence and prepare\\nyou for interviews.\\nThird, take action.\\nStaying productive by doing things like updating your resume,\\nmeeting people in your network, and even helping others can make\\nyou feel more in control and more confident.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2702278\",\"duration\":57,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Career planning after a layoff\",\"fileName\":\"4455105_en_US_01_03_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"What you did in your previous role doesn't need to be what you do in your next one. Here's how to think through the next stage of your career.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6754148,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"One of the most meaningful outcomes that can come out of a\\nlayoff is getting the chance to do a bit of soul searching.\\nDo you want to do the same role but work at a different\\ntype of company?\\nPerhaps you've always been curious about pivoting careers,\\nbut you didn't have time to think about it with a full time job.\\nHas your health taken a backseat all of these years?\\nHere are a few questions to help you figure out what you want\\nto focus on moving forward.\\nWhat are your values?\\nWhat skills do you have and what skills do you want to learn?\\nDo you care about being remote, in person,\\nhybrid?\\nWhat sort of life do you want for yourself in five,\\n10, 15 years?\\nWhat's your working style?\\nWhat have you liked most about your past jobs and what\\nhave you liked least?\\nGet clear on what your priorities and goals are at this\\npoint in life.\\n\\nIt will help make the job search process less overwhelming and help\\nyou be clear on the next steps you should take.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4466300\",\"duration\":49,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Share your layoff story\",\"fileName\":\"4455105_en_US_01_04_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"One of the best ways to let people know you're open to work is by making a post about it on LinkedIn. Here's how to write an effective post that will be seen by many.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5839460,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"After getting laid off, you may feel hesitant about\\nletting the world know.\\nThe good news, however is that getting laid off is\\nno longer a taboo topic.\\nI really encourage you to make a post on LinkedIn about your layoff\\nso others know to keep an eye out for opportunities for you.\\nWhen writing your post, keep these things in mind.\\nYou don't need to post it right away.\\nI took a few weeks before making my own because I wanted to take\\nthe time to process and figure out what I wanted to share.\\nDon't just say you got laid off and leave it at that.\\n\\nLet people know what you're looking for in your next role and\\njot down some highlights from your past experiences.\\nConsider adding a picture to your post.\\nIt adds a human element and is likely to get you more engagement.\\nAnd lastly, be vulnerable and genuine.\\nThese are the posts that resonate most with others.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4466299\",\"duration\":51,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Leverage your network after a layoff\",\"fileName\":\"4455105_en_US_01_05_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Your network will be one of the most important ways to learn about and get referred to new roles. Here's how to approach them for help.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6130448,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Your network will be one of the most promising ways to\\nland your next job.\\nIn fact, studies show that 85% of jobs are filled through\\npersonal connections.\\nMake a list of people who have supported you in the past and send\\nthem a personalized note to let them know you got laid off.\\nYou'll find that most people, you know,\\nif not all of them,\\nwill want to help you. Come to the meeting with an idea of what\\nyou're looking for in your next role\\nand take a look at people they're connected to on LinkedIn to see if\\nthey can make an introduction.\\n\\nDon't forget to offer to help them, too.\\nAfter all, networking is a two way street and you have very valuable\\nskills and insights to share.\\nOne more thing to remember. After you land your next job,\\nreach back out to your network to let them know. They will really\\nappreciate it and it will show that you value the help\\nthey gave you.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4468278\",\"duration\":74,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Set up informational interviews\",\"fileName\":\"4455105_en_US_01_06_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Connect with people who work at companies you're interested in or who are in similar roles you want to be hired for. Here's how to approach strangers who can help you with your job search.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9240002,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Informational interviews on meetings to learn more\\nabout an industry,\\na company or even someone else's career journey.\\nI love that because they help you expand your network,\\nlearn new insights, and can even help you\\nin your job search.\\nHere are four things to think about for a successful\\ninformational interview.\\nNumber one, send a personalized and polite note introducing\\nyourself.\\nto that person specifically.\\nThe more you can show that you've done your research,\\nthe more likely that person is to chat with you.\\n\\nSecond, make scheduling easy.\\nCreate a calendar link with multiple available dates and times\\nto avoid that back and forth that comes with scheduling.\\nAsk for a quick 15 minute chat instead of 30 minutes or 1 hour\\neven to make it seem like less of a lift on their end.\\nOftentimes, if they are enjoying the conversation,\\nthe meeting will run longer than you scheduled it for.\\nThird, have a prepared list of questions that you want\\nto go through, but stay flexible if the\\nconversation starts going in a different,\\ninteresting direction.\\n\\nAnd fourth, follow up after chatting.\\nSend a thank you note to show your appreciation and keep them\\nposted on your progress.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4465290\",\"duration\":55,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Ask for recommendations\",\"fileName\":\"4455105_en_US_01_07_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"After getting laid off, one of the first things you should do is ask for recommendations from former colleagues. Here's how to ask for recommendations that will help you land your next job.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6865259,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Think of recommendations like social proof for you\\nas a professional.\\nIf two candidates have the exact same skills and experience,\\nbut one has a lot of recommendations,\\nthat person with the recommendations is going to look\\nmore appealing as a candidate.\\nWhen asking for recommendations, keep these three things in mind.\\nFirst, when you reach out for a recommendation,\\ngive them specific questions and guidelines to make sure that the\\nrecommendation is going to be as helpful for you as possible based\\non what you want to do next.\\n\\nDo you want them to highlight your communication skills,\\nyour work as a culture builder, your superb marketing skills?\\nSecond, request the recommendation through LinkedIn so that you have\\nthe option to put it on your profile.\\nI always say the more recommendations,\\nthe better.\\nAnd third, offer to write one back.\\nIt will show you had a good working relationship,\\nwhich is important.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4469282\",\"duration\":42,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Avoid job application burnout\",\"fileName\":\"4455105_en_US_01_08_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Applying to hundreds of jobs per day may make you feel more productive, but it's actually working against you. Here's how to approach your job search strategically.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5425314,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"After getting laid off,\\nit's tempting to want to blast your resume out to as many\\ncompanies as possible.\\nIt may feel productive to do that, but it's a quick way to burnout.\\nInstead, you should come up with a job search strategy first so that\\nyou're spending your time in an efficient way.\\nHere are a few things to keep in mind.\\nSet realistic goals.\\nCome up with a number that seems manageable even if it's small.\\nTake breaks.\\nDo not let your whole day be about the job hunt.\\nGet outside and get in some physical activity.\\n\\nAnd lastly, prioritize.\\nSome job opportunities will be more exciting to you than others\\nand fit better with your experience.\\nMove those to the top of your list.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4466298\",\"duration\":54,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Write down your accomplishments\",\"fileName\":\"4455105_en_US_01_09_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Jot down your wins and accomplishments while they're still fresh in your mind. Here are a few frameworks that can help.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7009444,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Writing down your accomplishments will not only give you a\\nnice confidence boost,\\nit will also help prepare you for interviews.\\nHere are three ways to show the impact you had in your last role.\\nFirst, use the STAR method, which stands for Situation,\\nTask, Action and Results.\\nDescribe the situation of challenge, the task you\\nwere assigned,\\nthe action you took to tackle it, and then the result or outcome.\\nSecond, use as much data as possible.\\nInstead of saying wrote articles for the blog,\\nsay wrote five articles per month for the blog and increased traffic\\nby 20% year over year.\\n\\nThird, use action verbs such as lead,\\ncreated, improved and saved.\\nNeed help remembering just how awesome you are.\\nDon't be afraid to reach out to former colleagues who you had good\\nworking relationships with to help discuss what you can\\nadd to your list.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4469281\",\"duration\":72,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Leverage LinkedIn after a layoff\",\"fileName\":\"4455105_en_US_01_10_VV30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Leverage LinkedIn so that you can get found by more recruiters and hiring managers. Here's what to do to make sure you're optimizing your job search.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8524356,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"LinkedIn will be one of the most important tools in your toolbox\\nwhen searching for jobs.\\nMake sure you do these four things.\\nFirst, click the jobs tab at the top of your browser or in the\\nbottom of your mobile app and turn on job alerts.\\nSet multiple alerts for different regions and job titles\\nyou're interested in.\\nSecond, use LinkedIn's interview preparation feature.\\nYou'll get tips from experts and be able to practice your interview\\nresponses through video or by writing them down.\\n\\nThird, indicate that you're open to work on your profile.\\nAdd what roles you're looking for, the locations you want to work in,\\nhow soon you're ready to start, and what job types you're\\nlooking for.\\nYou can indicate here whether you only want people using LinkedIn\\nRecruiter to see it or everyone on LinkedIn.\\nYou can also add an open to work banner on your profile photo.\\nFourth, if a job posting you're interested in lists the hiring\\nmanager or the recruiter, send them a personalized note\\nwith a connection request.\\n\\nLet them know what role you applied for,\\nwhy you're excited, and what you would bring\\nto the role.\\nThis initiative and proactiveness\\nis often a great way to get your resume to the\\ntop of the pile.\\n\"}],\"name\":\"1. Navigating Life after a Layoff\",\"size\":71166134,\"urn\":\"urn:li:learningContentChapter:4466301\"}],\"size\":71166134,\"duration\":577,\"zeroBased\":false},{\"course_title\":\"Managing Your Finances Through a Career Transition or Layoff\",\"course_admin_id\":2887056,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2887056,\"Project ID\":null,\"Course Name\":\"Managing Your Finances Through a Career Transition or Layoff\",\"Course Name EN\":\"Managing Your Finances Through a Career Transition or Layoff\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Career transitions, whether planned or unexpected, trigger a barrage of time-sensitive financial planning questions. How much money do you need to fund your bottom line? What steps can you take to maintain health insurance coverage between jobs? In this course, longtime financial adviser Winnie Sun answers these questions and more, providing practical advice designed to help you survive a gap in income triggered by a layoff or career change. Discover how to leverage your assets during a transition, get your spending under control, and create a financial first-aid kit designed to help you plan your next steps. Plus, learn how to use COBRA to keep your insurance, roll over retirement funds, and start a new job with renewed financial goals.\",\"Course Short Description\":\"Learn what it takes to survive a gap in income triggered by a layoff or career change. Get practical tips on how to prepare your finances, manage your funds between jobs, and more.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":1991945116,\"Instructor Name\":\"Winnie Sun\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Financial Advisor, Speaker, Entrepreneur\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2021-03-18T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/managing-your-finances-through-a-career-transition-or-layoff\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Beginner\",\"LI Level EN\":\"Beginner\",\"Sensitivity\":null,\"Internal Library\":\"Business\",\"Internal Subject\":\"Finance and Accounting\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":2088.0,\"Visible Video Count\":11.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":278,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2415231\",\"duration\":76,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Getting ready for your career transition\",\"fileName\":\"2887056_00_01_WL30_welcome\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15874956,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Career transitions are changes  \\n at your workplace employment as when you retire,  \\n when you transition to another position  \\n at a different company, or when you've been laid off  \\n or terminated from your place of work.  \\n Hi, I'm Winnie Sun.  \\n I'm excited to share with you my two decades-plus experience  \\n helping clients transition and manage their money.  \\n Managing a career transition can be  \\n one of the most important financial planning events  \\n of a person's life.  \\n In this course,  \\n I'll teach you, first, to prepare your finances  \\n while you're still employed.  \\n Second, the critical steps to take  \\n when you've been informed that you're being let go.  \\n Third, to properly manage finances post-layoff  \\n during your job transition.  \\n And finally, some tools to help you prepare  \\n for your next job.  \\n This might be a scary, overwhelming time,  \\n and you may be feeling lost.  \\n I understand. I'm here to help.  \\n The terminology, the documents, the decisions,  \\n they all seem to come at once.  \\n Stay the course, stay with me as we break this process down  \\n step by step.  \\n I'm going to get you through this  \\n with more clarity and confidence.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2414278\",\"duration\":202,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Strengthening your financial mindset\",\"fileName\":\"2887056_00_02_MM30_mindset\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Even if all goes well, there could be some tough decisions to make about where to cut spending. This video describes how to approach making tough financial decisions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12016403,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - I remember like it was yesterday,  \\n The first time I met with employees  \\n of a major telecom company.  \\n We were having lunch and they were concerned.  \\n There were rumblings of layoffs coming  \\n and they were challenged in deciding whether or not  \\n they should volunteer for the severance package  \\n AKA volunteer to be laid off.  \\n Some were wondering whether they would be able  \\n to find another job quickly, others wondered  \\n if they were going to have medical insurance,  \\n and others, how long they would be able to cover their rent  \\n and household expenses, or if they could just hold tight,  \\n hoping enough people volunteer  \\n that their position would be spared.  \\n You may be feeling anxiety just listening to this story.  \\n Many people feel emotional about money  \\n and that is completely normal.  \\n After 20 plus years in this industry,  \\n I'll share that regardless of how much money you have,  \\n how much you learn, where you are in life,  \\n financial anxiety is sort of a universal truth.  \\n You may feel like you're alone in feeling this way,  \\n this insecurity.  \\n I'm here to tell you that we've all been there.  \\n I need you to embrace that you're not alone  \\n and we can build from these feelings  \\n and help you feel more financially in control.  \\n Some of the steps you can take to strengthen  \\n your financial mindset are:  \\n first, empower and educate yourself  \\n with some of these financial terms and principles.  \\n That's why you're here.  \\n And I'm so happy to have you here.  \\n Find a money buddy, someone or a team that you can talk to.  \\n You're naturally going to have questions  \\n as we go through this.  \\n If you have someone to bounce ideas,  \\n ask questions from,  \\n talk over when you just need a friend,  \\n your journey will be a lot easier.  \\n You're going to need a money hug now and then.  \\n If you don't have a buddy, seek out a professional.  \\n This can easily be done via Zoom or conference calls.  \\n Geography is less of an issue nowadays.  \\n Along with mapping things out,  \\n you'll want to become very organized.  \\n Learn a map and pace yourself in your financial journey.  \\n It's like when you make a shopping list for the supermarket  \\n or a packing list for your next vacation.  \\n Map out financial decisions.  \\n This isn't a time to put things in a pile  \\n and hope that things turn out okay.  \\n We're going to need to set up a system  \\n that helps you keep track of your important financial dates,  \\n such as when your severance paperwork needs to be turned in,  \\n when to file for unemployment if you're going to do this,  \\n when to establish medical insurance and so much more.  \\n You might also be feeling concerned  \\n about how your family will cope with this news.  \\n Household finances is a team effort  \\n and you'll need your team to step up and be there for you.  \\n So start this conversation by sharing the layoff news.  \\n Don't keep this a secret.  \\n The sooner you share it,  \\n the more quickly you can get planning your next steps.  \\n You could plan a family meeting to sit down  \\n without outside distractions to discuss a budget.  \\n Things might feel uncertain right now,  \\n but once you have a plan set for your financial future,  \\n you can gain confidence.  \\n Even though you don't always have control  \\n over the external forces at play,  \\n you can plan for how you will react to them.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":27891359,\"urn\":\"urn:li:learningContentChapter:2414281\"},{\"duration\":343,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2414279\",\"duration\":160,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The first thing to do if you find yourself laid off\",\"fileName\":\"2887056_01_01_MM30_first\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"This video lists the steps you should take if you learn you are being laid off. This will help make sure you are as well prepared as possible for an upcoming gap in income. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7829701,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When it comes to your career transition,  \\n I want you to know that timing is key.  \\n There are many decisions that need to be made  \\n within the first 15 days,  \\n and even more by the first 30 days.  \\n The first and most important thing to do  \\n is to document your company assets.  \\n Start by documenting all company contacts,  \\n emails and phone numbers of everyone  \\n at your soon-to-be former company  \\n that will be a help to you today and in the future  \\n to manage your finances through this transition.  \\n You can create a simple Google Doc  \\n or Notepad of individuals in Human Resources,  \\n your managers, the payroll managers,  \\n the plan sponsor of your 401k or 403b,  \\n the custodian of your company's stock, if you have one,  \\n the contacts to your health, medical, dental,  \\n vision plans, and more.  \\n Add to this a list of all your URLs.  \\n Once you leave the company,  \\n you won't be able to just pop into  \\n the benefits portal at work.  \\n You're going to need the external URLs.  \\n Test your usernames and passwords.  \\n Do this twice, and keep a record of this for yourself.  \\n Lastly, record all of your company account balances.  \\n You need to know where you stand financially.  \\n If you have a company pension,  \\n legal plan, everything, document it.  \\n Be over-prepared here.  \\n I'd rather you copy paste  \\n entire benefit company database here, than to be without  \\n because often once your away from your company,  \\n you lose access to your internet  \\n and the ease of finding people to help you out.  \\n Also, many times as layoffs occur,  \\n this could mean that your favorite HR contact  \\n is laid off too.  \\n So you're going to want redundancy here.  \\n If you have a Flexible Spending Account,  \\n or other spending account,  \\n find out how much you have left of your money  \\n and put together a plan to utilize this money  \\n so it doesn't get left on the table.  \\n Do you have unused vacation pay that will be paid out?  \\n How much and when can you expect these funds to be received?  \\n Document this.  \\n Once we know how much you own,  \\n you'll know how much money you have to work with  \\n to help you plan for the next few months and beyond.  \\n Documenting your company assets is the first step.  \\n It will help you plan.  \\n It will also help you feel more competent and secure  \\n in making a plan for moving forward.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2414280\",\"duration\":183,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Preparing your financial first-aid kit\",\"fileName\":\"2887056_01_02_MM30_firstaid\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"This video shows you how to create your personal financial first aid kit. This is a worksheet to set a financial baseline and understand all the financial tools that may be available so that you can effectively plan.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9096785,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A couple months before the pandemic,  \\n my parents went to the neighborhood park as they normally do  \\n to visit with their friends and get their steps in  \\n when my dad suddenly fell on the sidewalk, hit his head,  \\n and triggered his Apple Watch to call the paramedics.  \\n In a moment, everything went from being okay  \\n to not being okay.  \\n He was rushed to the hospital and soon to brain surgery.  \\n My mom panicked and the hospital began asking  \\n for all my dad's important documents,  \\n his medical records, his insurance info,  \\n and quickly his estate planning and healthcare directives.  \\n This inspired me to put together a financial first aid kit.  \\n Something that you can build yourself in just a weekend  \\n and have in place for when you'll need it.  \\n This is a place you go to  \\n to get all your financial information in one place  \\n organized and ready to go.  \\n Your career transition is a great time to put this together.  \\n To help you get started with your first aid kit,  \\n I've included document preparedness checklists  \\n in the exercise files folder  \\n but here's what you need to do to create yours.  \\n Start by collecting all your financial documents.  \\n An ideal time is soon after you file your taxes  \\n because you've collected many of these already.  \\n W-2s, 1099s and more.  \\n Add as many of the other financial documents  \\n as you can find from my lists.  \\n And yes, definitely add any others  \\n that I've omitted that apply to you.  \\n In the handout, I've included  \\n the most commonly own financial statements for you.  \\n Be sure you include a detailed list  \\n of contacts you may need to reach out to  \\n in regards to your finances.  \\n All your advisors, including financial advisor,  \\n accountant, attorney, pension or 401k plan sponsors  \\n and other trusted professionals.  \\n You'll want to include your contact information,  \\n phone number, email, website, and address.  \\n Parents, I'd recommend you also include  \\n a letter to your children and partner here.  \\n I encourage you to detail your wishes and thoughts here.  \\n Any special instructions, include them.  \\n Definitely include your estate planning documents  \\n like a will, living trust, health care directive and more.  \\n Make sure it's easy to get to  \\n and easy to find in case of immediate need.  \\n I also recommend keeping two copies of this,  \\n one with a financial advisor or trusted person  \\n who is geographically close to you  \\n and another who is out of state.  \\n Again, make sure all copies are secure  \\n and digitally encrypted.  \\n There are a lot of ways to easily do this nowadays.  \\n At our firm, we have the ability  \\n to keep our client's documents in a digital vault for them.  \\n If one of them loses their passport while on travel,  \\n they can reach out to us  \\n and we can securely send them a copy.  \\n Don't wait for a scare or an emergency to happen  \\n before getting motivated  \\n to create your financial first aid kit.  \\n Do it now.  \\n \\n\\n\"}],\"name\":\"1. Preparing to Leave Your Company\",\"size\":16926486,\"urn\":\"urn:li:learningContentChapter:2410274\"},{\"duration\":650,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2420223\",\"duration\":212,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What's your bottom line for survival?\",\"fileName\":\"2887056_02_01_MM30_bottomline\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn how to calculate your bottom line for survival. Moving the most limited budget will be key to a successful transition.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11087509,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A career transition often happens when we least expect it.  \\n Writing things down and having a plan  \\n will help you think pragmatically, not emotionally.  \\n To get through this phase successfully,  \\n we need to write down and map out what money is coming in  \\n and what money is going out.  \\n The key here is to be honest with what you truly need.  \\n The rule of thumb for using your own money  \\n during a career transition is this.  \\n Utilize taxable assets first.  \\n This includes your checking account,  \\n emergency funds, savings account, brokerage account,  \\n aka your non-retirement assets.  \\n Retirement assets are usually accounts such as IRAs,  \\n Roth IRAs, 401k, and so on that are considered  \\n qualified assets that have tax sheltered benefits  \\n attached to them.  \\n Then look at after-tax assets.  \\n This could be a brokerage account,  \\n a mutual fund, or trust account, just to name a few.  \\n Next, look at your Roth 401k or Roth IRA,  \\n as we have the ability to distribute contributions  \\n that you made without taxes and penalties.  \\n It's best not to touch your retirement funds  \\n prior to true retirement.  \\n If you're younger than age 59-1/2,  \\n your traditional 401k or traditional IRA  \\n would also be a last resort.  \\n If you're a homeowner, you might consider  \\n refinancing your home to a lower interest rate  \\n and/or applying for a home equity reserve line of credit.  \\n I highly recommend this to my clients,  \\n but be mindful that lenders will need to see income,  \\n so do this as soon as possible.  \\n Rates are at a historical low,  \\n so actively seek out opportunities in this area.  \\n You'll want to seek out at least two lending offers  \\n to compare which rate or term works best for you.  \\n The next step is to calculate how long your money will last,  \\n in other words, your financial bottom line.  \\n Your financial bottom line is all the money you have  \\n in checking, savings, retirement accounts, and so on,  \\n versus what your expenses are.  \\n Your basic expenses are your food costs, rent or mortgage,  \\n and your healthcare costs.  \\n To calculate your bottom line,  \\n complete the household budget form I provided  \\n in the exercise files folder.  \\n Focus on the three main expenses,  \\n housing, food, and medical needs.  \\n To do this right, repeat with a new budget worksheet  \\n for the next three months  \\n and average out your monthly spend.  \\n There will be some months that you spend more or less  \\n and we want to know how to plan your future needs.  \\n That's it.  \\n What does that number come out to be?  \\n If the number comes out to be more than you will have,  \\n don't freak out.  \\n This is the case with almost everyone I meet  \\n to plan out their income planning.  \\n There's always a Plan B.  \\n The earlier we plan, the better our options usually are.  \\n You may find that you need to reduce your monthly expenses.  \\n Remember, this is temporary until you find a new job.  \\n This might mean cutting car insurance  \\n on one of your household cars  \\n if you have more than one car.  \\n You could also sell the extra car.  \\n The good news is that there are always resources  \\n to help you out and remember to tell yourself,  \\n this is a temporary situation until you find a new job.  \\n And with a new job comes new income.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2420224\",\"duration\":195,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating your Plan B\",\"fileName\":\"2887056_02_02_MM30_planb\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"What if you can't fund your bottom line? This video goes over various alternative, although not preferred, ways to make the transition. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11218789,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - There's a saying in the financial industry  \\n that money is like a bar of soap,  \\n the more you touch it, use it, the smaller it gets.  \\n So my motto has always been,  \\n then we need to collect more soap.  \\n What this means for you during a career transition  \\n is to get creative, think different,  \\n and look for opportunities to bring in additional income.  \\n Recently, I met someone, let's call her Sandy,  \\n who was laid off from her employer  \\n after 15-plus years working there.  \\n It was a cost-cutting measure from her employer.  \\n She is only in her 40s,  \\n so still way too young to collect social security  \\n or penalty-free withdrawals from her retirement savings  \\n like 401k and IRAs.  \\n She had a very niche job and unique skill set.  \\n She was concerned that she wouldn't be able  \\n to find work quickly.  \\n How was she going to make her ends meet?  \\n She completed a budget worksheet for three months.  \\n Remember, I provided this worksheet in the exercise files.  \\n And that gave us an average of her expenses,  \\n but it also gave us a tool to identify the areas  \\n of her spending to reduce.  \\n Her company severance plus her extra vacation pay  \\n would not get her to a full year of expenses,  \\n which is the buffer time frame  \\n that she wanted to find another job.  \\n We calculate the shortfall, she applied for unemployment,  \\n and we put together a plan B.  \\n To make ends meet, she took on freelancing projects,  \\n sold things around the house she no longer needed,  \\n and reached out to her network  \\n to see who might need a consultant.  \\n We then put together the most tax and penalty-efficient plan  \\n of withdrawing distributions from her retirement plan  \\n in case we needed to pull from those.  \\n It wasn't what she wanted,  \\n but she had a plan to get her through her transition.  \\n This time for you is an opportunity  \\n to leverage your skills and abilities.  \\n Start that side hustle you've always wanted to try.  \\n Maybe sell unneeded items on eBay.  \\n Or maybe for you, it's creating a new craft,  \\n personalized item,  \\n and selling it on Facebook Marketplace or Etsy.  \\n Or perhaps, like for a friend of mine,  \\n it means temporarily working for DoorDash  \\n or recording voiceover for a company,  \\n or even editing writing on Fiverr.  \\n Get out there, join a social media community  \\n of others who are looking to work.  \\n Chat with people who know you  \\n and see if they have any ideas  \\n of income-generating projects you can start.  \\n There are a lot of options for you to consider,  \\n and often, they don't mimic exactly what you've been doing,  \\n but it doesn't mean you can't earn extra income  \\n in the meantime.  \\n It doesn't need to be the perfect job.  \\n It just needs to be a job that temporarily  \\n can bring in income to support you.  \\n Just remember, this isn't forever.  \\n It just buys you time  \\n and let you have time to wait for the full-time position.  \\n Some of the best business ideas came  \\n from the most challenging times.  \\n Once you earn a little,  \\n your motivation and confidence will grow.  \\n Just take that first step.  \\n Trust me, it's very empowering.  \\n After all, it takes intense pressure to create diamonds.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2420225\",\"duration\":243,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Planning health insurance during transition\",\"fileName\":\"2887056_02_03_MM30_cobra\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"This video lists the steps you should take to make sure you maintain insurance (health and life) during a career transition. Plus, get an overview of other benefits to consider.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11389825,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Having health insurance is always important,  \\n even between jobs, so that you can protect you  \\n from unexpected out-of-pocket expenses.  \\n After all, medical emergencies are unpredictable  \\n and can even occur when we're out of work.  \\n Often when we are in a job transition,  \\n we go without health insurance, hoping to save some money  \\n and hoping our new job comes quickly  \\n and with health insurance benefits.  \\n However, as you know, this can quickly become a mistake  \\n if we get sick.  \\n So what's the solution?  \\n When a life event happens, you'll want to move quickly,  \\n as you have a limited time  \\n to make a qualifying event change, typically just 30 days.  \\n First, let's talk about COBRA.  \\n COBRA stands for Consolidated Omnibus  \\n Budget Reconsolidation Act.  \\n This act gives employees and their families  \\n who lose health benefits  \\n the right to continue health benefits provided  \\n by their health insurance for limited periods of time  \\n under certain circumstances,  \\n such as job loss, death, divorce and other life events.  \\n Keep in mind, you often have the choice  \\n to extend your job-based coverage  \\n for up to 18 months with a COBRA plan.  \\n This will likely be more expensive,  \\n but it's a health plan you're familiar with  \\n through your past employer.  \\n When you're employed, your employer likely pays a major part  \\n of those health insurance premiums.  \\n And when you leave, you have to pay both your normal premium  \\n plus what the company paid as your employee benefit.  \\n You may be shocked by the price of COBRA coverage.  \\n However, there are other options.  \\n Short-term health insurance plans  \\n are another option to look into.  \\n These plans are typically cheaper,  \\n but they don't cover everything  \\n that a traditional health insurance plan would.  \\n They usually don't cover prescriptions, preventive care,  \\n maternity or pre-existing conditions.  \\n And another thing to keep in mind  \\n is that these plans also don't count  \\n as minimum essential coverage under the Affordable Care Act.  \\n Currently, as I'm saying this in 2021,  \\n there isn't any penalty.  \\n However, as legislation does change,  \\n I recommend to always check in on the website, irs.gov  \\n or ask your accountant if you have one.  \\n Here are some examples of plans  \\n that would not qualify for a MEC:  \\n plans that provide only discounts on healthcare services,  \\n plans that cover only dental or vision,  \\n care under workers' compensation plans,  \\n plans that provide care only for a specific condition  \\n rather than general medical coverage.  \\n Another option is buying a plan yourself  \\n through the health insurance marketplace.  \\n These are state-specific plans.  \\n For most states, you can do this easily online  \\n or call your local specialists to assist.  \\n For up to 60 days after you lose coverage  \\n from your past job,  \\n you qualify for a special enrollment period.  \\n During this time, you're able to enroll into a new plan.  \\n When applying, you'll learn  \\n if you qualify for federal financial assistance  \\n such as tax premium credits or cost sharing reductions.  \\n Lastly, if you have previously contributed  \\n to a health savings account or HSA,  \\n those funds are typically still available to you,  \\n even after you've left your job  \\n to help pay for eligible medical expenses.  \\n Research what the best approach is for you  \\n and your family's needs.  \\n The questions I provided in the exercise file  \\n are a great place to start  \\n if you're not sure what questions to ask.  \\n There is hope and protection for you and your family.  \\n You just have to take the first step  \\n in going out to find it.  \\n \\n\\n\"}],\"name\":\"2. Managing Finances while between Companies\",\"size\":33696123,\"urn\":\"urn:li:learningContentChapter:2417233\"},{\"duration\":740,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2419204\",\"duration\":244,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Evaluating insurance plans\",\"fileName\":\"2887056_03_01_MM30_insurance\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"This video describes keys to evaluating a benefits package, including insurance and retirement plans. It also includes a time-value-money chart. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10500029,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When considering a new job, you may not be as focused  \\n on the benefits package that comes with the position.  \\n However, taking a pause to review health care benefits  \\n especially if you have more than one job offer is important.  \\n Know that health insurance  \\n is not a one-size-fits-all proposition.  \\n There are so many acronyms that make up your choices.  \\n HMO, PPO, POS, and EPO.  \\n Let's start with PPO,  \\n which stands for preferred provider organization.  \\n It's important to know that PPO's,  \\n preferred provider organization, premiums  \\n are typically much higher than that of a HMO,  \\n which stands for a health maintenance organization.  \\n But with higher costs comes greater flexibility.  \\n In most cases you don't need to select  \\n a primary care provider, or PCP,  \\n for you and your covered family members in a PPO plan.  \\n A PPO also often has a larger healthcare provider list  \\n than an HMO because PPOs allow you to get  \\n both in-network and out-of-network care,  \\n though out-of-network providers generally cost more  \\n and you can also see a specialist without a referral.  \\n The general consensus is that the HMO plans,  \\n health management organization plans, are the budget option.  \\n HMO's typically require you to select  \\n a primary care provider who coordinates care.  \\n This person, your primary doctor, must then refer  \\n to any specialists that you may need to see.  \\n HMO's may have a deductible,  \\n but it's generally much lower than other plans.  \\n One drawback is that an HMO usually doesn't allow you  \\n to go outside your network,  \\n so make sure that the medical professionals  \\n that you visit and need are within the network.  \\n If you do need to visit a professional out of your network,  \\n be prepared that you may need to pay out of your own pocket.  \\n However, an exception to this would be  \\n if you're in need of emergency care,  \\n which requires the facility,  \\n but not necessary the proprietors to bill as in-network.  \\n Lastly, point of service plans, also known as POS,  \\n and the exclusive provider organization plans,  \\n known as EPO plans, fall somewhere in between  \\n the PPO and HMO plans.  \\n The vast majority of people don't have EPOs,  \\n so I won't go into much detail about these plans  \\n but ask your benefits department at your company  \\n for more information if they offer these plans.  \\n Here's what I would suggest doing to determine  \\n what plan works best for you and your family.  \\n Number one, talk to your primary care physician  \\n and ask for their opinion on what type of coverage of care  \\n is best suited for you.  \\n Be honest with them about any financial restraints  \\n or concerns you have about medical costs.  \\n Your doctor may even have suggestions  \\n on how to better manage those costs.  \\n Reach out to your doctor's billing department  \\n and ask them if they are within the network  \\n of insurance companies you're considering  \\n and ask their experiences with billing  \\n and having expenses such as yours covered.  \\n After all, if your healthcare professional  \\n has had a positive experience with a plan,  \\n you'll likely be able to keep seeing your trusted physician  \\n and together you'll have a better sense  \\n of what services and care options are covered.  \\n And also set up a call  \\n with your company's health plan representative.  \\n Pay attention to deductibles, per-visit costs  \\n and costs of any medical expenses  \\n or medications you've needed  \\n that you could potentially need again.  \\n And if you require alternative services,  \\n check on this as well before making your final decision.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2416240\",\"duration\":292,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understanding retirement plan options\",\"fileName\":\"2887056_03_02_MM30_retirement\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"This video shows you how to roll over your 401k, 403b, and other retirement plans. Review key timelines, as well as the pros and cons of IRAs. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15291668,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A new job is a fresh start for financial success.  \\n It's an ideal time to set up a financial plan for yourself.  \\n When assessing retirement plans,  \\n take time to understand your options.  \\n For most Americans, company plans such as 401ks,  \\n 403bs and more makeup the biggest savings vehicles  \\n for individuals saving for retirement.  \\n First, when you're considering a job offer ask,  \\n do you have a 401k option at work?  \\n Is it a traditional 401k or a Roth 401k?  \\n These are tax sheltered accounts  \\n that give you a chance to save for your future goals.  \\n And a traditional 401k,  \\n your contributions into your 401k aren't tax initially.  \\n And you continue to save  \\n tax deferred until ideally retirement.  \\n At which point,  \\n what you withdraw will now be taxed.  \\n The Roth 401k is the flip side of this.  \\n In terms of tax treatment,  \\n here you'll be taxed on the front end  \\n and then your money will be tax sheltered while invested.  \\n You'll be able to withdraw all your money tax-free  \\n if you keep your money invested  \\n until age 59 and a half.  \\n If you need to take money from either plan  \\n prior to that age, you can,  \\n but there could be penalties involved.  \\n These plans are so important  \\n because they help you gradually see towards retirement.  \\n This is partly the beauty of compounding interests  \\n which is the interest you earn on interests.  \\n For example, if you have a hundred dollars  \\n and it earns 5% interest each year,  \\n you'll have $105 at the end of the first year.  \\n At the end of the second year though,  \\n you'll have $110 and 25 cents.  \\n Now, if you instead use a regular taxable brokerage account  \\n and you use this money, your growth would be taxed.  \\n However in tax sheltered accounts  \\n like the ones we just mentioned,  \\n you don't pay taxes each year on that compounding growth.  \\n The IRA allows you to shelter your money  \\n until you make a withdraw or distribution.  \\n Additionally, these accounts allow you to name a beneficiary  \\n and a successor beneficiary  \\n so that you and your loved ones  \\n retain rights to the savings.  \\n Other questions I recommend you ask  \\n when assessing the retirement options  \\n are first who are the money managers  \\n of the funds in your 401k investment lineup?  \\n Perhaps your funds are managed  \\n by Fidelity, Vanguard, American Funds for instance.  \\n Second, is there a company match?  \\n Some companies match employee contributions  \\n dollar for dollar, free money  \\n while others put a portion of the company earnings  \\n into a special account for each employee.  \\n Third, how many investments selections do you have?  \\n Investment selections can be best defined  \\n as a various investment choices  \\n that your retirement plan at work offers.  \\n For example, you may have 20 or more mutual funds  \\n that you can select from.  \\n For example, choices could include  \\n an S&P 500 index mutual fund  \\n to international focus funds  \\n like a Euro Pacific Fund to fixed income mutual funds.  \\n You may even have age base or years  \\n until retirement age base bundled mutual funds  \\n to select from.  \\n You'll see these age-based options more now  \\n in company plans,  \\n they are designed to help investors  \\n who don't have a lot of experience selecting mutual funds  \\n what a one size fits all option.  \\n It's important to know though  \\n that these age-based portfolios  \\n tend to be a little higher in cost  \\n because you're adding a portfolio design  \\n and management costs  \\n to the overall mutual fund costs themselves.  \\n Lastly, is there a self-directed option?  \\n This is where you have the ability to choose  \\n from a greater pool of investment choices.  \\n You may be able to invest  \\n your retirement money and choices  \\n beyond the typical 15 to 30 mutual funds  \\n that most company retirement plans offer.  \\n These plans are for you.  \\n One of the easiest opportunities  \\n to save for retirement  \\n on a consistent monthly basis.  \\n Take the opportunity to seek out a financial advisor  \\n at this point and partner to build a diversified  \\n and risk appropriate portfolio.  \\n Always assess your investment time horizon.  \\n That is, how many years until you're likely going to need  \\n to access your money?  \\n With all these scenes in mind,  \\n you'll have the tools  \\n to build a portfolio to reach your future goals.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2419205\",\"duration\":204,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Refreshing your savings goals\",\"fileName\":\"2887056_03_03_MM30_goal\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"This video discusses the importance of making savings a key goal immediately upon landing a new job. It is key to consider your new role as a 90-day temp: get caught back up quick, just in case you decide that new role is not for you!\\n\\n\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10289850,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When you get your new paycheck, it's great to celebrate.  \\n And it's even better to now start saving  \\n with your new edited budget in mind.  \\n Get creative and celebrate in a budget-friendly way.  \\n You may be wondering how much of my new paycheck  \\n should go to savings?  \\n The answer is, it depends.  \\n Here's the first goal I recommend.  \\n Tackle pre-existing credit card debt.  \\n To do this, look at your after tax income  \\n and subtract your monthly necessary expenses  \\n from the budget handout found in the exercise files.  \\n Then take 80% of what's left over and divide it  \\n between saving in your emergency fund and paying  \\n down your highest interest rate credit card balance  \\n or smallest credit card debt amount.  \\n That's a personal choice.  \\n To build your emergency fund, I recommend automatically  \\n transferring money from your checking account  \\n into an account titled emergency fund  \\n for yourself each month.  \\n Open a savings account at the bank for this.  \\n Or you can open up an investment account or Roth IRA  \\n for this purpose.  \\n Target saving six months of living expenses per adult  \\n in your household and three months of living expenses  \\n for each child.  \\n More savings of course is always a bonus.  \\n After you paid off credit cards and saved an emergency fund,  \\n max out your contributions to your new 401k.  \\n Don't leave free money on the table.  \\n If your employer offers a company match into your 401k  \\n make sure you contribute at least that much  \\n towards your retirement savings.  \\n But my recommendation is to at least double that amount.  \\n If your employer is offering a 4% match,  \\n contribute a minimum of 8%.  \\n A financial advisor will be very meaningful  \\n for you again, here.  \\n Moving forward, continue the same habits you formed  \\n during your career transition.  \\n Don't buy things that you already have  \\n that are sufficient for your job.  \\n Before making that next purchase,  \\n is this a need or is this a want?  \\n Ask yourself what would give you the financial freedom  \\n in the future?  \\n Making more doesn't need to equate to spending more.  \\n This way you have something positive to save for  \\n versus feeling like your savings budgeting  \\n is a terrible sacrifice.  \\n Maybe this means saving for a grand vacation.  \\n Helping your child attend college.  \\n Maybe it's even giving you the freedom to retire early.  \\n Whatever it is, list it out, label those accounts  \\n and set up automatic contributions to those goal accounts.  \\n Take the time to list out all your top financial goals  \\n and invite your household to do the same.  \\n Be an example for your household and create a family goal  \\n to celebrate with.  \\n Rank your top three goals and set in process  \\n to meet those goals.  \\n In my family, we keep our monthly expenses pretty tight.  \\n But we have one common savings goal  \\n and that's a family vacation.  \\n And we are all on the same page and all our efforts  \\n come together to reach that goal and create new memories.  \\n \\n\\n\"}],\"name\":\"3. Your Finances and Starting a New Job\",\"size\":36081547,\"urn\":\"urn:li:learningContentChapter:2414282\"},{\"duration\":77,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2418239\",\"duration\":77,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Committing to lifelong learning\",\"fileName\":\"2887056_04_01_MM30_learning\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5162342,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Thank you so much for spending the time  \\n to empower yourself during your job transition.  \\n Don't forget to continuously invest in yourself,  \\n even when you have obtained a new job  \\n and seek out ways that don't cost you  \\n a significant investment.  \\n You could take an online course to master another skill  \\n that could potentially create more income,  \\n a job promotion, and more.  \\n Beef up your social media personal brand.  \\n Take the time to update your LinkedIn profile  \\n and create posts that illustrate  \\n your experience and expertise.  \\n Connect with other professionals in your industry.  \\n To learn more about me and to set up  \\n a complimentary financial advisor consultation,  \\n please visit sungroupwp.com.  \\n We work with clients all across the country  \\n and you can even reach out to have us speak personally  \\n for a group or a company.  \\n I encourage you to continue learning  \\n by checking out other courses on LinkedIn Learning,  \\n like Updating your LinkedIn Profile for a Career Search.  \\n It's an honor to serve as your guide  \\n and I sincerely hope that this gives you some tools  \\n to make the best decision for you  \\n during your own transition.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":5162342,\"urn\":\"urn:li:learningContentChapter:2414283\"}],\"size\":119757857,\"duration\":2088,\"zeroBased\":false},{\"course_title\":\"Navigating Your Career Through Restructuring, Layoffs, and Furloughs\",\"course_admin_id\":3002210,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3002210,\"Project ID\":null,\"Course Name\":\"Navigating Your Career Through Restructuring, Layoffs, and Furloughs\",\"Course Name EN\":\"Navigating Your Career Through Restructuring, Layoffs, and Furloughs\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"The COVID-19 pandemic has changed the workplace dramatically. You\u00e2\u20ac\u2122ve had to adapt to working remotely and independently, but also to facing increased chances of restructurings, layoffs, and furloughs. In this course, career coach Chris Taylor helps you navigate the rapidly changing workplace, giving you tools to understand what\u00e2\u20ac\u2122s happening in your work environment, and teaching you how to turn uncertainty to your future benefit.&lt;br&gt;&lt;br&gt;Learn how to recognize shifts in workplace dynamics, and then how to reframe mentally for what\u00e2\u20ac\u2122s next. Restructurings, layoffs, and furloughs are understandably intimidating, but they\u00e2\u20ac\u2122re also opportunities for growth and new experiences, especially if you know how to leverage your environment in a positive way. Chris helps you showcase your value as an employee, network  within your organization, and update your job search materials for new opportunities. Upon finishing this course, you\u00e2\u20ac\u2122ll have the tools to not only survive in the rapidly changing workplace, but also thrive.\",\"Course Short Description\":\"Reclaim your power in a rapidly changing workplace. Learn how to recognize shifts in workplace dynamics and turn uncertainty to your future benefit.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20517005,\"Instructor Name\":\"Christopher Allen Taylor\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Career coach helping people get noticed and get hired\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2022-01-28T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/navigating-your-career-through-restructuring-layoffs-and-furloughs\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"General\",\"LI Level EN\":\"General\",\"Sensitivity\":null,\"Internal Library\":\"Business\",\"Internal Subject\":\"Career Development\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":2307.0,\"Visible Video Count\":11.0,\"Contract Type\":\"STANDARD\"},\"sections\":[{\"duration\":84,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3048174\",\"duration\":84,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Adapt to an unpredictable workplace\",\"fileName\":\"3002210_en_US_00_01_WL30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1568301,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Chris] The only constant in life is change.  \\n Now you may have heard this before.  \\n But it doesn't just apply to life,  \\n it applies to your career too.  \\n Every career has twists and turns  \\n we never would have expected.  \\n And in many cases, those turns come in the form  \\n of a restructuring, lay off of furlough.  \\n You thought that you were in a job  \\n where you could continue to grow and thrive.  \\n But when word gets around that your company  \\n may be in the midst of major changes,  \\n it feels like the rug has been pulled out from under you.  \\n Now if this is where you find yourself, don't worry.  \\n These circumstances aren't always bad news.  \\n I'm Chris Taylor, also known as the Occupation Optimist,  \\n and I'm a career development specialist  \\n who works with professionals from entry level  \\n to executive level on a daily basis.  \\n To help them define their goals  \\n and build the careers of their dreams.  \\n I've seen countless clients come through restructurings  \\n and end up in a better place than they were before.  \\n I've even been through multiple restructurings of my own.  \\n So I've seen and experienced these transitions firsthand.  \\n In my LinkedIn learning course, I'm going to help you  \\n understand the dynamics of these types of workplace changes.  \\n And share with you concrete strategies  \\n to improve your situation  \\n if your employer goes through a restructuring.  \\n So settle in, get comfortable and join me as we explore  \\n how to navigate your career  \\n through restructurings, layoffs or furloughs.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":1568301,\"urn\":\"urn:li:learningContentChapter:3047164\"},{\"duration\":672,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3046163\",\"duration\":232,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Types of shifts in the workplace\",\"fileName\":\"3002210_en_US_01_01_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Restructurings, layoffs, and furloughs are all unique shifts in your workplace that need to be faced differently. In this video, learn about these changes and how they differ.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3513396,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - In my job as a career counselor,  \\n I work with clients on a daily basis  \\n who are facing the stressful uncertainties of job loss.  \\n Some are reaching out to me preemptively  \\n because they can sense the change is coming,  \\n and others have already been downsized.  \\n Either way, they've found themselves  \\n in the time-sensitive job hunt  \\n that nearly everyone has feared or encountered  \\n at some point in time in their career.  \\n Now, if you find yourself in this situation,  \\n the first hurdle is to understand the types of job loss  \\n or job change that may happen so that you can be prepared.  \\n Now, the three most common possibilities are  \\n restructurings, layoffs, and furloughs,  \\n so let's take a closer look at each one.  \\n A restructuring is a process that a company goes through  \\n when it assesses and reorganizes its workforce.  \\n Now truth be told, it's almost inevitable  \\n that you'll go through at least one or two restructurings  \\n throughout your career, and in fact,  \\n many Fortune 500 companies do some restructuring every year.  \\n If your company restructures,  \\n your position could stay exactly the same,  \\n you could find yourself on a different team  \\n or with a different leadership,  \\n or your position could be eliminated entirely.  \\n Now, a layoff, on the other hand,  \\n is more directly focused on  \\n reducing the workforce in your company.  \\n Companies often go through a wave of layoffs,  \\n they can't financially support their workforce,  \\n if they're shifting their business goals or their services,  \\n if they're changing locations,  \\n or if they're going through some other type of change.  \\n In other words, if you're going through a layoff,  \\n it's generally no fault of your own.  \\n Often it's just a straightforward matter  \\n of finances or logistics.  \\n And finally, a furlough is a unique type of job loss.  \\n A furlough is essentially a mandatory leave of absence  \\n in which you're no longer getting paid  \\n or working for the company,  \\n but you stay on employment roles.  \\n The intention is for the company to save money  \\n during a financially difficult time or a slow time,  \\n but to bring you back on as an employee  \\n when work actually picks up again.  \\n Unfortunately some furloughs do lead to permanent layoffs.  \\n Now, during the COVID-19 pandemic, for example,  \\n many employees were furloughed because employers didn't know  \\n what to expect from the economic crisis  \\n or how long the crisis would last.  \\n When companies start to consider or talk about  \\n restructurings, layoffs, or furloughs,  \\n it tends to cause quite a disruption  \\n in the work environment, and understandably so  \\n because people are worried about their livelihoods.  \\n Each of these shifts can happen in different  \\n and unpredictable ways.  \\n Sometimes they move more slowly  \\n while other times they seem to come  \\n clearly out of the blue sky.  \\n The bad news is that as the economy continues to recover  \\n from the turmoil of the COVID-19 pandemic,  \\n restructuring and reorganizing efforts  \\n are not expected to end any time soon.  \\n In fact, corporate giants like PWC and KPMG  \\n have publicized their expectations  \\n for corporate restructurings across many industries  \\n to continue for quite some time.  \\n The good news is that no matter what happens,  \\n you can come through a restructuring, a layoff,  \\n or a furlough in a way that preserves your career  \\n or even propels it forward.  \\n In my years of working in sales and recruiting  \\n before I began focusing on career coaching,  \\n I personally went through four restructurings,  \\n including one layoff.  \\n I've experienced the full range of emotions  \\n that come from these tricky situations,  \\n uncertainty, anger and frustration, confidence,  \\n and even excitement for what the next chapter would bring.  \\n I still look back at my layoff as a stressful  \\n and upsetting experience, but all these years later,  \\n I recognize that it was actually  \\n one of the greatest blessings in my life  \\n because it gave me the opportunity and necessity  \\n to turn my career in a direction  \\n I was truly passionate about  \\n and not just one that paid the bills.  \\n You, too can use your changing workplace  \\n as a stepping stone or even a springboard.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3044143\",\"duration\":253,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Recognize shifts in workplace dynamics\",\"fileName\":\"3002210_en_US_01_02_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Restructurings and other changes cause important shifts in workplace dynamics. In this video, learn about these changing dynamics and the signs of shifts ahead.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3821682,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - If you're feeling fulfilled and productive at your job,  \\n and then you're hit with the news  \\n of an upcoming restructuring lay off or furlough,  \\n it can feel like the rug has been pulled out from under you.  \\n It's like being in a relationship that you thought was going  \\n great until you hear the other person say, we need to talk.  \\n The truth is that these types of changes  \\n in the workplace never happen spontaneously.  \\n There are many factors that can lead to them ,  \\n like financial strain, a changing industry,  \\n or redirection of the company's goals, and so much more.  \\n If you're feeling that the wind has been knocked out of you,  \\n even if you're in a position that's still intact so far,  \\n you can ground yourself and get a better read on  \\n what to expect if you try to understand the dynamics  \\n of this new shift.  \\n Sometimes your company will come out candidly  \\n and tell you exactly why they're rethinking their workforce.  \\n That's especially true for smaller companies who tend to  \\n have more of a personal connection to their employees.  \\n Larger companies, on the other hand,  \\n have a lot more to consider in terms of their public image.  \\n They're more likely to announce restructurings,  \\n layoffs, and furloughs and widespread press releases  \\n that are designed more to save face  \\n than to communicate honestly with employees.  \\n Let's look at some of the top reasons your company  \\n may be reorganizing or downsizing their teams  \\n and learn how to recognize these changes  \\n and understand where they're coming from.  \\n First financial difficulty.  \\n This is an incredibly common reason for companies  \\n to downside their workforces,  \\n especially during the recent economic strain  \\n of the COVID-19 pandemic.  \\n For many types of businesses labor is their largest expense,  \\n so when the revenue drops significantly,  \\n they tend to cut down on their labor costs  \\n in order to remain financially stable.  \\n In many cases, there are signs for drop in revenue  \\n before companies reached the point of downsizing.  \\n You may have received memos about cutting the budget  \\n in other areas like supplies or discretionary spending.  \\n If your company is publicly traded  \\n you can check out its quarterly reports  \\n to see if revenue is dropping.  \\n Of course, none of these signals of lacking revenue  \\n necessarily mean there will be downsizing,  \\n but they can give you a heads up.  \\n A second reason for change in workforce  \\n is a shift in the industry or the marketplace.  \\n For example, maybe you work for an industry  \\n where new technology is on the rise  \\n and consumers are more interested in the new gadgets  \\n than in your more traditional products.  \\n To protect its revenues, your company may go through a shift  \\n to grow its technology teams while downsizing  \\n the teams that work on the traditional products.  \\n A great way to sense these changes are in the works  \\n is to keep an eye on industry journals  \\n and trends they're noticing.  \\n And you can also watch out for shifts  \\n in the company's marketing efforts,  \\n like putting out more ads for their high-tech products.  \\n A third reason for workforce changes  \\n are more cut and dry, a merger or an acquisition.  \\n If your company is merged with  \\n or has been purchased by another company,  \\n especially if that company is larger than yours,  \\n it's common for the acquiring company  \\n to adjust your workforce so that you're more aligned  \\n with their goals, and so that you're not duplicating  \\n the work of teams they already have.  \\n You'll generally know about mergers and acquisitions  \\n ahead of time because companies will announce them  \\n internally and sometimes externally too.  \\n Finally, a fourth common reason for restructurings, layoffs,  \\n and furloughs is a change in leadership.  \\n If your key leaders like the CEO,  \\n COO, CFO, or Board of Directors members have changed,  \\n they may decide to take the company a different direction  \\n than its current path.  \\n When your company announces changes  \\n to these leadership positions,  \\n look for signs of changing goals,  \\n like significant shifts in the budget  \\n or a hiring push in one particular segment of the business.  \\n It's important to note that some restructurings,  \\n layoffs, and furloughs are more sudden than others  \\n and not all of them will have noticeable signs.  \\n But now that you know some key indicators to look for,  \\n you're more likely to be able to keep an awareness  \\n of your workplace and prepare for possible changes  \\n in downsizing well in advance.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3046164\",\"duration\":187,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Mentally reframe your changing workplace\",\"fileName\":\"3002210_en_US_01_03_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Layoffs and furloughs are understandably intimidating, but you can turn them into opportunities for growth instead. In this video, learn how to leverage your shifting work environment positively.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2847294,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - There's no way around it.  \\n When you first hear that your workplace  \\n is going through a restructuring layoff or furlough,  \\n it's always jarring and stressful.  \\n One day you had a solid job  \\n and you knew all your bills would be paid,  \\n and the next day you're wondering  \\n if it'll be months before you see that next paycheck.  \\n If you're one of the 69% of US adults  \\n who has less than $1,000 in savings,  \\n it's especially stressful  \\n because you have little or no ability  \\n to support yourself during that employment gap.  \\n First of all, let's be clear,  \\n there's nothing wrong with feeling stressed  \\n or upset about a potential job loss.  \\n It's a very difficult situation  \\n and nearly all of us have felt this distress  \\n at some point in our careers.  \\n But after you take a little time  \\n to acknowledge and confront your worries,  \\n pushing your mindset toward focusing on the positive  \\n can make all the difference in your situation.  \\n In fact, there are plenty of reasons  \\n to feel optimistic about your workplace changes.  \\n If you're in the anticipatory stage,  \\n meaning that you expect or know  \\n that restructurings are coming  \\n but they haven't yet happened,  \\n there could be new internal opportunities heading your way.  \\n For example, if your position is eliminated,  \\n the company may offer you a position on a different team  \\n that could actually fit your career goals better,  \\n or could present a faster path toward a promotion.  \\n You could even end up with a direct promotion  \\n as a result of the restructuring.  \\n Your manager could move up in the company  \\n or move to a different department,  \\n freeing up their previous role for you to cease.  \\n I've seen it firsthand, people who feared their jobs  \\n disappearing due to a restructuring.  \\n And they went into a meeting with leadership,  \\n expecting to be laid off,  \\n but came out with the promotion instead.  \\n I've also seen others whose responsibilities or goals  \\n for their position change due to a restructuring,  \\n and this led them to discover new passions  \\n and aspirations they never knew existed.  \\n It opened the door to a whole new career path they loved,  \\n but may not have discovered otherwise.  \\n Even if your company's restructuring ends up  \\n with what you believe is the worst possible result,  \\n being laid off,  \\n this could be a blessing in disguise.  \\n You can now have the opportunity to pursue other companies,  \\n other career paths and other positions  \\n that you may be interested in  \\n because you no longer have to worry  \\n about losing your current job in the process.  \\n In fact, if you're not in love with your job,  \\n a lay off could be the best possible scenario.  \\n You have a free schedule for job hunting,  \\n oftentimes with severance pay  \\n to help you support yourself in the meantime,  \\n and you're not at fault for your job loss  \\n so it won't reflect poorly on your future job search.  \\n At the risk of sounding cheesy,  \\n you're free to find the job of your dreams.  \\n Adjusting your mindset  \\n about a restructuring lay off or furlough  \\n could be the motivation you need  \\n to truly make the most of this new change in your life.  \\n But how exactly do you do that?  \\n Throughout the upcoming chapter,  \\n we'll dig into the specifics  \\n of how to transform your changing workplace  \\n into an opportunity for growth.  \\n \\n\\n\"}],\"name\":\"1. Understanding the Changing Atmosphere of the Workplace\",\"size\":10182372,\"urn\":\"urn:li:learningContentChapter:3045141\"},{\"duration\":761,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3048175\",\"duration\":223,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Showcase your value as an employee\",\"fileName\":\"3002210_en_US_02_01_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn the value you hold as an employee and how to demonstrate it to your managers. With this skill, be more likely to maintain your job security amid restructurings.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3369215,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - If you've seen signs that a restructuring, lay off,  \\n or furlough is coming to your workplace,  \\n your first instinct is to probably look for ways  \\n to protect your job.  \\n Sure, the final decision is out of your control,  \\n but there are steps that you can take to make it more likely  \\n that you'll be among the lucky ones.  \\n Ultimately, the goal is to show your value  \\n to your employer so that they'll see you as an asset  \\n that they currently have on board.  \\n There are a few steps involved in doing this effectively.  \\n Step one is identifying  \\n and establishing your personal brand.  \\n What is it that makes you stand out in the workplace?  \\n Maybe you're the one who's always organized  \\n and on top of tasks  \\n so your boss knows that if they give you a project,  \\n it'll get done a week before the deadline,  \\n or maybe you're the ultimate problem solver,  \\n the one who never says, \\\"this can't be done\\\",  \\n but always says, \\\"how can I do this?\\\"  \\n Figure out what it is that sets you apart  \\n and makes you a necessary piece of the office's framework.  \\n If you're not quite sure what your personal brand is,  \\n there's a handy guide to help you  \\n in my previous LinkedIn learning course,  \\n Digital Networking Strategies.  \\n Once you've defined your personal brand,  \\n make sure you're leaning into that brand  \\n so that your coworkers  \\n and employers will recognize your strengths.  \\n The second step is figuring out what specific skills  \\n or experiences you have that make you an unmatched asset  \\n in the workplace.  \\n Pull out your resume  \\n and compile as many concrete accomplishments as you can  \\n for your current job,  \\n as well as the jobs that you've held in the past.  \\n Think about unique pieces not everyone has.  \\n Maybe there's a challenging hurdle that you were able  \\n to overcome or perhaps a task or a piece of technology  \\n that you have experience with that few others do.  \\n Now with a handle on the personal brand  \\n and past experiences that make you an asset,  \\n your third step is to make sure the right people  \\n in your company know about these great qualities.  \\n We want all of our coworkers to respect us,  \\n but it's the top leaders who will be deciding who stays  \\n and who goes so they're the ones who need  \\n to see your value the most.  \\n Your boss may meet with each person  \\n to discuss their positive qualities  \\n and see where they fit into the new corporate structure,  \\n but don't wait until an invitation comes through.  \\n One way to show the leaders your value is by  \\n just telling them outright.  \\n I had a client that got wind of the fact  \\n that his company was looking  \\n to make a major cut in headcount  \\n and as a new member of the leadership team  \\n at a small financial institution,  \\n he scheduled a time with the CEO  \\n to lay out the nature and importance  \\n as well as the impact of his role.  \\n The meeting led to the CEO suggesting a full day  \\n of shadowing to get to grasp his day-to-day duties.  \\n This enabled my client to truly show off his value.  \\n Now at your company booking time with the CEO  \\n may not be realistic,  \\n but you can set up time to sit down with leadership.  \\n Another option is to look for ways  \\n to show off your knowledge and capabilities  \\n by leading your other co-workers.  \\n Talk to your boss about leading training sessions  \\n for your colleagues, for example  \\n or pitch new ideas to propel the company forward  \\n like new marketing angles to pursue  \\n or new products and services.  \\n You could even take initiative of drawing up a 90 day plan  \\n to strengthen your department or your company  \\n and present these ideas to your boss.  \\n Any of these will show that you're someone willing  \\n to step outside of the box and that you take initiative  \\n to improve the business.  \\n Using this three-step process  \\n of establishing your personal brand,  \\n knowing the experiences that set you apart,  \\n and showing yourself to be a leader  \\n in these areas can go a long way  \\n toward helping you protect your job during uncertain times.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3044144\",\"duration\":207,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Network within your organization\",\"fileName\":\"3002210_en_US_02_02_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Networking internally allows you to keep tabs on the changes in your workplace while also opening doors for future jobs. In this video, learn how to build a network within your office community.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3137300,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - You've probably heard the saying  \\n when it comes to your career,  \\n it's not about what you know, it's about who you know.  \\n That's not just true when it comes to job searching,  \\n it's true when you're trying to keep your job  \\n during a shift in your workplace too.  \\n Indeed it helps to network with the top leaders  \\n and decision makers in your company  \\n because if they know you,  \\n they're less likely to let you off.  \\n But there are reasons to network  \\n with others in your organization too.  \\n Getting to know middle managers  \\n could help send your name up the ladder in a positive way  \\n and it could even put you in the know  \\n about the latest updates in the restructuring plan.  \\n Networking with your peers is an effective strategy too.  \\n You never know who has connections to the higher levels  \\n in the company and could advocate on your behalf.  \\n In a restructuring, those who are your peers today  \\n could be your managers tomorrow as well.  \\n Even in the worst case scenario,  \\n if your position is eliminated,  \\n every person you've networked with  \\n both inside and outside of your organization  \\n could have leads on exciting jobs you love.  \\n There are right ways and wrong ways to network though.  \\n Follow these tips to make sure  \\n you're giving your future self a helpful hand.  \\n First, choose your setting wisely  \\n and don't put too much pressure into the conversation.  \\n Networking is all about building mutual connections  \\n with people that you genuinely  \\n want the best for and vice versa.  \\n Strike up a casual yet positive conversation  \\n in a relaxed, comfortable setting  \\n like a company-wide lunch or by the office coffee pot.  \\n Second, make sure you don't say anything  \\n that paints you in a negative light.  \\n Don't try to pull a gossip out of the person for example.  \\n If they do start chatting and sharing information  \\n about the restructuring, take it with a grain of salt.  \\n You never know when someone is just repeating a rumor,  \\n so don't stake your career on what you hear.  \\n Third, don't wait for networking opportunities  \\n to come your way.  \\n Invite colleagues out for a team lunch, for example,  \\n or for happy hour after work,  \\n you can also get involved  \\n in any applicable employee resource groups in your company.  \\n Any of these are great ways to get to know your colleagues  \\n in a setting that's not exclusively work focused.  \\n Fourth, look for mentoring relationships.  \\n Talk to your manager,  \\n or other company leaders within the department  \\n or within your career path.  \\n Ask them out for coffee to get to know them  \\n and get their insights on the ways  \\n that you can grow your career.  \\n This is a great way to build strong connections,  \\n develop your career and make it clear,  \\n that you're a motivated growth minded person  \\n who takes initiative.  \\n Fifth, think about other departments or teams  \\n within your company that you may be interested in joining.  \\n Get in touch with the managers and leaders of these teams  \\n and let them know that you have an interest  \\n in their department so that if you are downsized,  \\n you already have a foot in the door for a new opportunity.  \\n I've personally seen people who have networked in this way  \\n during a restructuring receive the dreaded pink slip  \\n and secured an interview ultimately leading to a position  \\n with another team in the same company, almost immediately  \\n purely because their networking created an inroad.  \\n Internal networking is one of  \\n the most beneficial strategies to use  \\n when you sense coming changes in your workplace  \\n because it can lower your risk of losing your job  \\n and even if you do lose your job,  \\n the same networking may very well help you find a new one.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3043169\",\"duration\":331,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Update your job search materials\",\"fileName\":\"3002210_en_US_02_03_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Taking the time to prepare for a future job search allows you to take advantage of better opportunities before you. In this video, learn how to take immediate steps to update your resume and LinkedIn profile.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4991034,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - If your company is in the midst  \\n of a restructuring, lay off, or furlough,  \\n the reality is that while showing your value as an employee  \\n and networking within the organization can help,  \\n there are never any guarantees that you'll keep your job.  \\n Talk to some of the most successful  \\n and competent people you know,  \\n and it's quite certain that many of them have been laid off  \\n at some point in the past.  \\n For that reason,  \\n even as you're taking steps to protect your job,  \\n it's always a good idea to ensure  \\n that your job search materials are updated and ready to go.  \\n That way, if you do find yourself on the job market,  \\n you can hit the ground running.  \\n The two most important pieces to prepare  \\n are your resume and your LinkedIn profile.  \\n Some positions may also warrant other documents,  \\n like a portfolio of your creative work,  \\n but regardless, your resume and LinkedIn profile  \\n are the most essential pieces you need to get started.  \\n Let's dig into a few tips for updating these materials  \\n during a time of transition in your workplace.  \\n We'll begin with your resume.  \\n First things first, toss out that old rule  \\n that resumes can only be one page long.  \\n One page may be appropriate  \\n if you've only had one or two jobs in your career,  \\n but for anyone who is at the mid-career level or above,  \\n two pages is perfectly acceptable  \\n and it gives you space  \\n to actually show your accomplishments.  \\n Three pages is even acceptable  \\n for senior-level or executive-level positions.  \\n The key with your resume is to focus more  \\n on showing the concrete impact you've had within each job,  \\n rather than listing the duties you performed.  \\n Employers today want to see results,  \\n and the best way to do this  \\n is by getting quantifiable data as often as possible.  \\n For example, instead of saying,  \\n \\\"Developed strategic marketing campaigns,\\\"  \\n your resume could say,  \\n \\\"Drove 10% revenue growth year over year  \\n through strategic marketing campaigns.\\\"  \\n Remember that if you don't have exact data,  \\n estimates are fine as long as they're honest.  \\n As you're building your resume,  \\n don't forget to include keywords  \\n that will help your resume appear  \\n when employers and recruiters search online databases.  \\n These keywords are most often in the form of skills.  \\n For instance, if you're in marketing  \\n like the person in the last example,  \\n you could include a key skills list  \\n and include marketing skills  \\n like search engine optimization,  \\n pay-per-click advertising, website analytics, and so on.  \\n Once you have a powerful resume  \\n that shows the concrete impact  \\n you've made for your employers,  \\n it's time to move on to your LinkedIn profile.  \\n The goal is to have a profile that is visually appealing  \\n and presents a snapshot of your expertise  \\n and your most impressive accomplishments,  \\n so that it reels in recruiters and employers.  \\n Plus, with a LinkedIn profile that's optimized in this way,  \\n when you network with colleagues online,  \\n they'll have a better view of your strengths,  \\n so that if they hear of an opportunity  \\n that may be of a good fit for you,  \\n you'll come to mind.  \\n Start by focusing on the first pieces that people see,  \\n your photo and your headline.  \\n Make sure your photo looks professional and positive,  \\n and ideally make sure it fits well with your personal brand.  \\n For your headline,  \\n go beyond simply your job title,  \\n and make sure it speaks to three key areas.  \\n One, where you've been, two, where you are now,  \\n and three, and most importantly,  \\n where you're looking to go in your career,  \\n all while ensuring that it's as searchable as possible.  \\n For instance, try using the vertical line,  \\n called the pipe character,  \\n which is the Shift + Backslash on most keyboards,  \\n for a headline like, \\\"Digital Marketing- pipe-  \\n Product Marketing; Brand Marketing;  \\n Content Strategy; Consulting.\\\"  \\n Once you've got your photo and headline dialed in,  \\n it's time to move on to the experience section.  \\n You've already done the hard work  \\n of gathering data for your resume.  \\n The bullet points in your LinkedIn profile  \\n should just be reworded versions  \\n of the bullet points on your resume.  \\n You can word your bullets in a less formal way for LinkedIn,  \\n because it's a less formal medium.  \\n Finally, an often overlooked,  \\n but critical part of a LinkedIn profile  \\n are your recommendations.  \\n Think of these as small recommendation letters  \\n or reviews of you as a professional.  \\n Now is the time to start pulling in  \\n as many recommendations as possible.  \\n Talk to colleagues, past employers,  \\n possibly even vendors or external partners  \\n that you coordinate with at work,  \\n and anyone else who knows your professional expertise  \\n and ask them to post a recommendation for you.  \\n Preparing your job search materials before you need them  \\n is a practical way to make sure  \\n that if you do lose your job,  \\n you're ready to jump directly into the job market.  \\n But it's also a confidence booster,  \\n because you're taking stock  \\n of all the accomplishments and experiences  \\n that make you a fantastic asset to any company.  \\n You can even use those newly recognized achievements  \\n as talking points with your boss,  \\n as you're showcasing your value.  \\n Getting these job search materials in place  \\n will set you up for success  \\n no matter where the transitions in the workplace take you.  \\n Whether you're using them  \\n to start opening yourself up to new jobs,  \\n or put a spotlight on your talent for your current boss,  \\n preparing those materials  \\n will be a step in the right direction.  \\n \\n\\n\"}],\"name\":\"2. Preparing for the Uncertainty of Job Changes\",\"size\":11497549,\"urn\":\"urn:li:learningContentChapter:3046165\"},{\"duration\":628,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3041162\",\"duration\":176,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Start your job search\",\"fileName\":\"3002210_en_US_03_01_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"The best time to launch a job search is when you still have a job because it gives you the upper hand. In this video, learn the steps you can take to jumpstart your job search before layoffs and furloughs begin.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2675641,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Most of the strategies I've given you  \\n throughout this course so far, have been what if strategies.  \\n Through all about what you can do,  \\n if you aren't sure how restructuring is going to play out.  \\n Sometimes you stay in the dark the entire time,  \\n you don't expect to be downsized until you are.  \\n But other times you'll reach a point  \\n when it seems more likely than not  \\n that a pink slip is on the way.  \\n What do you do if you think you'll soon be downsized?  \\n First of all, don't panic.  \\n You're a skilled professional who knows what you're doing  \\n and one way or another things will work out.  \\n If you find yourself in this situation,  \\n one of the best things you can do  \\n is to start your job search proactively.  \\n It's not too early to start putting out feelers  \\n for new opportunities.  \\n In fact, it's better to look for a job  \\n while you're still employed,  \\n because you have the upper hand.  \\n You don't have to accept the first offer that comes your way  \\n and even if you like the first job you are offered,  \\n you have time to negotiate  \\n before your savings start to deplete.  \\n It's also far more empowering and stress reducing  \\n to kickoff the job search while you're still employed.  \\n You feel like you're taking back your power  \\n and taking control over the next steps in your life,  \\n rather than waiting for your current employer to decide.  \\n Besides it can take months to secure the right role  \\n and it's always better to start the process  \\n while you still have a paycheck coming in.  \\n The first step of your job search  \\n is preparing an up-to-date impactful resume  \\n and a LinkedIn profile that's sure to catch anyone's eyes.  \\n Once you've done that,  \\n the next step is to put your network to work.  \\n Tell colleagues in your industry  \\n that you're open to new opportunities.  \\n You may feel comfortable letting your coworkers  \\n know about this too,  \\n but if not other connections in your industry  \\n can be tremendously helpful.  \\n Let them know what you're looking for  \\n and ask if they're willing to let you know  \\n about any job openings they may hear about.  \\n Now, speaking and networking,  \\n now is the time to get more active on LinkedIn,  \\n so that your name crosses more recruiters eyes.  \\n First, go into your LinkedIn profile  \\n and change your settings  \\n to show that you're open to new opportunities.  \\n Then start posting regularly and interacting  \\n with other people's posts as well.  \\n Every post or interaction makes your profile  \\n more likely to be part of the right recruiters newsfeeds  \\n and from there,  \\n your dream job could be just right around the corner.  \\n Now, along with networking,  \\n you can move your job search forward  \\n with the age old process of searching online  \\n for job openings and applying for them.  \\n Look for job boards that specialize in your industry  \\n as well as general job boards, like LinkedIn,  \\n monster.com, Indeed and so on.  \\n Remember that starting your job search  \\n before you've been downsized,  \\n is all about giving yourself options.  \\n You don't need to be prepared to commit to anything.  \\n You're just opening doors and putting yourself out there  \\n so that if the right opportunity comes along,  \\n you're ready to take the leap.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3043170\",\"duration\":231,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Make use of headhunters\",\"fileName\":\"3002210_en_US_03_02_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Headhunters can offer leads on unique opportunities that are not yet public while minimizing your workload. In this video, learn how to best use headhunters in your job search.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3495842,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When people think of job searching,  \\n their first thought  \\n usually goes to the traditional job hunting process,  \\n finding job openings and submitting applications.  \\n While that should certainly  \\n be a part of the job hunt strategy,  \\n there's another valuable technique  \\n that's extremely underutilized,  \\n working with headhunters.  \\n If you're not familiar,  \\n a headhunter is essentially an independent recruiter.  \\n They work for headhunting firms,  \\n or more commonly known as recruiting agencies  \\n that are contracted by companies to fill certain roles.  \\n Now, this is different from a traditional recruiter  \\n who's usually someone who is employed full-time  \\n by one company and is filling a variety of roles  \\n within that same company.  \\n You may have heard headhunters use terms  \\n like \\\"executive search\\\"  \\n because they're often hired to fill high level positions,  \\n but there are plenty that are hired to fill roles  \\n at all professional levels.  \\n Now why are headhunter's such a valuable resource  \\n for professionals like you?  \\n There are a few reasons, actually.  \\n First of all, it takes a lot of time and work  \\n to hunt down job openings  \\n with wonderful growth minded companies  \\n that fit your strengths.  \\n When you're still employed and looking for a full-time job,  \\n job searching is a lot of time to add to your plate.  \\n Headhunters however,  \\n can take a lot of that time and work off your hands  \\n as they bring opportunities directly to you.  \\n Second, many of the positions  \\n that companies are hiring headhunters to fill  \\n are not publicly posted,  \\n after all headhunters specialize  \\n in identifying the best talent to fit any role,  \\n usually by using their very robust professional networks  \\n and companies would prefer to have headhunters  \\n bringing them top talent,  \\n rather than sorting through a pile of job applications.  \\n Ultimately, this means  \\n that if you are in contact with headhunters,  \\n you could get job leads that you'd never find  \\n by searching online on your own.  \\n Now here's the tricky part.  \\n How do you actually connect with headhunters  \\n so that you can make use of them in your job search?  \\n It's a lot easier than you think,  \\n message them on LinkedIn.  \\n Start by writing a quick but effective script  \\n that you can send each headhunter that you find,  \\n it should be brief, no more than a few short paragraphs.  \\n Now within the script, you should introduce yourself,  \\n explain your top qualities that make you an asset.  \\n And here's an example.  \\n Good morning, Ms. Smith.  \\n I'm an electrical engineer  \\n with 15 years of experience at cutting edge companies,  \\n including Intel and Apple,  \\n and I'm looking for the next chapter of my career.  \\n I love to connect and get to know you  \\n in case that I may be a fit for any current  \\n or future roles you may have available.  \\n It's quick and to the point,  \\n but that's all that it needs to be.  \\n Now, when you have that script ready to go  \\n start looking for headhunters,  \\n specifically search for these professionals on LinkedIn,  \\n who are in your local area and specialize in your field.  \\n Aim to identify 20 or more headhunters,  \\n when you find them just send them a connection request  \\n and in the process, add your script as a note  \\n that accompanies the connection request.  \\n If you've been following along throughout this course,  \\n your LinkedIn profile is already set up  \\n to impress those headhunters from their first click.  \\n If you haven't updated your profile yet,  \\n make sure that you do so before connecting with headhunters  \\n so that you're making the right first impression.  \\n Remember you can also find headhunters  \\n through other sources and email them,  \\n but if you do, make sure that you attach your resume,  \\n and include a link to your LinkedIn profile.  \\n Between headhunters and more traditional job hunt strategies  \\n like networking and submitting applications,  \\n it's just a matter of time  \\n before you connect with a great opportunity.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3045140\",\"duration\":221,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Leverage your employment options\",\"fileName\":\"3002210_en_US_03_03_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"When you're still employed while looking for a job, you have more negotiating power with new employers and your current employer. In this video, learn how to leverage your current work status to your benefit.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3351385,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - At this point, you're moving forward with your job search  \\n with the realization that you may be downsized  \\n in your workplace's restructuring, lay off, or furlough.  \\n This can be a stressful time,  \\n but you have a unique advantage.  \\n If you're still employed  \\n while you're looking for a new position,  \\n you can leverage this to benefit both your new job search  \\n and your position with your current company.  \\n But this brings up another question.  \\n If you're offered a new job while you're still employed,  \\n what do you do?  \\n Do you have to accept the new offer,  \\n or can you decide to keep your current job after all?  \\n You actually have more options here than you may realize.  \\n First, let's talk about how you can leverage your position  \\n of power as you're looking for a new role.  \\n From the start,  \\n you're a more attractive candidate for potential employers  \\n when you already have a full-time job.  \\n It creates the perception that you're in demand  \\n and you're someone who's worth competing for.  \\n Now, on the flip side,  \\n if you wait until you're unemployed  \\n to look for a new position,  \\n employers will inevitably wonder  \\n why your last company didn't keep you.  \\n Even if you were downsized through no fault of your own,  \\n the question is still there.  \\n Because of this,  \\n you may be more likely to get interviews  \\n when you're still employed,  \\n but being employed also gives you an advantage later  \\n in the process.  \\n For example, when a hiring manager wants to hire you  \\n when you're negotiating the terms of the new position,  \\n when you're at the negotiating table  \\n and you still have a job,  \\n the new employer knows they aren't your only option.  \\n They have to compete with your current employer,  \\n so if you're angling for higher pay or better benefits,  \\n there'll be more likely to agree  \\n and give you what you're asking for.  \\n In this way, leveraging your current position  \\n can put more dollars and cents in your pocket,  \\n even if you're not sure  \\n how much longer your current position will exist.  \\n Now, if your new employer offers you a position,  \\n there's another way to leverage your employment options,  \\n negotiate with your current employer.  \\n Maybe you truly love the company that you're working for  \\n and you prefer to keep your role with them,  \\n or perhaps take a step up within the company.  \\n A new job offer could be the gateway  \\n to keeping the job you love during a restructuring.  \\n Of course, these types of negotiations can be intimidating.  \\n I mean, what do you say  \\n and how do you start the conversation?  \\n My advice to you is keep it simple.  \\n When you have a new offer,  \\n go to your supervisor and say something like this.  \\n \\\"I've been working with the company  \\n for X number of years now  \\n and I truly love the work that I do here,  \\n and I love contributing to the company's mission,  \\n but I need to let you know that I've been offered  \\n a new position with a new company,  \\n who's offering me a higher salary,  \\n or a higher position, whatever the case may be,  \\n and unless our company is able to raise my salary  \\n or give me a higher position,  \\n whatever it is you're aiming for,  \\n it's in the best interest of my career  \\n if I accept the new offer.\\\"  \\n Be ready to answer your supervisor's questions  \\n about specifics, the salary, position,  \\n and benefits that the new employer is offering.  \\n Keep in mind that these negotiations can go back  \\n and forth for some time,  \\n because the supervisor may need to discuss the options  \\n with other decision makers.  \\n So don't expect an immediate answer.  \\n I understand these types of conversations  \\n and negotiations can be stressful,  \\n and we all wish our employers or new employers  \\n would just hand us fantastic salaries  \\n and the positions we want  \\n without all the uncomfortable exchanges in between,  \\n but that isn't realistic.  \\n Fortunately, though,  \\n when you're job hunting while you're still employed,  \\n you can leverage your options,  \\n whether you prefer to stay with your current employer,  \\n or land a new, exciting role.  \\n \\n\\n\"}],\"name\":\"3. What to Do If You Anticipate Downsizing\",\"size\":9522868,\"urn\":\"urn:li:learningContentChapter:3044145\"},{\"duration\":162,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3048176\",\"duration\":162,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Restructuring has ended; what's next?\",\"fileName\":\"3002210_en_US_04_01_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2467129,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - After all the changes and all the stress  \\n of a workplace restructuring, what do you when it's over?  \\n Whether you've been downsized  \\n or you stayed with the company, where do you go from here?  \\n If you've unfortunately lost your job,  \\n don't let it break your confidence.  \\n It doesn't mean that you aren't a valuable asset  \\n as an employee.  \\n It just means that your company had to make  \\n some difficult decisions.  \\n In many cases, the only criteria a company uses  \\n to decide who to let go, is your hire date,  \\n last in, first out.  \\n Regardless after you've taken a breath,  \\n now's the time to jump into the job market  \\n with motivation and confidence.  \\n Use the tips that I've shared with you here  \\n about networking and job hunting and go out and find  \\n that new dream job.  \\n If you stayed with the company,  \\n remember that the structure of the workplace has changed.  \\n Take some time to observe and get a feel  \\n for the shift in dynamics so that you can understand  \\n how you fit into the new structure.  \\n There will always be some chaos and confusion  \\n after the restructuring or lay off  \\n as people struggle to adjust.  \\n In the midst of this new adjustment and growth,  \\n try to establish yourself as a leader.  \\n Be the person who's willing to go to your supervisors  \\n with questions.  \\n Be the calm one who takes the time to think about  \\n the problem at hand and come up with a reasonable solution.  \\n Not only does this help to ease through the stress  \\n of the workplace, but it also positions you as a leader  \\n and sets you up for future possible promotions.  \\n Finally, whether you were downsized or not,  \\n don't lose contact with your former coworkers.  \\n Connect with them on LinkedIn,  \\n and if you haven't already done so,  \\n stay in touch with messages every so often.  \\n These people should remain as valuable colleagues  \\n and connections in the industry,  \\n regardless of where each of you find your career moving.  \\n I mean, who knows, you could find yourself hiring  \\n a former coworker in the future, or vice versa.  \\n As difficult a restructuring can be, remember,  \\n there's always light at the end of the tunnel.  \\n Your career may look a lot different  \\n than you may have expected it to look  \\n a few months down the road, but in many cases,  \\n your career ends up better after a restructuring,  \\n a layoff or a furlough than it was before.  \\n And now with the skills that you've learned here,  \\n you've got some great tools to help you make the most  \\n of the situation.  \\n Thank you for watching.  \\n I wish you the best of luck in your restructuring  \\n and in any career shifts that come your way.  \\n For more helpful skills and insights that you can use  \\n in your career development,  \\n be sure to check out my other LinkedIn Learning courses:  \\n \\\"Digital Networking Strategies\\\"  \\n and Finding a Job at Companies That Embrace Diversity  \\n and Inclusion.  \\n I'm Christopher Taylor, thanks again for joining me.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":2467129,\"urn\":\"urn:li:learningContentChapter:3044146\"}],\"size\":35238219,\"duration\":2307,\"zeroBased\":false},{\"course_title\":\"Python Essential Training\",\"course_admin_id\":4314028,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4314028,\"Project ID\":null,\"Course Name\":\"Python Essential Training\",\"Course Name EN\":\"Python Essential Training\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Python is one of the most commonly used dynamic languages for many large organizations, including Google, Yahoo, and IBM. Supported on all major operating systems, it comes pre-installed on Macs, as well as most Linux and Unix-based systems. In this course, senior software engineer Ryan Mitchell guides you through all the essentials of learning and using Python. Learn how computers think, as well as how to install Python, pip, and Jupyter Notebook and the basics of writing a program. Explore variables and types, operators, functions, classes, objects, and more. Go over basic data types like ints and floats, Booleans, and strings. Deep dive into basic data structures, control flow, functions, classes, and objects. Find out how to handle errors and exceptions, as well as threads and processes. Plus, discover how to work with different types of files in Python, pass command-line arguments to your Python script, and create modules and packages.\",\"Course Short Description\":\"Get a comprehensive overview of the Python programming language and gain enough command of Python 3 to create well-designed scripts and maintain existing projects.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":21410001,\"Instructor Name\":\"Ryan  Mitchell\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Senior Software Engineer at GLG\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2023-01-25T00:00:00\",\"Course Updated Date\":\"2024-04-08T00:00:00\",\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/python-essential-training-18764650,https://www.linkedin.com/learning/python-essential-training-18763640,https://www.linkedin.com/learning/python-essential-training-revision-q2-2022-high-visibility-revision-q4-2022\",\"Series\":\"Essential Training\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Beginner\",\"LI Level EN\":\"Beginner\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Programming Languages\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":15773.0,\"Visible Video Count\":56.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":300,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4403000\",\"duration\":50,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Getting started with Python\",\"fileName\":\"4314028_en_US_00_01_WL30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":953350,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(light music)\\n- Oh, hello.\\nI didn't see you come in.\\nI hear you're looking to learn Python.\\nWell, you are in for a real treat.\\nNow, sometimes introductory means oversimplified,\\nbut that's not the case with Python or this course.\\nSo if you're serious about learning Python\\nbut don't know where to start, congratulations.\\nYou've found the right place.\\nHi, I'm Ryan Mitchell.\\nI've been writing Python for over a decade\\nand I'll be your guide every step of the way\\nto show you what's going on behind the scenes.\\n\\nYou'll learn about data types and control flow,\\nclasses, and object-oriented programming,\\nparallel computing modules, packages,\\nand everything else you need to get coding.\\nYes, this is a crash course in Python and computer science\\nbut I won't let you crash and burn.\\nCome on, let's get learning.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4215213\",\"duration\":175,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Who this course is for\",\"fileName\":\"4314028_en_US_00_02_FY24Q4_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nTetris LA (Recorded backup SC with script on screen)\\n\\nPlease edit this movie in a very similar way to the original, just with the new LA and dialogue we recorded on this trip. The b-roll (including the \\\"printer\\\" b-roll), slides, and soundFX should be reused.\\n\\nSee script for specific placement notes (some original slides are to be omitted): https://docs.google.com/document/d/10Bj0Fk2ErjnGJfLpQvC495Kpw9U5CucP/edit\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":289,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":true},\"description\":\"This course is for anyone who wants to learn programming. Basic computer skills are required.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9646524,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Python is one of the best\\nintroductory programming languages\\nbecause of its intuitive syntax, wide popularity,\\nease of use, and similarity to other programming languages.\\nThis makes it not only easy to learn,\\nbut easy to port your Python skills over\\nto other languages you might want to program with\\nin the future.\\nIt's an excellent gateway language,\\nand this is why it was so important for me\\nwhen designing this course\\nto make it accessible to non-programmers.\\nOf course, there's a wide range of skills\\nbetween someone who's just not a programmer\\nand, say, someone who struggles\\nto get their printer to work.\\n\\nWait a minute, I struggled to get my printer to work.\\n\\\"Can't locate printer,\\\" but I put the internet cable in.\\n\\\"Calibrating ink cartridges.\\\"\\nIt's been doing this for 20 minutes now.\\nShould I try restarting it?\\nI don't know. It seems so busy.\\nWhat is it doing?\\nWhat is it thinking?\\nOn second thought, let's forget the printer thing.\\nWell, are you familiar with your operating system\\nand its structory structure?\\nWhen you download a file, you know where it goes.\\n\\nYou know what the file extension means\\nand how to unzip files.\\nMaybe you've used your terminal\\nor command line a little bit.\\nYou have some idea about how the internet works,\\nhow your browser fetches data from a remote server.\\nMaybe you've written some HTML\\nor even set up your own router.\\nYou know, in order to control the machines,\\nyou're going to have to have some understanding of them.\\nA strong background in logic and mathematics\\nor at least a willingness to learn will also be useful.\\nAnd if you've done some programming\\nor front end development before, great.\\nSome of this might be review,\\nbut having knowledge about\\nhow these concepts work in other programming languages\\nwill be a huge asset for this course.\\n\\nThis course was designed to be viewed sequentially\\nwith each segment building on the previous one\\nand lots of references to what we did in the past.\\nWe're going to be starting from foundations\\nand working up to give you a strong programming background.\\nIf you really want to dig into Python\\nand understand what makes it tick,\\nyou'll get out of this course what you put into it.\\nI especially recommend that you do the challenges.\\nEach one presents a bite-sized math\\nor computer science concept\\nthat programmers work with every day.\\nYou might breeze through some of these,\\nand you might find\\nsome of the challenges, well, challenging,\\nbut whatever you do,\\ndon't be afraid to do it at your own pace.\\n\\nPause, rewatch, give yourself time.\\nI also recommend that you set aside time\\nfor practice and review.\\nLook at it this way.\\nThis series is about 4 1/2 hours long.\\nIf you're starting from scratch,\\nit will probably take\\nmore than 4 1/2 hours of video watching\\nto become a proficient programmer.\\nAnd listen, if you're serious about learning Python,\\ndon't let the warnings in this video constrict you too much.\\nYou know, constrict, like a python.\\nActually, nevermind.\\n\\nI'm just saying, you'll be fine.\\nPythons don't bite, do they?\\n\"},{\"urn\":\"urn:li:learningContentVideo:4401001\",\"duration\":75,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Resources for this course\",\"fileName\":\"4314028_en_US_00_03_MM30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn about the resources needed for this course so you can follow along.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3088047,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] There's a lot of virtual paperwork\\nwith this course to help guide you on your Python journey.\\nLet me lay it out for you.\\nFirst, we have the Python Reference Guide.\\nIf you get lost and need to look something up,\\nI've created a document that contains a quick reference\\nto just about every major data type, function,\\nand operation that we cover in this course.\\nKeep it open as you code, and you may find\\nthat it helps things go more smoothly\\nas you get used to working with Python.\\nThen we have the handout.\\nThis is a list of all my favorite resources\\nfor Python learning, with a focus\\non where to go after this course.\\n\\nYou can find information about advanced Python topics\\nas well as complimentary courses that focus on the basics.\\nFinally, those exercise files that I mentioned previously.\\nYou can find them all on GitHub or in the Exercise folder,\\ndownloadable somewhere on your screen right now.\\nEach exercise file or directory corresponds to the chapter\\nand section number, so 02_01 is the code we wrote\\nduring chapter two, video one.\\nAnd if you need a bit of help finding your way,\\nthose instructions are also on the GitHub Read me.\\n\\nSo that's it, the Python Reference Guide,\\nthe handout, and the exercise files.\\nNow that the paperwork's out of the way,\\nlet's go gear up for Python.\\n\"}],\"name\":\"Introduction\",\"size\":13687921,\"urn\":\"urn:li:learningContentChapter:4402007\"},{\"duration\":1389,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4401002\",\"duration\":250,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How computers think\",\"fileName\":\"4314028_en_US_01_01_MM30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3782163,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Computers.\\nWhat goes on inside their heads?\\nHow do they think?\\nWell, it's nothing like this.\\nThanks.\\nDon't mind him.\\nHere, I'll show you how computers think.\\nYou're probably familiar\\nwith storing files on computers.\\nWhen you save a file,\\nlike a text file,\\nit has a file name\\nand some content,\\nall the text inside your file.\\nHere, this grid represents\\nyour computer's memory,\\nwhere it stores files and data.\\nAnd down here, I have a file name.\\n\\nThat file name is represented\\nin your computer's file directory,\\nand you can think of it\\nlike the file icon that you click on.\\nAnd stored with that file name\\nis the location or address of exactly\\nwhere the contents of that file are in memory.\\nSee, computers are really good\\nat jumping straight to a specific spot in memory\\nif they know what the address is.\\nAnd that address is literally a number.\\nEvery spot in memory gets a unique number.\\nAnd because the computer can jump\\ndirectly to that location\\nif it has an address,\\nwe call this address a \\\"pointer,\\\"\\nrepresented by this arrow.\\n\\nAnd these pointers point\\nto where the start of the file contents are.\\nThere's also information\\nstored with the file name.\\nFor example, the size of the file.\\nSo this file might be 4 kilobytes long.\\nSo the computer knows\\nthat if you want to access\\nthe contents in this file,\\nit follows the pointer\\nto where the file starts,\\nreads the next 4 kilobytes,\\nand then loads all of that content for you.\\nNow, when we write and run a computer program,\\nwhat we're doing is directly interacting\\nwith the computer's memory.\\nPrograms are constantly\\nmaking little bits of data,\\nkind of like mini files.\\n\\nThese bits of data are called \\\"variables.\\\"\\nThey have names, variable names.\\nThey point to little bits of data\\nthat we store in the computer's memory.\\nSo for example,\\nlet's create a simple program.\\nA is equal to 2,\\nB is equal to 3,\\nand C is equal to A plus B.\\nThe computer will read the first line,\\nwhich is assigns the value 2 to the variable A.\\nSo it makes a record that says\\nthe variable name A points to the value 2,\\nthe data at this location.\\n\\nThen it does the same thing for B,\\nmakes a variable called B,\\npoints it to the data 3 stored at,\\nsay this location,\\nthen it comes to this line.\\nThe computer first calculates\\nthe value of A plus B.\\nIn order to do this,\\nit looks at the variable A,\\nsees its memory location,\\nfetches the value 2,\\nthen goes to B,\\nlooks up its location,\\nfetches the value 3,\\nadds those two values together\\nand stores it in a third variable, C.\\n\\nNow, why do we need to know\\nwhat's actually going on behind the scenes\\nwhen computers are executing a program?\\nThis program is pretty straightforward.\\nI don't need to know\\nhow the computer is storing and fetching\\nall of this data when it runs.\\nBut consider this situation.\\nA is equal to a list of numbers.\\n1, 2, 3, 4, 5.\\nIn Python,\\nthis notation with the square brackets\\nindicates a list.\\n\\nYou have a list of values\\ninstead of a single value.\\nSo A is equal to 1, 2, 3, 4, 5.\\nAnd let's say that B is equal to A.\\nNow, what happens\\nif we modify some value in our variable A?\\nThis right here.\\nLet's say we change the 1 to a 6.\\nTurns out we're modifying the value\\nof both A and B.\\nBy saying B is equal to A,\\nwe're not duplicating A,\\nwe're literally assigning B\\nto the same location in memory.\\n\\nAnd this concept is going to come up\\ntime and time again as we start programming.\\nWhen we write programs\\nwe're working directly\\nwith the computer's memory.\\nWe're putting data into it.\\nWe're fetching data out.\\nWe're manipulating this data.\\nSo having a mental model\\nof what's going on behind the scenes\\nis extremely important.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4215214\",\"duration\":413,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Installing Python, Pip, and Jupyter Notebooks\",\"fileName\":\"4314028_en_US_01_02_FY24Q4_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\n\\nhttps://github.com/LinkedInLearning/python-essential-training-4314028/blob/main/installation_troubleshooting.pdf\\nhttps://github.com/LinkedInLearning/python-essential-training-4314028/wiki/troubleshooting\\nhttps://github.com/LinkedInLearning/python-essential-training-4314028\\nhttps://www.python.org/downloads\\nhttps://code.visualstudio.com/\\n\\nStart video ith some Stock b-roll, see script for paths\\n\\nLots of pickups to overwrite and insert for when Ryan refers to the Windows install. All audio was recorded in MacOS (MOVs) and that's what should be used in the final movie. The audio recorded in the MP4s is for reference only. Here are the time codes for placement, please line up the audio (MOV) and video (MP4):\\n\\nReplace video and audio 2:38-3:00 with \\nAUPU1 - Start at 0:22\\nVIDPU1 - Start at 0:18\\n\\nReplace video only 3:34-3:41 with \\nVIDPU2 - Start at 0:12\\n\\nReplace audio only 5:39-6:07 with \\nAUPU2 - Start at 0:21\\n\\nReplace video only 6:00-6:07 with \\nVIDPU3 - Start at 0:14\\n\\nTwo column script for placement: https://docs.google.com/document/d/1SpNI3jBmZt6YoFSTutyLUnO9R4iy-zN8/edit\",\"solutionVideo\":false,\"challengeVideo\":false,\"exerciseFileUrl\":\"https://github.com/LinkedInLearning/python-essential-training-4314028\",\"includesPickups\":true,\"graphicsIncluded\":false,\"rawDurationSeconds\":843,\"exerciseFileDisplayText\":\"main > installation_troubleshooting.pdf\",\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":true},\"description\":\"This video gives you a walkthrough of how to install Python, Pip, and Jupyter Notebooks on both Windows and Mac.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16912743,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] This is the part of the course\\nwhere knowing your way around a computer\\nis going to come in handy.\\nEvery computer operating system\\nand file configuration is different.\\nThese things get updated and changed all the time,\\nand while I hope your installation goes flawlessly,\\nI can't guarantee it.\\nTo assist with any road bumps,\\nI've created a Troubleshooting document\\nin the Exercise Files\\nthat goes over everything step by step,\\nand also includes a link\\nto the Troubleshooting Wiki on GitHub.\\nIf you go through all of these\\nand you still think that your problem is unique,\\nhit me up in the Q&A section on the Course page.\\n\\nI may add your problem and the solution\\nto the Troubleshooting Wiki\\nto help people out in the future.\\nCan't find the Exercise Files?\\nThey're on the Overview tab of the Course page\\nor you can get to them from the GitHub link.\\nIf you don't know how to use GitHub tools,\\non the GitHub page,\\nyou can just go to Code and then Download ZIP.\\nMake sure that you unzip the files\\nbefore you try to use them.\\nAlso, save them to a place that's easy to locate\\nwhere you know where they are.\\n\\nThis can be your Documents, or Desktop,\\nor somewhere easily reachable.\\nAgain, there's that Troubleshooting document\\nthat you're going to want to check if you run into problems.\\nOkay, so let's get started with installation.\\nFirst, we need to install Python.\\nGo to python.org/downloads.\\nYou should see a big yellow button here.\\nThe website automatically detects your operating system,\\nand it should be showing you the latest version\\nfor your operating system here.\\n\\nDownload it and then go through the installer.\\nSo this is very important.\\nFor Windows users, click Customize Installation,\\ngo to Next, and click Add Python to environment variables.\\nVery important that you check this box.\\nIf you don't check Add Python to environment variables,\\nyou'll have to consult the Troubleshooting Guide later on.\\nFinish the installation and you're set.\\nIf you're on a Mac, you may get a popup after installation.\\nJust close it.\\n\\nNext, you need to find your computer's terminal.\\nThis is where programmers enter commands.\\nHopefully, you've used it before or at least seen it around.\\nOn Windows, you're going to go to Start\\nand click on the Command Prompt,\\nor you can search for CMD and it will show up there.\\nOn Macs, go to Applications,\\nUtilities,\\nand Terminal.\\nOn Linux, it varies by distribution,\\nso just look that one up.\\nIt should be easy to find\\nbecause you tend to need the terminal a lot in Linux.\\nNow test your Python installation by typing python\\nand hit Enter.\\n\\nOn a Mac,\\nyou may need to type python3 instead of just python.\\nThis is to differentiate\\nbetween Python Versions 2.0 and 3.0,\\nwhich often both come on Macs.\\nHit Enter, and this should open up the Python command prompt\\nindicated by the three greater than signs right there.\\nSo this is the Python command prompt\\nwhere you can enter Python code.\\nMake sure that the version number printed here\\nmatches the version that you downloaded from the website.\\nAgain, if you're on a Mac\\nand you see a version that starts with 2 instead of 3,\\nyou may need to type python3 to get the correct version.\\n\\nWe can test our Python environment\\nby, say, typing 1 + 1.\\nHit Enter, and great, we get 2.\\nLooks like everything's in working order.\\nNow, we'll need to exit the Python command prompt\\nto install the rest of what we need.\\nWe can do this by typing Control + D.\\nYes, even for Macs, it's Control + D and not Command + D.\\nOr on Windows, type Control + Z, and hit Enter.\\nOn all operating systems,\\nyou can type quit, then open parenthesis, close parenthesis,\\nand hit Enter.\\n\\nOkay, so now that we're back\\nto our operating systems terminal,\\nwe can start the rest of the installation.\\nOkay, so now, we're back to our operating systems terminal.\\nWe're not in the Python terminal anymore.\\nMake sure you've definitely exited the Python command prompt\\nand you don't see the three greater than signs.\\nAnd now we're going to use a tool\\nthat should have been installed with Python,\\nand that's called pip, the package installer for Python.\\nSo this is Python's package management system,\\nand you can use it by typing pip.\\nIf I hit Enter right away,\\nyou can see a list of commands associated with it.\\n\\nNow, we're going to use pip\\nto install a program called JupyterLab.\\nJupyterLab is a piece of software\\nthat lets us view and edit Python Notebook files,\\nthe files with the .ipynb extension\\nthat make up most of the Exercise Files for this course.\\nSo I'm going to type pip install jupyterlab,\\nthat's Jupyter with a Y, and hit Enter.\\nSo wait a little bit, and it should be installed.\\n\\nNext, you'll need to use the command line\\nto navigate to where your Exercise Files are stored.\\nThe command that you're going to want to type is cd,\\nwhich stands for change directory.\\nThen you'll need to enter the file path\\nfor where you stored your Exercise Files.\\nI'm going to show you another way to do this later on,\\nbut one really easy way\\nis to open up File Explorer or Finder\\nand just copy the folder and paste it into your terminal.\\nThen, hit Enter.\\n\\nNow we've navigated to the correct directory.\\nNow that you're in the directory\\nwhere your Exercise Files are,\\nyou're going to type jupyter lab, space lab,\\nand this is going to start the Jupyter Notebook server\\non your computer\\nusing the Jupyter software that we just installed.\\nThis should cause a browser window to pop up\\nso that we can see all of the Exercise Files in there.\\nNow, Jupyter isn't the only software\\nthat can display these files.\\n\\nVisual Studio Code is an excellent development environment\\nthat can be used to run Python Notebook files,\\nas well as develop larger pieces of Python code.\\nWe'll be using Visual Studio Code\\nat several points during this course,\\nso I recommend that you download it\\nfrom code.visualstudio.com,\\nand know that if you run into issues\\nwith your JupyterLab installation,\\nyou can use this as well to work with Notebook files.\\nSo back to JupyterLab.\\nI'm going to open up one of these Notebook files here.\\nYou can do that just by clicking on the file in the left,\\nand then you can run these cells.\\n\\nEach cell is just a little bit of Python code\\nthat you can run independently.\\nSo play around with these a little if you want.\\nWe're going to be using them very heavily\\nshortly in this course,\\nbut next, we're going back to the command line\\nfor the next video.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4406000\",\"duration\":121,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The Zen of Python\",\"fileName\":\"4314028_en_US_01_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1856985,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Python has been around for 30 years,\\nand its popularity only seems to grow as it ages.\\nPython isn't clumsy or random, as JavaScript.\\nIt's an elegant language for a more civilized age.\\nFor example, the syntax,\\nor way you write the code to call one function,\\nis probably the same way you'd write the code\\nto call a similar function.\\nThe designers of Python tried, and in my opinion succeeded,\\nin keeping the language simple and consistent.\\nAnd Python isn't just a programming language for beginners.\\n\\nI use it every day at my job to build huge complex systems.\\nBecause when you're dealing with a lot of complexity,\\nthe last thing you want is to complicate things.\\nAnd that's where Python really shines.\\nThey even have a kind of mission statement\\nto drive this point,\\nhidden in an Easter egg called import this.\\nLet's go to the code.\\nOpen up any terminal and type Python\\nto enter the Python command prompt like we did previously.\\nYou should see two greater than symbols\\nletting you know that it's ready for a line of Python.\\n\\nAnd now we're going to type import this.\\nImport is a good command to know.\\nIt says, go fetch me a module so I can use it,\\nand this is the name of the module we're importing.\\nWe'll learn more about the import statements later,\\nbut if you type import this and then hit enter,\\nyou're going to get the following document printed out.\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\n\\nSee what I mean? Code gets complex enough on its own.\\nI'm not going to read this whole thing,\\nbut consider this your first sort of mini challenge.\\nOpen up a terminal, type import this and see what happens.\\nEven if you don't fully understand\\nevery word or statement this document is making,\\nI think you'll probably get the general sentiment.\\nAnd by the way, if you go back and reread this\\nwhen you've reached the end of this course,\\nI can almost guarantee\\nthat every part of it will make perfect sense,\\njust like Python itself.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4401003\",\"duration\":167,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Writing a program\",\"fileName\":\"4314028_en_US_01_04_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2502561,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, let's get warmed up.\\nWe're going to be writing our first Python program.\\nFor this you can use any text editor you'd like.\\nI recommend Visual Studio Code, which I'm using,\\nor you can use something like Sublime or PyCharm.\\nIf you're using Windows, you can also use Notepad++\\nwhich I've used in the past.\\nIf you don't have a text editor, pause now and go get one.\\nWe'll be using them for the challenges in this course\\nand a text editor is an essential tool\\nfor programming in any language.\\nSo create a file called hello.py; hello.py.\\n\\nAnd open it in your text editor of choice.\\nPY is the file extension for all Python files.\\nAnd we're just going to type a single line\\nof Python code that will print the text Hello, World!\\nto the screen.\\nSo this is the print function.\\nIt takes whatever text is passed into these parentheses\\nand just prints it out to the terminal.\\nAnd notice that I've surrounded the text\\nwith these single quotes.\\nSo this isn't actually part of the text,\\nbut it tells Python,\\nSo these quotes are important.\\n\\nWe can also write a comment.\\nSo let's give us a couple lines of space.\\nComments start with a hash,\\nand this is just human readable text\\nthat's completely ignored by the computer\\nwhen it's running the program.\\nSo comments are handy to make notes to other programmers\\nor remind yourself what a line is doing.\\nAnd I'm just going to write the comment,\\nprint hello, world! to the terminal.\\nGreat. Now save this file.\\nThen go to the terminal or command prompt.\\n\\nNavigate to where your file is stored.\\nUse the cd command, which stands for change directory.\\nAnd I'm going to type cd Documents GitHub\\npython-essential-training.\\nNow I'm not actually typing that fast.\\nSo if you don't know,\\nyou can use the tab key to auto complete directory names.\\nSo just type cd doc tab gi tab py tab.\\nAnd I can do ex tab\\nto get to the exercise files and then enter.\\n\\nSo now that I'm here,\\nI can run our hello.py file with the Python command\\npython hello.py, or I can just type h and then tab\\nand then that auto completes.\\nNow previously we've just typed Python\\nto get to the Python command prompt,\\nand here we're typing python and then the name of a file.\\nSo this tells Python to run the file as a Python program,\\nand we can see that our file is run\\nand it prints out Hello, World!\\nSo congratulations, you are now a Python programmer.\\n\\nGo take a break, add Python to your LinkedIn skills section,\\nand join me back here as we put this into practice.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4403001\",\"duration\":308,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Jupyter notebooks\",\"fileName\":\"4314028_en_US_01_05_XR30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video shows you how to use Jupyter notebooks for this course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4620001,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] We're going to be using Jupyter Notebooks\\nfor most of this course,\\nand after all the work of installing it,\\nyou might be thinking, \\\"What's this good for?\\n\\\"Why are we doing this?\\\"\\nWell, I'll tell you.\\nProject Jupyter is a nonprofit organization\\nthat makes Python tools for programming and data science,\\nand one of their best known tools is Jupyter Notebook,\\na web application that allows you to write\\nand run Python programs in your browser\\nrather than in the command line.\\nWhen you run Jupyter Notebook from the command line,\\nwhat you're really doing\\nis starting a web application server\\nrunning on your computer.\\n\\nSo you start it, wait a second,\\nit starts up and opens automatically in the browser.\\nIf the webpage doesn't open automatically\\nfor whatever reason,\\nyou can copy paste this URL here or this one,\\nthese are actually the same URL,\\nand just open it up in your browser.\\nSo here we see a list of files.\\nAnything ending in ipynb is an IPython notebook file,\\nor a notebook.\\nThese are the things\\nthat Jupyter Notebook helps you create and edit.\\nYou can also click on new, Python three\\nto create new notebook,\\nor let's just click and open this one here.\\n\\nThese notebooks are really popular\\nin the data science community\\nbecause it's easy to present your findings\\nand create plots and charts in an easily shareable way.\\nYou can also export them\\nas many different types of formats here.\\nI actually use notebooks pretty frequently\\nif I want to try out some experiment,\\nif I'm making a report for my boss that involves code\\nor, like right now, if I'm teaching Python\\nand want to lay the small pieces of code out\\nin a fast and organized way.\\n\\nSo each notebook has a series of cells,\\nand to make new cells, I can just hold down shift\\nand hit enter.\\nShift, enter, enter, enter, enter.\\nIt makes all the new cells I want.\\nTo delete cells, all I do is click outside the cell\\nin the margin here, so that margin turns blue,\\nand then type dd.\\nDd, dd, dd.\\nSo when I click outside the cell,\\nyou can see that this border turns blue,\\nand that's called command mode.\\n\\nSo this cell is in command mode.\\nWhen I click inside the cell, now we're in edit mode,\\nand I can enter some Python code.\\nPrint, doing some data science.\\nThat's what I use these for a lot.\\nTo run code inside the cell,\\nall you have to do is hold down that shift again,\\npress enter, and it runs the code.\\nNow up here, if I click, I'm in command mode again,\\nI press A and I can create a cell above that one.\\n\\nIf I press B, I create a cell below that one.\\nLet's take the cell up at the very top,\\nand let's say we want to make a title for this document.\\nSo not Python code, just some human readable text.\\nSo I'm going to go into command mode\\nby clicking outside the cell and press M.\\nOkay, now we're in markdown mode.\\nAnother way to get to markdown mode\\nis to go to cell type, markdown,\\nand you see the little M next to that?\\nThat gives you the hint that the keyboard shortcut\\nis the letter M.\\n\\nSo now the cell is in markdown mode,\\nand we can write some text.\\nShift and then enter to run it.\\nI can also make a title by doing a hash,\\nand you see that makes a title.\\nIf I double click again, I can make a smaller title.\\nSmaller title.\\nThere are tons of options for markdown.\\nWe can do bullet points, we can do italic text.\\nYou can actually see over in Jupyter Notebooks,\\nthere are a lot of options here you can use.\\n\\nHere I want to show you,\\nthere's even options for math equations,\\nso you can write all the math equations you want in here.\\nIf I just copy this, M for markdown mode, paste that\\nand we get a nice little math equation.\\nSo these notebooks are nice\\nalso because they're widely supported.\\nThey get displayed nicely in GitHub, like you can see here.\\nThis is in the Python essential training repo,\\nand you can see it's really pretty.\\nYou can't edit it from here, but if you do want to edit it,\\nyou can actually open it in an IDE\\nsuch as Visual Studio Code.\\n\\nSo over here, I've opened the same file\\nin Visual Studio Code, and you can see that you can edit it,\\nrun it with the same hot keys,\\nand you can actually do everything\\nthat you can in the web browser inside Visual Studio,\\nwhich is nice.\\nSo if you run into problems installing Jupyter\\nfrom the command line,\\nyou might try installing Visual Studio\\nand see if that works.\\nI know we've covered a lot of content\\nand a lot of keyboard shortcuts here.\\nDon't worry about learning every hot key\\nand memorizing every feature all at once.\\n\\nIf you just focus\\npick up new hot keys as you need them,\\nyou'll be a notebook expert in no time.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4216238\",\"duration\":130,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using Coderpad\",\"fileName\":\"4314028_en_US_01_06_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"ADDED\",\"editingNotes\":\"NEW VIDEO - Coderpad SC only\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":160,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4207588,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] For the challenges in this course,\\nwe'll be using CoderPad,\\nwhich is integrated into the\\nLinkedIn Learning Course website.\\nAll you have to do is click on the challenge.\\nThis makes it really easy to watch videos, write some code,\\ngo back and forth, test your solutions, all on one site.\\nI recommend that you use Coder Pad on a desktop browser.\\nYou can use the LinkedIn Learning mobile app\\nand write code on your phone with your thumbs,\\nbut why would you do that to yourself?\\nThere are four screens in CoderPad.\\n\\nYou can enlarge them\\nand shrink them as you see fit\\nwith these little handles here.\\nThe first screen you're going to want to look at is\\nthe instructions.\\nI wrote them myself,\\nso they are very important and good to read.\\nThis will tell you all about the challenge\\nand what the expected output is with examples\\nand where to go for more hints\\nand practice if you need them.\\nThe answer screen on the right is where you're going\\nto actually enter your code.\\nI've tried to make this as easy as possible\\nfor each challenge, so in general,\\nyou'll see an empty function.\\n\\nIt just has the function name written there,\\nand you'll just start to write your code inside of that.\\nJust below the answer panel is the test code.\\nHere you can see an actual value that will be used\\nto test your function and how that code will be used.\\nNow, you could look at these test values,\\nfigure out what the right answer is,\\nand just hard code that right answer into your function up\\nhere so that the test pass.\\nYou and I both know that you could do that,\\nbut you would be robbing yourself of a learning experience,\\nand I would personally be very, very disappointed.\\n\\nAfter you've written some code,\\nclick the \\\"Test my code\\\" button on the bottom right\\nand direct your attention to the fourth window,\\nthe console output.\\nKeep an eye on the console output,\\nespecially if your code is failing.\\nYou're going to see all your program output,\\nprint statements and errors\\nthat will help you debug your code.\\nAnd if you'd like some help, words of encouragement,\\nor other resources for learning,\\ncheck out the hints file in the exercise files\\nfor the corresponding challenge.\\nAnd don't forget the most important part of the challenges:\\nHave fun!\\n\"}],\"name\":\"1. Gearing Up for Python\",\"size\":33882041,\"urn\":\"urn:li:learningContentChapter:4406008\"},{\"duration\":2541,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4407000\",\"duration\":386,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Variables and types\",\"fileName\":\"4314028_en_US_02_01_MM30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5823452,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Variables are\\nthat are units that are assigned some value.\\nFor instance, I can take the variable x\\nand assign it the value 5.\\nThe equal sign, again, means put the value 5\\ninto the variable x.\\nAnd so we call this equal sign an assignment operator.\\nAnd I can run the cell in Jupyter Notebooks\\nby pressing Shift + Enter\\nand insert a new cell by clicking outside in the margin\\nand typing a.\\nIn the next line, I can do print x\\nand we see the value 5 printed out.\\n\\nOf course, in Jupyter Notebooks,\\nwe'll automatically display the value\\nof the last line of each cell when you run it.\\nSo I can just type x and it displays that x.\\nThere are a few rules around variable names.\\nThey can't start with numbers,\\nso I can do x1.\\nWell, I haven't defined x1,\\nbut I definitely can't do 1x.\\nAnd you see it's even highlighted in two different colors\\nand I get a syntax error if I run that.\\nAnd the syntax error occurs whenever Python\\ncan't understand what the heck you're trying to type.\\nIt doesn't understand a variable name\\nthat starts with a number.\\n\\nVariable names also can't have special characters\\nexcept for an underscore.\\nSo you can also do uppercase or lowercase letters.\\nTraditionally though, in Python,\\nvariable names always start with lowercase letters.\\nNever start a variable name with an uppercase letter\\nbecause it can get confused\\nfor something called a class,\\nwhich we'll discuss later.\\nBut just remember,\\nvariable names start with lowercase letters.\\nNow I've assigned things like 1, and 2, and 5\\nto these variables,\\nand these are all numbers, obviously,\\nbut we could also do something like this,\\nname = Ryan.\\n\\nAnd this sets the value of name to some text\\nwhich programmers call a string.\\nAnd the reason this is called a string\\nhas to do with the fact that it's a string of characters.\\nSo remember how computers lay things out in memory?\\nEach character in the string\\ngets its own segment of memory\\nand the computer strings them together\\ninto these arbitrarily large strings.\\nIf you ever forget the name of a type of variable,\\nthere's a handy function for that.\\nYou can just use this Python function called type,\\ngive it the name of your variable,\\nand it returns string, or str for string.\\n\\nWe could also give it the x that we did,\\nand we get int for integer.\\nThere are a lot of types of variables in Python.\\nSo let's just cover a few basic ones.\\nObviously, there are numbers.\\nProgrammers call whole numbers like 1, and 2, and 3\\nintegers, or in python an int.\\nBut not all numbers are whole numbers.\\nWe also have decimals or floats.\\nSo 1.5, that's a float.\\nWhy are they called floats?\\nWell, I can write a float like this.\\n\\nMost of the information\\nis on the right-hand side of the decimal place.\\nBut I could also write a float like this, .9,\\nmost of the information is on the left of the number.\\nRemember again how computers store things in memory.\\nThey also have to record\\nwhere that decimal place is in the number,\\nand they don't know whether all the information's\\ngoing to be on the left or the right.\\nSo that decimal place kind of floats around.\\nThat's why it's called a float.\\nAlso, for any complex math applications,\\nwe can use complex numbers.\\n\\nHonestly, I've only used these a couple times in my career,\\nbut as one of the basic number types in Python,\\nthey're worth knowing about.\\nSo remember back from algebra,\\nimaginary numbers are the square root of negative numbers\\nand usually represented by the letter i.\\nHowever, in Python,\\nthey use the notation common in engineering,\\nwhich is j.\\nSo we can write, let's look at the type of 2j.\\nIt's a complex number.\\nWe can also do math with these.\\nSo 1j times 1j,\\nthat asterisk is multiplication,\\nthat gives us negative one plus 0j, or negative one.\\n\\nSo remember i times i,\\nor 1j times 1j,\\nis negative one.\\nI mentioned strings a little bit earlier,\\nbut let's go over some fun things to do with them.\\nSo strings are declared with single quotes,\\nor with double quotes,\\nyou can also use double quotes.\\nIt's the popular style in Python these days.\\nSo that's what we'll be doing throughout this course.\\nSo I can also add strings together.\\nSo String 1 plus String 2\\nsticks the two strengths together,\\nor as programmers say, concatenates the strings.\\n\\nAnd something interesting I can do\\nis concatenate two strings that are numbers.\\nSo what's String 1 plus String 1?\\nIf you thought it was 2, you'd be very disappointed.\\nIt's actually 11, the string 11.\\nRemember, strings are not numbers.\\nSo Python's just sticking these two strings together\\nand that gives us the string 11.\\nWhat happens if we do String 1 plus 1?\\nSo a string plus a number.\\n(bomb booming)\\nJust kidding, your computer's not going to explode.\\n\\nPython just prints out a type error,\\n\\\"can only concatenate string, not int, to string.\\\"\\nSo when you get errors in Python,\\nit's important to read them and understand what's going on.\\nThe error will usually tell you what you're doing wrong.\\nFinally, let's look at booleans.\\nSo booleans are true and false values.\\nNote that they start with a capital letter here.\\nIf I try to do a lowercase true,\\nit tries to interpret this as a variable name\\nand says that it's not defined.\\nHowever, if you want to be very confusing,\\nyou can write a little program like this.\\n\\nSo how are booleans usually used in programming?\\nWell, they're not usually used directly\\nby typing true and false explicitly,\\nbut we usually get them\\nas the result of statements like this one.\\nNow remember a single equal sign, if we scroll up,\\nthis is an assignment operator.\\nThe double equal sign is a statement.\\nIt's saying 1 is equal to 1,\\nand we get back true.\\nWe could also do 1 is equal to 2,\\nwhich is, of course, false.\\n\\nThis double equals is a comparison operator.\\nSo this is a comparison operator,\\nwe're comparing two values,\\nversus the assignment operator,\\nwhere we're assigning a value into a variable.\\nSo this is a lot of information from one video.\\nDon't worry if you don't have everything memorized.\\nYou can't write a program without variables.\\nAnd so we're going to be revisiting these concepts\\nthroughout the course.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4406001\",\"duration\":438,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Data structures\",\"fileName\":\"4314028_en_US_02_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6577125,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] We just looked at simple variables\\nthat were assigned a single value.\\nBut a single value like five or true or false\\nis only so useful.\\nWe might want to have an array of values in a variable.\\nSo Python has something called data structures,\\nand the first one we're going to look at is a list.\\nSo if we say my list\\nis equal to open square bracket closed square bracket,\\nthis defines an empty list.\\nAnd then we can add some values to it with commas,\\nso this is a list of length four.\\nAnd if we print my list, we see that printed out there.\\n\\nNow we can put really anything we want in a list.\\nSo you could have list of strings,\\nand this is a list of length three\\ncontaining three different strings.\\nAlright, we could also have a list of mixed strings\\nand integers and Booleans and whatever we want.\\nFalse.\\nWe can even throw in another list in there.\\nIn fact, you can have a list of lists.\\n\\nLet me just do that.\\nOkay, so we have a list of lists.\\nAnd we can put values inside some of these inner lists,\\nand put a false and a true, whatever we want.\\nSo there's a nifty function you have with lists\\ncalled length.\\nOkay, so if I look at the length of my list, I get three.\\nAnd so that's this list here.\\nAnd even though we have lists of lists inside of here,\\nthe length of this list is three,\\nbecause there are three lists inside of it,\\nso it has a length of three.\\n\\nAnd let's look at a couple data structures\\nthat are very similar to lists.\\nAnd the first of these is called sets.\\nSo let's talk about sets.\\nA set is almost identical to a list,\\nexcept that all of the elements in it have to be unique.\\nSo we can define a set with curly brackets like this.\\nAnd let's put some elements in it.\\nAnd if we print it out, my set,\\nwe see those all get printed out\\nwith the curly brackets that indicate that it's a set.\\nWe can also call the type function.\\n\\nOf course it's a set.\\nAnd we can also use the length function.\\nSo it has a length of five,\\nthere are five elements in the set.\\nNow let's make a set equal to one one one two two,\\nand look at the length of that.\\nThe length is two.\\nRemember how I said that every element in a set\\nneeds to be unique?\\nSo when you add the elements one and one to the set,\\nit just takes in one, doesn't add the second one.\\n\\nAnd then, similarly, discards that second two.\\nSo if we print my set,\\nthere's only those two elements there.\\nAnd the other thing to know\\nis that the order of elements in a list is very important.\\nSo, I can say one comma two equals one comma two,\\nand that's true.\\nSo these are two lists, these are two equal lists.\\nBut if I do that, it's false,\\nbecause the order of elements in the second list\\nis different.\\n\\nBut if I do this with a set.\\nTwo comma one.\\nIt's true, the order of elements in sets does not matter.\\nI can even put a three in here.\\nIt's still true, and I can do a couple more ones.\\nStill true, these are the same sets.\\nNow let's look at tuples.\\nSo tuples are declared with parentheses, like this.\\nOne two three.\\nAnd tuples are very similar to lists.\\n\\nThey have a length, you can use the length function.\\nLet's call that my tuple, singular.\\nAnd length of my tuple is of course three.\\nThe order also matters with tuples.\\nSo, one comma two\\nis not going to be equal to two comma one, that's false.\\nThe difference with tuples\\nis that I can't append or add things to tuples.\\nSo if I do my list dot append four, and print my list,\\nwe're using that list from up top,\\nit adds the four to it.\\n\\nAnd I can append a six, adds that on, whatever I want.\\nBut if I call my tuple dot append four,\\ntuple object has no attribute append.\\nYou cannot modify tuples.\\nWe're going to learn a lot of ways\\nto modify the values and lists,\\nbut once a tuple is declared,\\nyou can't change it, add to it,\\nchange any of the values in it, it has to remain the same.\\nSo why would you use tuples?\\nWell, remember back to how computers store lists in memory.\\n\\nIf the computer knows\\nthat you can potentially add things onto a list,\\nthat list is going to increase in size,\\nand so Python will try and sort of pre-allocate\\na larger chunk of memory for that list\\nthan it needs in the moment.\\nWith tuples, Python knows\\nthat you're never going to be able to add to them.\\nSo it uses only exactly the amount of memory it needs\\nto store tuples.\\nSo tuples are often used\\nto, say, store X Y coordinate pairs.\\nYou could store many thousands or millions\\nof X Y coordinate pair tuples\\nmuch more efficiently in memory than you could with lists.\\n\\nAlright, and the final data structure we're going to look at\\nis the dictionary.\\nAnd this is very different than the previous three,\\nbut you'll use dictionaries a lot.\\nSo, remember dictionaries from the real world,\\nbig books, you look up words in them.\\nAnd when you look a word up,\\nyou get back a definition of that word.\\nAnd in Python, dictionaries are kind of like that.\\nSo let's make a dictionary here.\\nApple is going to be a red fruit.\\nBear is going to be a scary animal.\\n\\nOkay, and let's use my dictionary.\\nAnd look up the definition of apple.\\nOkay, so you can access the data in dictionaries like this,\\nand you see it prints out the value of red fruit,\\nthis is the definition\\nor the value that you get back for what we call the key.\\nAnd dictionaries are declared\\nwith these curly brackets, a bit like sets.\\nAnd you have these key value pairs inside of them.\\nThe keys in dictionaries also have to be unique,\\nso if we take this dictionary,\\nand, say, add a second definition to it.\\n\\n\\\"Sometimes a green fruit.\\\"\\nAnd then we call my dictionary\\nand get the definition for apple,\\nit actually just takes that second definition.\\nSo this is kind of interesting,\\nbecause sets also have to have unique values.\\nThe order with sets,\\nboth sets and dictionaries, doesn't matter,\\nyou can put these keys in any order you want.\\nSo I've always thought that dictionaries\\nwere a little bit like sets.\\nAnd of course they're both defined with the curly brackets.\\nWe're going to be using all of these data structures a lot\\nthroughout this course, this is just a quick introduction.\\n\\nSo have fun, play around with these, and I'll see you later.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4403002\",\"duration\":331,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Operators\",\"fileName\":\"4314028_en_US_02_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4994224,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Narrator] Operators perform operations\\non variables and values.\\nWhere variables are the data, operators are the instructions\\nas to what to do with that data.\\nThe most obvious type of operator you're probably\\nfamiliar with is the arithmetic operator.\\nThey do math.\\nSo we've seen the addition operator already.\\nOne plus one is two.\\nLet's go over a few other arithmetic operators\\nthat Python makes available for us.\\nThis is the multiplication operator.\\nIt's an asterisk.\\nIt obviously multiplies numbers\\ntogether, pretty straightforward.\\n\\nAnd this is the exponent.\\nSo this is five raised to the second power, which is 25.\\nWe can do division with a forward slash,\\nso 20 divided by five is four.\\nAnd notice that this returns a float value\\nrather than an integer.\\nAnytime you do division,\\nyou're going to get a float or a decimal value back.\\nThat's because you might not always get a whole number\\nas the result of that division.\\nSo if I do 20 divided by six, it's obviously a float, right?\\nSo these math operations are all pretty straightforward\\nbut there's one that's really kind of specific\\nto programming that we need to cover\\nand that's the modulus operator.\\n\\nThe modulus operator gives you the remainder\\nafter any division.\\nFor example, if I do 20 modulus 6, I get two back\\nbecause 20 divided by 6 is 18 with a remainder of two.\\nAnd this operation comes up a lot in programming.\\nPersonally, I use it all the time\\nand we'll see why in the video on mathematical operators\\na little later in this course.\\nThere are a couple basic operations\\nwe can do with strings as well.\\nSo I mentioned string concatenation earlier,\\nstring one plus string two,\\nand so this is the addition operator using strings\\nand it just concatenates or sticks them together.\\n\\nSo you can also do string multiplication,\\nstring one multiplied by four\\nand that repeats that string four times.\\nSo with the concatenation or the addition with strings,\\nobviously this takes a string and a string.\\nIt operates on two strings.\\nThis operates on a string or a number.\\nIf I do, you know, string plus four,\\nI'm going to get an error there.\\nSo just make sure you pay attention to the types\\nof the variables you're working with.\\n\\nAnd remember this one because it's a really handy trick\\nif you want to do a lot of repeated strings.\\nAll right, so let's look at another set of operators.\\nThese are comparison operators, logical operators,\\nidentity operators, and membership operators.\\nOkay, it sounds like a lot, but they're all really\\nstraightforward and you don't have to remember\\nwhich group each operator is in.\\nThese operators all evaluate two variables or values\\nand produce a Boolean, true or false.\\nThe first is the comparison operator\\nwhich we've already seen.\\nSo true is equal to true.\\n\\nThat's the double equal sign, is the comparison operator.\\nYou can also do less than.\\nFour is less than five.\\nYou can do less than or equals to.\\nThere, let's do five is less than equals to five.\\nThat's true, and of course you can do the greater than,\\nfive is greater than two\\nand five is greater than or equal to two,\\nso all pretty straightforward.\\nThen let's look at the logical operators.\\n\\nLogical operators are actually just plain English words.\\nThey operate on Booleans.\\nThere are three logical operators, and, or, and not.\\nWith the and operator, both sides have to be true,\\nevaluate to true, so true and true.\\nIf I did true and false, that's false.\\nRemember this has to be true and that has to be true.\\nThe other one is the or operator.\\nSo true or false, this side or that side.\\n\\nSo the only situation where this evaluates\\nto false is if I do false or false.\\nThen the not operator, this is a little bit special.\\nIt only operates on one thing at a time\\nand simply flips the Boolean that it's operating on.\\nSo if I say not true, that's false.\\nIf something is not true, it's false.\\nIf something is not false, it's true.\\nIt just flips whatever this variable is.\\nSo membership operators are also nice English words\\nand the two membership operators are in and not in.\\n\\nSo you can write 1 in 1, 2, 3, 4, 5, and you get true.\\nYou can say 10 in 1, 2, 3, 4, 5, and that's obviously false.\\n10 does not appear in this list.\\nBut if I say 10, not in 1, 2, 3, 4, 5, that's true.\\nYou can also do this with strings,\\nso cat in my pet cat.\\nThe string cat appears in the string.\\n\\nOf course, keep in mind\\nthat the word cat is also in catatonic.\\nSo be careful when you're using this trick\\nin Python when you're dealing with strings.\\nOf course, if I put not in here, as you can imagine,\\nthat simply flips the value.\\nAll right, so that was a whirlwind\\nthrough the concept of operators.\\nIf you didn't quite catch everything, don't worry.\\nWe'll be circling back around\\nand putting this to practice later on.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4403003\",\"duration\":267,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Control flow\",\"fileName\":\"4314028_en_US_02_04_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4028855,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] This is where programming\\nreally starts to get powerful.\\nThere are three main types of control flow\\nthat we're going to cover\\nand the first of these is the if statement.\\nSo this is pretty straightforward, a equals true,\\nif a: print It is true.\\nAnd if I change a to false, nothing prints out.\\nSo notice that I've indented\\nin the line after my if statement here.\\nSo this colon followed by an indent\\nmeans that everything indented under this line\\nbelongs under the if statement.\\n\\nIt sort of belongs to the if statement.\\nSo any indented code is executed only if a is true.\\nI could add another indented print line, Also print this,\\nand now both of these lines belong under the if statement.\\nWe say we're in the if block,\\na block of code as these indented lines under here.\\nNow, I could also outdent and add another line,\\nAlways print this.\\nWe see that even if a is false, this gets printed out\\nbecause it doesn't belong to this if statement here.\\n\\nAnd, of course, if a is true,\\nall three of these lines get printed.\\nI can also add an else statement here,\\nelse: print It is false.\\nOkay, so if a is true, do this block.\\nOtherwise, do this block.\\nSo the indenting in Python is very important here.\\nIt really controls the structure of your program.\\nThings can really get indented quite a bit,\\nlike let's bring this down into a new cell here\\nand let's add another variable.\\n\\nLet's call it b.\\nAnd we can actually indent under here\\nand make a completely new block.\\nIf b: Both are true.\\nAnd if we run this, we see Both are true printed out.\\nWe can even add a third variable, c.\\nJust keep indenting,\\nif c: print All three are true\\nand you see that gets printed out.\\nOf course, if we set any of these to false along the way,\\nwe never reach that line there.\\n\\nSo you can see how this could start\\nto get a little bit ridiculous.\\nIn order to prevent excessive indenting\\nand convoluted structures like this,\\nPython has another tool and that's called the loop.\\nLet's look at the for loop.\\nSo for loops iterate over,\\nwell, what we call in Python iterables.\\nA list is a type of iterable.\\nSo we can make a list like 1,2,3,4,5\\nfor item in my list, my iterable list a, print item.\\n\\nNow keep in mind that the in here\\nis not the same as we did previously.\\nSo 4 in a, that gives us a Boolean\\nthat says that yes, it is true that the number four\\nis in this list of items here.\\nThis in is actually very different\\nand it's just part of the for loop syntax.\\nYou say for each item in the list,\\ndo something with that item.\\nThe other thing to note is that the item here\\nis just a variable that we're declaring in this line.\\n\\nYou could use anything in here, for b in a,\\nfor number in a, you get to name it in that for loop.\\nJust remember to change the variable name\\ninside your for loop.\\nOtherwise, you'll get an error.\\nA while loop is similar to a for loop\\nexcept that it doesn't iterate over items in a list.\\nIt just keeps looping until the Boolean you pass is false.\\nSo say a is equal to zero,\\nwhile a is less than five, print a.\\n\\nNow here's a very important line,\\na is equal to a plus one,\\nand we see that we get basically the same results\\nas the for loop.\\nWe're starting with zero, of course,\\nbut it's very important that you have this line in here\\nbecause without it, the loop would never end\\nand we'd be printing the number zero forever.\\nMore than one programmer has made that mistake.\\nSo generally you want to use while loops\\nwhen conditions are changing or that are being impacted\\nby the block under the while loop.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400004\",\"duration\":265,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Functions\",\"fileName\":\"4314028_en_US_02_05_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4001555,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- A function can be thought of as a machine.\\nLike this toaster.\\nWe put in bread.\\nAnd we get out toast.\\nIt applies the toasting function to the bread.\\nWhat if I put in these breakfast pastries?\\nWell, it's not bread,\\nbut a toaster can still apply the toasting function to it.\\nLook, it returns toasted breakfast pastries.\\nWhat if I put in this brick?\\nOr three bricks?\\nThis gallon of milk?\\nHmm, if only this toaster were better programmed\\nto accommodate these inputs.\\n\\nLet's go to the code.\\nWe've seen a few functions so far.\\nSo print hello world, first one we saw.\\nAnd print is a function.\\nIt has a function name, print.\\nIt has these parentheses where you can stick all\\nof your inputs or arguments.\\nThis is like bread going into the toaster\\nand the argument for here is hello world.\\nAnd in Python we can even define our own functions.\\nIt's a bit like defining variables.\\nThe function name rules are the same\\nas the rules for variable names.\\n\\nStart with a lowercase letter.\\nYou can't start with a number, et cetera\\nbut we use a special keyword called def\\nwhich stands for definition.\\nSo we can make a function def multiply by three\\nand then we write our parenthesis\\nput any variable names for arguments that we want.\\nAnd this is just going to take one variable called val\\nfor value.\\nThen we add a colon.\\nAnd just like with the for and while loops,\\nthis colon means that we need to indent the next line\\nand start our block of code.\\n\\nSo we're going to return three times the value.\\nI'm going to use another keyword here called return.\\nSo functions usually return things\\nand what we're returning is three times the value\\nthat we passed into the function.\\nSo now we can call this function.\\nMultiply by three, four.\\nAnd the value that gets returned is 12.\\nWe could change this a bit\\nand make a function with two arguments.\\nDef multiply val one and val two\\nand we're going to return val one times val two.\\n\\nAnd then if we call it multiply three, four,\\nagain the returned value is 12.\\nNow functions don't always necessarily\\nhave to return anything.\\nFor instance, we can make a function\\nthat mutates or changes a value.\\nSo let's define a list A\\nand a function appendFour myList,\\nmyList.appendFour.\\n\\nAnd then we're going to call this\\non our variable A and then print A.\\nAnd we see that the number four has been added\\nto the end of this list.\\nThis function didn't return anything\\nbut it did, you know, perform a function.\\nThis is a bit like bread going\\ninto the toaster and leaving the toast there\\nfor a while for someone to go and collect later.\\nYou don't always want it popped back up at you.\\nIf we look at the print function,\\nwe also see that it doesn't return anything.\\n\\nSo let me just copy this and it prints something\\nto the screen, but it's not popping anything back at you.\\nSo what if we printed the returned value\\nof the print function?\\nYou see it prints none.\\nSo the print function actually returns none\\nand none is a special python keyword\\nlike null or undefined in many other languages.\\nIt doesn't really have a value.\\nIt represents the absence of value.\\n\\nIt has its own type, the none type.\\nAnd in general,\\nyou want to be really careful when using none.\\nIf you think you're getting a value\\nwhen you try to operate on it like none plus one,\\nyou're going to have a really bad time.\\n(toaster dinging)\\nOh, my milk is done.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4407001\",\"duration\":352,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Classes and objects\",\"fileName\":\"4314028_en_US_02_06_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5294172,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- We already talked about a toaster function,\\nbut what if we want to make a whole kitchen?\\nA kitchen has many abilities,\\ntoast, bake, microwave, wash dishes,\\nand of course, the all-important coffee maker.\\nThese various kitchen appliances have settings,\\nthe knob on the toaster, the power setting of the microwave.\\nThe dishwasher itself has different modes\\nand multiple functions that can apply to dishes.\\nI'm sure we could make a whole bunch\\nof functions and variables,\\nand throw them in a file somewhere.\\n\\nBut what if we want two separate kitchens\\nwith different abilities and sets of appliances?\\nWhat if we want to make a whole house\\nwith a kitchen, a laundry room, a bathroom?\\nMultiple houses, maybe one with no laundry room\\nthat has to outsource its laundry to a laundromat?\\nYou can imagine how these systems\\nwould lead to dozens or hundreds of functions,\\nthousands of variables,\\ncode that gets long and unmanageable pretty quickly.\\nFortunately, programmers have invented a tool\\nto deal with situations like this, the class.\\n\\nA Python class is a great way\\nto keep related collections of functions and attributes\\nlabeled and organized.\\nLet's go to the code.\\nThe classic way to demonstrate classes in programming\\nis by using animals, so let's make a class called Dog.\\nSo we need to define a class with a name\\nand you get to use an uppercase letter for class names.\\nThis is what makes them different\\nfrom variable and function names.\\nClasses usually start with uppercase letters.\\n\\nAnd because we've typed a colon,\\nthis indicates that we're going to indent to the next line.\\nAnd everything inside this indent\\nis going to be our class definition.\\nNow we can start defining all of the functions\\nand attributes that a dog has.\\nAnd the first function that we want to define\\nis a special one, the init function.\\nInit stands for initialization, and this function is called\\nwhenever an instance of the class Dog is created.\\nIt has two underscores on either side,\\nand this is a special Python defined thing\\nso the computer will recognize this\\nas the initialization function.\\n\\nThen we're going to pass in a variable called self.\\nThis variable is the specific instance\\nof the Dog class after we've initialized it.\\nAnd, well just watch,\\nthis is going to make more sense in a minute.\\nWe're going to define a couple attributes\\nand functions in here.\\nWe want to make a dog\\nwith four legs and a name, and we'll call it Rover.\\nSo name is equal to Rover and self.legs equals four.\\nWe're also going to make a function called speak\\nthat prints out bark, print bark.\\n\\nNotice that I passed the self variable\\nto the speak function.\\nThis means I have access to any\\nof the attributes or functions in this class.\\nFor instance, I could do this, self.name plus, says bark.\\nAnd this will concatenate the dog's name\\nwith this string here.\\nNow let's use this class.\\nLet's just run that.\\nAnd then my dog is equal to dog.\\n\\nSo my dog is equal to an instance,\\na newly created instance of the class Dog.\\nNow this is in text with the parentheses\\nmakes it look a little like a function\\nbut Dog is a class, not a function.\\nAnd this is why it's important to adhere\\nto the Python convention\\nof keeping variables and function names lowercase\\nand only class names are capitalized\\nso that you can tell the difference between the two.\\nWhen we do this, the initialization function gets called\\nand we get an instance of our Dog class returned.\\nWe can create another dog.\\n\\nIt's equal to dog.\\nOkay, so now we have my dog and another dog.\\nSo let's do my_dog.speak.\\nRover says bark.\\nAnd another_dog.speak.\\nAh.\\nit's a very common name,\\nbut this starts to get a little bit confusing.\\nWhat if we want to give dogs different names\\nand we want to maybe provide a name\\nwhen we initialize the dog?\\nAll we have to do is this, pass in a name variable\\nand say self.name is equal to name.\\n\\nThen when we create each dog, we pass the name in,\\nRover and Fluffy.\\nRover says bark and Fluffy says bark.\\nMuch better.\\nNotice that the speak function, when you call it,\\nit looks like it doesn't have any arguments.\\nThere's nothing being passed in these parentheses.\\nBut if we look at the function definition in the class\\nit does have one argument, self.\\nAnd the way Python works is\\nthat if you have a class instance,\\nlike these two things are instances\\nof the class Dog, and you use the dot function syntax,\\nit acts like your instance was actually passed in\\nas the first variable of this function.\\n\\nSo this self variable here is literally the instance\\nof the class that the function was called on.\\nSo if you've heard\\nof the term object oriented programming before,\\nthis is what it is.\\nThese class instances are also called objects.\\nThese are dog objects.\\nThe variables inside these classes are called attributes,\\nattributes of the objects.\\nThe functions in here are called methods\\nand you can call them class methods.\\nWe say that the Dog object has the method speak.\\n\\nSo this is a very brief introduction to some of the concepts\\nand terminology of object oriented programming,\\nbut I'm going to be showing off\\nreally how powerful they can be later on.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4218188\",\"duration\":220,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"About the challenges\",\"fileName\":\"4314028_en_US_02_06a_FY24Q4_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"ADDED\",\"editingNotes\":\"NEW VIDEO\\nTetris LA (Recorded backup SC with script on screen)\\n\\nRyan on screen for the first half, then slides at the end, but feel free to cut to some Coderpad or coding SC b-roll from the course as needed.\\n\\nSee script for slide placement: https://docs.google.com/document/d/13RMTc8H4i3ayh8Mv1c2cEyiuJV_KL40D/edit\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":248,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10900159,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Hi.\\nyou're going to be on your own with CoderPad.\\nI'm sorry, no friendly videos of me cheering you on.\\nJust click over to the challenge,\\nand you get your CoderPad screen,\\njust you and the open code.\\nBut here and now, I've made an exception\\nto give you a little, well, heads-up.\\nIf you've never programmed before,\\nthis first challenge might be daunting.\\nYou may stare at CoderPad, drawing a blank,\\nunable to even write that first line.\\nSo, how do you deal with this?\\nFirst, relax, it's normal.\\n\\nIt's not because you haven't learned any Python\\nor you're unprepared for the challenge.\\nIt's because writing a new program\\nis a new and weird way for your brain to work\\nthat it's never had to do before.\\nThis course is, what, 4 1/2 hours long?\\nYou're not going to go from zero to programmer\\nin the time it takes you to watch two feature-length movies.\\nAnd yeah, you've been watching me write programs.\\nI make it look super easy, right?\\nWell, I've been doing this for 20 years.\\nAnd also, here's a filmmaking secret:\\neverything is actually written beforehand.\\n\\nThat's right, the words I'm speaking right now\\nI wrote down previously,\\nsent through a team of editors, workshopped,\\nand I'm reading them off a teleprompter.\\nThe programs I wrote, I wrote them,\\nand then, while I record the screen capture,\\nI just retype them from what's written just off screen.\\nMovie magic.\\nAlso, watching someone write programs\\nand then writing them yourself\\nis like the difference between reading a novel\\nand writing one,\\nor being a passenger and then driving a car yourself.\\n\\nTotally different skills,\\ntotally different brain functions.\\nSo in this challenge, if you sail through it, good for you.\\nIf you find yourself frustrated and stuck,\\nalso, good for you.\\nFrustration motivates discovery\\nif you do it right.\\nIf you do get frustrated,\\nhere are some things that you can do.\\nSpend more time learning and understanding the problem.\\nI've created challenges\\nthat include bite-sized math and computer science topics\\nthat frequently come up in programming.\\nThere's a lot of explanatory text written\\nthat you may or may not need,\\nbut if you think you might need it,\\nmake sure to carefully read it.\\n\\nRun through a few examples on paper.\\nLook at other learning resources,\\nparticularly if you've never encountered\\na math concept before.\\nYou're allowed to use a search engine.\\nGo to the Hints file.\\nFor every challenge,\\nI've included a Python notebook in the exercise files\\nthat says Hints.\\nIt provides very explicit nudges in the right direction.\\nYou can copy and paste the code, run it, modify it.\\nGive yourself space and time.\\nAgain, if this is your first time writing code,\\nthis is not going to be a five-minute thing.\\n\\nUnderstand that if it takes you a long time to write,\\nthat's all time spent learning Python.\\nThe world does not need another factorial function.\\nThis is for you.\\nThis is about your learning process.\\nIf you do feel\\nthat there's a specific skill that you're lacking\\nor something you missed,\\nplease go back and watch the video again.\\nThis is not a university lecture hall.\\nIt's a series of short, fast-paced videos\\nthat are there for you to use as needed.\\nPause and rewatch.\\n\\nWrite something else.\\nGo back to the Python notebooks\\nand play around with the code.\\nWrite your own thing.\\nWrite a function\\nthat literally just returns the word \\\"Hello.\\\"\\nWrite anything.\\nRemember, you want to get your brain used to this new skill.\\nSo take a deep breath, and welcome to Python programming.\\nAnd if this is your first CoderPad challenge, good luck.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:661420e2498ed4169329010b\",\"duration\":1800,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Factorials\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:962244\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4222195\",\"duration\":282,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Factorials\",\"fileName\":\"4314028_en_US_02_08_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_02_08_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":328,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8000140,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] I hope you had fun\\nfiguring out those factorial functions.\\nWelcome back. How'd you do?\\nI'll show you my solution,\\nand if you looked at the hints file,\\nthis solution probably shouldn't come\\nas too much of a surprise.\\nThe first thing we want to do is make sure we're able\\nto take the factorial of our input,\\nso if our input is not an integer,\\nwe're going to return none.\\nSo this takes care of floats like 1.2\\nas well as the string \\\"spam, spam, spam, spam, spam, spam\\\"\\nthat you might have noticed was a test case.\\n\\nOf course, negative two is still a valid integer,\\nso we need to make a special case for that as well,\\nso we check to see if the input number is less than zero\\nand then we return none,\\nbecause you cannot have the factorial of a negative integer.\\nNow we want to get down to the business\\nwith calculating the factorial.\\nTo do this, I'm going to make two variables,\\nfact, short for factorial.\\nThis is the thing that we ultimately return,\\nand then counter to keep track\\nof how many loops we need to do.\\n\\nSo while counter is less than the input num,\\nthat's basically the number of iterations,\\nour factorial is equal to factorial, the existing factorial,\\ntimes the counter, and then with each pass in the loop,\\nwe increment or add one to our counter.\\nSo on the first pass, you're going to be multiplying by one,\\none times one.\\nOn the second pass, you're going to be multiplying by two,\\non the third pass, times three, et cetera,\\nup to the number that was passed in.\\n\\nSo if you pass in five,\\nyou're going to end up returning one times two\\ntimes three times four times five,\\nwhich is exactly what we want.\\nAnd remember, we have a special case\\nwhere the input number is equal to zero,\\nso mathematicians decided that the factorial of zero is one.\\nI didn't decide that, that was mathematicians,\\nbut we as computer programmers\\nmust follow the rules of mathematicians,\\nso does this work when the input number is zero?\\nIf num is zero, then we start the fact number at one.\\n\\nThe while loop never gets entered\\nbecause the input number zero\\nis already greater than the counter,\\nand so we just end up returning one,\\nwhich is correct, so great.\\nNow, there's also a shorter way to write this function,\\nand that's through recursion, where a function calls itself.\\nSo I just want to show you the solution really quick.\\nI'm actually going to keep the same checks here,\\nand I'm going to add an additional case.\\nIf num equals zero, return one.\\n\\nOkay, finally, we want to return num times factorial\\nnum minus one, and if we test this, that also works.\\nAwesome. So what's going on?\\nWell, let's say we call this function factorial\\nwith the number three,\\nand I'm just going to write a comment down here.\\nFactorial three is how we're going to call it,\\nand what this is equal to, this isn't Python code,\\nthis is just sort of a shorthand.\\n\\nWhat this is going to do is it's going to say, okay, great,\\nall these checks pass for the number three.\\nIt's not equal to zero, so we go down here\\nand we return three times factorial of three minus one,\\nwhich is two, so we end up returning three\\ntimes factorial two.\\nWell, what's factorial two?\\nSo it gets called again with num being two,\\npasses all of this, and it turns out that factorial two\\nis equal to two times factorial one.\\n\\nAll right, so what's factorial one?\\nWe call this again.\\nIt gets called here.\\nFactorial one is equal to one times factorial zero,\\none times factorial zero.\\nWell, what's factorial zero?\\nGets called again.\\nIf the number is zero, we return one,\\nso factorial zero is one, and it turns out\\nthat factorial three is three times two times one times one,\\nwhich is six, so our original function call,\\nfactorial three, is equal to six,\\nand ultimately, return six.\\n\\nNow, recursion might seem like magic at first,\\nbut don't be intimidated.\\nIt's just a fancy kind of loop.\\nIt does take a while to get the hang of,\\nbut it's also a very handy skill to have\\nin your programming repertoire.\\n\"}],\"name\":\"2. Quickstart\",\"size\":49619682,\"urn\":\"urn:li:learningContentChapter:4406009\"},{\"duration\":1758,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4400005\",\"duration\":233,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Ints and floats\",\"fileName\":\"4314028_en_US_03_01_MM30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Python represents whole numbers and integers very differently. This video explains operations with both, how and when to convert, and about the limitations of each.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3511734,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Okay, let's go back to ints and floats,\\ntwo basic Python number types,\\nand let's look at what happens when you use them together,\\nconvert between the two, and how to watch out for some\\nof the common pitfalls of each.\\nSo earlier we saw an example of doing math with ints\\nand getting a float back.\\nSo, 20 is an integer, four as an integer,\\nbut we get back this float, 5.0,\\nand Python is trying to be helpful here\\nand always return a float from division,\\nbecause there's a potential\\nfor non-whole numbers to come back.\\n\\nSimilarly, if we add a float with an int,\\nwe get back a float, and the same goes\\nfor multiplication and also exponents.\\n256.\\nAnd we want to convert this back to an int.\\nWe can use the int class to do that.\\nSo if I just grab this 256 as an integer.\\nNow notice I said the int class, not function,\\nand it looks like a function, it's lowercase,\\nbut int is actually a built-in class in Python.\\n\\nAnd Python sort of breaks these capitalization rules here,\\nspecifically for its built-in classes.\\nSo for, actually all of these things,\\nstrings, ints, floats, list, these are all classes.\\nSo when you convert from one type to another type,\\nlike here, I'm converting from a float to an int,\\nthis is called what programmer's call casting.\\nSo I'm casting from the float 256 to the integer 256.\\n\\nSo, casting this is pretty straightforward,\\nbut what about let's say 8.9?\\nHmm, that's an eight.\\nWhat about 8.99999 and then some other nines.\\nVery, very close to nine,\\nbut it's still the integer eight.\\nSo when you cast from a float to an int,\\nPython does not round for you.\\nAll it does is lops off everything\\nafter the decimal place.\\nInts don't have decimal places,\\nit just throws that part away.\\n\\nSo you have to be really careful.\\nSay, if you're doing something like this,\\nwhich is very close to five,\\nit will actually round to, not round, but turn it into four.\\nIf we want to round this to the nearest integer,\\nwe can use the round function and that gets you back five.\\nAlso, as an argument, we can pass\\nin the number of decimal places we want to round it to.\\nSo, 4.67 and that's actually doing rounding for you.\\nSo, let's look at one of the pitfalls of floats.\\n\\nLet's do 1.2 minus 1.0.\\nSo I'm a programmer, not a mathematician,\\nbut that doesn't look quite right to me.\\nSo what's going on here?\\nIf you look back at 14 over 3,\\nyou'll see that this is represented\\nwith a 67 at the end.\\nSo this, what 14 over 3 actually is, is 4.6 repeating,\\nbut its float representation literally ends in a 67.\\n\\nFloats are approximations.\\nFloats are stored as binary ones and zeros in memory,\\nand there's only a finite amount of memory to store them,\\nso Python uses some tricks and approximations\\nand this can occasionally result in weird rounding errors\\nthat result in this kind of thing.\\nNow, if you use the round function on something like this,\\nyou should be fine and we should probably give\\nthat a couple decimal places,\\nbut you should be a little cautious\\nabout using floats for this reason.\\n\\nNext, we're going to look at some other ways\\nof dealing with decimals, particularly\\nin situations where the number of decimal places is known,\\nlike with money.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4404001\",\"duration\":269,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Other types of numbers\",\"fileName\":\"4314028_en_US_03_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explores other ways to represent numbers in Python: decimals, hexadecimal, and octal.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4068644,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] All right, we're going to get\\nto the decimal class in a second.\\nBut first I just want to show you a couple\\nneat things you can do with the int class in Python.\\nSo if I pass in a number as a string, it will convert it.\\nWe're casting this string 100 to the integer 100.\\nNow a cool trick with this class is\\nthat if I optionally pass as a second argument,\\nI can pass a number, it will take the second argument\\nas the base that the number should be converted from.\\nSo 100 in base two is four in base 10.\\n\\nAnd this first argument has to be a string.\\nIf I try to do 100, two like that, it throws an error.\\nSo why is that?\\nThis is because when you're converting\\nfrom one base to base 10\\nyou might have things in the string that aren't numbers.\\nSo 1ab is perfectly valid in base 16\\nand that's apparently 427.\\nBut obviously, you know, 1ab is not an integer.\\nSo we have to have a string as the first argument\\nif we want to convert it from a different base.\\n\\nAnd so this int class is very cool and handy.\\nAnd let's look at another totally different number class\\nin Python that solves some\\nof the problems we saw with floats in the last video.\\nRemember, while floats are great at what they do\\nthey have what's called a floating point error.\\nAnd we saw this with 1.2 minus 1.0,\\nwe get something that's definitely not 0.2.\\nAnd for some applications\\nthese floating point errors can be annoying\\nor even create unacceptable risks\\nlike when you're working with money.\\n\\nAnd in these cases, Python has the decimal module.\\nTo use the decimal module, we're going to import a class\\nand a function at the top of our notebook,\\nand it's traditional to keep all imports\\nat the top of your code.\\nSo from decimal, import decimal, and getcontext, import.\\nAlright, so Python has some modules, basically handy pieces\\nof code available by default with your Python installation.\\nSo some of these things are available\\nwithout needing to explicitly import them\\nlike we're doing here, like print or float.\\n\\nBut some of these things like the decimal module\\nrequire you to write an import statement at the top.\\nSo this says, from the decimal module\\nwe're going to import this class decimal\\nand this function getcontext.\\nSo if we call this function, getcontext, we can use it now,\\nit returns a context object\\nwith a bunch of attributes in it.\\nAnd these are basically the global settings that get applied\\nto your usage of the decimal class.\\nWe can change any of these settings we want\\njust by saying getcontext.precision is equal to four.\\n\\nNow, if we call getcontext again\\nyou can see that it's changed to four.\\nYou can instantiate a decimal class with a number value.\\nSo if I do decimal one over decimal three,\\nit returns 0.3333 to four places of precision.\\nAnd if we change the precision to two,\\nlet's just do that and then rerun this.\\nYou can see that we get it to two decimal places.\\n\\nNow if I pass a float to decimal, 3.14, don't be alarmed.\\nThis isn't a failing of the decimal module.\\nWe're trying to exactly replicate the float\\nthat was passed in, capturing all the digits of information.\\nSo this is actually a really good example\\nof why floating point errors arise.\\nIt's taking this float\\nand it's saying this is what this float exactly is.\\nWhat we can do in this situation is do decimal,\\n3.14 as a string, and that looks a bit better.\\n\\nSo there are actually many ways\\nof representing numbers to the decimal class,\\nand I encourage you to check out the documentation\\nif you're interested in using it for your own project.\\nSo should you use a decimal class instead of floats\\nwhen dealing with decimals?\\nNot necessarily.\\nAlways round appropriately\\nbefore showing values to end users.\\nBe wary of situations where you're dealing\\nwith very small numbers or very, very large numbers.\\nHowever, most of the time, I'd say 98% of the time\\nfloats are actually just fine.\\n\\nSo instead of sending back 1.2 minus 1.0,\\nwe can round it and then return that to your users.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4401005\",\"duration\":395,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Booleans\",\"fileName\":\"4314028_en_US_03_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"As the most fundamental data type, Booleans are used in code often without realizing it. This video discusses truthy and falsy values.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5945365,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] We looked at Booleans earlier,\\nand you might have been left with the impression\\nthat there's not a lot left to say about them.\\nTrue and false, right, how hard could it be?\\nWell, there are a few actually tricky aspects\\nof them that we need to cover.\\nAnd because I'll use them day in,\\nand day out as a programmer,\\nit's extremely important to cover these.\\nHonestly, I occasionally find myself\\nbringing up a Python terminal to double check\\na line of boolean logic or confirm exactly\\nhow Python handles one case or another.\\nSo let's go to the code.\\nThe first thing I want to talk about is casting.\\n\\nSo Python will cast integers to booleans pretty nicely.\\n1 is true, and of course 0 is false.\\nIn fact, anything except a 0\\nwill be cast a boolean true.\\nSo something like -1 might feel false to us,\\nbut be careful to Python, it's true.\\nEven something like let's do imaginary one, that's true.\\nHowever, imaginary zero or float zero are both false.\\n\\nSo 0.0, and if we do zero j, they're false.\\nOkay, so what about strings?\\nBoolean true is true, fair enough.\\nBoolean false is true.\\nThat's because anything other than an empty string\\nis actually going to be true.\\nThere's nothing special about this string false.\\n\\nIt's just a string, python assumes that it's true.\\nOf course an empty string is the only false string.\\nBut be careful even putting something like a space in here,\\nmake sure that it's truly an empty string.\\nWhat about data structures?\\nWe can cast these to Booleans as well.\\nAn empty list is false.\\nAn empty dictionary is false.\\nIf I put anything inside of here though, it's true.\\n\\nRemember that non-value that Python returns from functions\\nthat if you don't add any explicit return value there,\\nwell, unsurprisingly, these get cast to false.\\nNow, why is it so important to learn\\nthe rules of casting Booleans and Python?\\nWell, remember that Booleans aren't usually used directly.\\nYou're usually checking the boolean value of statements\\ninside an if statement or a for loop.\\nSo you'll very often use them in situations like this.\\nMy list equals 1,2 if my list\\nprint \\\"My list has some values in it\\\", great.\\n\\nAnd what we're doing here is casting\\nthe value of my list to boolean in order to evaluate.\\nThis is equivalent to writing this.\\nYou can also do, something like this.\\na equals five, b is equal to five.\\nIf a minus b, print, \\\"a and b are not equal\\\".\\nGreat, didn't print, the only way\\nthat a minus b evaluates to zero or false\\nas if a is equal to b.\\n\\nOf course, this is a little overly clever.\\nIf we really want to do this, we could just do that.\\nAnd that brings me to my next point.\\nThere's usually more than one way to evaluate boolean.\\nSo you have to be a little bit careful\\nabout keeping track of this logic.\\nSo let's look at a situation where we're evaluating, say,\\nwhether or not to go for a walk.\\nSo weather is nice, is false, have umbrella is true.\\nSo if weather is nice or we have an umbrella,\\nwe can go for a walk.\\n\\nIf not weather is nice or have an umbrella,\\nwe must stay inside.\\nSo if not have umbrella, or weather is nice,\\nprint, \\\"Stay inside\\\", else, print, \\\"Go for a walk\\\".\\nSo if we have an umbrella,\\nthis tells us we can go for a walk.\\nLooks good, right?\\nBut python evaluates booleans left to right.\\n\\nSo this is saying not have an umbrella which is false,\\nor weather is nice, which is also false.\\nSo this whole thing evaluates to false.\\nThere are actually imaginary parenthesis\\naround the not have an umbrella here.\\nSo this isn't quite the logic we want.\\nIf we flipped the booleans\\nso that we don't have an umbrella, but the weather is nice,\\nyou can see that it does the wrong thing.\\n\\nIt's telling us to stay inside\\neven though the weather is nice.\\nSo there are a couple ways to fix this,\\nand fix this in a way that would give us the correct logic.\\nSo first, we could do this.\\nWe could put parentheses around the thing\\nthat we want to evaluate first.\\nAnd this would give us the correct logic.\\nThere's also kind of a cool thing we could do\\nwhich is rewrite this with an and statement.\\nSo let me just copy this.\\n\\nIf not have an umbrella and not weather is nice.\\nLet's do that, and this is actually\\nthe exact same logic we had before.\\nThese two are equivalent.\\nAlthough it's not strictly necessary,\\nit might be nice to put parenthesis\\naround this just for readability, like so.\\nBut that's just readability for humans, not computers.\\n\\nAnd of course we could also flip\\nthe order of these statements entirely,\\nwhich is probably the best,\\nand most readable way in my opinion.\\nSo if have umbrella or weather is nice,\\nprint \\\"Go for a walk\\\" else print, \\\"Stay inside.\\\"\\nSo yes, Booleans are at a certain level, very simple.\\nHowever, it's critically important that\\nwhen you're writing a boolean statement,\\nyou'd be very careful.\\n\\nThink about how Python is evaluating\\neach piece of the statement,\\nand always double check your logic.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4406002\",\"duration\":373,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Strings\",\"fileName\":\"4314028_en_US_03_04_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video goes over strings as variables representing text and lists of chars. Learn how arithmetic operators can be used with strings, as well as common string manipulation functions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5619440,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] All right, this is an exciting one.\\nIn Python, we're working with strings a lot,\\nwhether it's parsing them to extract some data\\nor constructing them to provide some information\\nto an end user.\\nAnd Python has a lot of tools\\nto both analyze and construct strings.\\nAnd the first one I want to take a look at is called slicing.\\nIt's called slicing because we're literally taking a slice\\nout of a string and returning it.\\nSo let's make a string.\\n\\\"My name is Ryan Mitchell.\\\"\\nOkay, and let's say we want to get\\njust the first character of that string.\\n\\nWe can do name zero.\\nRemember, programmers always start counting from zero,\\nso we say that m is at index zero in the string,\\nand we could also get the second character, name one,\\nwhich is that y at index one in the string.\\nWell, what if we want to get\\nthe first seven characters of a string?\\nThe words my name.\\nWe could use a colon, zero colon seven,\\nwhich means get me the characters\\nbetween zero and index seven.\\n\\nNote that it doesn't actually\\nget the character at index seven,\\nwhich is the space after name.\\nIt gets the characters up to index seven.\\nAnd there's also this sort of shorthand you can use\\nwith the slicing syntax, which is name seven.\\nIf you want to write a zero here,\\nyou can just leave that zero out\\nand it's equivalent to writing the zero.\\nSimilarly, if you want to get all the characters\\nfrom index 11 to the end of the string,\\nyou can just do 11 and then leave that out.\\n\\nAnd this is really handy\\nbecause we may not know the length of the string,\\nso you don't actually have to write it in\\nif you don't know it.\\nIt just goes up to the end of the string.\\nSo if you leave it out at the beginning,\\nit starts at the beginning of the string.\\nIf you leave it out at the end,\\nit goes up to the end of the string.\\nIt's also important to note\\nthat the slicing syntax is exactly the same\\nwhen you're working with lists.\\nSo if I have a list, one, two, three, four, five,\\nI can take a slice of that list.\\nMy list, two to four.\\n\\nLists and strings actually have\\na lot of similarities in Python.\\nSo I can take the length of a string.\\nSo the string has 24 characters,\\nI can also take the length of my list.\\nMy list has five elements.\\nWe're going to be looking at some other neat features\\nof the slicing syntax later on when we look at lists.\\nAnd so keep in mind that all these features\\ncan be used in the exact same way with strings too.\\nSo let's look at a few things now\\nthat are particular to strings.\\nSo Python is great at string formatting.\\n\\nThere are a few ways to create strings in Python,\\nincluding one very basic obvious way\\nwith string concatenation.\\nSo, let's do my number is string five...\\nSo my number is five.\\nWe can do this with something called an f string.\\nSimply type in f, which stands for format,\\nthen type your string\\nwithout any spaces between this f and your string.\\nSo put your variables inside curly braces.\\n\\nMy number is five.\\nSame exact thing.\\nYou can also write expressions inside the curly braces.\\nSo f my number is, let's say two.\\nLet's do five, and twice that is two times five.\\nWhoops.\\nThere we go.\\nYou can even do rounding and number formatting.\\n\\nIf we import the Python math library\\nby convention at the top of the file,\\nwe have access to math.pi\\nwhich is pi out to 15 decimal places.\\nAnd we can display pi rounded to two decimal places\\nwith a colon and a 0.2f.\\nSo let's just write this, pi is math.pi,\\nthat's going to be pi to 15 decimal places.\\nAnd then using the special string formatting syntax,\\nwe're going to round it to two decimal places.\\n\\nSo f strings came out with Python 3.6.\\nIt's a relatively new feature.\\nPrior to version 3.6, the string format function was used\\nwhich is very similar.\\nYou can see the format function.\\nI prefer f strings now, but let's just take a look at it.\\nPi is .format math.pi.\\nAnd finally, a new way to write strings.\\nThe multi-line string.\\n\\nIf you use three quotes,\\nPython will go into multi-line string mode.\\nIf I were to put a new line in the string up here,\\nit would return a syntax error.\\nYep, no good.\\nHowever, sometimes you want to include\\nnew lines in your strings.\\nSo my string here is a long block of text.\\nI can add new lines.\\nThe text doesn't stop until it sees...\\n\\nOh, look at that.\\nWhat if I want to put literal, triple quotes in there?\\nI can use that backspace character to escape it.\\nAnd if we print out my string, there we go.\\nYou see that this actually includes\\nthese backslash ends in here.\\nThis backslash ends are new lines.\\nThis indicates that we're going to a new line of text.\\nAnd this is just what Python prints out\\nwhen you're actually looking at the string.\\n\\nIf I do print my string,\\nyou can see it renders it a little more nicely.\\nSo Python is fantastically flexible at manipulating,\\nparsing, and creating strings.\\nThere are hundreds of string functions and ways to use them.\\nWe'll be covering more ways to use them,\\nbut if you want to look\\nI suggest checking out the official documentation\\non Python's website.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400006\",\"duration\":248,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Bytes\",\"fileName\":\"4314028_en_US_03_05_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video covers the Python bytes object and where it's found.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3752605,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] So here's one we haven't covered yet.\\nThe Python byte object.\\nSo in day-to-day programming,\\nyou won't often be working with it.\\nIt's common behind the scenes.\\nIt's data that gets passed around in a program\\nbut it's rarely manipulated or modified directly.\\nAs we all know, computers store information\\nas ones and zeros on the disk.\\nWhen Python loads that data,\\nthere's information that tells Python what the type is,\\nif it's a string, an int, some sort of class\\nwith properties, et cetera.\\nIn some cases though, all you really want is data.\\n\\nSome random series of ones and zeros.\\nAnd so there's the bytes object.\\nWhat kind of data is the bytes object?\\nWho cares.\\nWhat type is it?\\nWell, it's a bytes object.\\nIt's a sequence of data and that's all Python needs to know.\\nThe bytes object is commonly used for streaming files\\nor transmitting texts without knowing what the encoding is.\\nYou'll see it pop up a lot in Python libraries.\\nSo let's take a look\\nat how to recognize and use the bytes object.\\nSo first, let's create one.\\n\\nNow this looks like we're casting the integer four\\nto a bytes object, but not so fast.\\nWhat this does is it actually creates an empty bytes object\\nthat's four bytes long.\\nEach byte here is represented with a /x\\nfollowed by two hexadecimal or base 16 numbers.\\nSo remember\\nwhich is the same as two to the power of eight\\nor eight bits.\\nAnd of course there are eight bits to a byte.\\n\\nOkay, so this is four bytes long.\\nAnd this b here is used to differentiate bytes\\nfrom a regular string.\\nSo if you see something printed out\\nand it has the b in front of it, it's a bytes object.\\nLet's make a bytes object with actual data in it.\\nSo to do this, let's do a fun emoji here.\\nThe eye roll.\\nOkay.\\nWe need to tell Python what the type is.\\n\\nSo we're going to do utf-8.\\nSo in order to create the bytes object,\\nyou need to tell it what the type is\\nof the thing that you're trying to encode\\nso it knows how to find and isolate the data.\\nAnd in this case, emojis are encoded with utf-8\\nwhich is a type of Unicode transformation format.\\nSo once it knows the format of the thing you're feeding it,\\nit can represent the data correctly.\\nLet's call this smiley bytes.\\n\\nOkay. And there's the bytes for that emoji.\\nNow how do we go the other way?\\nTake a bytes object and represent it as a string again.\\nFor this, you need the decode function.\\nAnd again, you need to pass the format in.\\nSo decode utf-8.\\nAnd there we go.\\nBytes objects are immutable like tuples.\\nSo if we want bytes data that we can modify,\\nwe can use something called a byte array.\\nLet's actually just take this, change it to a byte array.\\n\\nThe syntax is very similar.\\nWe can see this is a byte array now.\\nWe can treat this smiley bytes object a lot like a string,\\nincluding modifying a specific byte value\\nusing the string slice notation.\\nSo let's take this value at the last position.\\nThis is hexadecimal 84, and we can take this\\nand that's at index three there.\\nSo we're going to say it's 85.\\n\\nLet's see what that is.\\nSo how do we get hexadecimal 85?\\nWe can use the int library, remember that?\\nSo let's take 85 in base 16, and then we set that.\\nAnd then we want to decode it, see what we get.\\nDecode utf-8.\\nIt looks like a shrugging emoji.\\nSo that's how to find, detect, use, and modify bytes.\\n\\n\"},{\"urn\":\"urn:li:learningContentAssessment:6614210c345084068bb5935b\",\"duration\":1800,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Converting hex to decimal\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:962247\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4222196\",\"duration\":240,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Converting hex to decimal\",\"fileName\":\"4314028_en_US_03_06_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_03_07_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":289,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6721740,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] All right.\\nI hope the hex didn't vex you too much.\\nI have two solutions that I want to go over with you,\\nand the first is pretty straightforward.\\nSo here I'm assuming that everything passed\\ninto this function is a string,\\nor rather a list of characters\\nis another way to think about it.\\nAnd the only test cases I gave you were strings.\\nSo if you did check for integers\\nor some other really wacky input, you are a more thorough\\nand diligent programmer than I am.\\nGood work, but I was really only worried about strings here.\\nJust as an upfront check,\\nI go through every character in hexNum\\nand just make sure that it's in our dictionary up here.\\n\\nAnd if it is in our dictionary,\\nthen I know I can process it.\\nSo there are three cases, three character strings,\\ntwo character strings, and one character strings.\\nFor the three character strings,\\nI take the leftmost character,\\nso that's the character index zero,\\nand multiply it by 256 or 16 squared.\\nRemember, this is the 256th place in a hexadecimal number.\\nThen I take the middle number, multiply it by 16\\nbecause that's in the 16ths place, or 16 to the first power.\\n\\nThen I have the one's place\\nand I just add that onto the rest and return it.\\nI have a similar solution for two character strings\\nand then one character strings.\\nOkay, so I want to look at another approach\\nthat can handle actually any length of string,\\nand that is down here.\\nSo this kind of a solution was definitely not required,\\nbut I think it's worth exploring.\\n\\nSo here we have the exact same checking code\\nthat we had in the previous solution.\\nIf every character is in our hex numbers dictionary,\\nwe know we can process it.\\nThen I added a placeholder called converted.\\nIt starts out as zero,\\nand this is the number that we ultimately return.\\nSo we're going to loop through our string\\nand sort of add all the numbers together.\\nThen we want to figure out what the exponent\\nfor the largest place is in our hexadecimal number.\\nRemember, in a hexadecimal number,\\nyou have the one's place, the 16ths place, the 256th place,\\nthe 4096th place, et cetera.\\n\\nSo that's 16 to the zeroth power, 16 to the first power,\\n16 to the second, 16th to the third, et cetera.\\nSo in general, the highest power or the highest exponent\\nwe're looking at is the number of characters\\nin the hexadecimal number minus one.\\nSo if we have a three character hex number,\\nvalue of the leftmost character\\nis 16 to the three minus one's place, or 16 squared, or 256.\\nSo if you're still confused,\\nrun through it a few times and you'll see what I mean.\\n\\nSo here in our code,\\nall I do is take the length of hex number minus one,\\nand then that gives us the highest exponent,\\nthe highest exponent of 16 in our number.\\nThen we're going to make our loop.\\nFor char in hexNum,\\nwe add the the new number to our converted number.\\nSo on the first pass, converted is going to be zero.\\nWe're not adding anything,\\nbut we take that hex number in the leftmost place,\\nmultiply it by 16 to the exponent power.\\n\\nThen in every loop, we subtract one from the exponent.\\nSo as we go from left to right, our exponents get smaller\\nand smaller and smaller until it eventually becomes zero,\\nand we are multiplying the hex number times one.\\nFinally, we return the final converted number.\\nIf you ever run into a programming problem\\nwhere you're not sure how to do it at first,\\ntry narrowing the scope.\\nHow do you do it for one character, for two characters,\\nfor three characters?\\nTry to find a pattern, get a feel for it,\\nand then approach the general case\\nfor all numbers of characters.\\n\\n\"}],\"name\":\"3. Basic Data Types\",\"size\":29619528,\"urn\":\"urn:li:learningContentChapter:4403007\"},{\"duration\":1850,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4406004\",\"duration\":321,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Lists\",\"fileName\":\"4314028_en_US_04_01_MM30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video shows you how to instantiate, modify, and manipulate lists. Learn about basic list functions: min, max, sum, and join.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4844770,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] We've looked at strings\\nIn Python, strings and lists are very similar types.\\nThe slicing syntax used for strings\\nis also applicable to lists.\\nSo if we have a list, one, two, three, four, five, myList,\\nthree to the end, there we go.\\nSo this is the slicing syntax.\\nAnother cool feature of the slicing syntax is\\nthat you can use a third value in here.\\nSo normally you'd use two values,\\nthe start and then the end,\\nbut you can also pass in the third value.\\n\\nSo if we do myList, zero, six,\\nlet's just go from the start to the end\\nwith a step size of two, that'll print out every other item.\\nOf course, we can put in a step size of three,\\nthat just gives us those two items.\\nAnd of course, all of this is equivalent\\nto colon colon two, because if you're going\\nfrom the very beginning to the very end of the list\\nyou actually don't have to give any values.\\nIt's assumed that you want the beginning and the end.\\n\\nAnd it might be easier to play around with this feature\\nif we can somehow dynamically generate much longer lists\\nthan just typing this all out by hand.\\nAnd for this, we can use the range function.\\nThe range function is a new sequence type\\nwe haven't covered yet.\\nIt's a bit like a tuple.\\nIt has an order and is immutable and isn't frequently used\\nexcept for looping through it in code like this,\\nfor i in range 100, whoops.\\nPrint i.\\n\\nOkay, and this is kind of an annoying output\\nso I'm just going to go ahead and clear that cell.\\nBut you can also take the range and convert it to a list.\\nSo myList equals list, range 100.\\nSo we're converting or casting it to a list.\\nAnd now if we take this\\nand go through every other number, there we go.\\nWe can also do a step size of five, all right, or 10.\\n\\nWhat happens if we enter a negative number?\\nWe actually step through the list backwards.\\nSo a negative step is stepping backwards through the list.\\nWe can even do -10.\\nThat's pretty nifty.\\nSo all of the things we've been doing so far have been\\nabout reading data from lists, taking slices,\\nextracting one value at a time.\\nLet's look at how to actually modify the lists.\\nSo let's grab this.\\n\\nLet's actually just do one, two, three, four,\\nmyList.append five, and then print myList.\\nGreat, append adds an item onto the end of the list.\\nIf you want to insert an item at any position\\nyou can use insert, myList.insert,\\nposition three, so that's the index,\\na new value, and then print myList.\\nThere you go.\\n\\nThere are a couple ways to remove items from a list.\\nThe first one is called, conveniently enough, remove.\\nmyList.remove.\\nAnd you don't have to pass an index in here, just the value.\\nAnd then if we look at myList again,\\nyou can see that's removed.\\nBut be careful, if the item isn't in the list\\nand you try to remove it, it'll throw an error.\\nSo if we run this a second time\\nwe can see that we get the error.\\nThe second way to remove an item\\nfrom the list is with pop, myList.pop.\\n\\nYou don't have to pass an argument at all.\\nIt just pops an item off the end of the list\\nand it also returns it to you.\\nSo now if we look at myList, there we go.\\nWe just have four items in it.\\nWe could also do something like this,\\nwhile length of myList,\\nso while there are items in myList,\\nremember this will evaluate to false when the length\\nof myList is zero, print myList.pop.\\nAnd if we look at myList now, it's empty.\\n\\nRemember that example earlier\\nabout how computers write values in memory?\\nLet's try this out.\\nA is one, two, three, four, five.\\nB is a.\\na.append six and let's print b.\\nWe can see that modifying a also modifies b\\nwhich we've set a to.\\nBut we can use a Python trick here called the copy function.\\nAnd this makes an identical copy\\nof the list stored separately in memory.\\n\\nSo let's take this whole thing.\\nInstead of setting b directly to a,\\nwe're going to set b equal to a.copy.\\nAnd let's just print out both of them\\nso you can see them side by side.\\nAnd so you can see the difference between setting a variable\\nto another variable and making a copy of it,\\nsetting it to the value of that variable.\\nLists are one of the most fundamental\\nand useful data structures in Python\\nand it's important to get a feel for how they work.\\nSo I encourage you to play around with them\\nin this notebook\\n\"},{\"urn\":\"urn:li:learningContentVideo:4401007\",\"duration\":464,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tuples and sets\",\"fileName\":\"4314028_en_US_04_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses sets and tuples, how they differ from lists, and when they should be used.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6976766,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Alright, let's take a deeper dive\\ninto two data structures we've covered only briefly before.\\nWe're talking about tuples and sets.\\nBut first, let's talk about sets.\\nRemember, a set is declared using curly brackets,\\nlike so, {'a', 'b', 'c'},\\nmySet.\\nThere we go, it has those curly brackets.\\nYou can also define it\\nby passing any sort of iterable object\\nin the constructor of the set class.\\nSo mySet, and here we have a set object constructor.\\n\\nAnd then you can do, {'a', 'b', 'c'}, same exact thing\\nor you could even use a tuple in here.\\nSo here we're passing a tuple with A, B, and C in there\\nand we still get the same set.\\nOne common pattern in programming\\nis to remove duplicates from a list.\\nWell, because you can convert a list to a set\\nand then back again and sets can only contain unique values\\nthis becomes pretty easy.\\nSo let's make a list that has some duplicate values in it\\nB, C, C, or let's make that a C.\\n\\nIt doesn't really matter.\\nmyList is equal to list.\\nSet myList and there we go.\\nWe've de-duplicated myList.\\nAnd this highlights another important property of sets.\\nThe order doesn't matter.\\nSets aren't ordered lists,\\nthey're more like big bags of elements all jumbled up.\\nKeep that in mind when you use this trick\\nto de-duplicate lists because sets are randomized.\\n\\nThe order of elements in your list\\nmay not be the same coming back out.\\nBecause of this, you can't fetch elements\\nby their index like you can with a set.\\nSo if we take mySet and try to get the first\\nor the element at the zero index, it won't let us do that.\\nThe set object is not subscriptable\\nso you can't use the slicing syntax with it.\\nIn Python, an object is subscriptable.\\nIf it contains elements that can be accessed by an index,\\nit contains ordered accessible subelements.\\n\\nLet's do something silly like number equals one\\nand then we do the zeroth element of of one, right?\\nWe get that same error.\\nThe int object is not subscriptable.\\nOne doesn't contain any subelements\\nand in a set it's not subscriptable\\nbecause it doesn't make any sense to get the first element\\nin sort of a big random pile.\\nHowever, you can add elements to a set.\\nSo let's take mySet and then add D.\\n\\nAnd let's just take a look at mySet.\\nThere we go.\\nNotice that this is different than the append function\\nin the list, which specifically appends the element\\nto the end of the list.\\nSet uses the add function,\\nwhich is kind of like tossing the element onto the pile.\\nHowever, like with lists,\\nyou can use the membership operator\\nto return boolean values.\\nSo if we say 'a' in mySet,\\nit returns true because A is there.\\nWe say 'z' is in mySet,\\nwe get false.\\n\\nAlso, like with lists, you can use the length function.\\nSo mySet should have four elements in it,\\nperfect.\\nAnd somewhat confusingly, set does have a pop function.\\nYou pop an element off the set.\\nOf course, unlike with lists\\nyou're not going to get an element\\nfrom the end of the set per se,\\nbut it'll grab an element for you\\nand return it while removing the element from the set.\\nSo we can write something like while length of mySet\\nmySet.pop, and let's make sure we print that out\\nso that we can see the results.\\n\\nAnd it's just happening to return these in order here,\\nbut keep in mind that order is not guaranteed.\\nIf you want to remove a specific element, you can do that.\\nSo mySet.discard{'a'}\\nNow notice that it didn't throw an error\\neven though mySet is empty.\\nIt's just an empty set right now.\\nLet's reset this again\\nand then print out mySet.\\n\\nYou can see it only contains the the elements B and C.\\nNow tuples, let's move on to those.\\nAs a quick review, they're very much like lists.\\nThey have an order except they're declared with parentheses.\\nSo myTuple is 'a' 'b'\\nneed commas in there and 'c'.\\nSo while tuples pulls are ordered and subscriptable,\\nthe trick here is that you cannot modify them.\\n\\nSo we can get tuple, get the first element of the tuple.\\nThe order does matter here,\\nbut if I try to do myTuple element at the index\\nzero equals D, we're going to get an error there.\\nTuple does not support item assignment.\\nOf course I can't show you any nifty functions\\nfor adding, removing, or popping elements off\\nof tuples, because you cannot do that.\\nYou can't modify a tuple.\\nOkay, why would we want to use tuples?\\nLike I mentioned before,\\nthey are more efficient than list\\nbecause Python doesn't have to worry\\nabout growing or changing them.\\n\\nIt can allocate exactly as much space as it needs\\nto in memory to really store these tuples compactly.\\nBut let's say you don't care about that.\\nAnother benefit is that they are often\\njust kind of used by default.\\nLet's write a python function that\\nreturns multiple values separated by commas.\\nAs it turns out, you can do the nifty trick in Python.\\nreturnsMultipleValues,\\nreturn 1, 2, 3.\\nWhat exactly is this function returning\\nwhen we separated them by commas with this?\\nLet's call it,\\nand then put whatever it's returning\\ninto the type function.\\n\\nIt returns a tuple.\\nOkay? Now of course we can also do this,\\nstill the same type\\nbut it turns out that Python\\ndoesn't really require parentheses around tuples at all.\\nSo you could say myTuple is 1, 2, 3\\nand that's perfectly fine.\\nmyTuple,\\nit's a tuple.\\nAlthough for situations like this,\\nif I saw this in code in the real world,\\nthis would look really odd to me.\\n\\nI would ask that the programmer\\nplease put parenthesis around that.\\nBut just so you know, you don't have to.\\nAnd the really cool thing is that in the case\\nwhere you're returning multiple values from functions\\nthis syntax without the parenthesis is actually preferred.\\nSo in this case,\\nbut we do prefer that you add parentheses\\nwhen you're just declaring a random Tuple.\\nAnd back to this function here.\\nIf you want to set variables\\nset many variables in a row, you can do this.\\n\\nSo let's say A, B, C is equal to returnsMultipleValues,\\nprint A,\\nprint B,\\nprint C\\nand unsurprisingly we have all these values set.\\nThis is called unpacking values,\\nwhich we'll see again a little bit later in this chapter.\\nSo while tuples are sometimes stubbornly unchangeable,\\nI think you'll find as you continue your Python journey\\nthat their convenience and elegance\\nmore than compensates in many situations.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4405001\",\"duration\":375,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Dictionaries\",\"fileName\":\"4314028_en_US_04_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video goes over how to use list comprehensions to modify or filter lists.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5639192,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(gentle music)\\nyou work with in Python will be lists,\\nbut that's followed very closely by dictionaries.\\nLists and dictionaries, dictionaries and lists.\\nThey work together like, well, like duct tape and WD-40.\\nYou know, if it's moving and it shouldn't, use duct tape,\\nif it should move and it doesn't, use WD-40.\\nIt's a complete solution for every situation.\\nSo with lists and dictionaries combined,\\nyou can solve just about any problem with Python.\\n\\nThat'll be easily 95%\\nof the data structures you're working with.\\nLet's go to the code.\\nSo let's start working\\nwith this dictionary of animals I've created.\\nHere, I've left a comma\\nat the end of this last key value pair in the dictionary,\\nand this is called a trailing comma.\\nSo you don't technically need this.\\nThis code will run just fine without it,\\nbut it is good practice.\\nIt's convention to have it on the end there.\\nSo, if we do animals a, we get aardvark back.\\n\\nWe can add a dog by using a similar syntax.\\nAnimals d is equal to dog.\\nGreat.\\nAnd if we print out the dictionary,\\nof course, we can see that's added there.\\nNow let's update the dictionary,\\nchange a to antelope, and print out the dictionary.\\nGreat, we've made a an antelope instead.\\nIf we want to get the keys and values of the dictionary,\\nanimals.keys and animals.values,\\nand that just prints out the keys and values.\\n\\nAnd notice that this is a dict keys object\\nrather than a list.\\nIt looks kind of like a list.\\nYou can iterate over dict keys.\\nThey are immutable.\\nYou can't change them directly, you just add to them.\\nYou have to modify the underlying dictionary\\nin order to change them, but you can convert them to list.\\nSo if I take this, pass in that, there we go.\\nWe've actually just made a copy of this,\\nof this keys dict keys object and turned it into a list.\\n\\nOkay, so what if I try to access a key that's not present?\\nAnimals e.\\nWe get an error.\\nSo, there is a function that's pretty handy for this\\nand that's called the get function, animals.get e,\\nand as a second argument, you can pass it a default.\\nAll right, so it didn't find e,\\nit returned elephant instead.\\nYou don't have to have a default value there.\\nThis will actually, if we print this out,\\nyou can see it is a none object that gets returned\\nif you don't provide a default value.\\n\\nAnd of course, if we do something like this,\\nwe'll get antelope back\\nbecause that does exist in the dictionary.\\nLike strings and lists,\\nyou can use the length function on the dictionary.\\nSo length animals, we get four\\nbecause there are four keys in our dictionary.\\nLet's look at one really common pattern in programming,\\nand that's a dictionary where the values are lists.\\nSo I'm just going to copy this,\\nand let's just keep the first two\\nand then turn this into a list.\\n\\nSorry, a dictionary of lists.\\nAnd then we can add our old friend the antelope here.\\nOkay, great.\\nSo, if we want to add bison to the structure of animals,\\nthat's pretty straightforward.\\nAnimals, bison starts with b, and then we just append bison.\\nOkay, great.\\nThe list for c doesn't exist,\\nso we have to do animals c is equal to,\\nrather than just depending,\\nis equal to a new list containing cat.\\n\\nBut what if there is already a caribou in that list\\nand we just overwrote it?\\nWhat if we don't know whether that key exists or not?\\nWe just know what we want to add.\\nSo, we have to write something like this.\\nIf c not in animals, animals c is equal to a new list.\\nAnd then, in either case, c append cat.\\nGreat, so that works.\\n\\nAnd notice that the not in operator\\ntells you if that key exists in the dictionary or not.\\nIs there a solution to this sort of convoluted code?\\nAnd there is, that is the,\\nas you can probably guess from the title down here,\\nthe default dict.\\nSo we have to import this from the collections package,\\nfrom collections import default dict.\\nOkay.\\nSo now we have access to it.\\nTo create a new default dict,\\nyou need to pass the type of object\\nthat it should return by default.\\n\\nSo animals equals default dict list.\\nWe want to return a list.\\nSo a common mistake here,\\na lot of people will return or pass in, rather,\\nan instance of the thing that they want returned.\\nBut you actually have to give it\\na sort of callable function, say, use this every time\\nyou need to make a new thing that gets returned.\\nSo now we have our new default dict, and if we look at it,\\nit doesn't have any values in it yet.\\nSo let's make one, animals e append elephant,\\nand let's take a look at it now.\\n\\nGreat.\\nWe didn't have to say, hey,\\nthis is equal to a new list.\\nIt just did all the work for us\\nand automatically added that.\\nIf we say animals e append emu,\\nthat gets added as well to our new list.\\nAnd the really cool thing is\\nif we say animals f, we get back an empty list\\nbecause we haven't added anything there yet.\\nWhile lists and dictionaries work excellently\\nwhen combined with each other,\\nthe same cannot be said for WD-40 and duct tape.\\n\\nSo in that way,\\nI think you'll find Python data structures are far superior.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400007\",\"duration\":322,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"List comprehensions\",\"fileName\":\"4314028_en_US_04_04_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explains how to use list comprehensions to modify or filter lists.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4865104,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Python has a really neat feature\\nthat's somewhat unique in programming languages,\\nand that is the list comprehension.\\nNote the word comprehension here\\nhas nothing to do with understanding\\nbut more to do with the word comprehensive,\\nso systematically listing everything out.\\nFor example, my list is one, two, three, four, five.\\nLet's write a list comprehension with this,\\ntwo times item for item in my list.\\nIsn't that neat?\\nSo square brackets surround the list comprehension\\nand then there's a syntax frame\\nmuch like the for loop that we saw before.\\n\\nSo for item in my list.\\nOf course item can be any variable name that you want.\\nJust make sure that you use the same variable name\\nover here when you're doing stuff with it.\\nA list comprehension allows you to essentially\\nmake a for loop in one line while returning a copy\\nof the list that you're iterating over.\\nIt also allows you to filter\\nor call functions on every item or of a list.\\nSo let's play around with it.\\nSo like I said, the list comprehension can act as a filter.\\nSo for example, my list is equal to list range 100.\\n\\nSo this is going to give us a list\\nwith all the numbers from zero to 99.\\nLet's make a filtered list,\\nit's equal to item for item in my list\\nif item modulus 10 is equal to zero.\\nRemember, this is the modulus operator.\\nIt gives you the remainder\\nafter dividing the variable here by the number on the right.\\nSo whenever the remainder after dividing item by 10\\nis equal to zero, this statement is true.\\n\\nSo item for item in my list, if it's divisible by 10.\\nAnd let's see what this looks like.\\nAll of the numbers that are divisible by 10.\\nWe could even do something like this.\\nLet's change this to less than three.\\nThat's pretty neat.\\nIt gives you all the numbers that end in zero, one, or two.\\nAnd let's just make this a print statement\\nto make it a little easier to read.\\n\\nThere, lie flat.\\nList comprehensions are really great for working\\nwith strings as well.\\nI want to show you a new string function called split.\\nSplit splits a string based on a character\\nor another string that you give it.\\nFor instance, myString is equal to,\\nmy name is Ryan Mitchell, I live in Boston.\\nOkay, myString.split.\\nAnd this splits it into two sentences\\nbased on where the period is.\\n\\nIf nothing is passed in,\\nthe split function will split on spaces.\\nmyString got split and there we go,\\nthat splits it into words.\\nWe might want to get rid of that period though,\\nand maybe just sort of normalize all the text a little bit.\\nSo for this, let's make a new function called cleanWord.\\nAnd this is going to return word.replace,\\nperiod with an empty string, and dot lower.\\n\\nSo here the replace function replaces any instances\\nof the first string, in this case a period,\\nwith the second string, which is empty.\\nEffectively, this removes all the periods.\\nAnd then the next function makes the string lowercase.\\nCalling one function after the other\\nin a single line like this is called chaining functions.\\nIt can be handy sometimes to keep your code clean,\\nbut be careful not to go too crazy with it\\nor it can lead to long and unreadable lines of code.\\nSo let's use this now in a list comprehension.\\n\\ncleanWord, word for word in myString.split.\\nSo now we have this nice clean list\\nof all the words in the text.\\nLet's say that we want to clean and filter at the same time.\\nFor instance, only getting the small words in the text.\\nWe could do something like this.\\nIf length of myString, or sorry, if the length\\nof cleanWord word is less than, let's say three.\\n\\nSo that gets all the one and two letter words in the text.\\nSo you can see how powerful list comprehensions are.\\nI use them all the time for cleaning text\\nand processing large amounts of data.\\nAnd as one final example\\nbefore I officially dub you the list comprehension expert,\\nthe nested list comprehension.\\nSo let's just give a quick example of that.\\ncleanWord word for word in sentence.split\\nfor sentence in myString.split on the period.\\n\\nSo don't get too overwhelmed by this.\\nAll this is doing is splitting this original text\\ninto sentences and then performing sort of\\nan inner list comprehension on each sentence.\\nSo now we have a list of lists, sort of like\\na two-dimensional structure that groups these clean words\\nby the sentence that they appeared in.\\nSo have fun with these.\\nUsing list comprehensions is a great way to write\\nclean, readable,\\nand as Python programmers say, Pythonic code.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4407002\",\"duration\":212,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Dictionary comprehensions\",\"fileName\":\"4314028_en_US_04_05_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video helps you to explore this new feature and learn how to generate dictionaries from iterables.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3221018,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Dictionary comprehensions are used\\nto generate dictionaries from iterable structures.\\nJust like list comprehensions create a new list,\\na dictionary comprehension creates a new dictionary.\\nI'll show you a basic example.\\nSo here we have a list of tuples\\nthat we'll be using as our key value pairs.\\nRemember, tuples work just like lists,\\nexcept that you can't alter the value of tuples\\nonce they've been declared.\\nAnd we can create a dictionary\\nfrom this list of tuples like this,\\nanimals equals item 0 colon item 1 for item in animalList.\\n\\nAnd there we see our dictionary.\\nThere's this familiar for item in list statement\\nexactly the same in both list and dictionary comprehensions,\\nbut now we need to define both the key\\nand the value separated by a colon\\ninstead of just a single value\\nlike we did for the list comprehension.\\nAnd of course, this dictionary comprehension\\nis surrounded with the curly braces,\\njust like the list comprehension\\nwas surrounded by the square brackets.\\nNow, there's a more elegant way\\nto write this dictionary comprehension as well.\\n\\nLet's check that out.\\nSo we can actually say\\nkey is equal to value\\nfor key comma value in animalList.\\nSo what kind of sorcery is happening here?\\nWell, whatever is between the for and the in\\nin this statement is what each tuple of animalList\\nis getting assigned to.\\nSo remember when we saw earlier\\nwhen we were discussing tuples and sets,\\nPython allows you to unpack values into multiple variables\\nas long as the number of variables\\nyou're assigning the values to\\nmatches the elements in this data structure.\\n\\nSo we have two items in each tuple here\\nand we're unpacking them into two key value variables here\\nthat we can use\\nand this just makes it a little bit cleaner.\\nSo we can do something like this,\\nbut if we try to unpack it into otherItem,\\nyou can see we'd get not enough values to unpack,\\nexpected three, but actually got two\\nwhen we iterated through this list.\\nSo that's the dictionary comprehension.\\nPretty straightforward.\\n\\nWell, what if we want to take our animal dictionary\\nand turn it back into a list?\\nLet's look at the dictionary function called items.\\nRemember we have animals.keys and animals.values.\\nThere's actually animals.items\\nand items returns a dict_items object\\ncontaining a list of key value pairs.\\nSo we can turn it back into something\\nthat looks like this animalList that we started with\\njust by doing list animals.items.\\nAnd there you go.\\nBut let's say we wanted to get a little more creative.\\n\\nWe want each item in our list to have a structure\\ndifferent than the one we started with.\\nWell, we could write a list comprehension\\nand let's make it key value, or let's call this name value\\nfor key comma value in animals.items.\\nThis returns a list of dictionary objects\\nwith the original keys and values\\nunder the letter and name fields\\nin each dictionary in the list.\\n\\nSo you can see how powerful\\nboth dictionary and list comprehensions are\\nfor processing and formatting data in Python.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:661421383450e2f05d06341e\",\"duration\":1800,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code Challenge: Encoding ASCII art\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:962249\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4215215\",\"duration\":156,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Encoding ASCII art\",\"fileName\":\"4314028_en_US_04_06_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_04_07_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":207,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4431732,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Hopefully this challenge put a smile\\non your face and on your screens.\\nThe encodeString function here looks like a lot of code,\\nunless maybe you did it in a more efficient way\\nor at least a shorter way than I did.\\nIt's really not that tricky.\\nJust a little tedious to keep track of everything.\\nAnd this is where having well-named variables really comes\\nin handy to make it clear what's going on.\\nSo here we have the stringVal that gets passed in\\nand we want to ultimately loop through that.\\nAlong the way, we're going to keep track of a few things.\\n\\nSo the first is our encodedList.\\nThis is what ultimately gets returned from the function.\\nThen we have prevChar.\\nThis is so we know when the string has changed.\\nIf the current character doesn't match\\nwhat the prevChar is, we know that we need\\nto add something to the encodedList.\\nAnd finally, we'll keep track of the count.\\nThis starts at zero\\nand it just keeps track\\nof how many characters we've gone through\\nwithout seeing any change yet.\\nThen we loop through the string.\\nIf the prevChar is not equal\\nto the current character, great, we've seen a change.\\n\\nSo this character is different\\nthan the last one that we saw.\\nAlso, notice that up here, the prevChar starts out\\nas the first character of the string.\\nSo we're never going to detect a change\\nwhen we're still on the first character.\\nWe have to wait until at least the second character\\nto detect a change at all.\\nSo if there is a change, we add prevChar\\nand the count to our encodedList.\\nReset the count.\\nNow, in every iteration, we set prevChar equal\\nto character, increment the count, add one to the count,\\nand then we go through again.\\n\\nOutside of our loop,\\nwe've reached the end of the string, so we need to make sure\\nthat we record the last few characters.\\nSo now we append a new tuple to the end there as well.\\nFinally, we return the encodedList.\\nSo now we have an encodeString function\\nthat can take in a string value and run length and code it.\\nFinally, we need to make our decodeString function.\\nFortunately, this one is way more straightforward.\\nAll we have to do is go through each item\\nin the encodedList, take that item,\\nmultiply it by the count,\\nand then add it to our string and return that.\\n\\nSo let's suss it out.\\nGreat. We have our smiley face.\\nI also included this very simple test case here\\nbecause it can be difficult to see if there are any bugs\\nwhen the strings are very large,\\nlike with this ASCII art smiley face.\\n\"}],\"name\":\"4. Basic Data Structures\",\"size\":29978582,\"urn\":\"urn:li:learningContentChapter:4407010\"},{\"duration\":1262,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4406005\",\"duration\":315,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"If and else\",\"fileName\":\"4314028_en_US_05_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video shows you how to use if, else, and elif statements to make decisions and use conditional assignments with single line if/else statements.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4749719,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- If you want to learn about conditional statements in Python,\\nyou're in the right place.\\nElse?\\nWell, you should learn\\nabout conditional statements in Python.\\nThey're critical to writing most programs.\\nAnd although we covered if and else previously,\\nnow we're going to show you a new statement\\nyou can add on to these if and else blocks,\\nas well as a new syntax for using the if statement.\\nIf you've done any other programming languages,\\nyou've probably encountered the switch statement.\\nYou evaluate a series of values\\nand run the code instructions\\nthat correspond to the first true value you find.\\n\\nAnd if you've never heard of a switch statement\\nand don't know what I'm talking about, that's fine.\\nObviously, other programming languages\\nare inferior to Python anyway.\\nLet's go to the code.\\nHere's a classic problem in programming.\\nIterate through the numbers one through 100.\\nIf the number is divisible by three, print Fizz.\\nIf the number is divisible by five, print Buzz.\\nIf the number is divisible by 15, print FizzBuzz.\\nOtherwise, just print the number.\\nSo the sequence looks like this.\\n1, 2, Fizz, 4, Buzz, Fizz, et cetera.\\n\\nSo let's write this in Python.\\nFor n in range, 1, 101,\\nif n % 15 == 0, print 'FizzBuzz',\\nelse if n % 3 == 0, print 'Fizz',\\nelse if n % 5 == 0, print 'Buzz',\\nelse just print n.\\n\\nWell, this works, but it's a little difficult to read.\\nThere's a lot of indenting going on.\\nSo let's rewrite this with an elif statement,\\nwhich stands for else if,\\nand I'm actually going to copy this code\\nand move it down here\\nand let's just rewrite this,\\nelif, elif and we can keep that else.\\nAnd out-dent a little bit.\\n\\nGreat.\\nSo this is the same output, but it's so much cleaner.\\nThe else if statement must always be proceeded\\nby an if statement.\\nSo if I remove this if statement here,\\nwe get a syntax error.\\nThe else statement at the end is optional.\\nSo we can actually run without this\\nand we just get all the Fizzes and Buzzes printed out.\\nSo the rule is you write a single if statement,\\nany number of elif statements and then, optionally,\\na single else statement at the very end,\\nto provide some sort of a default value\\nif nothing above it matches.\\n\\nOf course, if you want another if statement after that,\\nyou can also do that.\\nSo if n % 2 == 0, print 'It is even!'.\\nGet rid of that extra quote, there we go.\\nAnd so we get those all printing out.\\nAnd that will actually start a completely new block\\nof if and elif and else statements.\\nSo one issue with if else statements\\nis they can often drag on for too many lines.\\n\\nSometimes, you want to evaluate something in a one-liner.\\nSo let's set up an example here,\\nn == 3, print 'Fizz' if n % 3 == 0 else n\\nand we get Fizz printed out.\\nOf course, if we set n to 5, we get 5.\\nYou can also store this in a variable.\\nSo we could take this\\nand set variable fizzBuzz equal to this output.\\n\\nIn programming, this is what's known as a ternary operator.\\nSo a ternary operator takes in some Boolean condition,\\nin this case, N % 3 == 0,\\nevaluates it and returns one value if the condition is true\\nand then another value if the condition is false.\\nAs Python programmers,\\nour goal is always to write clean, readable code.\\nAlthough ternary operators easily accomplish this\\nwhen used correctly, you have to be careful with them,\\nso they can actually be strung together.\\n\\nLet's take this and add,\\nelse 'Buzz' if n % 5 == 0 else n,\\nand we get 'Buzz'.\\nWe can even do more stringing,\\nso we could add onto the beginning of this,\\n'FizzBuzz' if n % 15 == 0 else,\\nokay, and we get 'Buzz' again.\\n\\nWe can maybe even put these in a list.\\nSo let's take a list, for n in range 1 through 101.\\nSo while I'm not advocating\\nthat you definitely do this for your next job interview,\\nif you're asked to solve FizzBuzz,\\nI am saying that you could.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4218191\",\"duration\":418,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"While\",\"fileName\":\"4314028_en_US_05_02_FY24Q4_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_05_02_MM30\\n\\nReuse LA intro from original: /Volumes/en_US/4314028_en_US_Perpetual_Python_Essential_Training/4314028_0/2_Project/2_Footage/5_Other Assets/2449125_Python_Essential_Training/2_Project/2_Footage/2_Live Action/2449125_en_US_05_02_While_Standup1_A_01.MP4\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":458,\"exerciseFileDisplayText\":\"05_02_while.ipynb\",\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":true},\"description\":\"This video shows you how to create a basic while loop and use break, pass, and continue for more advanced control.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13635405,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- While loops look innocuous,\\nbut they're one of the most dangerous things\\nyou can write in Python.\\nOne small mistake and your program will run forever.\\nGranted, some programs we want to run forever,\\nlike a web service,\\nbut your program might run forever and not in a good way.\\nBut don't be afraid, while you're here,\\nyou'll learn advanced while loop control statements\\nto tame these wild beasts.\\nLet's go to the code.\\nOne thing I like to use to test while loops\\nis the Python datetime class,\\nfrom datetime import datetime.\\n\\nAll right and sure, we could increment some numbers\\nin our while loop to check if we've reached\\na particular number yet,\\nbut why wouldn't we just use a for loop for that?\\nChecking the actual time is much more exciting\\nand we can get the current date and time\\nby calling datetime.now()\\nand if we just want the seconds in the current minute,\\nwe can use .second so we're 34 seconds\\ninto the current minute.\\nNow, if we want to get two seconds into the future,\\njust add 2, but you have to be careful with this.\\n\\nBecause let's say we're currently at 59 seconds,\\nit's at one second into the next minute,\\nso we need to use modulus 60 to reflect that.\\nSo, here's why we're doing all of this,\\nlet's make a simple while loop that waits two seconds\\nand then prints out some message,\\nwait_until equals two seconds into the future\\nwhile datetime.now().second != wait_until:\\nprint ('Still waiting.')\\nFinally, we exit our while loop and print\\n\\\"We are at {wait_until} seconds!\\\"\\nOkay, now if we run this,\\nit very quickly fills up our screen.\\n\\nSo Python is very fast, let me clear this cell.\\nAll right, so what do we do in this situation?\\nWell, if we remove the print statement,\\nwe get a syntax error.\\nYou have to have something indented under the while loop.\\nWhat we could do is maybe do some useless calculation.\\nThis works but it's an awful waste\\nof computing power in my opinion.\\nOne thing we can use though is the pass statement.\\n\\n(instructor typing)\\nThere we go and what this past statement says is,\\nnothing to see here move along\\nbut it does critically preserve our indenting.\\nIt's also a great thing to use as a placeholder say,\\nif you're writing a function or a class definition,\\nbut you don't want to fill it in yet, you can just write pass.\\nSo let's take a look at another way\\nto write this using the break statement.\\nSo I'm going to use wait_until,\\nand then I'm going to say while True:\\nall right, so honestly, my heart skips a beat\\nwhenever I see while True: in someone's code\\nbut in this case it's safe, we're going to use it safely.\\n\\nIf datetime.now().second = wait_until: break\\nnow let me move this under the break statement there.\\nAll right, so it waits two seconds and then prints.\\nSo what the break statement does\\nis break out of the current loop that it's in.\\nYou can think of this as going up the lines\\nand saying, is this a loop?\\nNope, it's an if statement.\\n\\nIs this a loop?\\nYep, it's a while loop so it exits the current while loop,\\neven though it says while True:\\nNote, that the break statement only breaks out\\nof the first loop that it's in.\\nSo if I do this and change it to a while loop as well,\\nit waits two seconds, prints we are at 11 seconds...\\nWhoops, and it's still running.\\nYou can see the asterisk there\\nthat indicates that it's still running.\\nSo it will run for ever,\\nit never breaks out of this while True:\\nAnd every time the seconds reach 11 seconds,\\nit'll just print this message for a whole second.\\n\\nSo let me stop this and I'm going to clear\\nthe cell output again.\\nOkay, and the final control statement\\nfor, for loops, Continue.\\nContinue, skip any lines that follow it\\ninside of the while loop.\\nSo if I take this original code up here,\\nthen bring it down there...\\nJust going to put a continue statement there\\nand you can see that this line never prints.\\n\\nSo continue just skips everything else\\nthat follows it inside this while loop.\\nNow obviously, we could replace this entire thing with pass\\nand it would be exactly the same and a little bit cleaner.\\nSo usually you see a continue statement\\nused inside an if statement\\nto prevent the rest of the code in the loop\\nfrom being executed but only if some condition is met.\\nSo let's just copy this, change the while to True: again,\\nAnd then in here I'm going to say if datetime.now().second\\nis less than wait_until: continue\\nchange this to break.\\n\\nOkay, so when this continue statement is hit,\\nit skips everything else in the loop,\\nwhich is just this break statement.\\nAnd as soon as this, if statement is no longer true,\\nthen continue is no longer hit,\\nit actually reaches the break statement,\\nbreaking it outside of this while loop.\\nThen it prints \\\"We are at {wait_until} seconds!\\\"\\nOf course, this logic is basically the same\\nas putting this check inside the while loop itself\\nand then exiting the while loop after two seconds.\\n\\nAnd this is the big secret with continue and break,\\nthey're not technically logically necessary\\nbut they can help you rearrange and write code more clearly\\nfor other programmers to read.\\nSo it's important to understand them\\nand be ready to whip them out to depending on the situation.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4215216\",\"duration\":396,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"For\",\"fileName\":\"4314028_en_US_05_03_FY24Q4_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_05_03_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":472,\"exerciseFileDisplayText\":\"05_03_ForLoops.ipynb\",\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video shows you how to create a basic for loop, introduces the range function, and goes over how to use else for more advanced control.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11903498,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] I love the syntax of the for loop in Python.\\nMy list equals 1, 2, 3, 4.\\nFor item in myList, print item.\\nFor item in my list reads like plain English.\\nIt lets you declare a new variable to hold the value\\nof each element as you loop through it in Python.\\nIt's short and to the point\\nand I'm not alone in my love of Python's for loop.\\nIn fact, it's the most common loop you'll use\\nand see others use as you program in Python.\\n\\nSo like the for loop,\\nI'm going to keep this video short and to the point.\\nAll the statements we covered in the video on while loops,\\nyou can use in the for loop as well.\\nSo if we want to write a stub for a for loop\\nand maybe come back and fill it in later,\\nwe can use pass.\\nfor letter, animals.\\nThat's going to be our animal list,\\nin animalLookup.items, pass.\\nWe can also skip the rest of the loop\\nduring each iteration if we want,\\nusing the continue statement.\\n\\nSo if length\\nof animals is greater than one, continue.\\nThen outside of our if block,\\nprint Only one animal.\\nAnd let's print out the animals here.\\nWe can loop through and stop partway\\nif we found what we're looking for\\nusing the break statement.\\n\\nSo pasting our code over here\\nand then under here,\\nprint Found length animals.\\nWe're just going to count the number of animals\\nin our list.\\nAnimals.\\nAnd then break.\\nNote that if there are more instances\\nof two or more animals in our list,\\nit will just stop after the first instance\\nbecause of the break statement.\\n\\nNow, there is one really cool thing\\nthat we haven't covered yet,\\nand that is the break else statement\\nor the for else statement.\\nAnd one of my favorite examples to demonstrate this with\\nis finding prime numbers,\\nsomething computers do all the time\\nfor cryptography and security.\\nAnd we can do it too in just a few lines of Python.\\nSo we're going to find all of the primes\\nbetween two and 104.\\nfor number in range(2, 100).\\nSo number is the number\\nthat we're going to be testing for primality.\\n\\nAnd then we need to loop through all the potential factors\\nof that number to test each one\\nand see if it's divisible by that factor.\\nSo for factor in range(2, int(number int number**0.5) + 1).\\nWe only need to go up to the square root of the number\\nor that number raised to the half power\\nto test to see if it's prime.\\n\\nIf we haven't found a factor\\nby the square root of the number\\nby the time we haven't reached the square root,\\nthen we know that it's prime.\\nSo inside here, I'm going to test each factor.\\nIf number % factor == 0, break.\\nOkay, so we can use a modulus\\nto see if it's evenly divisible.\\nAnd if it is evenly divisible,\\nwe know that the number isn't prime because it has a factor.\\nSo at that point, we just break\\nand then we add our else statement.\\n\\nSo I'm going to add it,\\noops, in line with this inner for loop right there.\\nSo we have the break that breaks out of this for loop\\nand then we have an else statement.\\nAnd under here, we say print number is prime.\\nAll right, so this else statement will only be entered\\nif a break didn't happen in the previous loop.\\n\\nSo if our number had a factor,\\nthis break happens and we skip the else.\\nElse, we didn't find any factors,\\nthe break didn't occur and it's prime.\\nSo let's check this out.\\nYeah, those all look prime to me.\\nNote that this break-else pattern\\ncan also be used with while loops.\\nIf you put a break in your while loop,\\nyou can add an else statement at the end of it\\nimmediately after that loop.\\nAnd that else only happens if the break wasn't thrown.\\n\\nSo very often, you'll see code written\\nby Python programmers less knowledgeable than yourself\\nthat look like this, with an extra variable.\\nSo for number in range, two through 100,\\nfound_factors = False.\\nFor factor in range(2, int(number**0.5) + 1),\\nif number % factor == 0,\\nfound_factors = True.\\n\\nAnd then we break.\\nAnd then outside here,\\nif not found_factors,\\nprint number is prime.\\nOkay.\\nAnd if we run this, we get the exact same output.\\nAnd actually, these are two equivalent pieces of code.\\nWe're just using this found_factors to keep track\\nof whether or not a break happened.\\nAnd instead of having an else statement there,\\nwe have an if not found_factors,\\nbut they do basically the same thing.\\n\\nBut this down here is obviously a lot more code.\\nIt's messy, you have an extra check.\\nUnderstanding and using pass, continue, break,\\nand else will help keep your loops clean, elegant,\\nand as we say, Pythonic.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:661421613450122504c42082\",\"duration\":1800,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Finding primes faster\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:962251\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4215217\",\"duration\":133,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Finding primes faster\",\"fileName\":\"4314028_en_US_05_04_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_05_05_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":177,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3406759,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Narrator] For this challenge,\\nas you probably figured out,\\nit helps to keep a list of prime numbers as you go along.\\nNot only is this list the thing\\nthat gets returned at the end of the function,\\nbut we'll use it to check for factors of the number\\nthat we're currently testing.\\nSo here's our list of primes.\\nI'll add a two in here to start.\\nAnd the number two is an odd prime.\\nWait, let me rephrase that.\\nThe number two is a strange prime.\\nIt's the only even prime, which makes it odd.\\nSo starting with this value,\\nthis two in our list, will help our function calculate\\nthe rest of the primes up to the number we've been given.\\n\\nThen, for each number between three\\nand the number we passed into the function,\\nwe're going to get the square root.\\nNote that I'm putting this value into a variable.\\nI could just put a number to the 0.5 power in there,\\nbut then we'd be recalculating it\\nevery time we go through that loop.\\nSo it saves a little bit of computing power\\njust to store the result up here.\\nIf our number is divisible by the factor,\\nso if the number modulus factor equals zero,\\nthen we know that it's not prime.\\n\\nIt has a divisors, and we break.\\nElse, if we've gone past the square root of the number\\nand we haven't found any factors yet,\\nwe know that it's prime.\\nSo we can append that number to our list of primes.\\nWe found a new one.\\nAwesome.\\nFinally, we return the list of primes we've collected.\\nOften in programming, you'll make a first pass at a problem\\nand find a less than ideal solution,\\nlike with our first prime number program\\nearlier in this chapter.\\nThen you might have some insight\\nor learn something that allows you\\nto dramatically increase the efficiency of your code.\\n\\nSo one time, I figured out\\nhow to write a program more efficiently\\nas I was drifting off to sleep.\\nI had to turn the lights on, code it up,\\nand I stayed up way too late, but it was worth it.\\nIt took the runtime of my program\\ndown from two days to 15 minutes.\\nI was so excited.\\nAlways be careful not to over-optimize your programs.\\nYou can write a pile of unreadable garbage\\nwhile chasing some slight efficiency\\nthat doesn't even matter.\\nRemember that happy middle ground?\\nThat sweet spot is the most Pythonic way.\\n\\n\"}],\"name\":\"5. Control Flow\",\"size\":33695381,\"urn\":\"urn:li:learningContentChapter:4403008\"},{\"duration\":1212,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4406006\",\"duration\":418,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The anatomy of a function\",\"fileName\":\"4314028_en_US_06_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video goes over function declarations and return values, args, and kwargs.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6280607,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- We've been working with functions throughout this course.\\nI mean, literally the first Python program we wrote\\nused the print function to print Hello World.\\nSo many introductory programming courses use\\nthe recipe metaphor for programming.\\nA program is like a cake recipe.\\nFollow the step-by-step instructions one at a time\\nand you'll get your cake.\\nAnd sure, at some level, programs are executed step by step,\\nby a process, reading lines of instruction.\\n\\nBut programs are really so much more than that.\\nIt's not a flat, linear, start here\\nand end here set of instructions.\\nThe programmer must think in terms of systems, of tasks,\\nof objects and interacting components.\\nIn terms of designing and thinking about programs,\\nthe basic unit of a program is not a line of instruction,\\nbut a function, and a program\\nwithout any functions is, well, functionless.\\nSo let's take a closer look\\nat this basic and vital unit of programming, the function.\\n\\nLet's go to the code.\\nAs we all know, functions have a name and some parameters\\nthat are indicated using the def statement.\\nSo let's make a function.\\nperformOperation, num1, num2, and operation.\\nSo let's make a simple function that takes in two numbers\\nand an operation, either the string sum\\nor the string multiply, and returns a result.\\nSo if the operation is equal to sum, we're going to\\nreturn num1 plus num2.\\n\\nIf operation equals multiply,\\nI return num1 times num2.\\nAnd we can call it performOperation, two three, and sum.\\nAnd we get five.\\nSo let's say that most of the time we want to\\nadd the parameters together, but we don't want to have to\\nwrite sum all of the time.\\nWe can provide a default value using what's called\\nname parameters or keyword arguments.\\n\\nSo let's bring this down here and let's say the operation,\\nlet's give it a default value of sum.\\nNow we can take this away and we get our five.\\nOf course we can also provide our own value.\\nOperation equals multiply, and that overrides it.\\nNow you don't actually have to say operation equals multiply\\nwhen you're calling this function.\\nYou can also just pass multiply in as the third parameter.\\n\\nBut if you have a function\\nwith lots and lots of these optional keyword parameters,\\nyou don't want to have to worry\\nabout what order you're passing everything in.\\nSo sometimes it's easier,\\nmore readable to say operation equals multiply.\\nFor example, we can add another keyword argument\\nto our function here.\\nLet's say we have a message,\\nand there's some default message\\nand then that message gets printed out.\\nOkay.\\nSo when we call this function, we can pass message\\nbefore or after the operation.\\n\\nA new message.\\nAdd a comma in there.\\nAs long as we're defining which argument is which.\\nOne rule however, the keyword arguments have to come after\\nthe what's called positional arguments, this two and three.\\nThe first two arguments, this order matters very much.\\nThey're not optional.\\nBut then after them\\nthe keyboard arguments can be in any order you want.\\nSo these optional arguments are nice,\\nbut there's still this sort of fundamental limitation\\nor functional limitation on what we can do here.\\n\\nWe need to anticipate all\\nof the variables that the user might be passing in.\\nWhat if we want to allow them to pass in\\nany number of variables they want?\\nSounds crazy, right?\\nWell, let's do this.\\nperformOperation args, print args.\\nperformOperation one, two, three.\\nWell, what did you expect?\\nThere's a syntax error.\\nThe way I written this function, I'm telling it that\\nit's supposed to be expecting a single variable called args\\nbut there are three of them I'm passing in.\\n\\nSo there's a mismatch.\\nBut watch this, as you might guess from the title there.\\nNice.\\nThis asterisk right here on the args tells Python\\nthe variable name isn't literally args.\\nThis is just a reference,\\na pointer to the stuff that's being passed in.\\nTechnically, you don't have to use the word args here\\nas this variable name, but you should use args\\nbecause it's sort of the Python standard.\\nAnd of course when we call this\\nwe get our old friend the tuple.\\n\\nNow this trick only works\\nfor positional arguments, not keyword arguments.\\nSo if I pass this in, let's actually do this down here.\\nSo if I pass this in,\\nI still get an unexpected keyword argument, okay?\\nAnd to handle keyword arguments, we need to\\ndo this differently with something called kwargs, okay?\\nWhich stands for keyword arguments.\\nNow, if we take this, and let's also print kwargs.\\n\\nThere we go.\\nNotice that the keyword arguments are a dictionary\\ninstead of a tuple.\\nAnd this makes sense\\nbecause keyword arguments can have keys and values.\\nThey can also be passed in any order\\nso you need a dictionary to reference them.\\nAnd now for the piece de resistance,\\nlet's rewrite our performOperation function\\nfor ultimate flexibility.\\nAnd to do this, we're going to need a little help\\nfrom the math library, import math.\\n\\nOkay, so let's take this and rewrite this.\\nI'll just use args.\\nWe do want to keep operation equals sum by default.\\nIf operation equals sum, return math.sum args.\\nIf operation equals multiply, return math.prod args.\\nAnd now we can perform this operation there.\\n\\nOh whoop, sorry,\\nthat's a default Python library thing there.\\nAnd we get six.\\nIf we add on a six, seven, eight, we get 27.\\nIf this code were any more Pythonic\\nit'd be eating small birds and rodents at the zoo.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400009\",\"duration\":390,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Variables and scope\",\"fileName\":\"4314028_en_US_06_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explains how variables are referenced by functions, as well as how to avoid common pitfalls and write clearer code.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5854764,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Welcome class.\\nToday we're covering global\\nand local variable scope interaction in Python.\\n- Geez, that sounds tedious.\\nIgnore them.\\nI promise there's nothing crazy to memorize here.\\nJust watch, learn, get a feel for it.\\nIt's easy.\\nPreviously, we saw how we could print out the arguments\\npassed into function using asterisk args\\nand asterisk asterisk kwargs.\\nSo you see it prints out that tuple and a dictionary there.\\nBut there's another way we can get access\\nto all the variables in a Python function\\nwithout using any asterisks at all,\\nand that's the locals function.\\n\\nSo let's rewrite our original function definition,\\nperform operation num1, num2, operation equals\\nby default sum.\\nAnd we're going to print the output\\nof this locals function that's built into Python,\\nand we can call this perform operation one comma two,\\nand let's call the operation multiply, okay?\\nAnd what we get is a dictionary\\nof all the variables that have been passed in,\\nwhether they're positional arguments or keyword arguments.\\n\\nAnd why is this function here called locals?\\nWell, these are the variable names\\nthat are available locally inside the function.\\nRemember, we can define variables to have any name we want\\nin our function definition,\\nand they're available anywhere inside that function.\\nSo obviously, I can't do something like this, num1.\\nWe get an error\\nbecause I haven't defined num1 out here.\\nSo in Python we talk about local variables,\\nthings that are defined inside the function.\\n\\nWe also talk about global variables,\\nso things that are defined outside the function\\nin the main body of the code.\\nAnd conveniently enough,\\nthere's also a built-in Python function called globals\\nthat will get you all of these variables.\\nGlobals.\\nNow you may not think\\nthat we have many global variables defined in here,\\nbut watch, if we run it,\\nthat's a lot of stuff.\\nSome of these are built-in Python variables\\nthat will be useful later on when we start working\\nwith classes and packages.\\nBut there are also a lot of variables\\nthat Jupyter Notebooks uses to keep track of its data.\\n\\nSee, all of this stuff in here is actually the contents\\nof my Jupyter Notebook cells.\\nThere are lots of things going on\\nbehind the scenes in Python.\\nSo when you're talking about which variables\\nyou have access to in a particular line of code,\\nthat's called the scope.\\nSo we might talk about the global variable scope\\nand the local variable scope,\\nor the scope of variables inside this function.\\nSo let's look at how global\\nand local variable scopes interact\\nwith each other by making a couple of functions\\nand just sort of playing around with this.\\n\\nSo let's make function one,\\nand it's going to have the variables A and the variable B.\\nIt's just going to print out locals.\\nAnd then we'll make function two,\\nand that's going to have a varC and a varB again.\\nLet's print out locals there too.\\nLet's call function one with one comma two,\\nfunction two with three comma four.\\n\\nSo these two functions have their own local variable scope.\\nThey also have access to any variables\\ninside the global scope.\\nSo if out here I define message equals some global data,\\nand then let's print message,\\nI may actually print that up there.\\nThen print message.\\nAnd you can see they have access to that.\\nThey don't, however, have access to each other's data.\\n\\nSo if I try to print varA there,\\nyou can see varA isn't defined.\\nIt's defined in this function, not that one.\\nBut what if I define varA in the global scope?\\nVarA equals two.\\nWhat happens if I print out, let's say print varA here,\\nand then also print varA here.\\nOkay, so this is VarA being printed out for both functions.\\n\\nAnd you see that the first function prints out one\\nbecause it's using varA that we passed in\\nin the local scope.\\nAnd the second function prints out two\\nbecause it's using our definition here in the global scope.\\nSo when Python goes to look up the data associated\\nwith the variable name, it checks the local scope first.\\nAnd then if that's not defined, it goes to the global scope.\\nI can also say redefine message\\nso that this first function\\ngets its own local value for message.\\nSome local data.\\n\\nAnd you see that prints out some local data\\nand some global data.\\nAnother cool thing we can do is actually declare a function\\nwithin another function, like this.\\nLet me clean up some of this stuff.\\nInner function, varA, varB, print.\\nLet's make this an f-string, inner function, local scope.\\nIt's going to be locals.\\n\\nAnd then out here, but still inside this function,\\nwe're going to call inner function\\nwith one, two, three, four, five, six.\\nWe'll call function again on the outside.\\nOkay, so here we're calling function one,\\nwhich defines this inner function\\nand has its own local scope.\\nAnd then it calls that inner function.\\nNote that we can't call inner function\\noutside of function one.\\nSo if I take this and move it down here,\\nwe get a syntax error because inner function isn't defined.\\n\\nOkay, another cool thing we can do\\nis let's say we print these local variables,\\nprint locals down here,\\nand then we call that again.\\nAnd you see that when it prints out the local variables\\ninside function one, we actually have inner function\\ndefined in there as a variable.\\nHmm.\\nCould functions just be variables?\\nWell, I think we'll find out shortly.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4402001\",\"duration\":301,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Functions as variables\",\"fileName\":\"4314028_en_US_06_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video shows you how to use lambda functions to sort lists and pass functions around as variables.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4551550,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Variables have a name\\nand some data associated with them.\\nFunctions have a function name\\nand some data associated with them.\\nOkay, in the case of a function, this data is information\\nabout the required parameters, if any,\\nand also some lines of instruction need to be executed.\\nAnd a function is actually represented\\nin Python as an object.\\nAnd we can see this using\\nthe underscore underscore code attribute\\nof Python function objects.\\nOkay, so if I print out co, varnames,\\nlet's do print in here and then print co_code.\\n\\nOkay, so here are the variable names.\\nIn this case we don't have any.\\nAnd also a Python byte object\\nof all of the lines of instruction in this function.\\nNow, you'll probably never to actually need to use this.\\nI actually looked it up specifically for this lesson\\nso please don't take notes on underscore underscore code.\\nYou're not going to need it.\\nBut what you do need to know is\\nthat functions are not anything special in Python.\\nThey are just variables associated with some data.\\n\\nAnd to demonstrate this\\nhere's some text that you will probably recognize\\nfrom earlier, and also some function names.\\nAnd these two various text processing operations.\\nSo we have function that makes the text\\nall lowercase, removes punctuations,\\nremoves any new line characters\\nrepresented with that backslash n,\\nremoves words if the the word length is three or less,\\nand then also removes the long words.\\nNow I can easily mix\\nand match the order I perform these functions in\\nand which functions I apply by calling them in a list.\\n\\nSo let's make a list called processing functions, okay?\\nAnd add lowercase, remove punctuation, remove new lines.\\nOkay, for func in processing functions,\\ntext is equal to func text, whoops.\\nPrint text.\\nAnd you can see that I can easily add functions here\\nlike remove long words.\\n\\nNow we have all the short words.\\nSo you can imagine how powerful this pattern can be\\nfor many business processes that suffer from,\\nlet's just say, frequently changing requirements.\\nAnd finally, one last way to represent a function\\nthat you might use and encounter.\\nSo not every piece of data needs a variable name, right?\\nLike I can just type five and that kind of exists.\\nI can do two plus three, no variable name required.\\nWell, you can do the same with functions as well\\nand they're called lambda functions\\nlike the Greek letter lambda.\\n\\nAnd you can define a small function without a variable name\\nlike this, lambda x, and then a colon, x plus three.\\nAnd we can call it then with five and that returns eight.\\nSo you type lambda, followed by your parameter names.\\nIn this case, just that single parameter X, then a colon,\\nand then a one line function.\\nSorry, no multiline functions with lambda functions.\\nYou don't need to type return.\\n\\nThe return is automatically assumed.\\nThere's an implied return, as we call it.\\nAnd so this takes the value five, adds three,\\nand returns eight.\\nAnd sometimes this comes in handy\\nin some Python functions that take in a function\\nas their argument.\\nFor instance, for sorting a list of values\\nyou might use the function sorted.\\nSo here's my list and it's five, four, three, two.\\nGreat, sorted, my list.\\n\\nAnd you can see it sorts those values.\\nBut if the things you're sorting don't have\\nan obvious numeric value, you can pass in a function\\nthat takes an item in the list\\nand returns the value that Python should be using\\nto sort it.\\nOkay, for example, my list,\\nit's going to be a list of dictionaries now,\\nnum three, num two, and num one.\\nOkay, now we want to call this sorted function again.\\nMy list, and you can see that we can't sort it.\\n\\nBut if we pass in this key parameter, which is a function,\\nlambda x, x is going to be our item in here,\\nand then return x number, and now it can sort it.\\nA lambda function is really a convenient\\nand concise way to write little mini functions\\nthat you just need while you're writing your code.\\nAnd that's it,\\nyou are now a functionally competent programmer.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:661421863450b547867f6a2e\",\"duration\":1800,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Sum of triangles\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:990543\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4216239\",\"duration\":103,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Sum of triangles\",\"fileName\":\"4314028_en_US_06_04_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_06_05_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":141,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2475480,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] The main trick in this challenge is realizing\\nthat two triangles, when put together, make a square.\\nNow there is one other trick\\nand that is figuring out which triangles to use.\\nLet's say that we want to get the square of four,\\nfour squared or 16.\\nStart with the fourth triangular number,\\nfour plus three plus two plus one,\\nwhich can be arranged in a triangle four tall by four wide,\\nand overlay this on our square.\\nNow, if we were to get another four by four triangle\\nand stick it on top of the square,\\nwe can see that it's too big.\\n\\nThe diagonals overlap.\\nHowever, a three by three triangle\\nfits in that corner just fine.\\nAnd then we get exactly 16.\\nIn general, the square of a number, num,\\nis equal to triangle num plus triangle num minus one.\\nThe other thing you might have noticed\\nis our friend recursion popping up again.\\nSo hopefully you looked at this triangle function.\\nYou didn't just take my word for it that it worked.\\nYou can see the triangle actually calls itself,\\nit's a recursive function.\\n\\nIt's actually a very similar recursive function\\nto the one we saw earlier in the factorial challenge.\\nIn fact, if I take this addition sign,\\nchange it to a multiplication sign,\\nand just modify our base case so that if\\nthe number is equal to zero, we return one,\\nthis is in fact a factorial function.\\nSo this challenge wasn't really meant\\nto get you bent too out of shape,\\nbut I really want to drive the point home\\nthat these same patterns appear again\\nand again in math recursion and programming.\\n\\nAnd hopefully you'll start to recognize them\\nand use them as you continue your journey.\\n\"}],\"name\":\"6. Functions\",\"size\":19162401,\"urn\":\"urn:li:learningContentChapter:4400012\"},{\"duration\":1355,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4402003\",\"duration\":318,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The anatomy of a class\",\"fileName\":\"4314028_en_US_07_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video shows you how to create a simple class and use the __init__ method, self, and static methods.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4795163,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Oh, hello there.\\nClass can be a confusing subject.\\nWhat is it?\\nWe're often told simply that we should never talk about it.\\nAs my dear friend Guido van Rossum, the creator of Python,\\ntold me at a party last week, now is better than never.\\nLet's go to the code.\\nHere we have a class that we made previously, the dog class.\\nIt has two instance attributes, name and legs,\\nthe number of legs on the dog.\\n\\nWe call them instance attributes because they're attributes\\nthat each instance of the dog class has.\\nSo if I make a new instance, my dog,\\nI'll give it the name Rover, print my dog dot name,\\nprint my dog dot legs.\\nSo great, it has the name and legs attributes.\\nBut notice that even though this value is hard coded\\nin the dog initialization function,\\nwe can't see what that value is directly.\\nSo if we say dog.legs, we get an error,\\nbut we can't really change the value of legs.\\n\\nSo what if we decide that having four legs\\nis an intrinsic property of being a dog?\\nOf course, adorable three-legged dogs exist,\\nand we can make a class for them too.\\nBut for now, let's make legs an attribute\\nof the class itself.\\nWe can do that by moving it outside\\nof this initialization function of the constructor.\\nWe just define it up here\\nand get rid of it down here.\\nAnd notice that each instance still has this value\\nas always, but now if we call dog.legs,\\nwe can see it on the class itself.\\n\\nProgrammers call these static attributes\\nor static variables, in the sense that they're unchanging\\nwith each instance.\\nThey're not dynamic, they're static.\\nTraditionally, static variables are used to hold constants\\nand fundamental business logic and that sort of thing.\\nBut be careful.\\nBecause just like any variable,\\nyou can reset it on the class.\\nYou can set the value of legs to something else.\\nNow, if we make a new dog.\\nRover is one of those adorable little three-legged doggies.\\n(dog whimpering)\\nSo the convention to prevent this sort of thing\\nis to add an underscore before the variable name.\\n\\nNote that this doesn't actually stop anyone\\nfrom messing with the variable, but the underscore\\nis just an indicator or a warning,\\nmess with this at your own risk\\nbecause you could break things by changing the value.\\nThe underscore also has another connotation,\\nthat the user shouldn't rely on\\nor even reference the values directly.\\nThese private variables are implementation details,\\nsubject to change without notice, don't look at them.\\nIn this case, we might use what's called a getter function\\nor a get method or a getter method for the legs.\\n\\nSo let's call this get legs.\\nGetter methods always start with get, self,\\nreturn self dot underscore legs.\\nOh, and we need to use that here.\\nGet legs.\\nOkay, great.\\nNow, strictly speaking,\\nwe don't need to pass the self attribute\\ninto this getter function.\\nRemember, self is an object instance\\nthat's literally the same instance\\nwe're calling the function on.\\nSo self is my dog, right?\\nSame value.\\n\\nBut legs is a static variable in this class, right?\\nSo we could rewrite \\\"get number of legs\\\" as this,\\nand now we don't actually need self.\\nThe problem is that now we can't call this method\\nlike we're used to.\\nIt'll throw an error.\\nAnd it's complaining because when we call a method\\non a class instance, like my dog dot get legs,\\nthe class instance, my dog, gets passed in\\nas the first value automatically,\\nand saying zero positional arguments but one was given.\\n\\nAnd that's because we're passing\\nthis invisible value in there.\\nWe could still call the function like this,\\ndog dot get legs,\\nbut that's just not very intuitive.\\nIt looks a little odd.\\nIn my opinion, the best way to do this is like this,\\nand just call it in the traditional way.\\nAlso note that classes have their own variable scope rules\\nthat are very similar to the variable scope rules\\nthat we discussed with functions previously.\\n\\nSo self dot legs, if it's not set to something else,\\nreferences the class variable legs.\\nHowever, we could also do something like this.\\nMy dog dot legs equals three and print dog dot legs.\\nOkay, so you can see\\nthat we're changing the instance variable, underscore legs,\\nbut not the class variable.\\nThat remains the same.\\nAs you can see,\\nthere are a lot of options when creating a class.\\n\\nWriting a class is like creating user interface for code.\\nYou need to think about how the class will be used,\\nwhat the user's expectations are, what's most convenient,\\nwhether variables should be accessed directly,\\nor should or should not be modified.\\nEven if you know that you're the only person\\nwho will ever use this code, be careful.\\nI've cursed many badly written classes, only to discover\\nthat the author was me three years ago. (slurps)\\n\"},{\"urn\":\"urn:li:learningContentVideo:4402004\",\"duration\":449,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Static and instance methods\",\"fileName\":\"4314028_en_US_07_02_XR30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video goes over how to create several instances of a class, use type to show the class name, and call both static and instance methods.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6724394,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's take a look at one my favorite things\\nto do in Python, String Parsing.\\nI'm going to make a class called Word Set,\\nand like its name implies,\\nit is going to contain a set of words.\\nSo self dot words is equal to an empty set.\\nSo this set starts out empty, and as we go,\\nwe can add to it.\\nTo add to it, I just want to pass in big blocks of text.\\nLike many programmers, I'm fairly lazy,\\nand I don't want to have to clean my text,\\nor do anything special before I pass it in,\\nso I'm just going to pass it in, punctuation, and all.\\n\\nWord set, it's going to be equal to new word set.\\nWord set, dot, add text.\\nHi, I'm, let's escape that,\\nescape that apostrophe there.\\nHere is a sentence I want to add,\\nthen word set dot add text.\\nLet's make another sentence.\\nHere is another sentence I want to add, period.\\n\\nOkay, so obviously we need to write\\na method here called add text,\\nand that's going to take in self and some text.\\nThe first thing, add text is going\\nto do is called clean text,\\nself dot, clean text, text.\\nAnother method we want to write def, clean text, self text.\\nAll right, so clean text is going to take in some text,\\nthen remove the punctuation.\\n\\nText is equal to text dot replace.\\nReplace the exclamation point with an empty string.\\nReplace the period with an empty string,\\nReplace that with an empty string.\\nReplace, we need to replace that apostrophe\\nwith an empty string as well.\\nOkay, so notice that I can call these replace functions\\none right after the other like this.\\nAnd if you remember from previously in the course,\\nthis is called chaining functions.\\n\\nYou don't want to go too overboard with this,\\nbut it helps group all these punctuation replacements\\ntogether and just makes it look nice on one line.\\nThen we're going to return, text dot lower.\\nMake everything lowercase after stripping out\\nthe punctuation, then let's fill\\nin the rest of add text, so it cleans the text.\\nThen for word in text dot split.\\nSelf dot words dot add word.\\nRemember the split function splits a string on a space.\\n\\nIt splits the string on each space,\\nand transforms that into a list.\\nSo this will take a sentence,\\nand turn it into a list of words.\\nAnd finally, let's print word set dot words.\\nAll right, so that looks pretty good.\\nOne minor thing you might have have noticed though,\\nclean text has this self instance passed in,\\nbut it never actually gets used.\\nSelf is a completely unused variable.\\nIf we try to remove it 'cause we don't need it, right?\\nAnd we run this class, we get an error\\nbecause we're still passing the self instance\\ninto the method, but it only takes a single parameter now.\\n\\nSo let's remove self up here,\\nrun it again.\\nWell, now we get another error.\\nSo this now has no idea where\\nto look for the function clean text.\\nSo it says that it's not defined.\\nIt's expecting it to be defined somewhere out here,\\nbut instead, it's defined in the word set class.\\nSo we can actually fix this by doing that,\\nand that works, too.\\nNow this method, clean text\\nis what's called a static method.\\n\\nBy removing the self, the class instance\\nfrom the parameters that get passed into this method,\\nwe've said this method doesn't belong\\nto any particular class instance.\\nIt's actually part of the word set class definition itself.\\nAnd programmers call these static methods in the sense\\nthat they're unchanging, they're not dynamic,\\nthey're static.\\nSo traditionally, static methods are used to hold constants,\\nunchanging variables, fundamental business logic,\\nand that sort of thing.\\nAs a side note, methods like add text are instance methods.\\n\\nThey're methods that belong\\nto a particular instance of the class.\\nSo you have static methods and instance methods.\\nIn addition to static methods,\\nthere are also static attributes.\\nWe saw an example of this previously\\nwith the legs attribute on the dog's class.\\nThat's a static attribute because it's part\\nof the class definition rather than being associated\\nwith a particular class instance.\\nSo let's make a static variable called replace puncs,\\nand we can add this to our word set class\\nto control which punctuations get replaced.\\n\\nSo we want to replace the exclamation point, the period,\\nthe comma, and that quote there.\\nOkay. And we can use it like this.\\nLet's just copy this, put it down there.\\nLet's make a new class.\\nAnd then let's say, for punc, word set dot replace puncs,\\ntext is equal to text, dot replace, punc empty string.\\n\\nAll right? And we get the same results.\\nSo with static variables, we have the option\\nto use the the class name word set\\nor the class instance self.\\nIf of course, we were passing self in here,\\nbut we can use either self\\nor the class name interchangeably.\\nBut remember, we can't do this\\nwith self dot clean text, right?\\nWe can't do that because that would actually pass\\nthe instance into this function.\\nSo there's a little bit of a dilemma there.\\n\\nWe have to use word set.\\nHowever, we can solve this with a nifty trick in Python\\nand that is called a Decorator.\\nSo let me copy this, bring it down here,\\nand I'm going to add static method.\\nSo this is called a decorator\\nand a decorator in python is an annotation,\\nor description for your function definition.\\nIt actually belongs to the function definition there.\\nSo decorators always start with the at sign.\\n\\nSo this is the static method decorator.\\nAnd your decorators just defined some special attributes\\nor information about the function,\\nso that Python knows how to handle it.\\nAnd now that we've explicitly told Python\\nthat clean text is a static method,\\nthat self should not be passed in as an argument,\\nwe can actually do this.\\nAnd if we run it, there you go.\\nKeep in mind you don't have\\nto use the static method decorator.\\nI usually don't unless there's a good reason to.\\n\\nDepending on the company you work for,\\nthey may require you to use it just as a matter of style.\\nThere are many, many ways to write the same piece of code.\\nI encourage you to develop your own style\\nas you progress with Python.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400010\",\"duration\":353,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Inheritance\",\"fileName\":\"4314028_en_US_07_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explains class extension and inheritance.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5314052,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- My child, one day, all of this will be yours.\\nYour inheritance. (ethereal music)\\nSo you see, in computer science and in Python,\\na class can extend another class.\\nThe original class is called the parent class,\\nand the class extending it is the child class.\\nAnd the child class inherits\\nall of the parent classes' methods and attributes.\\nBut this inheritance happens automatically\\nwhen the child class is created.\\nLet's go to the code. - Yeah.\\n\\n- [Instructor] Here, we have the dog class\\nthat we used previously,\\nand say we want to use this to make a chihuahua class,\\nwhich is a type of small dog.\\nHere's how we can do that.\\nClass Chihuahua dog.\\nAnd let's just add pass for now.\\nWe use these parentheses\\nafter the class name to indicate\\nthat this class is extending the parent dog class.\\nAnd for now, let's just not add anything else.\\nJust write pass to get this class in place.\\nSo we can use this to create a new Chihuahua,\\nand you can see that it has all of the attributes\\nand methods of the parent dog class.\\n\\nSo Chihuahua, let's call it Roxy, and dog dot speak.\\nHmm, that doesn't seem quite right.\\nHave you ever actually heard a chihuahua say bark?\\nLet's fix this.\\nLet's extend this method, print.\\nLet's use an f-string for this.\\nSelf dot name says yap, yap, yap.\\n\\nOkay. Much better.\\nIf the child class, chihuahua, defines any attributes\\nor methods that conflict with the parent class,\\nthe parent class's methods get overwritten,\\nand the child class method is used instead.\\nSo you can see that we can make an actual dog still.\\nMy dog equals dog, Rover, my dog dot speak,\\nand that still says bark.\\nWe can also add additional methods to the child class.\\n\\nFor example, we can do this,\\nwag tail, print vigorous wagging.\\nOkay, so now our chihuahua should have a wagtail method.\\nWagtail. Great.\\nSo this can be extremely useful if, for example,\\nthere's a class that you really want to use,\\nbut it just needs a couple tweaks\\nor maybe an extra method or something like that.\\nWe can even do this with Python's own built-in classes.\\n\\nRemember, in Python, you can instantiate a new list\\nby calling it like this.\\nMy list equals list, okay?\\nAnd even though this is lowercase,\\nand it looks like a function, list is actually a class.\\nSo let's say we want to make a list that guarantees\\nthat all of the items appended to it are unique.\\nA bit like a set.\\nWe can extend the list class\\nand make our own unique list class.\\nOur unique list extends list, okay.\\n\\nThen we're going to override the append function.\\nAppend self item, if item in self,\\nreturn self dot append item.\\nOkay, but wait, not so fast.\\nWe're calling self dot append,\\nwhich is going to call this exact same function right here.\\nThis is self dot append,\\nand this is going to lead to infinite recursion\\nor a never ending loop and break our program.\\n\\nWhat we actually want to do is call append\\nin the parent class, the original list class.\\nIn this case, we can use a function called super,\\nwhich gets the underlying instance\\nof the parent class, and we'll call super dot append.\\nSo let's try this out.\\nUnique list is equal to unique list.\\nSo we're creating a new list.\\nLet's do unique list dot append one, append one, append two,\\nand print unique list.\\n\\nAnd you can see that even though we added one twice,\\nit only recorded it once.\\nThere's also another really common use case\\nwhere super is used, and that's in the constructor.\\nSo, say you want to add another attribute\\nto your child class instance,\\nwe could do something like this, init self,\\nself dot some property equals unique list.\\n\\nOkay, so the problem is that we're completely overwriting\\nthe constructor and the parent class now,\\nwhere it may have some really important stuff\\nthat it needs to initialize.\\nWe can solve this by using super again.\\nInit, okay, and this makes sure\\nthat the parent constructor gets called first,\\nand then we add our new property,\\nand we can see that when we instantiate this.\\nLet's print out some property.\\n\\nThere we go.\\nClass extensions might look complicated at first\\nbut it's an incredibly elegant and powerful tool\\nthat can solve a lot of really tricky coding problems.\\nYou certainly don't need an estate lawyer\\nto figure out inheritance.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:661421a534505b4d053f74bb\",\"duration\":1800,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Drawing shapes\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:962256\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4220205\",\"duration\":235,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Drawing shapes\",\"fileName\":\"4314028_en_US_07_04_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_07_05_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":281,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6660141,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Presenter] Technically speaking,\\nthis challenge was the easiest\\nbecause it had no wrong answers.\\nIt's arts and crafts day. Anything you do is great.\\nBut really I do hope you got\\nsome sort of triangle printed out.\\nSo let's take a look at our classes\\nand a couple ways to do this.\\nSo here we have the base class shape.\\nIt's not a particular shape,\\nit's just defining general properties of shapes.\\nIt has a default width and height of five.\\nSort of saying, \\\"All shapes, all good basic shapes\\nhave a width and a height of five,\\nbecause that's the sort of width and height\\nthat shapes in general should have.\\\"\\nSure, you can agree with that or not.\\n\\nMaybe you want to override it in an extending class.\\nThen we have the print character. And so this is a hash.\\nAnd this is just the character we use to print out\\nthe body of our ASCII art shapes.\\nThen the print method.\\nIt iterates through the height,\\nprinting out one row at a time,\\ncalling print row with the sort of height index\\nwhere zero is the top row, and four,\\nusing the default height, is the bottom row.\\nSo in our square implementation,\\nwe implement print row there\\nand each row is exactly the same.\\n\\nSquares are the same at the top as they are on the bottom.\\nYou can see that it doesn't even use\\nthis height index that gets passed in at all.\\nSo it's a really simple case.\\nThe triangle is a little different,\\nand this is what you had to implement in the challenge.\\nOne easy way to do this is to multiply printChar\\nby the height index plus one.\\nSo if you run this,\\nwe get one character printed out on the first line\\nall the way down to five characters\\nprinted out on the last line.\\n\\nAnd this is a sort of right angle triangle,\\nbut I think we can do even better.\\nSo what about a symmetrical triangle?\\nSo first we're going to need something wider than it is tall.\\nSo I'm going to set the height to five.\\nAnd I'm going to set the width to two times the height.\\nAnd this is because for each row to stack on top\\nof subsequent larger rows in a symmetrical way,\\nthe number of characters in each row needs to be odd.\\n\\nAnd we can do this\\nby defining a triangle width\\nat that height, at each height, using I times two plus one.\\nSo that guarantees the width of our triangle at height I\\nwill always be an odd number\\nand we can stack these rows symmetrically.\\nThere also needs to be some initial padding space\\nbefore we start printing the row.\\nAnd that padding space\\nis going to get smaller as we go down.\\n\\nWe can calculate the padding\\nas the width of the entire figure,\\nwhich is two times the height, minus triangle width.\\nSo padding equals self.with minus triangleWidth,\\nall divided by two\\nbecause we want to have equal padding on both sides.\\nAnd then we're going to convert that to an int\\nso we can multiply it by our character to get a nice string.\\n\\nThen we're going to print everything out.\\nSo print our padding first.\\nSo that's going to be a space multiplied by\\nthe number of padding spaces we want,\\nplus self.printChar\\ntimes triangle width.\\nWe don't need to print out the padding\\non the right hand side of the triangle\\nbecause that's just going to be sort of implied.\\nIt's going to be blank over there.\\nAnd there we go. Two different ways to print a triangle.\\n\\n\"}],\"name\":\"7. Classes and Objects\",\"size\":23493750,\"urn\":\"urn:li:learningContentChapter:4404006\"},{\"duration\":1012,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4405004\",\"duration\":232,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Errors and exceptions\",\"fileName\":\"4314028_en_US_08_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3498005,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] We've seen a lot of errors\\nworking with Python so far.\\nYou know, it's that thing that happens\\nwhen you divide something by zero.\\nYou get a zero division error.\\nWorking with Python,\\nyou'll see that sometimes these things are called errors\\nand sometimes they're called exceptions.\\nAnd if you read the official Python documentation,\\nyou'll find something like\\nexceptions are decided during runtime and are retryable,\\nerrors are not retryable, eh.\\nThere are so many, well, exceptions to this rule\\neven within the official Python code\\nit's not really worth worrying too much about.\\n\\nThey all work the same anyway.\\nControversial opinion, but errors and exceptions\\nare the same thing.\\nAll Python errors and exceptions\\nultimately extend a class called the base exception.\\nSo division by zero error extends arithmetic error\\nwhich extends the exception which extends base exception.\\nAnd base exception is the thing that gives us really useful\\nand powerful properties of exceptions,\\nwhich is to halt the execution of code\\nand give you some information\\nabout how and why that execution was halted.\\n\\nIn this zero division error, for example,\\nwe can see the file this occurred in.\\nIt's a little bit difficult to tell\\nbecause it's all a Jupyter Notebook file,\\nbut we can also see the line, line one.\\nAnd if we put 1/0 into function,\\nlet's make it called causeError,\\nand then this is going to return 1/0,\\noh, and of course we need to call it causeError.\\nWe can see that this gets a little bit longer.\\n\\nWe can see where the function was called originally,\\nthen we can see where in that function\\nthat we called the error happened.\\nAnd this is called a stack trace.\\nThis whole thing is called a stack trace.\\nIf you think about these nested calls\\nlike a stack of operations,\\nit provides a trace through the stack\\nthat we can use to debug our program.\\nAnd we can make the stack trace even larger\\nby doing something like this.\\nLet's make a function called callCauseError,\\nreturn causeError, and of course,\\nwe're going to call that one.\\n\\nNow our stack trace gets even larger.\\nYou can imagine that in very large programs with many files,\\nthese stack traces can get fairly large,\\nso it's important to be able to read them\\nand also write your code clearly\\nand pay attention to your program's architecture\\nso that it doesn't get too difficult to debug.\\nExceptions might seem intimidating at first.\\nAfter all, any tiny mistake\\nin any of hundreds of lines of code\\ncould cause your beautiful program to just blow up, right?\\nThey're terrifying!\\nBut don't worry.\\nThey're actually just classes.\\n\\nWe'll cover this in more detail later,\\nbut we can catch an exception using a try except statement,\\nand we can get an instance\\nof that exception that was raised.\\nSo, let's give it a try.\\nLet's just do 1/0 in here and then except.\\nGoing to except exception as e,\\nso e is going to be our variable.\\nActually, that instance of the exception that was raised,\\nprint type e, and there you go.\\n\\nThis thing is a zero division error.\\nWe have caught this exception.\\nWe have it, it's not being raised anymore.\\nIt's just a class, it has attributes,\\nyou can create them, they can even be returned.\\nExceptions are nothing to worry about,\\nbut they do require some careful consideration.\\nExceptions when used and handled correctly\\nare almost like a secondary layer of code\\nunderlying all the existing and more obvious code.\\nSo stick with me and we'll learn how to write code\\nthat if not error free, at least has beautiful errors.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4405005\",\"duration\":459,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Handling exceptions\",\"fileName\":\"4314028_en_US_08_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6903479,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Exceptions are not to be feared\\nbut they do need to be reigned in.\\nWe saw a little bit about how to do this previously\\nwith the Try-Except statement.\\nSo here, we are catching this exception\\nand then just returning it.\\nSo we don't get a stack trace or anything,\\nbut we do see that\\nthis zero division error instance is returned.\\nThere are a few interesting things you can do\\nwith this Try-Except pattern.\\nFor instance, if we don't care\\nabout getting the specific instance of the exception,\\nwe just maybe want to print something.\\n\\nWe don't have to have the as e\\nin order to catch an exception.\\nThere was some sort of error.\\nAnd then that just prints out.\\nAnother useful thing you can do with this\\nis the finally statement.\\nSo if I take my Try-Except block and add a finally to it,\\nthis will always execute.\\nAnd you see that gets printed out.\\nFinally statements can be useful\\nbecause they will always execute\\nno matter what happens inside this try block.\\n\\nYou don't even need any except statements, right?\\nSo this error is thrown, but this still printed out.\\nEven if no exception is raised at all,\\nthat still executes.\\nI often use them when I'm timing\\nhow long a function takes to execute.\\nSo if we import the time class up here, import time,\\nwe can use this to actually time our function.\\n\\nSo I'm going to make a timer.\\nWe need the start time,\\ntime.time will give you the current time and seconds.\\nAnd in our finally statement,\\nwe're going to make this an f-string\\nand say, Function took, yeah, time.time\\nminus start seconds to execute.\\nAnd another fun thing we can do with this is time.sleep.\\nAnd time.sleep just pauses execution\\nfor some number of seconds.\\n\\nIn this case, we're going to pause it for half a second.\\nLet's see how long that takes.\\nSo you can see that half second\\nand then that very fast execution there.\\nIf I change the statement to something\\nthat causes a zero division error,\\nyou see that timer still happens.\\nThis try-finally pattern keeps your code clean and compact\\nand lets you do any needed cleanup or logging\\nafter a statement completes\\nno matter what happens inside the try block.\\n\\nBut back to exception catching up here.\\nSo I'm going to just grab this.\\nNotice that I'm always catching this exception class.\\nI could add another except statement above this.\\nYou can chain these together just fine.\\nZero division error.\\nSo we're going to catch that one specifically, print\\nThere was a zero division error,\\nand now that prints out.\\n\\nI could also add say a type error statement,\\nexcept type error.\\nAll right, let's print There was a type error.\\nBut of course there was a zero division error,\\nnot a type error.\\nLet's maybe cause a type error\\nby trying to add an int to string.\\nNow there was a type error.\\nThe order of these except statements does matter here.\\nSo Python will try the first one.\\nSay, does this match type error?\\nYes, and it doesn't bother with the other ones.\\n\\nSo if I move this general exception up,\\nso this is the class from which all of these extend,\\nthere was some sort of error.\\nSo you always want your most general exceptions down here.\\nAnd then the more specific ones up top.\\nSometimes you're doing really involved\\nexception handling and catching.\\nFor instance, I see this a lot\\nwith HTTP request response handling\\nwhere there are a lot of different types of HTTP errors\\nand you'll have a lot of except statements all in a row.\\n\\nAnd then you'll just copy and paste\\nall of these different blocks into many different functions.\\nAnd in this situation, it can be really handy\\nto move this trying and catching into a single function.\\nAnd you can also use a custom decorator to do this.\\nWe saw decorators previously\\nwith the static method decorator\\nbut now we're going to write our own.\\nSo let me grab these\\nall these exception handlings that we've done\\nand I'm going to make a new function called handleException.\\n\\nAnd we're going to pass as an argument, a function.\\nAnd then we're going to define an inner function\\nin here called wrapper.\\nWe're going to try to execute this function\\nthat was passed in\\nand then we're going to paste our exceptions here.\\nWhoops, there we go.\\nOkay, now we return this wrapper function.\\nNow we can use this.\\nSo let's make a decorator handleException\\nand put it on a causeError function.\\n\\nAnd this is just going to return one over zero.\\nNow if we call causeError,\\nyou see that this handle exception was used\\nto except those various exceptions that this could throw.\\nAnd we can of course reuse this decorator\\nfor another function.\\nLet's talk about raising exceptions.\\nLet's use our handle exception decorator.\\nMake a a function called raiseError raise Exception.\\n\\nThis raise statement that I've used raises or throws\\nthis new exception that I'm creating when it's reached.\\nFor instance, we can turn this into function\\nthat excepts any input except the number zero.\\nSo let's add an argument here\\nand say if n is equal to zero, we raise an exception.\\nOtherwise, we print n.\\nAnd notice that I'm not using an else statement here, right?\\nI don't need it because once the exception is raised here,\\nthis execution will just halt, it'll throw this exception,\\nand then the print n will never be reached.\\n\\nSo we don't need to bother with an else statement there.\\nNow there is one problem with this.\\nNotice up in our handleException function,\\nthis is the function that gets passed in,\\nthis raiseErrors being passed in.\\nBut when we call it, there aren't any arguments\\neven though our function has an argument.\\nSo now we're trying to use this handler\\non a function that takes arguments.\\nSo we need to modify it a bit using the variable args.\\n\\nRemember that?\\nAnd we can pass our args to this function there.\\nSo let's rerun that.\\nAnd now if we do that, there is some sort of error.\\nNow we get an error printed out\\nif the argument we pass in is zero,\\notherwise it just prints out the value.\\nWriting your functions to be able to raise exceptions\\nis especially powerful\\nwhen you combine it with custom exceptions.\\nSo let's go take a look at those next.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4407004\",\"duration\":249,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Custom exceptions\",\"fileName\":\"4314028_en_US_08_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3767803,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] All right, this is an easy one.\\nIn fact, you already know how to do this,\\nclass CustomException extends Exception:pass.\\nAll right, we've written a custom exception. Next lesson.\\nI'm just kidding.\\nThere are a few more things we need to cover.\\nSo here, we're using the pass statement\\nbecause we literally don't need to define anything\\nfor our new CustomException class.\\nIt inherits the constructor of the Exception class\\nthat it's extending.\\n\\nThe key information is in the name, CustomException.\\nAnd often, this is all the information you need to know\\nto help debug your app\\nor let the user know what they're doing wrong.\\nWe can write a function\\nthat raises this new CustomException,\\ndef causeError:raise CustomException\\nand then let's call this function.\\nSo we can see our CustomException error class in the name,\\nthen there's this colon,\\nand then after that, it is curiously blank.\\n\\nSo let's pass a custom message into our new class.\\nYou called the causeError function\\nand you see now that message gets printed out.\\nCustom exceptions are usually lightweight classes\\nwith very little in the way of special attributes\\nand methods and things,\\nbut you might have some attributes\\nthat are useful for organizing and presenting information\\nto the user about the error.\\nFor example, if you're writing a web server\\nand need to raise HTTP exceptions\\nat various points in the code,\\nyou might have an HttpException class\\nand various specific HttpException classes that extend it.\\n\\nSo let's write an HTTP exception with a static status code\\nand a message attribute\\nand then some information about how to format the string\\nthat it passes to the parent exception.\\nSo here's our HttpException.\\nIt's going to extend Exception.\\nWe're going to give it a status code.\\nLet's make that None for now,\\nso that's that special None value, and a message.\\nWe'll also make that None.\\nAnd then we're going to override the parent constructor,\\nso we need to define our own constructor,\\ncall the parent constructor.\\n\\nAnd then when we call that parent constructor,\\nwe're going to pass in the status code message,\\nis statusCode and message is self.message,\\nsorry, and that needs to be self.statusCode.\\nOkay.\\nNow let's write a couple child classes\\nthat extend the HttpException,\\nNotFound HttpException.\\nAnd all we need to do here is define our status code,\\nwhich is going to be 404,\\nand our message which is going to be Resource not found.\\n\\nOkay, now let's write a ServerError class,\\nclass ServerError extends HttpException\\nstatusCode 500 and message This server messed up!\\nGreat.\\nNow let's write a function\\nthat say raises a ServerError,\\nraiseServerError\\nraise ServerError,\\nand then let's call it.\\n\\nGreat.\\ngets formatted with our status code and message\\nbecause it extends this HttpException.\\nWriting custom exception classes is a great way\\nto keep your code clean and organized.\\nThese classes act as documentation\\nfor all the problems that could happen,\\nwhat cause them, what the solutions are,\\nand they also separate common expected errors\\nfrom something perhaps really bad\\nthat requires developer attention.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:661422222056ab5f5f4a7538\",\"duration\":1800,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Bad arguments\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:962254\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4218192\",\"duration\":72,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Bad arguments\",\"fileName\":\"4314028_en_US_08_04_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_08_05_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":96,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2034848,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Custom annotations work really well\\nwith exception handling.\\nIt's one of my favorite Python tricks\\nfor writing clean enterprise code.\\nFor this challenge, you needed\\nto write a new custom exception\\ncalled NonIntArgumentException.\\nAnd this is probably the easiest part.\\nYou literally don't need to do anything\\nbesides define the class,\\nmake it extend exception,\\nand then you can just write pass under that.\\nWe just need it defined.\\nThen you want to fill in the rest of this wrapper function\\nunder here.\\nAs you can see,\\nthe function sum down here takes in three arguments,\\nbut I opted to make the wrapper handle any number\\nof arguments just by iterating through the args tub here.\\n\\nI check each one, make sure it's an integer.\\nIf it's not an integer,\\nI raise my NonIntArgument exception.\\nFinally, I make sure to return the function\\nthat was passed in with its original arguments.\\nSo remember, if you don't return this, then that will mean\\nthat some isn't going to return anything,\\nand then the caller is going to be really confused\\nwhen they don't get a result there.\\nFinally, if everything looks good,\\nlet's go ahead and test it.\\nAll right, all the test cases pass.\\n\\n\"}],\"name\":\"8. Errors\",\"size\":16204135,\"urn\":\"urn:li:learningContentChapter:4402008\"},{\"duration\":754,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4407007\",\"duration\":161,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Intro to threads and processes\",\"fileName\":\"4314028_en_US_09_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses computational operations, threads, and processes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2456531,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- I have to come clean.\\nEarlier in the course, well, I lied to you.\\nYou know that explanation I did\\nabout how computers operate on memory?\\nWell it's a little more complicated than that.\\nI know you're shocked.\\nShocked that an introductory explanation\\nof computational operations\\nmight have glossed over some of the details.\\nBut I swear I'll make it up to you, don't leave.\\nI'll tell you everything.\\nHow computers really work.\\nYou see, computers have both memory and file storage.\\n\\nIt's like short-term and long-term memory.\\nWhen we save a file and load to file from the disc,\\nthat's in storage, long-term memory.\\nWhen we declare a variable in our program,\\nthat's short-term memory in the processor.\\nIt looks a bit like this.\\nSo what's the big deal?\\nWhy can't we think of both storage\\nand memory as one big blob of accessible data?\\nWell, let's bring in a second program.\\n\\nThe first program saves a file to the disk.\\nThe second program, running in a second process,\\ncan pick it up.\\nThey both have access\\nto the same long-term storage on the physical machine.\\nBut if this program writes something to memory,\\nthe second program can't access it.\\nYou see, the operating system is responsible\\nfor allocating memory\\nto each process running on the computer.\\nIt puts walls between the processes\\nso they can't access each other's memory.\\nMemory isn't one giant vague blob\\nlike I implied in that earlier video.\\n\\nIt's segmented.\\nAccess is controlled by the operating system.\\nIt's very important\\nto a programmer where these things are being stored\\nand who has access to what.\\nBut here's the nifty thing\\nthat operating systems allow us to do.\\nMove these two pieces of code into the same process.\\nWhen we move them into the same process,\\nthey get to share memory.\\nWe still get to run them in parallel, at the same time,\\nbut instead of separate processes,\\nthey're run with separate threads.\\n\\nA process can have multiple threads\\nand execute code at the same time in parallel.\\nEverything we've been doing in Python so far has been\\ninside a single thread, inside a single process.\\nThat is we compute each statement sequentially.\\nBut in this chapter,\\nwe're going to start computing things in parallel,\\ninside different threads and processes.\\nI hope that you can forgive my earlier simplifications,\\nbut if you're willing to stick with me,\\nwe can start coding faster than ever before.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4401009\",\"duration\":266,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Multithreading\",\"fileName\":\"4314028_en_US_09_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video covers when and where to use multithreading.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4021453,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Processes and threads may seem\\nlike abstract concepts right now,\\nbut let's get hands-on and start spinning some up.\\nThe other programmers are going to look at your code\\nand say, \\\"Nice threads.\\\"\\nThe first thing we want to do is import the threading\\nand time modules.\\nSo import threading, import time.\\nThen we're going to create a function\\nthat calculates the square of a number\\nbut takes a really long time to do it.\\nWe can call it, appropriately, longSquare.\\nYou pass in a number time.sleep for a whole second\\nand then return that number squared.\\n\\nLet's say we want to calculate the square of a few numbers.\\nIt's going to take a long time.\\nFor in and range zero through five.\\nThis is obviously a fairly contrived example,\\nbut these situations often arise in programming.\\nFor instance, waiting to fetch data back\\nfrom a remote server.\\nYour code is just sitting around doing nothing,\\nwaiting for that data to come back,\\nand this is where threads come in handy.\\nSo you can do all that waiting in parallel\\nrather than one at a time.\\nTo demonstrate this, we're going to make two threads.\\n\\nt1 is threading.thread.\\nAnd then t2, threading.thread.\\nWe're going to pass in two keyword arguments.\\nThe first one is called target,\\nand that's the name of the target function, longSquare.\\nThe second is called args.\\nThat's going to be the arguments we pass to the function.\\nAnd let's copy this and put it there.\\nOkay, now I'm putting a comma after this,\\njust to show Python that it's a tuple\\nand not a random variable with parentheses around it.\\n\\nIf you only have one value in the tuple,\\nsometimes that's necessary.\\nOkay, now we need to start both of the threads\\nwith the start function, t1.start t2.start.\\nAnd finally, we join them, t1.join t2.join.\\nThis join function checks to see\\nif the thread has completed execution yet\\nand pauses until execution's complete.\\nAnd you can see this runs\\nin about half the time it would take us\\nto run these one at a time.\\nBut one little problem,\\nwhere are the results of our function?\\nYou might try to get the results from the thread object\\nby saying t1.results return value,\\nbut I promise you're not going to find it.\\n\\nThe return value of this function\\nis actually nowhere in these threads.\\nThere is no way to get the output of this function directly,\\nso here's where we can take advantage of the fact\\nthat threads share memory.\\nLet's create a results dictionary\\nand bring this code down here and modify our function\\nso that that results dictionary gets passed in.\\nThen rather than returning anything,\\nit's going to take results\\nand then just add it to the dictionary.\\n\\nOkay, and pass in results, results.\\nJust bring that down there to keep things organized.\\nWhoops, there.\\nFinally, print results.\\nAnd there you go.\\nThreads share memory and can modify the same object.\\nOf course, writing out t1, t2, start, join is laborious\\nif we want lots and lots of values\\nor a variable number of values back.\\nSo it's a common pattern to put all these into a list,\\nso let's do that.\\n\\nLet's make a list called threads, plural,\\nand say threading.thread.\\nTarget is going to be longSquare, args.\\nIt's going to be n, results\\nfor n in range 0, 10.\\nOkay, then we need to say t1.,\\nor sorry, t.start for t in threads.\\n\\nAnd finally, t.join for t in threads.\\nAnd then we can print results.\\nThat was fast.\\nAnd just for fun, let's do 100 threads.\\n(laughs) Much faster than waiting one at a time.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4405006\",\"duration\":327,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Multiprocessing\",\"fileName\":\"4314028_en_US_09_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explains how to use multiprocessing in Python to manage programs.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4928087,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] You're probably great at multi-processing\\nand Python already and don't even know it.\\nHere, I'll show you.\\nI have a file called 1000seconds.py.\\nAll it does is call time.sleep for a thousand seconds.\\nSo I'm going to open a second tab and run it in the second tab.\\nSo now we have two tabs running this program.\\nGreat. Two Python processes running independently\\non my machine, multi-processing, and Python.\\nAll right, so that's how you do that,\\nonto the next subject then.\\n\\nJust kidding.\\nYes, I do have two separate Python processes running\\nbut I had to start them by hand.\\nHow do we write a program to start, stop,\\nand manage these for us?\\nWell, conveniently, there's a module that's very similar\\nto the threading module we used previously.\\nLet's check it out.\\nAnd that module is called multi-processing.\\nFrom multiprocessing import Process.\\nOkay, so before I run this,\\nthere is a small hitch\\nwith using the official Python multi-processing module.\\n\\nOn some operating systems,\\nyou can't use this to spin up a new process\\nthat runs the function\\nif that function is defined in the same file as opposed\\nto imported at the top, like this, import myFunction.\\nThat's going to make life difficult for us\\nfor example purposes where we want to define\\nand run functions in the same Jupyter notebook.\\nSo fortunately there is a third party module\\nthat solves this called multi-process\\nand you can install it with pip install multiprocess.\\n\\nThe multi-process module has all of the same functions\\nand is used exactly the same as multi-processing\\nbut it doesn't have the bug\\nwith pickiness about where the function is defined.\\nSo play around with it,\\nuse either of them for these examples,\\nbut I'm going to use multi-process\\nand also I'm going to import the time module.\\nAnd this process class is so similar\\nto the thread class we used earlier\\nthat I can actually just copy this code.\\nSo I'm going to do that and paste it down here.\\n\\nNow, instead of threading.thread,\\nwe want process.\\nSo replace both of those and instead of t1 and t2,\\nlet's call them p1 and p2.\\nThis should work exactly the same now.\\nAnd there we go.\\nOh, there aren't any results.\\nBut of course, remember,\\nprocesses don't share memory.\\nThey get a copy of this dictionary\\nin their own separate memory space,\\nand we have no way of accessing it\\nexcept if they record it somewhere like a file system\\nor a database.\\n\\nOne thing we can do though is print the computed value from\\nwithin the function itself.\\nSo rather than returning this or saving it in the results,\\nwe just print\\nand there we go.\\nBut you see it printed them right next\\nto each other,\\nnot a 14, it's a one and a four.\\nWhat happens if we add another line in here,\\nlike Finished computing?\\nSo it's printing the one and the four very quickly,\\nthen it prints both processes,\\nprint Finished computing,\\nand then we have this extra weird new line.\\n\\nWell, what happens if we add 10 processes to the mix?\\nAnd again, I'm going to use the same pattern\\nthat we used previously with the threads.\\nSo processes is equal to a list,\\nn for n in range (0,10)\\nthen p.start, p for in processes,\\nand p.join p for p in processes\\nand we don't need to bother printing the results.\\n\\nOh, whoops, bad syntax there.\\nOkay. And you can see this output starts\\nto look a little bit funky.\\nNew lines aren't where you expected them to be.\\nThere's overlap between the separate function calls.\\nIf we copy our threads code over,\\nwe can do a similar thing with that.\\nLet me just copy this\\nand I'm just going to import the threading module at the top.\\n\\nOkay. And we're going to use the same long square function\\nso it should print things out.\\nOh, and let's just do zero through 10 there.\\nSo that actually looks a little bit nicer\\nthen with the multiple processes.\\nSo what's going on?\\nWe usually talk\\nabout threads and processes as computing things in parallel.\\nAnd with processes, that's true.\\nModern computers have multiple processors\\nand you're literally asking\\nfor multiple processors to process your tasks in parallel.\\n\\nHowever, with threads,\\nwhat's happening is that the same\\nprocessor will execute a statement\\nfrom thread A, thread B, thread C, then thread A again,\\nand it basically picks them up in a round robin fashion.\\nIt will go to work on a different thread\\nif one of them is hanging around waiting\\nfor something for whatever reason,\\nlike a time.sleep.\\nSo threading emulates parallel computing\\nand can sometimes be very powerful\\nif your programs have periods\\nof downtime where you're waiting for something.\\n\"}],\"name\":\"9. Threads and Processes\",\"size\":11406071,\"urn\":\"urn:li:learningContentChapter:4404007\"},{\"duration\":1342,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4403005\",\"duration\":407,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Opening, reading, and writing\",\"fileName\":\"4314028_en_US_10_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video shows you how to open a text file on disk, read data, overwrite the file, append to it, and close the file to flush the buffer.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6112718,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Watching output being printed\\nto the screen is all well and great,\\nbut often as programmers we're asked\\nto produce something real, you know, something tangible,\\nusually for those management types that want to\\nsee a physical file they can attach to email\\nor open in Excel or whatever it is they do with files.\\nSometimes they give you files\\nand they want your program to read them.\\nFine, we'll use their dang files.\\nLet's go to the code.\\nThe first thing you need to know about working\\nwith files in Python is that it's not quite as simple\\nas when you double-click an icon on your desktop.\\n\\nWe're working a little more directly\\nwith the operating system\\nand so there are some things that you need to manage.\\nAnd one of those things is whether\\nwe're simply reading the contents of the file\\nor whether we intend to make changes to it, writing it.\\nAnd this is because it causes problems\\nif two applications are making changes\\nto the same file at the same time.\\nSo the operating system needs to know who's doing what.\\nSo I can use the open function\\nand pass in the name of a file.\\nAnd I have a file 10_01_file.txt right there.\\n\\nSo I'm going to write 10_01_file.txt.\\nAnd then the second argument is going to be the string R.\\nWe're going to open this file in the read mode\\nand if we print f at this point, we get a file object.\\nAnd there are a couple ways to get the actual text\\ninside the file.\\nAnd the first is readline,\\nso f.readline.\\nAnd this reads the lines of the file one at a time.\\n\\nYou can see if I run it again,\\nI get a different line each time.\\nSo this file object contains a sort\\nof bookmark of which lines of the file it's already read.\\nSo you could obviously put f.readline inside\\nof some sort of a loop and get all the lines of the file.\\nBut there's a second easier way\\nif you want to get all the lines of the file,\\nand that is readlines, plural.\\nAnd this gets all of the lines\\nof the file that haven't been read already\\nand then puts them into a list of strings.\\n\\nWe can print out the contents\\nof this file fairly nicely if we do something like this,\\nfor line in f.readlines, print line.\\nNotice that these lines are all double-spaced\\nand that's because each line of the file\\nhas a new line character on it on the end there,\\nand this print statement also includes its own new line.\\nWe can fix this by stripping out any leading\\nor trailing white space, including new lines,\\nand we do that with the strip function on each line.\\n\\nBeautiful, and that is better than ugly.\\nNow let's look at writing files.\\nSo we're going to do something similar to this\\nbut instead of an R, we're going to do a W for write.\\nWe're also going to call this output.txt,\\nwhich doesn't exist yet, but when we run this,\\nit'll create the file for us\\nwhich is a pretty nice feature.\\nSo if we go over here, okay, we see that file's created\\nand then let's write a couple of lines.\\n\\nSo we're going to use the write function,\\nwrite line, line 1, f.write, line 2,\\nand then run that.\\nAnd if we open this output file over here,\\nhmm, there's nothing there.\\nSo what's going on?\\nWell, writing to files is an expensive operation\\nand Python tries to make file writing more efficient\\nby putting all of the data you're writing\\nto the file in a buffer.\\nAnd it only writes to the file when that buffer gets full\\nor when you close the file.\\n\\nSo if we close the file,\\nwe can do that with f.close and then run that.\\nLet's close this file and then reopen it.\\nThere's our lines.\\nSo what's going on here?\\nYou see it didn't print a new line character\\nbetween the lines.\\nWe have to add that ourselves when we're writing files.\\nSo let's add that new line character, open this file again,\\nwrite those lines, and then close it.\\nLet's reopen the file.\\nOkay, now you see our two lines,\\nbut what happened to our previous data\\nin this file where they were side-by-side like that?\\nWell, when you open a file in write mode\\nand start writing to it,\\nit's actually more like a create mode.\\n\\nPython will overwrite any existing data in that file\\nand we can fix that by opening the file\\nin append mode instead.\\nSo we're going to open this file again, but instead of a W,\\nwe're going to have an A for append.\\nThen we're going to take these and write line 3\\nand line 4 and then close the file.\\nIf we open this file again,\\nyou see we get all of our lines.\\n\\nAnd to close this lesson, let's talk about this close line.\\nIt's very important that this gets called.\\nIt basically releases the file,\\ntelling the operating system we're all done writing to it.\\nNow these files will eventually get closed.\\nThere's a process in Python that cleans up\\nold variables that aren't being used anymore\\nand will close them.\\nThat's kind of a longer discussion.\\nUnfortunately, that behavior is unpredictable\\nand you might get some kind of strange behavior\\nif you're not managing the closing of these files yourself.\\nIt's best practice to close them when you're done with them.\\n\\nAnd the most common way to do that\\nis with the with statement.\\nSo let's say with, open, we're going to open this\\nin append mode as f, f.write,\\nsome stuff, f.write, some other stuff.\\nOkay, and as soon as we outdent and leave this code block,\\nthis file gets closed.\\nNotice that we still have access to this variable f, though.\\n\\nSo if I run this, it will write that and f still exists.\\nSo it's not like the if statements\\nor functions where you only have access\\nto if inside of that block.\\nHowever, if I tried to do something\\nlike this, f.write, PS, I forgot some stuff,\\nwe get an I/O error or an input/output error\\nbecause this file is already closed for writing.\\nSo file this away in your brain\\nbecause we're going to be reading and writing,\\nalthough no arithmetic, throughout the rest of this chapter.\\n\\nUgh, more of these.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4402005\",\"duration\":362,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"CSV\",\"fileName\":\"4314028_en_US_10_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video goes over how to use the CSV module to read and write CSV files.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5457872,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Lecturer] It's time to look at the CSV module and Python.\\nNo need to install anything.\\nIt comes with Python.\\nJust import CSV at the top.\\nAnd there you go.\\nI have included a CSV file\\nthat we're going to be working with\\nand this is 10_02_us.csv.\\nAnd this is derived from a dataset from geonames.org\\nwhich provides millions of place names\\nin geographical data sets spanning the globe.\\nAnd this particular data set contains every zip code\\nin the US along with information\\nabout the city or town that it represents\\nand then the latitude and longitude of its location.\\n\\nWe're going to open this file\\nfor reading with open 10_02_us.csv.\\nOpen it in read mode, obviously.\\nAnd then we're going to take that file object\\nand pass it to a new csv.reader.\\nAll right, now, this reader object isn't a list.\\nIf you look at the type, it's actually a CSV reader class\\nbut we can use it\\nas like you would use a list\\nand it's an iterable.\\n\\nSo we can do for row in reader print row,\\nand there you go.\\nYou get all the rows printed out.\\nNow notice something funny about this,\\ndidn't quite parse this correctly, and that's\\nbecause this is not the traditional comma delimited,\\ncomma separated value that you're used to seeing.\\nThe CSV file actually contains tab separated values.\\nSo all of these are tabs.\\nSo we can fix this output\\nby taking the spac slash T and passing it\\nin as a delimiter argument, backslash T right there.\\n\\nAnd then you see that all those values get split up, and\\nby default this will parse comma separated values correctly.\\nBut if you have something other than a comma,\\nyou need to put in that delimiter specifically.\\nYou can also see that the first row that gets printed\\nout here is the header.\\nAnd if you want to skip the header, the CSV reader also\\nhas a neat function you can use called next.\\nSo all we have to do is call next reader,\\nand then that header gets skipped over.\\nSo our reader actually has sort of an internal bookmark\\nthat keeps track of where you are.\\n\\nSo you can call next multiple times and it'll skip\\nover that row for you.\\nOf course, you can also just convert this to a list.\\nSo if we say list CSV reader, we don't have to call next,\\nwe can just use the list slicing syntax like that\\nand that will also skip over the header.\\nThe CSV module definitely has a concept of headers though,\\nso if you want to use that header data\\nyou might consider the dict reader.\\n\\nSo csv.DictReader, we're going to keep that same delimiter.\\nAll right, so notice\\nthat this header doesn't get printed out as a row of data,\\nbut it's actually used\\nas the keys in each dictionary in this list.\\nAnd this list of dictionaries\\ncan be a really handy data format to work with in Python.\\nSo let's convert this from a reader object to a list object.\\n\\nLet's just call it data.\\nOkay, so now we have some data that we can work with.\\nNow I'm in the market for some prime real estate.\\nAnd so I'm really interested\\nin finding postal codes that are only divisible\\nby one in themselves.\\nYou know, prime.\\nSo I borrowed some code that we wrote previously\\nand what this does is it just gets all the prime numbers\\nbetween 2 and 99,999.\\nRemember, postal codes can start with 0.\\n\\nSo if a postal code is say 02155,\\nmy hometown of Medford, Massachusetts,\\nthat would be equivalent to 2,155\\nwhich is divisible by five and therefore not prime.\\nSo let's filter these to only the prime locations.\\nSo data equals row for row in data\\nif int data postal code in primes.\\n\\nI also don't want to buy anything out of state\\nso I'm going to limit my search\\nto Massachusetts and row state code equals MA.\\nAnd let's print out the length of data.\\nWhoops, row, there we go.\\n91, so it looks like we found 91 prime postal codes\\nin Massachusetts and I want to write this all back\\nto CSV file to send to my real estate agent.\\n\\nYou know, real estate agents love CSV files.\\nSo with open 10_02, let's call it ma_prime.csv\\nwe're going to open this for writing, this F.\\nOkay.\\nAnd then we're going to create a new CSV writer,\\nCSV dot writer, and then pass this file name\\nin for row in data.\\nSo our data from up here, writer.writerow.\\n\\nNow we have to pass in the row as a list,\\nso we get to decide which values we want here.\\nWhat does my real estate agent need?\\nMaybe a place name and a county.\\nSo we could make the delimiter tabs again by passing\\nin a delimiter keyword argument to the writer here.\\nBut by default, a comma will be used,\\nwhich is what I'd prefer anyway.\\nSo let's just use that.\\nOkay, now let's go over here and see what we've got.\\n\\nHmm, there you go.\\nLook at all of this prime real estate.\\nBarnstable.\\nHow many agricultural buildings can you fit into town name?\\n\"},{\"urn\":\"urn:li:learningContentVideo:4404005\",\"duration\":349,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"JSON\",\"fileName\":\"4314028_en_US_10_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explains how to load and parse JSON from files, as well as write it back to the file.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5265528,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Previously, we've been focusing a lot\\non reading and writing files to and from the disk.\\nJSON files with the .json extension are common, of course,\\nand you might regularly be working with them.\\nBut for now, we'll mostly be focusing with JSON strings.\\nI'm going to assume by this point that you're pretty good\\nat reading files from the disk.\\nYou can load their contents into a string\\nand now you find yourself with a JSON string.\\nSo what do you do?\\nWell, let's make a JSON string,\\na is apple,\\nb is bear,\\nc is cat.\\n\\nOkay.\\nSomething to keep in mind, JSON is not Python.\\nThis JSON formatted string\\nlooks a lot like a Python dictionary, but it's not.\\nIt's a string.\\nI've seen a lot of even very experienced programmers\\nget confused about this\\nand lose track of what they're working with.\\nThis is a string that just happens to be in the JSON format.\\nAnd in order to turn it into a dictionary,\\nwe need to import the JSON module\\nat the top of our notebook, import json,\\nand then we're going to use a method called json.loads\\nand pass in the string, jsonString.\\n\\nNotice that this is called loads plural\\nand not load singular.\\nAnother common mistake.\\nSo now we have a Python dictionary.\\nI can copy this Python dictionary\\nand add a trailing comma, and that's just fine.\\nBut if I add a trailing comma to this JSON string,\\nwe get a JSON decode error.\\nSo it's very common if you're working with JSON\\nfrom a potentially untrustworthy source\\nto surround this json.loads with a try except\\nJSONDecodeError:print Could not parse JSON.\\n\\nAnd because this JSONDecodeError\\ncomes from the JSON module,\\nwe need to specifically import it as well.\\nSo from json import JSONDecodeError.\\nSo that's reading JSON,\\nbut what about going in the opposite direction,\\ndumping a Python dictionary into a JSON string?\\nFor this, use the json.dumps method.\\nSo here's my pythonDict,\\nI'm going to use json.dumps pythonDict.\\n\\nAnd again, notice that this is dumps plural.\\nYou usually wouldn't add any exception handling in this case\\nbecause if you have a valid Python dictionary,\\nthere's not a lot that could go wrong\\nwhen you're formatting it as a JSON string.\\nHowever, there is one exception to this rule\\nwhere an exception could be thrown.\\nAnd to demonstrate that,\\nlet's create an animal class real quick,\\nclass Animal\\ninit\\nself, name,\\nself.name equals name,\\nand let's modify our dictionary to use this Animal class.\\n\\nObviously an apple isn't an animal,\\nso I'm going to replace this with aardvark\\nand just put that in there.\\nAnimal\\nbear\\nand Animal\\ncat.\\nOkay, now let's dump this dictionary.\\nWhoops.\\n\\nAnimal. There we go.\\nOkay, so you see that we get a TypeError,\\nObject of type Animal is not JSON serializable.\\nThe JSON module has no idea how to handle this Animal class.\\nIt doesn't know what the JSON equivalent should be.\\nWhat we do here is override the default JSON encoder\\nthat it's using with a JSON encoder of our own.\\nSo first, we're going to import the JSONEncoder.\\n\\nAll right, and now we can make one.\\nSo we're going to extend the JSONEncoder class\\nto create a new AnimalEncoder class JSONEncoder.\\nAll right, and the only thing we need to override here\\nis the default method,\\nso def default self and o.\\nO is the object that's being passed in here\\nthat needs to be decoded into JSON.\\n\\nSo if type o is equal to Animal,\\nif we're dealing with an Animal object,\\nreturn o.name.\\nElse, return super default o.\\nSo if it's not an animal,\\nwe pass it off to the parent version of the encoder\\nby using super, which is the parent JSONEncoder class\\nand then calling that default method.\\nAnd then we need to let JSON dumps know\\nthat it needs to use this encoder\\nand we can do that by passing the cls keyword argument,\\nAnimalEncoder,\\nand there you go.\\n\\nAgain, generally, you don't need to surround json.dumps\\nin a try except statement\\nbecause you're usually creating the dictionaries\\nthat you pass into json.dumps in your own code,\\nand you should appropriately handle any data types\\nthat you're passing in there.\\nBut if you get any crazy JSON formatted files\\nfrom unknown sources, it's best to beware.\\nStay safe out there.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:6614224634508ad786781aab\",\"duration\":1800,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Compressing ASCII art\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:962257\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4221227\",\"duration\":224,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Compressing ASCII art\",\"fileName\":\"4314028_en_US_10_04_FY24Q4_C_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"UPDATED\",\"editingNotes\":\"RE-RECORD\\nReplaces 4314028_en_US_10_05_XR30\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":274,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8096449,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] This is the final challenge of the course\\nand not coincidentally,\\nit's also the challenge that has the greatest number\\nof possible solutions.\\nYou could do just about anything you wanted to do here\\nand it would probably work.\\nSo let's go over three basic types\\nof data compression you might have done here\\nand if you didn't do any of these\\nor a variation on them, awesome.\\nThe great thing about data compression\\nis that as long as the data shrinks\\nand then expands back to more or less the original,\\nno one really cares how you got there, but I care.\\n\\nSo if you do find something cool, let me know.\\nSo the first thing I did\\nwas take that JSON blob from encode string\\nand then just write it to a file.\\nAnd then with decode file, we can open that file name again,\\nread the JSON blob, and then run it through decode string.\\nSo if I run this,\\nso the file compression is not the greatest here,\\nwent down to 2,441 bytes,\\nbut technically we did reduce the file size.\\nSo hooray, file compression.\\n\\nThe thing you might've noticed is that this JSON blob,\\nand I have an example of it here,\\nit has a lot of characters in it.\\nSo if you look at this closed parenthesis comma space\\nopen parenthesis quote, that's five characters\\nfor what's essentially just a delimiter\\nbetween a number and the next character.\\nSo what if we use delimiters like this,\\nlike a pipe or a tilda to sort of shrink up this JSON blob\\nand make it a little bit smaller?\\nSo let me get rid of this solution\\nand then I have an example of that right here.\\n\\nSo here's something else you might have done,\\nand if we test this,\\nit shrinks it quite a bit to 1007 bytes.\\nSo this is pretty good, but can we go even smaller?\\nSo let me just get rid of this.\\nAnd then we have a new solution down here,\\nand that is the byte solution.\\nSo earlier in this course we discussed working with bytes.\\nSo you can store any integer up to 255\\nin a single byte of data.\\n\\nSo rather than storing the number 255 as a string\\nwith three characters, which takes up three bites,\\nyou can use one single byte.\\nYou store it as an integer rather than a string.\\nAnd each of these characters in the ASCI art\\nare also one byte or one character or one byte.\\nSo if we make sure that we write our file precisely,\\none character, one number, one character, one number,\\none character, one number,\\nand then we read it in precisely,\\nthe first byte's, the character,\\nthe next byte's, the number, et cetera,\\nwe can encode and decode this image extremely efficiently.\\n\\nThere are no delimiters,\\nwe're just depending on the pattern being exactly correct\\nevery single time, which hey,\\nthat's what computers are really good at.\\nSo in this version of the solution here,\\nI've used a few language features\\nthat I didn't cover in the course,\\nbut if you are interested in writing byte files,\\nfile creation, and data compression,\\nI recommend that you play around\\nwith these solutions and use them\\nas starting points for future learning.\\nAnd if you're not excited about the code, that's fine.\\n\\nCheck out these results.\\nIt gets the file down to 466 bytes.\\nSo that's nearly a sixfold reduction in size\\nover the original 2749.\\nSometimes these concepts of memory and bytes\\nand encodings can seem really, I don't know,\\nuseless and academic,\\nbut I want to stress that they do have very real\\nand important impacts day-to-day as a programmer,\\na reduction in file size like this can be\\nreal money if you have enough files.\\n\"}],\"name\":\"10. Working with Files\",\"size\":24932567,\"urn\":\"urn:li:learningContentChapter:4401011\"},{\"duration\":839,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4403006\",\"duration\":340,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Command-line arguments\",\"fileName\":\"4314028_en_US_11_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explains how to pass command-line arguments to your Python script using argparse to add flags and include help text.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5123326,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] When we run a Python program\\nfrom the terminal, we type python and then the name\\nof the file we want to run, for example, example.py.\\nBut you can also pass in a number\\nof what's called command-line arguments after that.\\nAnd these command-line arguments can be of two types.\\nA single character proceeded\\nby a dash, for instance, -h, which might stand for help.\\nAnd if you run it, it usually prints out some documentation\\nabout the program along with available commands.\\nOr you can do a longer word proceeded\\nby two dashes, like --help\\nwhich might do the same thing as -h.\\n\\nAnd these command-line arguments can also take values.\\nFor instance, -i might stand for an input.\\nAnd then you could have some string\\nof text or let's say a file name\\nlike somefile.txt that the program reads in.\\nThere are a number\\nand use these command-line arguments and values.\\nBut my favorite is argparse.\\nHere, I'm going to be writing all\\nof the code inside 11_1_writefile.py,\\nwhich is obviously not a Jupyter Notebook\\nbut a Python script that will be run from the command line.\\n\\nSo argparse provides an ArgumentParser class.\\nLet's import that, from argparse, import ArgumentParser.\\nAnd the ArgumentParser class allows you\\nto create an object that keeps track\\nof all of the arguments your program accepts.\\nSo let's make a new ArgumentParser instance\\ncalled parser, ArgumentParser.\\nAnd let's create a new command-line argument\\ncalled output, parser.add_argument --output.\\n\\nAnd because this argument is a full word,\\nI have two dashes in front of it as is convention.\\nSo let's say we want to provide a file name\\nfrom the command line like this,\\nPython 11_1 --output, that's our new command-line argument,\\nsomefile.txt.\\nSo how do we get this value somefile.txt?\\nLet's use the parse_args method\\non our parser instance.\\n\\nParser.parse_args\\nand let's make a variable called args,\\nset that equal to the output.\\nSo this return value args is an object that has all\\nof our arguments as attributes on it.\\nSo we can access the file name like this.\\nPrint args.output\\nwhere output is the name of our command-line argument.\\nSo now when we run this,\\nwe'll see somefile.txt printed out.\\nWe can make this argument output required using\\na keyword argument required equals True.\\n\\nAnd there's another keyword argument\\nthat's helpful here, help.\\nWe can provide some help text to the user\\nthat lets them know what this command is for.\\nSo this might be the destination file\\nfor the output of this program.\\nSo now, when we run this,\\nand we use the command-line argument h,\\nwe see this help text printed out.\\nAnd you see there's the string that we passed\\nin to that method.\\n\\nAnd also notice that if we run this without using output,\\nwe get an error.\\nThe following arguments are required, output.\\nBy convention, we want to give the user options\\nfor these arguments.\\nSo allowing them to either type output or simply -o.\\nSo all of the different arguments we want to allow,\\nwe can put them in here.\\nAnd while we're at it,\\nlet's create another argument called text, text or -t.\\n\\nIt's also required, and let's change the help text,\\nthe text to write to the file.\\nAnd you can probably see where we're going with this.\\nLet's write a couple lines to write this text to a new file.\\nSo with open args.output, open it\\nin write mode as f.\\nF.write, args.text,\\nplus, let's add a new line character\\nto the end of this text, just to keep our files clean.\\n\\nAnd then let's add a print statement at the end,\\nso that the user knows that our program\\nhas run successfully.\\nPrint, wrote arg.text to file args.output\\nand let's put some double quotes\\naround this to keep this output message nice.\\nAll right, and now we can run this program\\nwith something like this, -o somefile.txt.\\nAnd the text is some text to write to the file.\\n\\nSo note that I have these quotes around this string\\nand these quotes aren't actually part of the string\\nbut any time you have a value with spaces in it,\\nyou need to put quotes around the string,\\nso that the terminal doesn't get confused\\nabout what's a single value\\nand what's potentially multiple values.\\nSo it looks like it ran successfully.\\nLet's go back to our files and see if we can see anything.\\nAll right, and a file just popped up,\\nsomefile.txt and it looks like we have some text in it.\\n\\nAs you can see, we've made some very powerful arguments.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400011\",\"duration\":499,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating modules and packages\",\"fileName\":\"4314028_en_US_11_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video covers how to package a simple Python module, use __init__.py for organization, create a setup.py file, and install a package.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7496658,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Modules, packages, libraries, oh my.\\nWe've been using them throughout the course\\nwith the import statement.\\nBut what are these things actually?\\nAnd what's going on under the hood?\\nOkay, let's get this out of the way right up front.\\nThere's no real formal definition of a library in python.\\nIt's more of a general computer science word.\\nIt just means imported files.\\nCode that you're referencing that lives somewhere else.\\nWhen people say Python libraries,\\nthey could either be talking about a module or a package,\\nbut usually they're talking about a package.\\n\\nSo with that in mind,\\nwe're going to focus on modules and packages.\\nLet's go to the code.\\nA module is literally just a Python file.\\nAnd here I've created a file or a module called primes.py\\nand it has two functions in it.\\nIsPrime, which takes in a number\\nand returns whether or not that number is prime.\\nAnd listPrimes, which returns a list of primes\\nup to that number.\\nI made a new Python file called use module,\\nand it's currently blank.\\n\\nAnd I'm going to import primes.\\nThen I'm going to print primes.isPrime.\\nSo here we're importing our primes module\\nand using the isPrime function\\nto decide whether or not five is prime.\\nPython use module,\\nand it looks like five is prime.\\nI can also rewrite my import statement\\nto import an individual function\\ninstead of the whole primes module.\\n\\nSo from primes,\\nimport listPrimes.\\nWe're going to print listPrimes 100.\\nAnd now I can call that function directly\\nother than saying primes.listPrimes.\\nSo that lists all the prime numbers up to 100.\\nSo primes is a module.\\nThen what's a package?\\nWell, a package is simply a collection of modules.\\nIt's a collection of related Python files\\nall bundled up into a single package.\\n\\nAnd here I've created a simple package called numbers.\\nAnd this contains two modules.\\nFactors, which contains a single function called getFactors.\\nJust returns a list of all the factors\\nof the number you pass in.\\nAnd then primes, which is the same\\nmodule that we used before,\\nbut inside this numbers package.\\nThere's also a very important file called init.py.\\nIf you look at it, it's completely blank.\\nBut it's required to tell Python,\\n\\\"Hey, this is a package,\\n\\\"not just a random collection of Python files in a folder.\\\"\\nNote the init.py like the constructor\\nor the initialization function of class\\nhas two dashes before and after the init.\\n\\nSo when this init.py file is in this directory,\\nit allows us to do imports like this.\\nAnd I'm going to go to usepackage.py\\nand do from numbers.factors import getFactors.\\nAnd then I can print getFactors of 100.\\nSo numbers is the package,\\nfactors is the module,\\nand I'm importing the function getFactors.\\nPython usePackage.py, there you go.\\n\\nAll the factors of 100.\\nNow watch what happens when I delete the init.py file.\\nGet out of there. Okay.\\nLet's run this again.\\nUh-oh, module not found error.\\nAnd it literally says numbers is not a package.\\nSo now it's just some random directory.\\nSo it's very important to have that init.py file there.\\nSo I'm going to add that init.py file back.\\n\\nUnderscore underscore init underscore underscore dot py.\\nJust add that back before I forget.\\nSo like I said before,\\nthe modules in these packages are generally\\nclosely related in functionality,\\nso it can be useful to let them reference each other.\\nLet's take this primes module here,\\nand I can rewrite this isPrime function\\nto use the getFactors function\\nby importing the factors module\\nfrom numbers.factors import getFactors.\\n\\nSo I'm just going to return the length of getFactors\\nof that number equals two.\\nSo we can take advantage of the fact\\nthat prime numbers have exactly two factors.\\nAnd one last thing I want to show you\\nis a built-in Python variable called name.\\nNow, I'm going to go to the module primes.py.\\nSo this isn't in the package but the module.\\nAnd I'm going to add this line.\\nPrint F primes.py module name is\\nunderscore underscore name underscore underscore.\\n\\nAnd now if I run primes.py directly from the command line,\\nsee what happens.\\nPython, let me clear this.\\nPrimes.py.\\nSo I'm not running useModule,\\nI'm running primes.py directly.\\nAnd you see primes.py module name is\\nunderscore underscore main.\\nMain is the default module name\\nfor the sort of main piece of code\\nthat you're running directly.\\nNow let's go to use module.py,\\nand you can see that it imports\\nthe primes module at the top.\\n\\nAnd when that module gets imported,\\nin this import primes line,\\nPython will actually run through and execute\\nall of the code in this module.\\nSo when we run useModule.py,\\nthe name of that module will print out.\\nPython useModule.py.\\nAnd you can see that the module name is now primes.\\nIt's not main, it's primes.\\nSo this is the module name,\\nand if I run it directly it's main.\\nAnd we can see this at work in packages too.\\n\\nSo if I go to my numbers package.\\nAnd let's go to the init.py file.\\nSo often this file is blank,\\nbut we can still add code to it.\\nFor instance,\\nname in init.py is\\nunderscore underscore name.\\nThere we go.\\nAnd in factors.py I'm going to add this.\\nPrint name in factors.py is name.\\n\\nNow let's run usePackage.py.\\nPython usePackage.py.\\nSo you can see that in init.py we get the package name.\\nSo this is the package file.\\nAnd in factors.py we get numbers.factors.\\nThat's the module within the package.\\nOne common pattern in Python\\nwhen writing modules and packages\\nis to take advantage of this\\nunderscore underscore name variable\\nby creating code that will only be run\\nif your module is called directly,\\nversus being imported.\\n\\nSo, for instance,\\nlet's go back to the primes module.\\nAnd note that this is the module, not the package.\\nWe can add some helper text\\nif our users get confused by doing this.\\nIf name\\nis equal to the string main,\\nwith two underscores,\\nprint this is a module,\\nplease import using new line import primes.\\n\\nNow you can see, if I run primes.py directly,\\nwe get some nice helper texts there.\\nHowever, if I run useModule.py,\\nthat doesn't print out.\\nBy using what you've learned in this chapter,\\ncommand line arguments, documentation, help text,\\nmodules and package organization,\\nyou can create code that's not usable just by you,\\nbut accessible to others.\\nWhether those people are in your organization\\nor across the globe.\\n\\nThey can import it, use it, modify it, share it.\\nAnd who knows, I might use one of your packages someday.\\n\"}],\"name\":\"11. Packaging Python\",\"size\":12619984,\"urn\":\"urn:li:learningContentChapter:4406010\"},{\"duration\":159,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4402006\",\"duration\":112,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Wrap up\",\"fileName\":\"4314028_en_US_12_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1720512,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- So long, Farewell, auf wiedersehen, adieu.\\nIf you enjoyed this course, please leave a review,\\nand if you didn't enjoy the course,\\nwell, hey, at least you know Python now, right?\\nFrom here, your journey depends\\non what skills you're trying to acquire.\\nIf you're looking to enhance\\nyour foundational Python skills,\\nI recommend picking a project you're interested in\\nand just trying to build it.\\nSee what you get.\\nTo show off and track your changes, host it on GitHub.\\nIf you're pretty comfortable with what you've learned here,\\nwhat do you need?\\nData science, web apps, automation?\\nPython has you covered.\\n\\nThere's no better data science library than scikit=learn.\\nCombine it with data structures from Pandas\\nor the Python Data Analysis Library,\\nand you'll be a professional data wizard \\\\in no time.\\nIf you want to build the next big app,\\nFlask makes it fast and easy to build scalable rest APIs.\\nThe project is very intuitive and well-documented\\nand they make it really easy to plug in\\nwith other libraries to build enterprise code.\\nAnd a subject near and dear to my heart, web scraping.\\nPython is, in my opinion, the best language\\nfor building powerful scrapers and bots\\nto trawl the internet.\\n\\nThe Python request Library's one of the best,\\neasiest HTTP request libraries I've found,\\nand Python's ability to integrate with web browser drivers\\nlike Selenium is unparalleled.\\nFor information on LinkedIn courses\\nthat cover these libraries,\\nsee my course recommendations guide in the exercise files.\\nAll of these libraries and projects I've mentioned\\nare ones I've used and continue to use,\\nsometimes on a daily basis myself.\\nFor almost every application of technology\\nand computer science, there's a Python project\\ndedicated to that field just waiting for you to install it.\\n\\nI really hope we meet again, it truly has been a blast.\\nThank you so much for watching this course\\nand I hope you enjoyed it as much as I did.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4401010\",\"duration\":47,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Python challenge project\",\"fileName\":\"4314028_en_US_12_02_XR30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video presents a Python challenge project course that you can take that utilizes the concepts taught in this course to expand and practice your new skills.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1644523,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Hi, you're still here?\\nI told you, the course is over.\\nThere's no more.\\nIt's done.\\nYou did it, congratulations.\\n(audience cheers)\\nYou want more essential training\\nin the Python programming language?\\nWell, okay, fine.\\nLet's do it.\\nSo here's a course you might enjoy:\\nPython Challenge Project.\\nIt follows chapter by chapter with Python Essential Training\\nto reinforce learning\\nand get you working with a large, more complex project\\nthat you can write in an IDE and run from the command line.\\n\\nIf you want to get a feel\\nfor what it's really like being a Python developer,\\nthis is a great place to start.\\nAll right, well, it has been a blast, but I do have to go.\\nI mean, you can stay here if you want\\nbut I'm going to head on over to the next course.\\nHope to see you there.\\n\"}],\"name\":\"Conclusion\",\"size\":3365035,\"urn\":\"urn:li:learningContentChapter:4404008\"}],\"size\":301667078,\"duration\":15773,\"zeroBased\":false}]}"